<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Learning statistics with R: A tutorial for psychology students and other beginners. (Version 0.6.1)</title>
  <meta name="description" content="<em>Learning Statistics with R</em> covers the contents of an introductory statistics class, as typically taught to undergraduate psychology students, focusing on the use of the R statistical software." />
  <meta name="generator" content="bookdown #bookdown:version# and GitBook 2.6.7" />

  <meta property="og:title" content="Learning statistics with R: A tutorial for psychology students and other beginners. (Version 0.6.1)" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="<em>Learning Statistics with R</em> covers the contents of an introductory statistics class, as typically taught to undergraduate psychology students, focusing on the use of the R statistical software." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Learning statistics with R: A tutorial for psychology students and other beginners. (Version 0.6.1)" />
  
  <meta name="twitter:description" content="<em>Learning Statistics with R</em> covers the contents of an introductory statistics class, as typically taught to undergraduate psychology students, focusing on the use of the R statistical software." />
  

<meta name="author" content="Danielle Navarro (bookdown translation: Emily Kothe)" />


<meta name="date" content="2020-07-30" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<!--bookdown:link_prev-->
<!--bookdown:link_next-->
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



<!--bookdown:title:start-->
<div id="header">
<h1 class="title">Learning statistics with R: A tutorial for psychology students and other beginners. (Version 0.6.1)</h1>
<p class="author"><em>Danielle Navarro (bookdown translation: Emily Kothe)</em></p>
<p class="date"><em>2020-07-30</em></p>
</div>
<!--bookdown:title:end-->

<!--bookdown:toc:start-->
  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">
<!--bookdown:toc2:start-->
<ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#licensing">Licensing</a></li>
<li><a href="#dedication">Dedication</a></li>
<li><a href="#preface">Preface</a><ul>
<li><a href="#preface-to-version-0.6.1"><span class="toc-section-number">0.1</span> Preface to Version 0.6.1</a></li>
<li><a href="#preface-to-version-0.6"><span class="toc-section-number">0.2</span> Preface to Version 0.6</a></li>
<li><a href="#preface-to-version-0.5"><span class="toc-section-number">0.3</span> Preface to Version 0.5</a></li>
<li><a href="#preface-to-version-0.4"><span class="toc-section-number">0.4</span> Preface to Version 0.4</a></li>
<li><a href="#preface-to-version-0.3"><span class="toc-section-number">0.5</span> Preface to Version 0.3</a></li>
</ul></li>
<li><a href="#part-i.-background">Part I. Background</a></li>
<li><a href="#why-do-we-learn-statistics"><span class="toc-section-number">1</span> Why do we learn statistics?</a><ul>
<li><a href="#whywhywhy"><span class="toc-section-number">1.1</span> On the psychology of statistics</a><ul>
<li><a href="#the-curse-of-belief-bias"><span class="toc-section-number">1.1.1</span> The curse of belief bias</a></li>
</ul></li>
<li><a href="#the-cautionary-tale-of-simpsons-paradox"><span class="toc-section-number">1.2</span> The cautionary tale of Simpson’s paradox</a></li>
<li><a href="#statistics-in-psychology"><span class="toc-section-number">1.3</span> Statistics in psychology</a></li>
<li><a href="#statistics-in-everyday-life"><span class="toc-section-number">1.4</span> Statistics in everyday life</a></li>
<li><a href="#theres-more-to-research-methods-than-statistics"><span class="toc-section-number">1.5</span> There’s more to research methods than statistics</a></li>
</ul></li>
<li><a href="#studydesign"><span class="toc-section-number">2</span> A brief introduction to research design</a><ul>
<li><a href="#continuousdiscrete"><span class="toc-section-number">2.0.1</span> Continuous versus discrete variables</a></li>
</ul></li>
<li><a href="#part-ii.-an-introduction-to-r">Part II. An introduction to R</a></li>
<li><a href="#introR"><span class="toc-section-number">3</span> Getting started with R</a><ul>
<li><a href="#gettingR"><span class="toc-section-number">3.1</span> Installing R</a><ul>
<li><a href="#installing-r-on-a-windows-computer"><span class="toc-section-number">3.1.1</span> Installing R on a Windows computer</a></li>
<li><a href="#installing-r-on-a-mac"><span class="toc-section-number">3.1.2</span> Installing R on a Mac</a></li>
<li><a href="#installing-r-on-a-linux-computer"><span class="toc-section-number">3.1.3</span> Installing R on a Linux computer</a></li>
<li><a href="#installingrstudio"><span class="toc-section-number">3.1.4</span> Downloading and installing RStudio</a></li>
<li><a href="#startingR"><span class="toc-section-number">3.1.5</span> Starting up R</a></li>
</ul></li>
<li><a href="#firstcommand"><span class="toc-section-number">3.2</span> Typing commands at the R console</a><ul>
<li><a href="#an-important-digression-about-formatting"><span class="toc-section-number">3.2.1</span> An important digression about formatting</a></li>
<li><a href="#be-very-careful-to-avoid-typos"><span class="toc-section-number">3.2.2</span> Be very careful to avoid typos</a></li>
<li><a href="#r-is-a-bit-flexible-with-spacing"><span class="toc-section-number">3.2.3</span> R is (a bit) flexible with spacing</a></li>
<li><a href="#r-can-sometimes-tell-that-youre-not-finished-yet-but-not-often"><span class="toc-section-number">3.2.4</span> R can sometimes tell that you’re not finished yet (but not often)</a></li>
</ul></li>
<li><a href="#arithmetic"><span class="toc-section-number">3.3</span> Doing simple calculations with R</a><ul>
<li><a href="#adding-subtracting-multiplying-and-dividing"><span class="toc-section-number">3.3.1</span> Adding, subtracting, multiplying and dividing</a></li>
<li><a href="#taking-powers"><span class="toc-section-number">3.3.2</span> Taking powers</a></li>
<li><a href="#bedmas"><span class="toc-section-number">3.3.3</span> Doing calculations in the right order</a></li>
</ul></li>
<li><a href="#assign"><span class="toc-section-number">3.4</span> Storing a number as a variable</a><ul>
<li><a href="#variable-assignment-using---and--"><span class="toc-section-number">3.4.1</span> Variable assignment using <code>&lt;-</code> and <code>-&gt;</code></a></li>
<li><a href="#doing-calculations-using-variables"><span class="toc-section-number">3.4.2</span> Doing calculations using variables</a></li>
<li><a href="#rules-and-conventions-for-naming-variables"><span class="toc-section-number">3.4.3</span> Rules and conventions for naming variables</a></li>
</ul></li>
<li><a href="#usingfunctions"><span class="toc-section-number">3.5</span> Using functions to do calculations</a><ul>
<li><a href="#functionarguments"><span class="toc-section-number">3.5.1</span> Function arguments, their names and their defaults</a></li>
</ul></li>
<li><a href="#RStudio1"><span class="toc-section-number">3.6</span> Letting RStudio help you with your commands</a><ul>
<li><a href="#autocomplete-using-tab"><span class="toc-section-number">3.6.1</span> Autocomplete using “tab”</a></li>
<li><a href="#browsing-your-command-history"><span class="toc-section-number">3.6.2</span> Browsing your command history</a></li>
</ul></li>
<li><a href="#vectors"><span class="toc-section-number">3.7</span> Storing many numbers as a vector</a><ul>
<li><a href="#creating-a-vector"><span class="toc-section-number">3.7.1</span> Creating a vector</a></li>
<li><a href="#a-handy-digression"><span class="toc-section-number">3.7.2</span> A handy digression</a></li>
<li><a href="#vectorsubset"><span class="toc-section-number">3.7.3</span> Getting information out of vectors</a></li>
<li><a href="#altering-the-elements-of-a-vector"><span class="toc-section-number">3.7.4</span> Altering the elements of a vector</a></li>
<li><a href="#veclength"><span class="toc-section-number">3.7.5</span> Useful things to know about vectors</a></li>
</ul></li>
<li><a href="#text"><span class="toc-section-number">3.8</span> Storing text data</a><ul>
<li><a href="#simpletext"><span class="toc-section-number">3.8.1</span> Working with text</a></li>
</ul></li>
<li><a href="#logicals"><span class="toc-section-number">3.9</span> Storing “true or false” data</a><ul>
<li><a href="#assessing-mathematical-truths"><span class="toc-section-number">3.9.1</span> Assessing mathematical truths</a></li>
<li><a href="#logical-operations"><span class="toc-section-number">3.9.2</span> Logical operations</a></li>
<li><a href="#storing-and-using-logical-data"><span class="toc-section-number">3.9.3</span> Storing and using logical data</a></li>
<li><a href="#vectors-of-logicals"><span class="toc-section-number">3.9.4</span> Vectors of logicals</a></li>
<li><a href="#logictext"><span class="toc-section-number">3.9.5</span> Applying logical operation to text</a></li>
</ul></li>
<li><a href="#indexing"><span class="toc-section-number">3.10</span> Indexing vectors</a><ul>
<li><a href="#extracting-multiple-elements"><span class="toc-section-number">3.10.1</span> Extracting multiple elements</a></li>
<li><a href="#logical-indexing"><span class="toc-section-number">3.10.2</span> Logical indexing</a></li>
</ul></li>
<li><a href="#quitting-r"><span class="toc-section-number">3.11</span> Quitting R</a></li>
<li><a href="#summary"><span class="toc-section-number">3.12</span> Summary</a></li>
</ul></li>
<li><a href="#mechanics"><span class="toc-section-number">4</span> Additional R concepts</a><ul>
<li><a href="#comments"><span class="toc-section-number">4.1</span> Using comments</a></li>
<li><a href="#packageinstall"><span class="toc-section-number">4.2</span> Installing and loading packages</a><ul>
<li><a href="#the-package-panel-in-rstudio"><span class="toc-section-number">4.2.1</span> The package panel in RStudio</a></li>
<li><a href="#packageload"><span class="toc-section-number">4.2.2</span> Loading a package</a></li>
<li><a href="#packageunload"><span class="toc-section-number">4.2.3</span> Unloading a package</a></li>
<li><a href="#a-few-extra-comments"><span class="toc-section-number">4.2.4</span> A few extra comments</a></li>
<li><a href="#downloading-new-packages"><span class="toc-section-number">4.2.5</span> Downloading new packages</a></li>
<li><a href="#updating-r-and-r-packages"><span class="toc-section-number">4.2.6</span> Updating R and R packages</a></li>
<li><a href="#what-packages-does-this-book-use"><span class="toc-section-number">4.2.7</span> What packages does this book use?</a></li>
</ul></li>
<li><a href="#workspace"><span class="toc-section-number">4.3</span> Managing the workspace</a><ul>
<li><a href="#listing-the-contents-of-the-workspace"><span class="toc-section-number">4.3.1</span> Listing the contents of the workspace</a></li>
<li><a href="#removing-variables-from-the-workspace"><span class="toc-section-number">4.3.2</span> Removing variables from the workspace</a></li>
</ul></li>
<li><a href="#navigation"><span class="toc-section-number">4.4</span> Navigating the file system</a><ul>
<li><a href="#filesystem"><span class="toc-section-number">4.4.1</span> The file system itself</a></li>
<li><a href="#navigationR"><span class="toc-section-number">4.4.2</span> Navigating the file system using the R console</a></li>
<li><a href="#why-do-the-windows-paths-use-the-wrong-slash"><span class="toc-section-number">4.4.3</span> Why do the Windows paths use the wrong slash?</a></li>
<li><a href="#nav3"><span class="toc-section-number">4.4.4</span> Navigating the file system using the RStudio file panel</a></li>
</ul></li>
<li><a href="#load"><span class="toc-section-number">4.5</span> Loading and saving data</a><ul>
<li><a href="#loading-workspace-files-using-r"><span class="toc-section-number">4.5.1</span> Loading workspace files using R</a></li>
<li><a href="#loading-workspace-files-using-rstudio"><span class="toc-section-number">4.5.2</span> Loading workspace files using RStudio</a></li>
<li><a href="#importing-data-from-csv-files-using-loadingcsv"><span class="toc-section-number">4.5.3</span> Importing data from CSV files using <code id="loadingcsv">loadingcsv</code></a></li>
<li><a href="#importing-data-from-csv-files-using-rstudio"><span class="toc-section-number">4.5.4</span> Importing data from CSV files using RStudio</a></li>
<li><a href="#saving-a-workspace-file-using-save"><span class="toc-section-number">4.5.5</span> Saving a workspace file using <code>save</code></a></li>
<li><a href="#save1"><span class="toc-section-number">4.5.6</span> Saving a workspace file using RStudio</a></li>
<li><a href="#other-things-you-might-want-to-save"><span class="toc-section-number">4.5.7</span> Other things you might want to save</a></li>
</ul></li>
<li><a href="#useful"><span class="toc-section-number">4.6</span> Useful things to know about variables</a><ul>
<li><a href="#specials"><span class="toc-section-number">4.6.1</span> Special values</a></li>
<li><a href="#names"><span class="toc-section-number">4.6.2</span> Assigning names to vector elements</a></li>
<li><a href="#variable-classes"><span class="toc-section-number">4.6.3</span> Variable classes</a></li>
</ul></li>
<li><a href="#factors"><span class="toc-section-number">4.7</span> Factors</a><ul>
<li><a href="#introducing-factors"><span class="toc-section-number">4.7.1</span> Introducing factors</a></li>
<li><a href="#labelling-the-factor-levels"><span class="toc-section-number">4.7.2</span> Labelling the factor levels</a></li>
<li><a href="#moving-on"><span class="toc-section-number">4.7.3</span> Moving on…</a></li>
</ul></li>
<li><a href="#dataframes"><span class="toc-section-number">4.8</span> Data frames</a><ul>
<li><a href="#introducing-data-frames"><span class="toc-section-number">4.8.1</span> Introducing data frames</a></li>
<li><a href="#pulling-out-the-contents-of-the-data-frame-using"><span class="toc-section-number">4.8.2</span> Pulling out the contents of the data frame using <code>$</code></a></li>
<li><a href="#getting-information-about-a-data-frame"><span class="toc-section-number">4.8.3</span> Getting information about a data frame</a></li>
<li><a href="#looking-for-more-on-data-frames"><span class="toc-section-number">4.8.4</span> Looking for more on data frames?</a></li>
</ul></li>
<li><a href="#lists"><span class="toc-section-number">4.9</span> Lists</a></li>
<li><a href="#formulas"><span class="toc-section-number">4.10</span> Formulas</a></li>
<li><a href="#generics"><span class="toc-section-number">4.11</span> Generic functions</a></li>
<li><a href="#help"><span class="toc-section-number">4.12</span> Getting help</a><ul>
<li><a href="#how-to-read-the-help-documentation"><span class="toc-section-number">4.12.1</span> How to read the help documentation</a></li>
<li><a href="#other-resources"><span class="toc-section-number">4.12.2</span> Other resources</a></li>
</ul></li>
<li><a href="#summary-1"><span class="toc-section-number">4.13</span> Summary</a></li>
</ul></li>
<li><a href="#part-iii.-working-with-data">Part III. Working with data</a></li>
<li><a href="#descriptives"><span class="toc-section-number">5</span> Descriptive statistics</a><ul>
<li><a href="#centraltendency"><span class="toc-section-number">5.1</span> Measures of central tendency</a><ul>
<li><a href="#mean"><span class="toc-section-number">5.1.1</span> The mean</a></li>
<li><a href="#calculating-the-mean-in-r"><span class="toc-section-number">5.1.2</span> Calculating the mean in R</a></li>
<li><a href="#median"><span class="toc-section-number">5.1.3</span> The median</a></li>
<li><a href="#mean-or-median-whats-the-difference"><span class="toc-section-number">5.1.4</span> Mean or median? What’s the difference?</a></li>
<li><a href="#housingpriceexample"><span class="toc-section-number">5.1.5</span> A real life example</a></li>
<li><a href="#trimmedmean"><span class="toc-section-number">5.1.6</span> Trimmed mean</a></li>
<li><a href="#mode"><span class="toc-section-number">5.1.7</span> Mode</a></li>
</ul></li>
<li><a href="#var"><span class="toc-section-number">5.2</span> Measures of variability</a><ul>
<li><a href="#range"><span class="toc-section-number">5.2.1</span> Range</a></li>
<li><a href="#interquartile-range"><span class="toc-section-number">5.2.2</span> Interquartile range</a></li>
<li><a href="#aad"><span class="toc-section-number">5.2.3</span> Mean absolute deviation</a></li>
<li><a href="#variance"><span class="toc-section-number">5.2.4</span> Variance</a></li>
<li><a href="#sd"><span class="toc-section-number">5.2.5</span> Standard deviation</a></li>
<li><a href="#mad"><span class="toc-section-number">5.2.6</span> Median absolute deviation</a></li>
<li><a href="#which-measure-to-use"><span class="toc-section-number">5.2.7</span> Which measure to use?</a></li>
</ul></li>
<li><a href="#skewandkurtosis"><span class="toc-section-number">5.3</span> Skew and kurtosis</a></li>
<li><a href="#summary"><span class="toc-section-number">5.4</span> Getting an overall summary of a variable</a><ul>
<li><a href="#summarising-a-variable"><span class="toc-section-number">5.4.1</span> “Summarising” a variable</a></li>
<li><a href="#summarising-a-data-frame"><span class="toc-section-number">5.4.2</span> “Summarising” a data frame</a></li>
<li><a href="#describing-a-data-frame"><span class="toc-section-number">5.4.3</span> “Describing” a data frame</a></li>
</ul></li>
<li><a href="#groupdescriptives"><span class="toc-section-number">5.5</span> Descriptive statistics separately for each group</a></li>
<li><a href="#zscore"><span class="toc-section-number">5.6</span> Standard scores</a></li>
<li><a href="#correl"><span class="toc-section-number">5.7</span> Correlations</a><ul>
<li><a href="#the-data"><span class="toc-section-number">5.7.1</span> The data</a></li>
<li><a href="#the-strength-and-direction-of-a-relationship"><span class="toc-section-number">5.7.2</span> The strength and direction of a relationship</a></li>
<li><a href="#the-correlation-coefficient"><span class="toc-section-number">5.7.3</span> The correlation coefficient</a></li>
<li><a href="#calculating-correlations-in-r"><span class="toc-section-number">5.7.4</span> Calculating correlations in R</a></li>
<li><a href="#interpretingcorrelations"><span class="toc-section-number">5.7.5</span> Interpreting a correlation</a></li>
<li><a href="#spearmans-rank-correlations"><span class="toc-section-number">5.7.6</span> Spearman’s rank correlations</a></li>
<li><a href="#the-correlate-function"><span class="toc-section-number">5.7.7</span> The <code>correlate()</code> function</a></li>
</ul></li>
<li><a href="#missing"><span class="toc-section-number">5.8</span> Handling missing values</a><ul>
<li><a href="#the-single-variable-case"><span class="toc-section-number">5.8.1</span> The single variable case</a></li>
<li><a href="#missing-values-in-pairwise-calculations"><span class="toc-section-number">5.8.2</span> Missing values in pairwise calculations</a></li>
</ul></li>
<li><a href="#summary-2"><span class="toc-section-number">5.9</span> Summary</a></li>
<li><a href="#epilogue-good-descriptive-statistics-are-descriptive"><span class="toc-section-number">5.10</span> Epilogue: Good descriptive statistics are descriptive!</a></li>
</ul></li>
<li><a href="#graphics"><span class="toc-section-number">6</span> Drawing graphs</a><ul>
<li><a href="#rgraphics"><span class="toc-section-number">6.1</span> An overview of R graphics</a></li>
<li><a href="#introplotting"><span class="toc-section-number">6.2</span> An introduction to plotting</a><ul>
<li><a href="#a-tedious-digression"><span class="toc-section-number">6.2.1</span> A tedious digression</a></li>
<li><a href="#figtitles"><span class="toc-section-number">6.2.2</span> Customising the title and the axis labels</a></li>
<li><a href="#changing-the-plot-type"><span class="toc-section-number">6.2.3</span> Changing the plot type</a></li>
<li><a href="#changing-other-features-of-the-plot"><span class="toc-section-number">6.2.4</span> Changing other features of the plot</a></li>
<li><a href="#changing-the-appearance-of-the-axes"><span class="toc-section-number">6.2.5</span> Changing the appearance of the axes</a></li>
<li><a href="#dont-panic"><span class="toc-section-number">6.2.6</span> Don’t panic</a></li>
</ul></li>
<li><a href="#hist"><span class="toc-section-number">6.3</span> Histograms</a><ul>
<li><a href="#visual-style-of-your-histogram"><span class="toc-section-number">6.3.1</span> Visual style of your histogram</a></li>
</ul></li>
<li><a href="#stem"><span class="toc-section-number">6.4</span> Stem and leaf plots</a></li>
<li><a href="#boxplots"><span class="toc-section-number">6.5</span> Boxplots</a><ul>
<li><a href="#visual-style-of-your-boxplot"><span class="toc-section-number">6.5.1</span> Visual style of your boxplot</a></li>
<li><a href="#boxplotoutliers"><span class="toc-section-number">6.5.2</span> Using box plots to detect outliers</a></li>
<li><a href="#multipleboxplots"><span class="toc-section-number">6.5.3</span> Drawing multiple boxplots</a></li>
</ul></li>
<li><a href="#scatterplots"><span class="toc-section-number">6.6</span> Scatterplots</a><ul>
<li><a href="#more-elaborate-options"><span class="toc-section-number">6.6.1</span> More elaborate options</a></li>
</ul></li>
<li><a href="#bargraph"><span class="toc-section-number">6.7</span> Bar graphs</a><ul>
<li><a href="#par"><span class="toc-section-number">6.7.1</span> Changing global settings using par()</a></li>
</ul></li>
<li><a href="#saveimage"><span class="toc-section-number">6.8</span> Saving image files using R and Rstudio</a><ul>
<li><a href="#the-ugly-details-advanced"><span class="toc-section-number">6.8.1</span> The ugly details (advanced)</a></li>
</ul></li>
<li><a href="#summary-3"><span class="toc-section-number">6.9</span> Summary</a></li>
</ul></li>
<li><a href="#datahandling"><span class="toc-section-number">7</span> Pragmatic matters</a><ul>
<li><a href="#freqtables"><span class="toc-section-number">7.1</span> Tabulating and cross-tabulating data</a><ul>
<li><a href="#creating-tables-from-vectors"><span class="toc-section-number">7.1.1</span> Creating tables from vectors</a></li>
<li><a href="#creating-tables-from-data-frames"><span class="toc-section-number">7.1.2</span> Creating tables from data frames</a></li>
<li><a href="#converting-a-table-of-counts-to-a-table-of-proportions"><span class="toc-section-number">7.1.3</span> Converting a table of counts to a table of proportions</a></li>
<li><a href="#low-level-tabulation"><span class="toc-section-number">7.1.4</span> Low level tabulation</a></li>
</ul></li>
<li><a href="#transform"><span class="toc-section-number">7.2</span> Transforming and recoding a variable</a><ul>
<li><a href="#creating-a-transformed-variable"><span class="toc-section-number">7.2.1</span> Creating a transformed variable</a></li>
<li><a href="#cutting-a-numeric-variable-into-categories"><span class="toc-section-number">7.2.2</span> Cutting a numeric variable into categories</a></li>
</ul></li>
<li><a href="#mathfunc"><span class="toc-section-number">7.3</span> A few more mathematical functions and operations</a><ul>
<li><a href="#rounding-a-number"><span class="toc-section-number">7.3.1</span> Rounding a number</a></li>
<li><a href="#modulus-and-integer-division"><span class="toc-section-number">7.3.2</span> Modulus and integer division</a></li>
<li><a href="#logarithms-and-exponentials"><span class="toc-section-number">7.3.3</span> Logarithms and exponentials</a></li>
</ul></li>
<li><a href="#subset"><span class="toc-section-number">7.4</span> Extracting a subset of a vector</a><ul>
<li><a href="#refresher"><span class="toc-section-number">7.4.1</span> Refresher</a></li>
<li><a href="#using-in-to-match-multiple-cases"><span class="toc-section-number">7.4.2</span> Using <code>%in%</code> to match multiple cases</a></li>
<li><a href="#using-negative-indices-to-drop-elements"><span class="toc-section-number">7.4.3</span> Using negative indices to drop elements</a></li>
<li><a href="#splitting-a-vector-by-group"><span class="toc-section-number">7.4.4</span> Splitting a vector by group</a></li>
</ul></li>
<li><a href="#subsetdataframe"><span class="toc-section-number">7.5</span> Extracting a subset of a data frame</a><ul>
<li><a href="#using-the-subset-function"><span class="toc-section-number">7.5.1</span> Using the <code>subset()</code> function</a></li>
<li><a href="#using-square-brackets-i.-rows-and-columns"><span class="toc-section-number">7.5.2</span> Using square brackets: I. Rows and columns</a></li>
<li><a href="#using-square-brackets-ii.-some-elaborations"><span class="toc-section-number">7.5.3</span> Using square brackets: II. Some elaborations</a></li>
</ul></li>
</ul></li>
</ul>
<!--bookdown:toc2:end-->
      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Learning statistics with R: A tutorial for psychology students and other beginners. (Version 0.6.1)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!--bookdown:toc:end-->
<!--bookdown:body:start-->
<div id="overview" class="section level1 unnumbered">
<h1>Overview</h1>
<p><em>Learning Statistics with R</em> covers the contents of an introductory statistics class, as typically taught to undergraduate psychology students, focusing on the use of the R statistical software. The book discusses how to get started in R as well as giving an introduction to data manipulation and writing scripts. From a statistical perspective, the book discusses descriptive statistics and graphing ﬁrst, followed by chapters on probability theory, sampling and estimation, and null hypothesis testing. After introducing the theory, the book covers the analysis of contingency tables, t-tests, ANOVAs and regression. Bayesian statistics are covered at the end of the book.</p>
</div>
<div id="licensing" class="section level1 unnumbered">
<h1>Licensing</h1>
<p>This book is published under a Creative Commons BY-SA license (CC BY-SA) version 4.0. This means that this book can be reused, remixed, retained, revised and redistributed (including commercially) as long as appropriate credit is given to the authors. If you remix, or modify the original version of this open textbook, you must redistribute all versions of this open textbook under the same license - CC BY-SA.
<a href="https://creativecommons.org/licenses/by-sa/4.0/" class="uri">https://creativecommons.org/licenses/by-sa/4.0/</a></p>
</div>
<div id="dedication" class="section level1 unnumbered">
<h1>Dedication</h1>
<p><em>This book was brought to you today by the letter ‘R’.</em></p>
</div>
<div id="preface" class="section level1 unnumbered">
<h1>Preface</h1>
<div id="preface-to-version-0.6.1" class="section level2">
<h2><span class="header-section-number">0.1</span> Preface to Version 0.6.1</h2>
<p>Hi! I’m not Danielle.</p>
<p>This version is a work in progress to transport the book from LaTeX to bookdown, this allows for the code chunks shown in the text to be interactively rendered and is the first step in updating sections to make use of the <strong>tidyverse</strong>.</p>
<p>Moving from LaTeX is a bit fiddly so there are broken pieces in this version that I am updating progressively. If you notice errors or have suggestions feel free to raise an issue (or pull request) at <a href="http://github.com/ekothe/rbook" class="uri">http://github.com/ekothe/rbook</a></p>
<p>Cheers
Emily Kothe</p>
</div>
<div id="preface-to-version-0.6" class="section level2">
<h2><span class="header-section-number">0.2</span> Preface to Version 0.6</h2>
<p>The book hasn’t changed much since 2015 when I released Version 0.5 – it’s probably fair to say that I’ve changed more than it has. I moved from Adelaide to Sydney in 2016 and my teaching profile at UNSW is different to what it was at Adelaide, and I haven’t really had a chance to work on it since arriving here! It’s a little strange looking back at this actually. A few quick comments…</p>
<ul>
<li>Weirdly, the book <em>consistently</em> misgenders me, but I suppose I have only myself to blame for that one :-) There’s now a brief footnote on page 12 that mentions this issue; in real life I’ve been working through a gender affirmation process for the last two years and mostly go by she/her pronouns. I am, however, just as lazy as I ever was so I haven’t bothered updating the text in the book.<br />
</li>
<li>For Version 0.6 I haven’t changed much I’ve made a few minor changes when people have pointed out typos or other errors. In particular it’s worth noting the issue associated with the etaSquared function in the <strong>lsr</strong> package (which isn’t really being maintained any more) in Section 14.4. The function works fine for the simple examples in the book, but there are definitely bugs in there that I haven’t found time to check! So please take care with that one.</li>
<li>The biggest change really is the licensing! I’ve released it under a Creative Commons licence (CC BY-SA 4.0, specifically), and placed all the source files to the associated GitHub repository, if anyone wants to adapt it.</li>
</ul>
<p>Maybe someone would like to write a version that makes use of the <strong>tidyverse</strong>… I hear that’s become rather important to R these days :-)</p>
<p>Best,
Danielle Navarro</p>
</div>
<div id="preface-to-version-0.5" class="section level2">
<h2><span class="header-section-number">0.3</span> Preface to Version 0.5</h2>
<p>Another year, another update. This time around, the update has focused almost entirely on the theory sections of the book. Chapters 9, 10 and 11 have been rewritten, hopefully for the better. Along the same lines, Chapter 17 is entirely new, and focuses on Bayesian statistics. I think the changes have improved the book a great deal. I’ve always felt uncomfortable about the fact that all the inferential statistics in the book are presented from an orthodox perspective, even though I almost always present Bayesian data analyses in my own work. Now that I’ve managed to squeeze Bayesian methods into the book somewhere, I’m starting to feel better about the book as a whole. I wanted to get a few other things done in this update, but as usual I’m running into teaching deadlines, so the update has to go out the way it is!</p>
<p>Dan Navarro
February 16, 2015</p>
</div>
<div id="preface-to-version-0.4" class="section level2">
<h2><span class="header-section-number">0.4</span> Preface to Version 0.4</h2>
<p>A year has gone by since I wrote the last preface. The book has changed in a few important ways: Chapters 3 and 4 do a better job of documenting some of the time saving features of Rstudio, Chapters 12 and 13 now make use of new functions in the lsr package for running chi-square tests and t tests, and the discussion of correlations has been adapted to refer to the new functions in the lsr package. The soft copy of 0.4 now has better internal referencing (i.e., actual hyperlinks between sections), though that was introduced in 0.3.1. There’s a few tweaks here and there, and many typo corrections (thank you to everyone who pointed out typos!), but overall 0.4 isn’t massively different from 0.3.</p>
<p>I wish I’d had more time over the last 12 months to add more content. The absence of any discussion of repeated measures ANOVA and mixed models more generally really does annoy me. My excuse for this lack of progress is that my second child was born at the start of 2013, and so I spent most of last year just trying to keep my head above water. As a consequence, unpaid side projects like this book got sidelined in favour of things that actually pay my salary! Things are a little calmer now, so with any luck version 0.5 will be a bigger step forward.</p>
<p>One thing that has surprised me is the number of downloads the book gets. I finally got some basic tracking information from the website a couple of months ago, and (after excluding obvious robots) the book has been averaging about 90 downloads per day. That’s encouraging: there’s at least a few people who find the book useful!</p>
<p>Dan Navarro
February 4, 2014</p>
</div>
<div id="preface-to-version-0.3" class="section level2">
<h2><span class="header-section-number">0.5</span> Preface to Version 0.3</h2>
<p>There’s a part of me that really <strong>doesn’t</strong> want to publish this book. It’s not finished.</p>
<p>And when I say that, I mean it. The referencing is spotty at best, the chapter summaries are just lists of section titles, there’s no index, there are no exercises for the reader, the organisation is suboptimal, and the coverage of topics is just not comprehensive enough for my liking. Additionally, there are sections with content that I’m not happy with, figures that really need to be redrawn, and I’ve had almost no time to hunt down inconsistencies, typos, or errors. In other words, <em>this book is not finished</em>. If I didn’t have a looming teaching deadline and a baby due in a few weeks, I really wouldn’t be making this available at all.</p>
<p>What this means is that if you are an academic looking for teaching materials, a Ph.D. student looking to learn R, or just a member of the general public interested in statistics, I would advise you to be cautious. What you’re looking at is a first draft, and it may not serve your purposes. If we were living in the days when publishing was expensive and the internet wasn’t around, I would never consider releasing a book in this form. The thought of someong shelling out $80 for this (which is what a commercial publisher told me it would retail for when they offered to distribute it) makes me feel more than a little uncomfortable. However, it’s the 21st century, so I can post the pdf on my website for free, and I can distribute hard copies via a print-on-demand service for less than half what a textbook publisher would charge. And so my guilt is assuaged, and I’m willing to share! With that in mind, you can obtain free soft copies and cheap hard copies online, from the following webpages:</p>
<ul>
<li><a href="http://www.compcogscisydney.com/learning-statistics-with-r.html" class="uri">http://www.compcogscisydney.com/learning-statistics-with-r.html</a></li>
<li><a href="http://www.lulu.com/content/13570633" class="uri">http://www.lulu.com/content/13570633</a></li>
</ul>
<p>Even so, the warning still stands: what you are looking at is Version 0.3 of a work in progress. If and when it hits Version 1.0, I would be willing to stand behind the work and say, yes, this is a textbook that I would encourage other people to use. At that point, I’ll probably start shamelessly flogging the thing on the internet and generally acting like a tool. But until that day comes, I’d like it to be made clear that I’m really ambivalent about the work as it stands.</p>
<p>All of the above being said, there is one group of people that I can enthusiastically endorse this book to: the psychology students taking our undergraduate research methods classes (DRIP and DRIP:A) in 2013. For you, this book is ideal, because it was written to accompany your stats lectures. If a problem arises due to a shortcoming of these notes, I can and will adapt content on the fly to fix that problem. Effectively, you’ve got a textbook written specifically for your classes, distributed for free (electronic copy) or at near-cost prices (hard copy). Better yet, the notes have been tested: Version 0.1 of these notes was used in the 2011 class, Version 0.2 was used in the 2012 class, and now you’re looking at the new and improved Version 0.3. I’m not saying these notes are titanium plated awesomeness on a stick – though if <em>you</em> wanted to say so on the student evaluation forms, then you’re totally welcome to – because they’re not. But I am saying that they’ve been tried out in previous years and they seem to work okay. Besides, there’s a group of us around to troubleshoot if any problems come up, and you can guarantee that at least <em>one</em> of your lecturers has read the whole thing cover to cover!</p>
<p>Okay, with all that out of the way, I should say something about what the book aims to be. At its core, it is an introductory statistics textbook pitched primarily at psychology students. As such, it covers the standard topics that you’d expect of such a book: study design, descriptive statistics, the theory of hypothesis testing, <span class="math inline">\(t\)</span>-tests, <span class="math inline">\(\chi^2\)</span> tests, ANOVA and regression. However, there are also several chapters devoted to the R statistical package, including a chapter on data manipulation and another one on scripts and programming. Moreover, when you look at the content presented in the book, you’ll notice a lot of topics that are traditionally swept under the carpet when teaching statistics to psychology students. The Bayesian/frequentist divide is openly disussed in the probability chapter, and the disagreement between Neyman and Fisher about hypothesis testing makes an appearance. The difference between probability and density is discussed. A detailed treatment of Type I, II and III sums of squares for unbalanced factorial ANOVA is provided. And if you have a look in the Epilogue, it should be clear that my intention is to add a lot more advanced content.</p>
<p>My reasons for pursuing this approach are pretty simple: the students can handle it, and they even seem to enjoy it. Over the last few years I’ve been pleasantly surprised at just how little difficulty I’ve had in getting undergraduate psych students to learn R. It’s certainly not easy for them, and I’ve found I need to be a little charitable in setting marking standards, but they do eventually get there. Similarly, they don’t seem to have a lot of problems tolerating ambiguity and complexity in presentation of statistical ideas,
as long as they are assured that the assessment standards will be set in a fashion that is appropriate for them. So if the students can handle it, why <em>not</em> teach it? The potential gains are pretty enticing. If they learn R, the students get access to CRAN, which is perhaps the largest and most comprehensive library of statistical tools in existence. And if they learn about probability theory in detail, it’s easier for them to switch from orthodox null hypothesis testing to Bayesian methods if they want to. Better yet, they learn data analysis skills that they can take to an employer without being dependent on expensive and proprietary software.</p>
<p>Sadly, this book isn’t the silver bullet that makes all this possible. It’s a work in progress, and maybe when it is finished it will be a useful tool. One among many, I would think. There are a number of other books that try to provide a basic introduction to statistics using R, and I’m not arrogant enough to believe that mine is better. Still, I rather like the book, and maybe other people will find it useful, incomplete though it is.</p>
<p>Dan Navarro
January 13, 2013</p>
<!--chapter:end:index.Rmd-->
</div>
</div>
<div id="part-i.-background" class="section level1 unnumbered">
<h1>Part I. Background</h1>
<!--chapter:end:01.00-Part1.Rmd-->
</div>
<div id="why-do-we-learn-statistics" class="section level1">
<h1><span class="header-section-number">1</span> Why do we learn statistics?</h1>
<blockquote>
<p>"Thou shalt not answer questionnaires<br />
Or quizzes upon World Affairs,</p>
</blockquote>
<blockquote>
<p>Nor with compliance<br />
Take any test. Thou shalt not sit<br />
With statisticians nor commit"</p>
</blockquote>
<blockquote>
<p>– W.H. Auden<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></p>
</blockquote>
<div id="whywhywhy" class="section level2">
<h2><span class="header-section-number">1.1</span> On the psychology of statistics</h2>
<p>To the surprise of many students, statistics is a fairly significant part of a psychological education. To the surprise of no-one, statistics is very rarely the <em>favourite</em> part of one’s psychological education. After all, if you really loved the idea of doing statistics, you’d probably be enrolled in a statistics class right now, not a psychology class. So, not surprisingly, there’s a pretty large proportion of the student base that isn’t happy about the fact that psychology has so much statistics in it. In view of this, I thought that the right place to start might be to answer some of the more common questions that people have about stats…</p>
<p>A big part of this issue at hand relates to the very idea of statistics. What is it? What’s it there for? And why are scientists so bloody obsessed with it? These are all good questions, when you think about it. So let’s start with the last one. As a group, scientists seem to be bizarrely fixated on running statistical tests on everything. In fact, we use statistics so often that we sometimes forget to explain to people why we do. It’s a kind of article of faith among scientists – and especially social scientists – that your findings can’t be trusted until you’ve done some stats. Undergraduate students might be forgiven for thinking that we’re all completely mad, because no-one takes the time to answer one very simple question:</p>
<blockquote>
<p><em>Why do you do statistics? Why don’t scientists just use <strong>common sense?</strong></em></p>
</blockquote>
<p>It’s a naive question in some ways, but most good questions are. There’s a lot of good answers to it,<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> but for my money, the best answer is a really simple one: we don’t trust ourselves enough. We worry that we’re human, and susceptible to all of the biases, temptations and frailties that humans suffer from. Much of statistics is basically a safeguard. Using “common sense” to evaluate evidence means trusting gut instincts, relying on verbal arguments and on using the raw power of human reason to come up with the right answer. Most scientists don’t think this approach is likely to work.</p>
<p>In fact, come to think of it, this sounds a lot like a psychological question to me, and since I do work in a psychology department, it seems like a good idea to dig a little deeper here. Is it really plausible to think that this “common sense” approach is very trustworthy? Verbal arguments have to be constructed in language, and all languages have biases – some things are harder to say than others, and not necessarily because they’re false (e.g., quantum electrodynamics is a good theory, but hard to explain in words). The instincts of our “gut” aren’t designed to solve scientific problems, they’re designed to handle day to day inferences – and given that biological evolution is slower than cultural change, we should say that they’re designed to solve the day to day problems for a <em>different world</em> than the one we live in. Most fundamentally, reasoning sensibly requires people to engage in “induction”, making wise guesses and going beyond the immediate evidence of the senses to make generalisations about the world. If you think that you can do that without being influenced by various distractors, well, I have a bridge in Brooklyn I’d like to sell you. Heck, as the next section shows, we can’t even solve “deductive” problems (ones where no guessing is required) without being influenced by our pre-existing biases.</p>
<div id="the-curse-of-belief-bias" class="section level3">
<h3><span class="header-section-number">1.1.1</span> The curse of belief bias</h3>
<p>People are mostly pretty smart. We’re certainly smarter than the other species that we share the planet with (though many people might disagree). Our minds are quite amazing things, and we seem to be capable of the most incredible feats of thought and reason. That doesn’t make us perfect though. And among the many things that psychologists have shown over the years is that we really do find it hard to be neutral, to evaluate evidence impartially and without being swayed by pre-existing biases. A good example of this is the <strong><em>belief bias effect</em></strong> in logical reasoning: if you ask people to decide whether a particular argument is logically valid (i.e., conclusion would be true if the premises were true), we tend to be influenced by the believability of the conclusion, even when we shouldn’t. For instance, here’s a valid argument where the conclusion is believable:</p>
<blockquote>
<p>No cigarettes are inexpensive (Premise 1)<br />
Some addictive things are inexpensive (Premise 2)<br />
Therefore, some addictive things are not cigarettes (Conclusion)</p>
</blockquote>
<p>And here’s a valid argument where the conclusion is not believable:</p>
<blockquote>
<p>No addictive things are inexpensive (Premise 1)<br />
Some cigarettes are inexpensive (Premise 2)<br />
Therefore, some cigarettes are not addictive (Conclusion)</p>
</blockquote>
<p>The logical <em>structure</em> of argument #2 is identical to the structure of argument #1, and they’re both valid. However, in the second argument, there are good reasons to think that premise 1 is incorrect, and as a result it’s probably the case that the conclusion is also incorrect. But that’s entirely irrelevant to the topic at hand: an argument is deductively valid if the conclusion is a logical consequence of the premises. That is, a valid argument doesn’t have to involve true statements.</p>
<p>On the other hand, here’s an invalid argument that has a believable conclusion:</p>
<blockquote>
<p>No addictive things are inexpensive (Premise 1)<br />
Some cigarettes are inexpensive (Premise 2)<br />
Therefore, some addictive things are not cigarettes (Conclusion)</p>
</blockquote>
<p>And finally, an invalid argument with an unbelievable conclusion:</p>
<blockquote>
<p>No cigarettes are inexpensive (Premise 1)<br />
Some addictive things are inexpensive (Premise 2)<br />
Therefore, some cigarettes are not addictive (Conclusion)</p>
</blockquote>
<p>Now, suppose that people really are perfectly able to set aside their pre-existing biases about what is true and what isn’t, and purely evaluate an argument on its logical merits. We’d expect 100% of people to say that the valid arguments are valid, and 0% of people to say that the invalid arguments are valid. So if you ran an experiment looking at this, you’d expect to see data like this:</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="center">conclusion feels true</th>
<th align="center">conclusion feels false</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>argument is valid</td>
<td align="center">100% say “valid”</td>
<td align="center">100% say “valid”</td>
</tr>
<tr class="even">
<td>argument is invalid</td>
<td align="center">0% say “valid”</td>
<td align="center">0% say “valid”</td>
</tr>
</tbody>
</table>
<p>If the psychological data looked like this (or even a good approximation to this), we might feel safe in just trusting our gut instincts. That is, it’d be perfectly okay just to let scientists evaluate data based on their common sense, and not bother with all this murky statistics stuff. However, you guys have taken psych classes, and by now you probably know where this is going…</p>
<p>In a classic study, <span class="citation">Evans, Barston, and Pollard (<a href="#ref-Evans1983" role="doc-biblioref">1983</a>)</span> ran an experiment looking at exactly this. What they found is that when pre-existing biases (i.e., beliefs) were in agreement with the structure of the data, everything went the way you’d hope:</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="center">conclusion feels true</th>
<th align="center">conclusion feels false</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>argument is valid</td>
<td align="center">92% say “valid”</td>
<td align="center"></td>
</tr>
<tr class="even">
<td>argument is invalid</td>
<td align="center"></td>
<td align="center">8% say “valid”</td>
</tr>
</tbody>
</table>
<p>Not perfect, but that’s pretty good. But look what happens when our intuitive feelings about the truth of the conclusion run against the logical structure of the argument:</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="center">conclusion feels true</th>
<th align="center">conclusion feels false</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>argument is valid</td>
<td align="center">92% say “valid”</td>
<td align="center"><strong>46% say “valid”</strong></td>
</tr>
<tr class="even">
<td>argument is invalid</td>
<td align="center"><strong>92% say “valid”</strong></td>
<td align="center">8% say “valid”</td>
</tr>
</tbody>
</table>
<p>Oh dear, that’s not as good. Apparently, when people are presented with a strong argument that contradicts our pre-existing beliefs, we find it pretty hard to even perceive it to be a strong argument (people only did so 46% of the time). Even worse, when people are presented with a weak argument that agrees with our pre-existing biases, almost no-one can see that the argument is weak (people got that one wrong 92% of the time!)<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a></p>
<p>If you think about it, it’s not as if these data are horribly damning. Overall, people did do better than chance at compensating for their prior biases, since about 60% of people’s judgements were correct (you’d expect 50% by chance). Even so, if you were a professional “evaluator of evidence”, and someone came along and offered you a magic tool that improves your chances of making the right decision from 60% to (say) 95%, you’d probably jump at it, right? Of course you would. Thankfully, we actually do have a tool that can do this. But it’s not magic, it’s statistics. So that’s reason #1 why scientists love statistics. It’s just <em>too easy</em> for us to “believe what we want to believe”; so if we want to “believe in the data” instead, we’re going to need a bit of help to keep our personal biases under control. That’s what statistics does: it helps keep us honest.</p>
</div>
</div>
<div id="the-cautionary-tale-of-simpsons-paradox" class="section level2">
<h2><span class="header-section-number">1.2</span> The cautionary tale of Simpson’s paradox</h2>
<p>The following is a true story (I think…). In 1973, the University of California, Berkeley had some worries about the admissions of students into their postgraduate courses. Specifically, the thing that caused the problem was that the gender breakdown of their admissions, which looked like this…</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="center">Number of applicants</th>
<th align="center">Percent admitted</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Males</td>
<td align="center">8442</td>
<td align="center">46%</td>
</tr>
<tr class="even">
<td>Females</td>
<td align="center">4321</td>
<td align="center">35%</td>
</tr>
</tbody>
</table>
<p>…and the were worried about being sued.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a> Given that there were nearly 13,000 applicants, a difference of 9% in admission rates between males and females is just way too big to be a coincidence. Pretty compelling data, right? And if I were to say to you that these data <em>actually</em> reflect a weak bias in favour of women (sort of!), you’d probably think that I was either crazy or sexist.</p>
<p>Oddly, it’s actually sort of true …when people started looking more carefully at the admissions data <span class="citation">(Bickel, Hammel, and O’Connell <a href="#ref-Bickel1975" role="doc-biblioref">1975</a>)</span> they told a rather different story. Specifically, when they looked at it on a department by department basis, it turned out that most of the departments actually had a slightly <em>higher</em> success rate for female applicants than for male applicants. Table @ref(tab:simpsontable) shows the admission figures for the six largest departments (with the names of the departments removed for privacy reasons):</p>
<table>
<caption>(#tab:simpsontable)Admission figures for the six largest departments by gender</caption>
<thead>
<tr class="header">
<th align="center">Department</th>
<th align="center">Male Applicants</th>
<th align="center">Male Percent Admitted</th>
<th align="center">Female Applicants</th>
<th align="center">Female Percent admitted</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">A</td>
<td align="center">825</td>
<td align="center">62%</td>
<td align="center">108</td>
<td align="center">82%</td>
</tr>
<tr class="even">
<td align="center">B</td>
<td align="center">560</td>
<td align="center">63%</td>
<td align="center">25</td>
<td align="center">68%</td>
</tr>
<tr class="odd">
<td align="center">C</td>
<td align="center">325</td>
<td align="center">37%</td>
<td align="center">593</td>
<td align="center">34%</td>
</tr>
<tr class="even">
<td align="center">D</td>
<td align="center">417</td>
<td align="center">33%</td>
<td align="center">375</td>
<td align="center">35%</td>
</tr>
<tr class="odd">
<td align="center">E</td>
<td align="center">191</td>
<td align="center">28%</td>
<td align="center">393</td>
<td align="center">24%</td>
</tr>
<tr class="even">
<td align="center">F</td>
<td align="center">272</td>
<td align="center">6%</td>
<td align="center">341</td>
<td align="center">7%</td>
</tr>
</tbody>
</table>
<p>Remarkably, most departments had a <em>higher</em> rate of admissions for females than for males! Yet the overall rate of admission across the university for females was <em>lower</em> than for males. How can this be? How can both of these statements be true at the same time?</p>
<p>Here’s what’s going on. Firstly, notice that the departments are <em>not</em> equal to one another in terms of their admission percentages: some departments (e.g., engineering, chemistry) tended to admit a high percentage of the qualified applicants, whereas others (e.g., English) tended to reject most of the candidates, even if they were high quality. So, among the six departments shown above, notice that department A is the most generous, followed by B, C, D, E and F in that order. Next, notice that males and females tended to apply to different departments. If we rank the departments in terms of the total number of male applicants, we get <strong>A</strong>&gt;<strong>B</strong>&gt;D&gt;C&gt;F&gt;E (the “easy” departments are in bold). On the whole, males tended to apply to the departments that had high admission rates. Now compare this to how the female applicants distributed themselves. Ranking the departments in terms of the total number of female applicants produces a quite different ordering C&gt;E&gt;D&gt;F&gt;<strong>A</strong>&gt;<strong>B</strong>. In other words, what these data seem to be suggesting is that the female applicants tended to apply to “harder” departments. And in fact, if we look at all Figure @ref(fig:berkeley) we see that this trend is systematic, and quite striking. This effect is known as Simpson’s paradox. It’s not common, but it does happen in real life, and most people are very surprised by it when they first encounter it, and many people refuse to even believe that it’s real. It is very real. And while there are lots of very subtle statistical lessons buried in there, I want to use it to make a much more important point …doing research is hard, and there are <em>lots</em> of subtle, counterintuitive traps lying in wait for the unwary. That’s reason #2 why scientists love statistics, and why we teach research methods. Because science is hard, and the truth is sometimes cunningly hidden in the nooks and crannies of complicated data.</p>
<div class="figure">
<img src="lsr_files/figure-html/berkeley-1.png" alt="The Berkeley 1973 college admissions data. This figure plots the admission rate for the 85 departments that had at least one female applicant, as a function of the percentage of applicants that were female. The plot is a redrawing of Figure 1 from @Bickel1975. Circles plot departments with more than 40 applicants; the area of the circle is proportional to the total number of applicants. The crosses plot department with fewer than 40 applicants." width="672" />
<p class="caption">
(#fig:berkeley)The Berkeley 1973 college admissions data. This figure plots the admission rate for the 85 departments that had at least one female applicant, as a function of the percentage of applicants that were female. The plot is a redrawing of Figure 1 from <span class="citation">Bickel, Hammel, and O’Connell (<a href="#ref-Bickel1975" role="doc-biblioref">1975</a>)</span>. Circles plot departments with more than 40 applicants; the area of the circle is proportional to the total number of applicants. The crosses plot department with fewer than 40 applicants.
</p>
</div>
<p>Before leaving this topic entirely, I want to point out something else really critical that is often overlooked in a research methods class. Statistics only solves <em>part</em> of the problem. Remember that we started all this with the concern that Berkeley’s admissions processes might be unfairly biased against female applicants. When we looked at the “aggregated” data, it did seem like the university was discriminating against women, but when we “disaggregate” and looked at the individual behaviour of all the departments, it turned out that the actual departments were, if anything, slightly biased in favour of women. The gender bias in total admissions was caused by the fact that women tended to self-select for harder departments. From a legal perspective, that would probably put the university in the clear. Postgraduate admissions are determined at the level of the individual department (and there are good reasons to do that), and at the level of individual departments, the decisions are more or less unbiased (the weak bias in favour of females at that level is small, and not consistent across departments). Since the university can’t dictate which departments people choose to apply to, and the decision making takes place at the level of the department it can hardly be held accountable for any biases that those choices produce.</p>
<p>That was the basis for my somewhat glib remarks earlier, but that’s not exactly the whole story, is it? After all, if we’re interested in this from a more sociological and psychological perspective, we might want to ask <em>why</em> there are such strong gender differences in applications. Why do males tend to apply to engineering more often than females, and why is this reversed for the English department? And why is it it the case that the departments that tend to have a female-application bias tend to have lower overall admission rates than those departments that have a male-application bias? Might this not still reflect a gender bias, even though every single department is itself unbiased? It might. Suppose, hypothetically, that males preferred to apply to “hard sciences” and females prefer “humanities”. And suppose further that the reason for why the humanities departments have low admission rates is because the government doesn’t want to fund the humanities (Ph.D. places, for instance, are often tied to government funded research projects). Does that constitute a gender bias? Or just an unenlightened view of the value of the humanities? What if someone at a high level in the government cut the humanities funds because they felt that the humanities are “useless chick stuff”. That seems pretty <em>blatantly</em> gender biased. None of this falls within the purview of statistics, but it matters to the research project. If you’re interested in the overall structural effects of subtle gender biases, then you probably want to look at <em>both</em> the aggregated and disaggregated data. If you’re interested in the decision making process at Berkeley itself then you’re probably only interested in the disaggregated data.</p>
<p>In short there are a lot of critical questions that you can’t answer with statistics, but the answers to those questions will have a huge impact on how you analyse and interpret data. And this is the reason why you should always think of statistics as a <em>tool</em> to help you learn about your data, no more and no less. It’s a powerful tool to that end, but there’s no substitute for careful thought.</p>
</div>
<div id="statistics-in-psychology" class="section level2">
<h2><span class="header-section-number">1.3</span> Statistics in psychology</h2>
<p>I hope that the discussion above helped explain why science in general is so focused on statistics. But I’m guessing that you have a lot more questions about what role statistics plays in psychology, and specifically why psychology classes always devote so many lectures to stats. So here’s my attempt to answer a few of them…</p>
<p><strong>Why does psychology have so much statistics?</strong></p>
<p>To be perfectly honest, there’s a few different reasons, some of which are better than others. The most important reason is that psychology is a statistical science. What I mean by that is that the “things” that we study are <em>people</em>. Real, complicated, gloriously messy, infuriatingly perverse people. The “things” of physics include object like electrons, and while there are all sorts of complexities that arise in physics, electrons don’t have minds of their own. They don’t have opinions, they don’t differ from each other in weird and arbitrary ways, they don’t get bored in the middle of an experiment, and they don’t get angry at the experimenter and then deliberately try to sabotage the data set (not that I’ve ever done that…). At a fundamental level psychology is harder than physics.<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a></p>
<p>Basically, we teach statistics to you as psychologists because you need to be better at stats than physicists. There’s actually a saying used sometimes in physics, to the effect that “if your experiment needs statistics, you should have done a better experiment”. They have the luxury of being able to say that because their objects of study are pathetically simple in comparison to the vast mess that confronts social scientists. It’s not just psychology, really: most social sciences are desperately reliant on statistics. Not because we’re bad experimenters, but because we’ve picked a harder problem to solve. We teach you stats because you really, really need it.</p>
<p><strong>Can’t someone else do the statistics?</strong></p>
<p>To some extent, but not completely. It’s true that you don’t need to become a fully trained statistician just to do psychology, but you do need to reach a certain level of statistical competence. In my view, there’s three reasons that every psychological researcher ought to be able to do basic statistics:</p>
<ul>
<li>Firstly, there’s the fundamental reason: statistics is deeply intertwined with research design. If you want to be good at designing psychological studies, you need to at least understand the basics of stats.</li>
<li>Secondly, if you want to be good at the psychological side of the research, then you need to be able to understand the psychological literature, right? But almost every paper in the psychological literature reports the results of statistical analyses. So if you really want to understand the psychology, you need to be able to understand what other people did with their data. And that means understanding a certain amount of statistics.</li>
<li>Thirdly, there’s a big practical problem with being dependent on other people to do all your statistics: statistical analysis is <em>expensive</em>. If you ever get bored and want to look up how much the Australian government charges for university fees, you’ll notice something interesting: statistics is designated as a “national priority” category, and so the fees are much, much lower than for any other area of study. This is because there’s a massive shortage of statisticians out there. So, from your perspective as a psychological researcher, the laws of supply and demand aren’t exactly on your side here! As a result, in almost any real life situation where you want to do psychological research, the cruel facts will be that you don’t have enough money to afford a statistician. So the economics of the situation mean that you have to be pretty self-sufficient.</li>
</ul>
<p>Note that a lot of these reasons generalise beyond researchers. If you want to be a practicing psychologist and stay on top of the field, it helps to be able to read the scientific literature, which relies pretty heavily on statistics.</p>
<p><strong>I don’t care about jobs, research, or clinical work. Do I need statistics?</strong></p>
<p>Okay, now you’re just messing with me. Still, I think it should matter to you too. Statistics should matter to you in the same way that statistics should matter to <em>everyone</em>: we live in the 21st century, and data are <em>everywhere</em>. Frankly, given the world in which we live these days, a basic knowledge of statistics is pretty damn close to a survival tool! Which is the topic of the next section…</p>
</div>
<div id="statistics-in-everyday-life" class="section level2">
<h2><span class="header-section-number">1.4</span> Statistics in everyday life</h2>
<blockquote>
<p><em>“We are drowning in information, but we are starved for knowledge”</em></p>
<p>-Various authors, original probably John Naisbitt</p>
</blockquote>
<p>When I started writing up my lecture notes I took the 20 most recent news articles posted to the ABC news website. Of those 20 articles, it turned out that 8 of them involved a discussion of something that I would call a statistical topic; 6 of those made a mistake. The most common error, if you’re curious, was failing to report baseline data (e.g., the article mentions that 5% of people in situation X have some characteristic Y, but doesn’t say how common the characteristic is for everyone else!) The point I’m trying to make here isn’t that journalists are bad at statistics (though they almost always are), it’s that a basic knowledge of statistics is very helpful for trying to figure out when someone else is either making a mistake or even lying to you. In fact, one of the biggest things that a knowledge of statistics does to you is cause you to get angry at the newspaper or the internet on a far more frequent basis: you can find a good example of this in Section @ref(housingpriceexample). In later versions of this book I’ll try to include more anecdotes along those lines.</p>
</div>
<div id="theres-more-to-research-methods-than-statistics" class="section level2">
<h2><span class="header-section-number">1.5</span> There’s more to research methods than statistics</h2>
<p>So far, most of what I’ve talked about is statistics, and so you’d be forgiven for thinking that statistics is all I care about in life. To be fair, you wouldn’t be far wrong, but research methodology is a broader concept than statistics. So most research methods courses will cover a lot of topics that relate much more to the pragmatics of research design, and in particular the issues that you encounter when trying to do research with humans. However, about 99% of student <em>fears</em> relate to the statistics part of the course, so I’ve focused on the stats in this discussion, and hopefully I’ve convinced you that statistics matters, and more importantly, that it’s not to be feared. That being said, it’s pretty typical for introductory research methods classes to be very stats-heavy. This is not (usually) because the lecturers are evil people. Quite the contrary, in fact. Introductory classes focus a lot on the statistics because you almost always find yourself needing statistics before you need the other research methods training. Why? Because almost all of your assignments in other classes will rely on statistical training, to a much greater extent than they rely on other methodological tools. It’s not common for undergraduate assignments to require you to design your own study from the ground up (in which case you would need to know a lot about research design), but it <em>is</em> common for assignments to ask you to analyse and interpret data that were collected in a study that someone else designed (in which case you need statistics). In that sense, from the perspective of allowing you to do well in all your other classes, the statistics is more urgent.</p>
<p>But note that “urgent” is different from “important” – they both matter. I really do want to stress that research design is just as important as data analysis, and this book does spend a fair amount of time on it. However, while statistics has a kind of universality, and provides a set of core tools that are useful for most types of psychological research, the research methods side isn’t quite so universal. There are some general principles that everyone should think about, but a lot of research design is very idiosyncratic, and is specific to the area of research that you want to engage in. To the extent that it’s the details that matter, those details don’t usually show up in an introductory stats and research methods class.</p>
<!--chapter:end:01.01-intro.Rmd-->
</div>
</div>
<div id="studydesign" class="section level1">
<h1><span class="header-section-number">2</span> A brief introduction to research design</h1>
<blockquote>
<p><em>To consult the statistician after an experiment is finished is often merely to ask him to conduct a post mortem examination. He can perhaps say what the experiment died of.</em></p>
<p>– Sir Ronald Fisher<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a></p>
</blockquote>
<p>In this chapter, we’re going to start thinking about the basic ideas that go into designing a study, collecting data, checking whether your data collection works, and so on. It won’t give you enough information to allow you to design studies of your own, but it will give you a lot of the basic tools that you need to assess the studies done by other people. However, since the focus of this book is much more on data analysis than on data collection, I’m only giving a very brief overview. Note that this chapter is “special” in two ways. Firstly, it’s much more psychology-specific than the later chapters. Secondly, it focuses much more heavily on the scientific problem of research methodology, and much less on the statistical problem of data analysis. Nevertheless, the two problems are related to one another, so it’s traditional for stats textbooks to discuss the problem in a little detail. This chapter relies heavily on <span class="citation">Campbell and Stanley (<a href="#ref-Campbell1963" role="doc-biblioref">1963</a>)</span> for the discussion of study design, and <span class="citation">Stevens (<a href="#ref-Stevens1946" role="doc-biblioref">1946</a>)</span> for the discussion of scales of measurement. Later versions will attempt to be more precise in the citations.</p>
<p>##Introduction to psychological measurement {#measurement}</p>
<p>The first thing to understand is data collection can be thought of as a kind of <strong><em>measurement</em></strong>. That is, what we’re trying to do here is measure something about human behaviour or the human mind. What do I mean by “measurement”?</p>
<p>###Some thoughts about psychological measurement</p>
<p>Measurement itself is a subtle concept, but basically it comes down to finding some way of assigning numbers, or labels, or some other kind of well-defined descriptions to “stuff”. So, any of the following would count as a psychological measurement:</p>
<ul>
<li>My <strong>age</strong> is <em>33 years</em>.</li>
<li>I <em>do not</em> <strong>like anchovies</strong>.</li>
<li>My <strong>chromosomal gender</strong> is <em>male</em>.</li>
<li>My <strong>self-identified gender</strong> is <em>male</em>.<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a></li>
</ul>
<p>In the short list above, the <strong>bolded part</strong> is “the thing to be measured”, and the <em>italicised part</em> is “the measurement itself”. In fact, we can expand on this a little bit, by thinking about the set of possible measurements that could have arisen in each case:</p>
<ul>
<li>My <strong>age</strong> (in years) could have been <em>0, 1, 2, 3 …</em>, etc. The upper bound on what my age could possibly be is a bit fuzzy, but in practice you’d be safe in saying that the largest possible age is <em>150</em>, since no human has ever lived that long.</li>
<li>When asked if I <strong>like anchovies</strong>, I might have said that <em>I do</em>, or <em>I do not</em>, or <em>I have no opinion</em>, or <em>I sometimes do</em>.</li>
<li>My <strong>chromosomal gender</strong> is almost certainly going to be <em>male (XY)</em> or <em>female (XX)</em>, but there are a few other possibilities. I could also have <em>Klinfelter’s syndrome (XXY)</em>, which is more similar to male than to female. And I imagine there are other possibilities too.</li>
<li>My <strong>self-identified gender</strong> is also very likely to be <em>male</em> or <em>female</em>, but it doesn’t have to agree with my chromosomal gender. I may also choose to identify with <em>neither</em>, or to explicitly call myself <em>transgender</em>.</li>
</ul>
<p>As you can see, for some things (like age) it seems fairly obvious what the set of possible measurements should be, whereas for other things it gets a bit tricky. But I want to point out that even in the case of someone’s age, it’s much more subtle than this. For instance, in the example above, I assumed that it was okay to measure age in years. But if you’re a developmental psychologist, that’s way too crude, and so you often measure age in <em>years and months</em> (if a child is 2 years and 11 months, this is usually written as “2;11”). If you’re interested in newborns, you might want to measure age in <em>days since birth</em>, maybe even <em>hours since birth</em>. In other words, the way in which you specify the allowable measurement values is important.</p>
<p>Looking at this a bit more closely, you might also realise that the concept of “age” isn’t actually all that precise. In general, when we say “age” we implicitly mean “the length of time since birth”. But that’s not always the right way to do it. Suppose you’re interested in how newborn babies control their eye movements. If you’re interested in kids that young, you might also start to worry that “birth” is not the only meaningful point in time to care about. If Baby Alice is born 3 weeks premature and Baby Bianca is born 1 week late, would it really make sense to say that they are the “same age” if we encountered them “2 hours after birth”? In one sense, yes: by social convention, we use birth as our reference point for talking about age in everyday life, since it defines the amount of time the person has been operating as an independent entity in the world, but from a scientific perspective that’s not the only thing we care about. When we think about the biology of human beings, it’s often useful to think of ourselves as organisms that have been growing and maturing since conception, and from that perspective Alice and Bianca aren’t the same age at all. So you might want to define the concept of “age” in two different ways: the length of time since conception, and the length of time since birth. When dealing with adults, it won’t make much difference, but when dealing with newborns it might.</p>
<p>Moving beyond these issues, there’s the question of methodology. What specific “measurement method” are you going to use to find out someone’s age? As before, there are lots of different possibilities:</p>
<ul>
<li>You could just ask people “how old are you?” The method of self-report is fast, cheap and easy, but it only works with people old enough to understand the question, and some people lie about their age.</li>
<li>You could ask an authority (e.g., a parent) “how old is your child?” This method is fast, and when dealing with kids it’s not all that hard since the parent is almost always around. It doesn’t work as well if you want to know “age since conception”, since a lot of parents can’t say for sure when conception took place. For that, you might need a different authority (e.g., an obstetrician).</li>
<li>You could look up official records, like birth certificates. This is time consuming and annoying, but it has its uses (e.g., if the person is now dead).</li>
</ul>
<p>###Operationalisation: defining your measurement</p>
<p>All of the ideas discussed in the previous section all relate to the concept of <strong><em>operationalisation</em></strong>. To be a bit more precise about the idea, operationalisation is the process by which we take a meaningful but somewhat vague concept, and turn it into a precise measurement. The process of operationalisation can involve several different things:</p>
<ul>
<li>Being precise about what you are trying to measure. For instance, does “age” mean “time since birth” or “time since conception” in the context of your research?</li>
<li>Determining what method you will use to measure it. Will you use self-report to measure age, ask a parent, or look up an official record? If you’re using self-report, how will you phrase the question?</li>
<li>Defining the set of the allowable values that the measurement can take. Note that these values don’t always have to be numerical, though they often are. When measuring age, the values are numerical, but we still need to think carefully about what numbers are allowed. Do we want age in years, years and months, days, hours? Etc. For other types of measurements (e.g., gender), the values aren’t numerical. But, just as before, we need to think about what values are allowed. If we’re asking people to self-report their gender, what options to we allow them to choose between? Is it enough to allow only “male” or “female”? Do you need an “other” option? Or should we not give people any specific options, and let them answer in their own words? And if you open up the set of possible values to include all verbal response, how will you interpret their answers?</li>
</ul>
<p>Operationalisation is a tricky business, and there’s no “one, true way” to do it. The way in which you choose to operationalise the informal concept of “age” or “gender” into a formal measurement depends on what you need to use the measurement for. Often you’ll find that the community of scientists who work in your area have some fairly well-established ideas for how to go about it. In other words, operationalisation needs to be thought through on a case by case basis. Nevertheless, while there a lot of issues that are specific to each individual research project, there are some aspects to it that are pretty general.</p>
<p>Before moving on, I want to take a moment to clear up our terminology, and in the process introduce one more term. Here are four different things that are closely related to each other:</p>
<ul>
<li><strong><em>A theoretical construct</em></strong>. This is the thing that you’re trying to take a measurement of, like “age”, “gender” or an “opinion”. A theoretical construct can’t be directly observed, and often they’re actually a bit vague.</li>
<li><strong><em>A measure</em></strong>. The measure refers to the method or the tool that you use to make your observations. A question in a survey, a behavioural observation or a brain scan could all count as a measure.</li>
<li><strong><em>An operationalisation</em></strong>. The term “operationalisation” refers to the logical connection between the measure and the theoretical construct, or to the process by which we try to derive a measure from a theoretical construct.</li>
<li><strong><em>A variable</em></strong>. Finally, a new term. A variable is what we end up with when we apply our measure to something in the world. That is, variables are the actual “data” that we end up with in our data sets.</li>
</ul>
<p>In practice, even scientists tend to blur the distinction between these things, but it’s very helpful to try to understand the differences.</p>
<p>##Scales of measurement{#scales}</p>
<p>As the previous section indicates, the outcome of a psychological measurement is called a variable. But not all variables are of the same qualitative type, and it’s very useful to understand what types there are. A very useful concept for distinguishing between different types of variables is what’s known as <strong><em>scales of measurement</em></strong>.</p>
<p>###Nominal scale</p>
<p>A <strong><em>nominal scale</em></strong> variable (also referred to as a <strong><em>categorical</em></strong> variable) is one in which there is no particular relationship between the different possibilities: for these kinds of variables it doesn’t make any sense to say that one of them is “bigger’ or”better" than any other one, and it absolutely doesn’t make any sense to average them. The classic example for this is “eye colour”. Eyes can be blue, green and brown, among other possibilities, but none of them is any “better” than any other one. As a result, it would feel really weird to talk about an “average eye colour”. Similarly, gender is nominal too: male isn’t better or worse than female, neither does it make sense to try to talk about an “average gender”. In short, nominal scale variables are those for which the only thing you can say about the different possibilities is that they are different. That’s it.</p>
<p>Let’s take a slightly closer look at this. Suppose I was doing research on how people commute to and from work. One variable I would have to measure would be what kind of transportation people use to get to work. This “transport type” variable could have quite a few possible values, including: “train”, “bus”, “car”, “bicycle”, etc. For now, let’s suppose that these four are the only possibilities, and suppose that when I ask 100 people how they got to work today, and I get this:</p>
<table>
<thead>
<tr class="header">
<th align="center">Transportation</th>
<th align="center">Number of people</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">(1) Train</td>
<td align="center">12</td>
</tr>
<tr class="even">
<td align="center">(2) Bus</td>
<td align="center">30</td>
</tr>
<tr class="odd">
<td align="center">(3) Car</td>
<td align="center">48</td>
</tr>
<tr class="even">
<td align="center">(4) Bicycle</td>
<td align="center">10</td>
</tr>
</tbody>
</table>
<p>So, what’s the average transportation type? Obviously, the answer here is that there isn’t one. It’s a silly question to ask. You can say that travel by car is the most popular method, and travel by train is the least popular method, but that’s about all. Similarly, notice that the order in which I list the options isn’t very interesting. I could have chosen to display the data like this</p>
<table>
<thead>
<tr class="header">
<th align="center">Transportation</th>
<th align="center">Number of people</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">(3) Car</td>
<td align="center">48</td>
</tr>
<tr class="even">
<td align="center">(1) Train</td>
<td align="center">12</td>
</tr>
<tr class="odd">
<td align="center">(4) Bicycle</td>
<td align="center">10</td>
</tr>
<tr class="even">
<td align="center">(2) Bus</td>
<td align="center">30</td>
</tr>
</tbody>
</table>
<p>and nothing really changes.</p>
<p>###Ordinal scale</p>
<p><strong><em>Ordinal scale</em></strong> variables have a bit more structure than nominal scale variables, but not by a lot. An ordinal scale variable is one in which there is a natural, meaningful way to order the different possibilities, but you can’t do anything else. The usual example given of an ordinal variable is “finishing position in a race”. You <em>can</em> say that the person who finished first was faster than the person who finished second, but you <em>don’t</em> know how much faster. As a consequence we know that 1st &gt; 2nd, and we know that 2nd &gt; 3rd, but the difference between 1st and 2nd might be much larger than the difference between 2nd and 3rd.</p>
<p>Here’s an more psychologically interesting example. Suppose I’m interested in people’s attitudes to climate change, and I ask them to pick one of these four statements that most closely matches their beliefs:</p>
<blockquote>
<ol style="list-style-type: decimal">
<li>Temperatures are rising, because of human activity</li>
<li>Temperatures are rising, but we don’t know why</li>
<li>Temperatures are rising, but not because of humans</li>
<li>Temperatures are not rising</li>
</ol>
</blockquote>
<p>Notice that these four statements actually do have a natural ordering, in terms of “the extent to which they agree with the current science”. Statement 1 is a close match, statement 2 is a reasonable match, statement 3 isn’t a very good match, and statement 4 is in strong opposition to the science. So, in terms of the thing I’m interested in (the extent to which people endorse the science), I can order the items as 1 &gt; 2 &gt; 3 &gt; 4. Since this ordering exists, it would be very weird to list the options like this…</p>
<blockquote>
<ol start="3" style="list-style-type: decimal">
<li>Temperatures are rising, but not because of humans</li>
<li>Temperatures are rising, because of human activity</li>
<li>Temperatures are not rising</li>
<li>Temperatures are rising, but we don’t know why</li>
</ol>
</blockquote>
<p>… because it seems to violate the natural “structure” to the question.</p>
<p>So, let’s suppose I asked 100 people these questions, and got the following answers:</p>
<table>
<thead>
<tr class="header">
<th>Response</th>
<th align="center">Number</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>(1) Temperatures are rising, because of human activity</td>
<td align="center">51</td>
</tr>
<tr class="even">
<td>(2) Temperatures are rising, but we don’t know why</td>
<td align="center">20</td>
</tr>
<tr class="odd">
<td>(3) Temperatures are rising, but not because of humans</td>
<td align="center">10</td>
</tr>
<tr class="even">
<td>(4) Temperatures are not rising</td>
<td align="center">19</td>
</tr>
</tbody>
</table>
<p>When analysing these data, it seems quite reasonable to try to group (1), (2) and (3) together, and say that 81 of 100 people were willing to <em>at least partially</em> endorse the science. And it’s <em>also</em> quite reasonable to group (2), (3) and (4) together and say that 49 of 100 people registered <em>at least some disagreement</em> with the dominant scientific view. However, it would be entirely bizarre to try to group (1), (2) and (4) together and say that 90 of 100 people said… what? There’s nothing sensible that allows you to group those responses together at all.</p>
<p>That said, notice that while we <em>can</em> use the natural ordering of these items to construct sensible groupings, what we <em>can’t</em> do is average them. For instance, in my simple example here, the “average” response to the question is 1.97. If you can tell me what that means, I’d love to know. Because that sounds like gibberish to me!</p>
<p>###Interval scale</p>
<p>In contrast to nominal and ordinal scale variables, <strong><em>interval scale</em></strong> and ratio scale variables are variables for which the numerical value is genuinely meaningful. In the case of interval scale variables, the <em>differences</em> between the numbers are interpretable, but the variable doesn’t have a “natural” zero value. A good example of an interval scale variable is measuring temperature in degrees celsius. For instance, if it was 15<span class="math inline">\(^\circ\)</span> yesterday and 18<span class="math inline">\(^\circ\)</span> today, then the 3<span class="math inline">\(^\circ\)</span> difference between the two is genuinely meaningful. Moreover, that 3<span class="math inline">\(^\circ\)</span> difference is <em>exactly the same</em> as the 3<span class="math inline">\(^\circ\)</span> difference between 7<span class="math inline">\(^\circ\)</span> and 10<span class="math inline">\(^\circ\)</span>. In short, addition and subtraction are meaningful for interval scale variables.<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a></p>
<p>However, notice that the 0<span class="math inline">\(^\circ\)</span> does not mean “no temperature at all”: it actually means “the temperature at which water freezes”, which is pretty arbitrary. As a consequence, it becomes pointless to try to multiply and divide temperatures. It is wrong to say that <span class="math inline">\(20^\circ\)</span> is <em>twice as hot</em> as 10<span class="math inline">\(^\circ\)</span>, just as it is weird and meaningless to try to claim that 20<span class="math inline">\(^\circ\)</span> is negative two times as hot as -10<span class="math inline">\(^\circ\)</span>.</p>
<p>Again, lets look at a more psychological example. Suppose I’m interested in looking at how the attitudes of first-year university students have changed over time. Obviously, I’m going to want to record the year in which each student started. This is an interval scale variable. A student who started in 2003 did arrive 5 years before a student who started in 2008. However, it would be completely insane for me to divide 2008 by 2003 and say that the second student started “1.0024 times later” than the first one. That doesn’t make any sense at all.</p>
<p>###Ratio scale</p>
<p>The fourth and final type of variable to consider is a <strong><em>ratio scale</em></strong> variable, in which zero really means zero, and it’s okay to multiply and divide. A good psychological example of a ratio scale variable is response time (RT). In a lot of tasks it’s very common to record the amount of time somebody takes to solve a problem or answer a question, because it’s an indicator of how difficult the task is. Suppose that Alan takes 2.3 seconds to respond to a question, whereas Ben takes 3.1 seconds. As with an interval scale variable, addition and subtraction are both meaningful here. Ben really did take 3.1 - 2.3 = 0.8 seconds longer than Alan did. However, notice that multiplication and division also make sense here too: Ben took 3.1 / 2.3 = 1.35 times as long as Alan did to answer the question. And the reason why you can do this is that, for a ratio scale variable such as RT, “zero seconds” really does mean “no time at all”.</p>
<div id="continuousdiscrete" class="section level3">
<h3><span class="header-section-number">2.0.1</span> Continuous versus discrete variables</h3>
<p>There’s a second kind of distinction that you need to be aware of, regarding what types of variables you can run into. This is the distinction between continuous variables and discrete variables. The difference between these is as follows:</p>
<ul>
<li>A <strong><em>continuous variable</em></strong> is one in which, for any two values that you can think of, it’s always logically possible to have another value in between.</li>
<li>A <strong><em>discrete variable</em></strong> is, in effect, a variable that isn’t continuous. For a discrete variable, it’s sometimes the case that there’s nothing in the middle.</li>
</ul>
<p>These definitions probably seem a bit abstract, but they’re pretty simple once you see some examples. For instance, response time is continuous. If Alan takes 3.1 seconds and Ben takes 2.3 seconds to respond to a question, then it’s possible for Cameron’s response time to lie in between, by taking 3.0 seconds. And of course it would also be possible for David to take 3.031 seconds to respond, meaning that his RT would lie in between Cameron’s and Alan’s. And while in practice it might be impossible to measure RT that precisely, it’s certainly possible in principle. Because we can always find a new value for RT in between any two other ones, we say that RT is continuous.</p>
<p>Discrete variables occur when this rule is violated. For example, nominal scale variables are always discrete: there isn’t a type of transportation that falls “in between” trains and bicycles, not in the strict mathematical way that 2.3 falls in between 2 and 3. So transportation type is discrete. Similarly, ordinal scale variables are always discrete: although “2nd place” does fall between “1st place” and “3rd place”, there’s nothing that can logically fall in between “1st place” and “2nd place”. Interval scale and ratio scale variables can go either way. As we saw above, response time (a ratio scale variable) is continuous. Temperature in degrees celsius (an interval scale variable) is also continuous. However, the year you went to school (an interval scale variable) is discrete. There’s no year in between 2002 and 2003. The number of questions you get right on a true-or-false test (a ratio scale variable) is also discrete: since a true-or-false question doesn’t allow you to be “partially correct”, there’s nothing in between 5/10 and 6/10. Table @ref(tab:scalescont) summarises the relationship between the scales of measurement and the discrete/continuity distinction. Cells with a tick mark correspond to things that are possible. I’m trying to hammer this point home, because (a) some textbooks get this wrong, and (b) people very often say things like “discrete variable” when they mean “nominal scale variable”. It’s very unfortunate.</p>
<table>
<caption>(#tab:scalescont)The relationship between the scales of measurement and the discrete/continuity distinction. Cells with a tick mark correspond to things that are possible.</caption>
<tbody>
<tr class="odd">
<td></td>
<td align="center">continuous</td>
<td align="center">discrete</td>
</tr>
<tr class="even">
<td>nominal</td>
<td align="center"></td>
<td align="center"><span class="math inline">\(\checkmark\)</span></td>
</tr>
<tr class="odd">
<td>ordinal</td>
<td align="center"></td>
<td align="center"><span class="math inline">\(\checkmark\)</span></td>
</tr>
<tr class="even">
<td>interval</td>
<td align="center"><span class="math inline">\(\checkmark\)</span></td>
<td align="center"><span class="math inline">\(\checkmark\)</span></td>
</tr>
<tr class="odd">
<td>ratio</td>
<td align="center"><span class="math inline">\(\checkmark\)</span></td>
<td align="center"><span class="math inline">\(\checkmark\)</span></td>
</tr>
</tbody>
</table>
<p>###Some complexities</p>
<p>Okay, I know you’re going to be shocked to hear this, but … the real world is much messier than this little classification scheme suggests. Very few variables in real life actually fall into these nice neat categories, so you need to be kind of careful not to treat the scales of measurement as if they were hard and fast rules. It doesn’t work like that: they’re guidelines, intended to help you think about the situations in which you should treat different variables differently. Nothing more.</p>
<p>So let’s take a classic example, maybe <em>the</em> classic example, of a psychological measurement tool: the <strong><em>Likert scale</em></strong>. The humble Likert scale is the bread and butter tool of all survey design. You yourself have filled out hundreds, maybe thousands of them, and odds are you’ve even used one yourself. Suppose we have a survey question that looks like this:</p>
<blockquote>
<p>Which of the following best describes your opinion of the statement that “all pirates are freaking awesome” …</p>
</blockquote>
<p>and then the options presented to the participant are these:</p>
<blockquote>
<ol style="list-style-type: decimal">
<li>Strongly disagree</li>
<li>Disagree</li>
<li>Neither agree nor disagree</li>
<li>Agree</li>
<li>Strongly agree</li>
</ol>
</blockquote>
<p>This set of items is an example of a 5-point Likert scale: people are asked to choose among one of several (in this case 5) clearly ordered possibilities, generally with a verbal descriptor given in each case. However, it’s not necessary that all items be explicitly described. This is a perfectly good example of a 5-point Likert scale too:</p>
<blockquote>
<ol style="list-style-type: decimal">
<li>Strongly disagree</li>
<li></li>
<li></li>
<li></li>
<li>Strongly agree</li>
</ol>
</blockquote>
<p>Likert scales are very handy, if somewhat limited, tools. The question is, what kind of variable are they? They’re obviously discrete, since you can’t give a response of 2.5. They’re obviously not nominal scale, since the items are ordered; and they’re not ratio scale either, since there’s no natural zero.</p>
<p>But are they ordinal scale or interval scale? One argument says that we can’t really prove that the difference between “strongly agree” and “agree” is of the same size as the difference between “agree” and “neither agree nor disagree”. In fact, in everyday life it’s pretty obvious that they’re not the same at all. So this suggests that we ought to treat Likert scales as ordinal variables. On the other hand, in practice most participants do seem to take the whole “on a scale from 1 to 5” part fairly seriously, and they tend to act as if the differences between the five response options were fairly similar to one another. As a consequence, a lot of researchers treat Likert scale data as if it were interval scale. It’s not interval scale, but in practice it’s close enough that we usually think of it as being <strong><em>quasi-interval scale</em></strong>.</p>
<p>##Assessing the reliability of a measurement{#reliability}</p>
<p>At this point we’ve thought a little bit about how to operationalise a theoretical construct and thereby create a psychological measure; and we’ve seen that by applying psychological measures we end up with variables, which can come in many different types. At this point, we should start discussing the obvious question: is the measurement any good? We’ll do this in terms of two related ideas: <em>reliability</em> and <em>validity</em>. Put simply, the <strong><em>reliability</em></strong> of a measure tells you how <em>precisely</em> you are measuring something, whereas the validity of a measure tells you how <em>accurate</em> the measure is. In this section I’ll talk about reliability; we’ll talk about validity in the next chapter.</p>
<p>Reliability is actually a very simple concept: it refers to the repeatability or consistency of your measurement. The measurement of my weight by means of a “bathroom scale” is very reliable: if I step on and off the scales over and over again, it’ll keep giving me the same answer. Measuring my intelligence by means of “asking my mum” is very unreliable: some days she tells me I’m a bit thick, and other days she tells me I’m a complete moron. Notice that this concept of reliability is different to the question of whether the measurements are correct (the correctness of a measurement relates to it’s validity). If I’m holding a sack of potatos when I step on and off of the bathroom scales, the measurement will still be reliable: it will always give me the same answer. However, this highly reliable answer doesn’t match up to my true weight at all, therefore it’s wrong. In technical terms, this is a <em>reliable but invalid</em> measurement. Similarly, while my mum’s estimate of my intelligence is a bit unreliable, she might be right. Maybe I’m just not too bright, and so while her estimate of my intelligence fluctuates pretty wildly from day to day, it’s basically right. So that would be an <em>unreliable but valid</em> measure. Of course, to some extent, notice that if my mum’s estimates are too unreliable, it’s going to be very hard to figure out which one of her many claims about my intelligence is actually the right one. To some extent, then, a very unreliable measure tends to end up being invalid for practical purposes; so much so that many people would say that reliability is necessary (but not sufficient) to ensure validity.</p>
<p>Okay, now that we’re clear on the distinction between reliability and validity, let’s have a think about the different ways in which we might measure reliability:</p>
<ul>
<li><strong><em>Test-retest reliability</em></strong>. This relates to consistency over time: if we repeat the measurement at a later date, do we get a the same answer?</li>
<li><strong><em>Inter-rater reliability</em></strong>. This relates to consistency across people: if someone else repeats the measurement (e.g., someone else rates my intelligence) will they produce the same answer?</li>
<li><strong><em>Parallel forms reliability</em></strong>. This relates to consistency across theoretically-equivalent measurements: if I use a different set of bathroom scales to measure my weight, does it give the same answer?</li>
<li><strong><em>Internal consistency reliability</em></strong>. If a measurement is constructed from lots of different parts that perform similar functions (e.g., a personality questionnaire result is added up across several questions) do the individual parts tend to give similar answers.</li>
</ul>
<p>Not all measurements need to possess all forms of reliability. For instance, educational assessment can be thought of as a form of measurement. One of the subjects that I teach, <em>Computational Cognitive Science</em>, has an assessment structure that has a research component and an exam component (plus other things). The exam component is <em>intended</em> to measure something different from the research component, so the assessment as a whole has low internal consistency. However, within the exam there are several questions that are intended to (approximately) measure the same things, and those tend to produce similar outcomes; so the exam on its own has a fairly high internal consistency. Which is as it should be. You should only demand reliability in those situations where you want to be measure the same thing!</p>
<p>##The “role” of variables: predictors and outcomes{#ivdv}</p>
<p>Okay, I’ve got one last piece of terminology that I need to explain to you before moving away from variables. Normally, when we do some research we end up with lots of different variables. Then, when we analyse our data we usually try to explain some of the variables in terms of some of the other variables. It’s important to keep the two roles “thing doing the explaining” and “thing being explained” distinct. So let’s be clear about this now. Firstly, we might as well get used to the idea of using mathematical symbols to describe variables, since it’s going to happen over and over again. Let’s denote the “to be explained” variable <span class="math inline">\(Y\)</span>, and denote the variables “doing the explaining” as <span class="math inline">\(X_1\)</span>, <span class="math inline">\(X_2\)</span>, etc.</p>
<p>Now, when we doing an analysis, we have different names for <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, since they play different roles in the analysis. The classical names for these roles are <strong><em>independent variable</em></strong> (IV) and <strong><em>dependent variable</em></strong> (DV). The IV is the variable that you use to do the explaining (i.e., <span class="math inline">\(X\)</span>) and the DV is the variable being explained (i.e., <span class="math inline">\(Y\)</span>). The logic behind these names goes like this: if there really is a relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> then we can say that <span class="math inline">\(Y\)</span> depends on <span class="math inline">\(X\)</span>, and if we have designed our study “properly” then <span class="math inline">\(X\)</span> isn’t dependent on anything else. However, I personally find those names horrible: they’re hard to remember and they’re highly misleading, because (a) the IV is never actually “independent of everything else” and (b) if there’s no relationship, then the DV doesn’t actually depend on the IV. And in fact, because I’m not the only person who thinks that IV and DV are just awful names, there are a number of alternatives that I find more appealing. The terms that I’ll use in these notes are <strong><em>predictors</em></strong> and <strong><em>outcomes</em></strong>. The idea here is that what you’re trying to do is use <span class="math inline">\(X\)</span> (the predictors) to make guesses about <span class="math inline">\(Y\)</span> (the outcomes).<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a> This is summarised in Table @ref(tab:ivdv).</p>
<table>
<caption>(#tab:ivdv)The terminology used to distinguish between different roles that a variable can play when analysing a data set. Note that this book will tend to avoid the classical terminology in favour of the newer names.</caption>
<thead>
<tr class="header">
<th align="left">role of the variable</th>
<th align="left">classical name</th>
<th align="left">modern name</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">to be explained</td>
<td align="left">dependent variable (DV)</td>
<td align="left">outcome</td>
</tr>
<tr class="even">
<td align="left">to do the explaining</td>
<td align="left">independent variable (IV)</td>
<td align="left">predictor</td>
</tr>
</tbody>
</table>
<p>##Experimental and non-experimental research{#researchdesigns}</p>
<p>One of the big distinctions that you should be aware of is the distinction between “experimental research” and “non-experimental research”. When we make this distinction, what we’re really talking about is the degree of control that the researcher exercises over the people and events in the study.</p>
<p>###Experimental research</p>
<p>The key features of <strong><em>experimental research</em></strong> is that the researcher controls all aspects of the study, especially what participants experience during the study. In particular, the researcher manipulates or varies the predictor variables (IVs), and then allows the outcome variable (DV) to vary naturally. The idea here is to deliberately vary the predictors (IVs) to see if they have any causal effects on the outcomes. Moreover, in order to ensure that there’s no chance that something other than the predictor variables is causing the outcomes, everything else is kept constant or is in some other way “balanced” to ensure that they have no effect on the results. In practice, it’s almost impossible to <em>think</em> of everything else that might have an influence on the outcome of an experiment, much less keep it constant. The standard solution to this is <strong><em>randomisation</em></strong>: that is, we randomly assign people to different groups, and then give each group a different treatment (i.e., assign them different values of the predictor variables). We’ll talk more about randomisation later in this course, but for now, it’s enough to say that what randomisation does is minimise (but not eliminate) the chances that there are any systematic difference between groups.</p>
<p>Let’s consider a very simple, completely unrealistic and grossly unethical example. Suppose you wanted to find out if smoking causes lung cancer. One way to do this would be to find people who smoke and people who don’t smoke, and look to see if smokers have a higher rate of lung cancer. This is <em>not</em> a proper experiment, since the researcher doesn’t have a lot of control over who is and isn’t a smoker. And this really matters: for instance, it might be that people who choose to smoke cigarettes also tend to have poor diets, or maybe they tend to work in asbestos mines, or whatever. The point here is that the groups (smokers and non-smokers) actually differ on lots of things, not <em>just</em> smoking. So it might be that the higher incidence of lung cancer among smokers is caused by something else, not by smoking per se. In technical terms, these other things (e.g. diet) are called “confounds”, and we’ll talk about those in just a moment.</p>
<p>In the meantime, let’s now consider what a proper experiment might look like. Recall that our concern was that smokers and non-smokers might differ in lots of ways. The solution, as long as you have no ethics, is to <em>control</em> who smokes and who doesn’t. Specifically, if we randomly divide participants into two groups, and force half of them to become smokers, then it’s very unlikely that the groups will differ in any respect other than the fact that half of them smoke. That way, if our smoking group gets cancer at a higher rate than the non-smoking group, then we can feel pretty confident that (a) smoking does cause cancer and (b) we’re murderers.</p>
<p>###Non-experimental research</p>
<p><strong><em>Non-experimental research</em></strong> is a broad term that covers “any study in which the researcher doesn’t have quite as much control as they do in an experiment”. Obviously, control is something that scientists like to have, but as the previous example illustrates, there are lots of situations in which you can’t or shouldn’t try to obtain that control. Since it’s grossly unethical (and almost certainly criminal) to force people to smoke in order to find out if they get cancer, this is a good example of a situation in which you really shouldn’t try to obtain experimental control. But there are other reasons too. Even leaving aside the ethical issues, our “smoking experiment” does have a few other issues. For instance, when I suggested that we “force” half of the people to become smokers, I must have been talking about <em>starting</em> with a sample of non-smokers, and then forcing them to become smokers. While this sounds like the kind of solid, evil experimental design that a mad scientist would love, it might not be a very sound way of investigating the effect in the real world. For instance, suppose that smoking only causes lung cancer when people have poor diets, and suppose also that people who normally smoke do tend to have poor diets. However, since the “smokers” in our experiment aren’t “natural” smokers (i.e., we forced non-smokers to become smokers; they didn’t take on all of the other normal, real life characteristics that smokers might tend to possess) they probably have better diets. As such, in this silly example they wouldn’t get lung cancer, and our experiment will fail, because it violates the structure of the “natural” world (the technical name for this is an “artifactual” result; see later).</p>
<p>One distinction worth making between two types of non-experimental research is the difference between <strong><em>quasi-experimental research</em></strong> and <strong><em>case studies</em></strong>. The example I discussed earlier – in which we wanted to examine incidence of lung cancer among smokers and non-smokers, without trying to control who smokes and who doesn’t – is a quasi-experimental design. That is, it’s the same as an experiment, but we don’t control the predictors (IVs). We can still use statistics to analyse the results, it’s just that we have to be a lot more careful.</p>
<p>The alternative approach, case studies, aims to provide a very detailed description of one or a few instances. In general, you can’t use statistics to analyse the results of case studies, and it’s usually very hard to draw any general conclusions about “people in general” from a few isolated examples. However, case studies are very useful in some situations. Firstly, there are situations where you don’t have any alternative: neuropsychology has this issue a lot. Sometimes, you just can’t find a lot of people with brain damage in a specific area, so the only thing you can do is describe those cases that you do have in as much detail and with as much care as you can. However, there’s also some genuine advantages to case studies: because you don’t have as many people to study, you have the ability to invest lots of time and effort trying to understand the specific factors at play in each case. This is a very valuable thing to do. As a consequence, case studies can complement the more statistically-oriented approaches that you see in experimental and quasi-experimental designs. We won’t talk much about case studies in these lectures, but they are nevertheless very valuable tools!</p>
<p>##Assessing the validity of a study{#validity}</p>
<p>More than any other thing, a scientist wants their research to be “valid”. The conceptual idea behind <strong><em>validity</em></strong> is very simple: can you trust the results of your study? If not, the study is invalid. However, while it’s easy to state, in practice it’s much harder to check validity than it is to check reliability. And in all honesty, there’s no precise, clearly agreed upon notion of what validity actually is. In fact, there’s lots of different kinds of validity, each of which raises it’s own issues, and not all forms of validity are relevant to all studies. I’m going to talk about five different types:</p>
<ul>
<li>Internal validity</li>
<li>External validity</li>
<li>Construct validity</li>
<li>Face validity</li>
<li>Ecological validity</li>
</ul>
<p>To give you a quick guide as to what matters here… (1) Internal and external validity are the most important, since they tie directly to the fundamental question of whether your study really works. (2) Construct validity asks whether you’re measuring what you think you are. (3) Face validity isn’t terribly important except insofar as you care about “appearances”. (4) Ecological validity is a special case of face validity that corresponds to a kind of appearance that you might care about a lot.</p>
<p>###Internal validity</p>
<p><strong><em>Internal validity</em></strong> refers to the extent to which you are able draw the correct conclusions about the causal relationships between variables. It’s called “internal” because it refers to the relationships between things “inside” the study. Let’s illustrate the concept with a simple example. Suppose you’re interested in finding out whether a university education makes you write better. To do so, you get a group of first year students, ask them to write a 1000 word essay, and count the number of spelling and grammatical errors they make. Then you find some third-year students, who obviously have had more of a university education than the first-years, and repeat the exercise. And let’s suppose it turns out that the third-year students produce fewer errors. And so you conclude that a university education improves writing skills. Right? Except… the big problem that you have with this experiment is that the third-year students are older, and they’ve had more experience with writing things. So it’s hard to know for sure what the causal relationship is: Do older people write better? Or people who have had more writing experience? Or people who have had more education? Which of the above is the true <em>cause</em> of the superior performance of the third-years? Age? Experience? Education? You can’t tell. This is an example of a failure of internal validity, because your study doesn’t properly tease apart the <em>causal</em> relationships between the different variables.</p>
<p>###External validity</p>
<p><strong><em>External validity</em></strong> relates to the <strong><em>generalisability</em></strong> of your findings. That is, to what extent do you expect to see the same pattern of results in “real life” as you saw in your study. To put it a bit more precisely, any study that you do in psychology will involve a fairly specific set of questions or tasks, will occur in a specific environment, and will involve participants that are drawn from a particular subgroup. So, if it turns out that the results don’t actually generalise to people and situations beyond the ones that you studied, then what you’ve got is a lack of external validity.</p>
<p>The classic example of this issue is the fact that a very large proportion of studies in psychology will use undergraduate psychology students as the participants. Obviously, however, the researchers don’t care <em>only</em> about psychology students; they care about people in general. Given that, a study that uses only psych students as participants always carries a risk of lacking external validity. That is, if there’s something “special” about psychology students that makes them different to the general populace in some <em>relevant</em> respect, then we may start worrying about a lack of external validity.</p>
<p>That said, it is absolutely critical to realise that a study that uses only psychology students does not necessarily have a problem with external validity. I’ll talk about this again later, but it’s such a common mistake that I’m going to mention it here. The external validity is threatened by the choice of population if (a) the population from which you sample your participants is very narrow (e.g., psych students), and (b) the narrow population that you sampled from is systematically different from the general population, <em>in some respect that is relevant to the psychological phenomenon that you intend to study</em>. The italicised part is the bit that lots of people forget: it is true that psychology undergraduates differ from the general population in lots of ways, and so a study that uses only psych students <em>may</em> have problems with external validity. However, if those differences aren’t very relevant to the phenomenon that you’re studying, then there’s nothing to worry about. To make this a bit more concrete, here’s two extreme examples:</p>
<ul>
<li>You want to measure “attitudes of the general public towards psychotherapy”, but all of your participants are psychology students. This study would almost certainly have a problem with external validity.</li>
<li>You want to measure the effectiveness of a visual illusion, and your participants are all psychology students. This study is very unlikely to have a problem with external validity</li>
</ul>
<p>Having just spent the last couple of paragraphs focusing on the choice of participants (since that’s the big issue that everyone tends to worry most about), it’s worth remembering that external validity is a broader concept. The following are also examples of things that might pose a threat to external validity, depending on what kind of study you’re doing:</p>
<ul>
<li>People might answer a “psychology questionnaire” in a manner that doesn’t reflect what they would do in real life.</li>
<li>Your lab experiment on (say) “human learning” has a different structure to the learning problems people face in real life.</li>
</ul>
<p>###Construct validity</p>
<p><strong><em>Construct validity</em></strong> is basically a question of whether you’re measuring what you want to be measuring. A measurement has good construct validity if it is actually measuring the correct theoretical construct, and bad construct validity if it doesn’t. To give very simple (if ridiculous) example, suppose I’m trying to investigate the rates with which university students cheat on their exams. And the way I attempt to measure it is by asking the cheating students to stand up in the lecture theatre so that I can count them. When I do this with a class of 300 students, 0 people claim to be cheaters. So I therefore conclude that the proportion of cheaters in my class is 0%. Clearly this is a bit ridiculous. But the point here is not that this is a very deep methodological example, but rather to explain what construct validity is. The problem with my measure is that while I’m <em>trying</em> to measure “the proportion of people who cheat” what I’m actually measuring is “the proportion of people stupid enough to own up to cheating, or bloody minded enough to pretend that they do”. Obviously, these aren’t the same thing! So my study has gone wrong, because my measurement has very poor construct validity.</p>
<p>###Face validity</p>
<p><strong><em>Face validity</em></strong> simply refers to whether or not a measure “looks like” it’s doing what it’s supposed to, nothing more. If I design a test of intelligence, and people look at it and they say “no, that test doesn’t measure intelligence”, then the measure lacks face validity. It’s as simple as that. Obviously, face validity isn’t very important from a pure scientific perspective. After all, what we care about is whether or not the measure <em>actually</em> does what it’s supposed to do, not whether it <em>looks like</em> it does what it’s supposed to do. As a consequence, we generally don’t care very much about face validity. That said, the concept of face validity serves three useful pragmatic purposes:</p>
<ul>
<li>Sometimes, an experienced scientist will have a “hunch” that a particular measure won’t work. While these sorts of hunches have no strict evidentiary value, it’s often worth paying attention to them. Because often times people have knowledge that they can’t quite verbalise, so there might be something to worry about even if you can’t quite say why. In other words, when someone you trust criticises the face validity of your study, it’s worth taking the time to think more carefully about your design to see if you can think of reasons why it might go awry. Mind you, if you don’t find any reason for concern, then you should probably not worry: after all, face validity really doesn’t matter much.</li>
<li>Often (very often), completely uninformed people will also have a “hunch” that your research is crap. And they’ll criticise it on the internet or something. On close inspection, you’ll often notice that these criticisms are actually focused entirely on how the study “looks”, but not on anything deeper. The concept of face validity is useful for gently explaining to people that they need to substantiate their arguments further.</li>
<li>Expanding on the last point, if the beliefs of untrained people are critical (e.g., this is often the case for applied research where you actually want to convince policy makers of something or other) then you <em>have</em> to care about face validity. Simply because – whether you like it or not – a lot of people will use face validity as a proxy for real validity. If you want the government to change a law on scientific, psychological grounds, then it won’t matter how good your studies “really” are. If they lack face validity, you’ll find that politicians ignore you. Of course, it’s somewhat unfair that policy often depends more on appearance than fact, but that’s how things go.</li>
</ul>
<p>###Ecological validity</p>
<p><strong><em>Ecological validity</em></strong> is a different notion of validity, which is similar to external validity, but less important. The idea is that, in order to be ecologically valid, the entire set up of the study should closely approximate the real world scenario that is being investigated. In a sense, ecological validity is a kind of face validity – it relates mostly to whether the study “looks” right, but with a bit more rigour to it. To be ecologically valid, the study has to look right in a fairly specific way. The idea behind it is the intuition that a study that is ecologically valid is more likely to be externally valid. It’s no guarantee, of course. But the nice thing about ecological validity is that it’s much easier to check whether a study is ecologically valid than it is to check whether a study is externally valid. An simple example would be eyewitness identification studies. Most of these studies tend to be done in a university setting, often with fairly simple array of faces to look at rather than a line up. The length of time between seeing the “criminal” and being asked to identify the suspect in the “line up” is usually shorter. The “crime” isn’t real, so there’s no chance that the witness being scared, and there’s no police officers present, so there’s not as much chance of feeling pressured. These things all mean that the study <em>definitely</em> lacks ecological validity. They might (but might not) mean that it also lacks external validity.</p>
<p>##Confounds, artifacts and other threats to validity</p>
<p>If we look at the issue of validity in the most general fashion, the two biggest worries that we have are <em>confounds</em> and <em>artifact</em>. These two terms are defined in the following way:</p>
<ul>
<li><strong><em>Confound</em></strong>: A confound is an additional, often unmeasured variable<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a> that turns out to be related to both the predictors and the outcomes. The existence of confounds threatens the internal validity of the study because you can’t tell whether the predictor causes the outcome, or if the confounding variable causes it, etc.</li>
<li><strong><em>Artifact</em></strong>: A result is said to be “artifactual” if it only holds in the special situation that you happened to test in your study. The possibility that your result is an artifact describes a threat to your external validity, because it raises the possibility that you can’t generalise your results to the actual population that you care about.</li>
</ul>
<p>As a general rule confounds are a bigger concern for non-experimental studies, precisely because they’re not proper experiments: by definition, you’re leaving lots of things uncontrolled, so there’s a lot of scope for confounds working their way into your study. Experimental research tends to be much less vulnerable to confounds: the more control you have over what happens during the study, the more you can prevent confounds from appearing.</p>
<p>However, there’s always swings and roundabouts, and when we start thinking about artifacts rather than confounds, the shoe is very firmly on the other foot. For the most part, artifactual results tend to be a concern for experimental studies than for non-experimental studies. To see this, it helps to realise that the reason that a lot of studies are non-experimental is precisely because what the researcher is trying to do is examine human behaviour in a more naturalistic context. By working in a more real-world context, you lose experimental control (making yourself vulnerable to confounds) but because you tend to be studying human psychology “in the wild” you reduce the chances of getting an artifactual result. Or, to put it another way, when you take psychology out of the wild and bring it into the lab (which we usually have to do to gain our experimental control), you always run the risk of accidentally studying something different than you wanted to study: which is more or less the definition of an artifact.</p>
<p>Be warned though: the above is a rough guide only. It’s absolutely possible to have confounds in an experiment, and to get artifactual results with non-experimental studies. This can happen for all sorts of reasons, not least of which is researcher error. In practice, it’s really hard to think everything through ahead of time, and even very good researchers make mistakes. But other times it’s unavoidable, simply because the researcher has ethics (e.g., see @ref(differentialattrition)).</p>
<p>Okay. There’s a sense in which almost any threat to validity can be characterised as a confound or an artifact: they’re pretty vague concepts. So let’s have a look at some of the most common examples…</p>
<p>###History effects</p>
<p><strong><em>History effects</em></strong> refer to the possibility that specific events may occur during the study itself that might influence the outcomes. For instance, something might happen in between a pre-test and a post-test. Or, in between testing participant 23 and participant 24. Alternatively, it might be that you’re looking at an older study, which was perfectly valid for its time, but the world has changed enough since then that the conclusions are no longer trustworthy. Examples of things that would count as history effects:</p>
<ul>
<li>You’re interested in how people think about risk and uncertainty. You started your data collection in December 2010. But finding participants and collecting data takes time, so you’re still finding new people in February 2011. Unfortunately for you (and even more unfortunately for others), the Queensland floods occurred in January 2011, causing billions of dollars of damage and killing many people. Not surprisingly, the people tested in February 2011 express quite different beliefs about handling risk than the people tested in December 2010. Which (if any) of these reflects the “true” beliefs of participants? I think the answer is probably both: the Queensland floods genuinely changed the beliefs of the Australian public, though possibly only temporarily. The key thing here is that the “history” of the people tested in February is quite different to people tested in December.</li>
<li>You’re testing the psychological effects of a new anti-anxiety drug. So what you do is measure anxiety before administering the drug (e.g., by self-report, and taking physiological measures, let’s say), then you administer the drug, and then you take the same measures afterwards. In the middle, however, because your labs are in Los Angeles, there’s an earthquake, which increases the anxiety of the participants.</li>
</ul>
<p>###Maturation effects</p>
<p>As with history effects, <strong><em>maturational effects</em></strong> are fundamentally about change over time. However, maturation effects aren’t in response to specific events. Rather, they relate to how people change on their own over time: we get older, we get tired, we get bored, etc. Some examples of maturation effects:</p>
<ul>
<li>When doing developmental psychology research, you need to be aware that children grow up quite rapidly. So, suppose that you want to find out whether some educational trick helps with vocabulary size among 3 year olds. One thing that you need to be aware of is that the vocabulary size of children that age is growing at an incredible rate (multiple words per day), all on its own. If you design your study without taking this maturational effect into account, then you won’t be able to tell if your educational trick works.</li>
<li>When running a very long experiment in the lab (say, something that goes for 3 hours), it’s very likely that people will begin to get bored and tired, and that this maturational effect will cause performance to decline, regardless of anything else going on in the experiment</li>
</ul>
<p>###Repeated testing effects</p>
<p>An important type of history effect is the effect of <strong><em>repeated testing</em></strong>. Suppose I want to take two measurements of some psychological construct (e.g., anxiety). One thing I might be worried about is if the first measurement has an effect on the second measurement. In other words, this is a history effect in which the “event” that influences the second measurement is the first measurement itself! This is not at all uncommon. Examples of this include:</p>
<ul>
<li><em>Learning and practice</em>: e.g., “intelligence” at time 2 might appear to go up relative to time 1 because participants learned the general rules of how to solve “intelligence-test-style” questions during the first testing session.<br />
</li>
<li><em>Familiarity with the testing situation</em>: e.g., if people are nervous at time 1, this might make performance go down; after sitting through the first testing situation, they might calm down a lot precisely because they’ve seen what the testing looks like.</li>
<li><em>Auxiliary changes caused by testing</em>: e.g., if a questionnaire assessing mood is boring, then mood at measurement at time 2 is more likely to become “bored”, precisely because of the boring measurement made at time 1.</li>
</ul>
<p>###Selection bias</p>
<p><strong><em>Selection bias</em></strong> is a pretty broad term. Suppose that you’re running an experiment with two groups of participants, where each group gets a different “treatment”, and you want to see if the different treatments lead to different outcomes. However, suppose that, despite your best efforts, you’ve ended up with a gender imbalance across groups (say, group A has 80% females and group B has 50% females). It might sound like this could never happen, but trust me, it can. This is an example of a selection bias, in which the people “selected into” the two groups have different characteristics. If any of those characteristics turns out to be relevant (say, your treatment works better on females than males) then you’re in a lot of trouble.</p>
<p>###Differential attrition{#differentialattrition}</p>
<p>One quite subtle danger to be aware of is called <strong><em>differential attrition</em></strong>, which is a kind of selection bias that is caused by the study itself. Suppose that, for the first time ever in the history of psychology, I manage to find the perfectly balanced and representative sample of people. I start running “Dan’s incredibly long and tedious experiment” on my perfect sample, but then, because my study is incredibly long and tedious, lots of people start dropping out. I can’t stop this: as we’ll discuss later in the chapter on research ethics, participants absolutely have the right to stop doing any experiment, any time, for whatever reason they feel like, and as researchers we are morally (and professionally) obliged to remind people that they do have this right. So, suppose that “Dan’s incredibly long and tedious experiment” has a very high drop out rate. What do you suppose the odds are that this drop out is random? Answer: zero. Almost certainly, the people who remain are more conscientious, more tolerant of boredom etc than those that leave. To the extent that (say) conscientiousness is relevant to the psychological phenomenon that I care about, this attrition can decrease the validity of my results.</p>
<p>When thinking about the effects of differential attrition, it is sometimes helpful to distinguish between two different types. The first is <strong><em>homogeneous attrition</em></strong>, in which the attrition effect is the same for all groups, treatments or conditions. In the example I gave above, the differential attrition would be homogeneous if (and only if) the easily bored participants are dropping out of all of the conditions in my experiment at about the same rate. In general, the main effect of homogeneous attrition is likely to be that it makes your sample unrepresentative. As such, the biggest worry that you’ll have is that the generalisability of the results decreases: in other words, you lose external validity.</p>
<p>The second type of differential attrition is <strong><em>heterogeneous attrition</em></strong>, in which the attrition effect is different for different groups. This is a much bigger problem: not only do you have to worry about your external validity, you also have to worry about your internal validity too. To see why this is the case, let’s consider a very dumb study in which I want to see if insulting people makes them act in a more obedient way. Why anyone would actually want to study that I don’t know, but let’s suppose I really, deeply cared about this. So, I design my experiment with two conditions. In the “treatment” condition, the experimenter insults the participant and then gives them a questionnaire designed to measure obedience. In the “control” condition, the experimenter engages in a bit of pointless chitchat and then gives them the questionnaire. Leaving aside the questionable scientific merits and dubious ethics of such a study, let’s have a think about what might go wrong here. As a general rule, when someone insults me to my face, I tend to get much less co-operative. So, there’s a pretty good chance that a lot more people are going to drop out of the treatment condition than the control condition. And this drop out isn’t going to be random. The people most likely to drop out would probably be the people who don’t care all that much about the importance of obediently sitting through the experiment. Since the most bloody minded and disobedient people all left the treatment group but not the control group, we’ve introduced a confound: the people who actually took the questionnaire in the treatment group were <em>already</em> more likely to be dutiful and obedient than the people in the control group. In short, in this study insulting people doesn’t make them more obedient: it makes the more disobedient people leave the experiment! The internal validity of this experiment is completely shot.</p>
<p>###Non-response bias</p>
<p><strong><em>Non-response bias</em></strong> is closely related to selection bias, and to differential attrition. The simplest version of the problem goes like this. You mail out a survey to 1000 people, and only 300 of them reply. The 300 people who replied are almost certainly not a random subsample. People who respond to surveys are systematically different to people who don’t. This introduces a problem when trying to generalise from those 300 people who replied, to the population at large; since you now have a very non-random sample. The issue of non-response bias is more general than this, though. Among the (say) 300 people that did respond to the survey, you might find that not everyone answers every question. If (say) 80 people chose not to answer one of your questions, does this introduce problems? As always, the answer is maybe. If the question that wasn’t answered was on the last page of the questionnaire, and those 80 surveys were returned with the last page missing, there’s a good chance that the missing data isn’t a big deal: probably the pages just fell off. However, if the question that 80 people didn’t answer was the most confrontational or invasive personal question in the questionnaire, then almost certainly you’ve got a problem. In essence, what you’re dealing with here is what’s called the problem of <strong><em>missing data</em></strong>. If the data that is missing was “lost” randomly, then it’s not a big problem. If it’s missing systematically, then it can be a big problem.</p>
<p>###Regression to the mean</p>
<p><strong><em>Regression to the mean</em></strong> is a curious variation on selection bias. It refers to any situation where you select data based on an extreme value on some measure. Because the measure has natural variation, it almost certainly means that when you take a subsequent measurement, that later measurement will be less extreme than the first one, purely by chance.</p>
<p>Here’s an example. Suppose I’m interested in whether a psychology education has an adverse effect on very smart kids. To do this, I find the 20 psych I students with the best high school grades and look at how well they’re doing at university. It turns out that they’re doing a lot better than average, but they’re not topping the class at university, even though they did top their classes at high school. What’s going on? The natural first thought is that this must mean that the psychology classes must be having an adverse effect on those students. However, while that might very well be the explanation, it’s more likely that what you’re seeing is an example of “regression to the mean”. To see how it works, let’s take a moment to think about what is required to get the best mark in a class, regardless of whether that class be at high school or at university. When you’ve got a big class, there are going to be <em>lots</em> of very smart people enrolled. To get the best mark you have to be very smart, work very hard, and be a bit lucky. The exam has to ask just the right questions for your idiosyncratic skills, and you have to not make any dumb mistakes (we all do that sometimes) when answering them. And that’s the thing: intelligence and hard work are transferrable from one class to the next. Luck isn’t. The people who got lucky in high school won’t be the same as the people who get lucky at university. That’s the very definition of “luck”. The consequence of this is that, when you select people at the very extreme values of one measurement (the top 20 students), you’re selecting for hard work, skill and luck. But because the luck doesn’t transfer to the second measurement (only the skill and work), these people will all be expected to drop a little bit when you measure them a second time (at university). So their scores fall back a little bit, back towards everyone else. This is regression to the mean.</p>
<p>Regression to the mean is surprisingly common. For instance, if two very tall people have kids, their children will tend to be taller than average, but not as tall as the parents. The reverse happens with very short parents: two very short parents will tend to have short children, but nevertheless those kids will tend to be taller than the parents. It can also be extremely subtle. For instance, there have been studies done that suggested that people learn better from negative feedback than from positive feedback. However, the way that people tried to show this was to give people positive reinforcement whenever they did good, and negative reinforcement when they did bad. And what you see is that after the positive reinforcement, people tended to do worse; but after the negative reinforcement they tended to do better. But! Notice that there’s a selection bias here: when people do very well, you’re selecting for “high” values, and so you should <em>expect</em> (because of regression to the mean) that performance on the next trial should be worse, regardless of whether reinforcement is given. Similarly, after a bad trial, people will tend to improve all on their own. The apparent superiority of negative feedback is an artifact caused by regression to the mean <span class="citation">(see Kahneman and Tversky <a href="#ref-Kahneman1973" role="doc-biblioref">1973</a> for discussion)</span>.</p>
<p>###Experimenter bias</p>
<p><strong><em>Experimenter bias</em></strong> can come in multiple forms. The basic idea is that the experimenter, despite the best of intentions, can accidentally end up influencing the results of the experiment by subtly communicating the “right answer” or the “desired behaviour” to the participants. Typically, this occurs because the experimenter has special knowledge that the participant does not – either the right answer to the questions being asked, or knowledge of the expected pattern of performance for the condition that the participant is in, and so on. The classic example of this happening is the case study of “Clever Hans”, which dates back to 1907 <span class="citation">(Pfungst <a href="#ref-Pfungst1911" role="doc-biblioref">1911</a>; Hothersall <a href="#ref-Hothersall2004" role="doc-biblioref">2004</a>)</span>. Clever Hans was a horse that apparently was able to read and count, and perform other human like feats of intelligence. After Clever Hans became famous, psychologists started examining his behaviour more closely. It turned out that – not surprisingly – Hans didn’t know how to do maths. Rather, Hans was responding to the human observers around him. Because they did know how to count, and the horse had learned to change its behaviour when people changed theirs.</p>
<p>The general solution to the problem of experimenter bias is to engage in double blind studies, where neither the experimenter nor the participant knows which condition the participant is in, or knows what the desired behaviour is. This provides a very good solution to the problem, but it’s important to recognise that it’s not quite ideal, and hard to pull off perfectly. For instance, the obvious way that I could try to construct a double blind study is to have one of my Ph.D. students (one who doesn’t know anything about the experiment) run the study. That feels like it should be enough. The only person (me) who knows all the details (e.g., correct answers to the questions, assignments of participants to conditions) has no interaction with the participants, and the person who does all the talking to people (the Ph.D. student) doesn’t know anything. Except, that last part is very unlikely to be true. In order for the Ph.D. student to run the study effectively, they need to have been briefed by me, the researcher. And, as it happens, the Ph.D. student also knows me, and knows a bit about my general beliefs about people and psychology (e.g., I tend to think humans are much smarter than psychologists give them credit for). As a result of all this, it’s almost impossible for the experimenter to avoid knowing a little bit about what expectations I have. And even a little bit of knowledge can have an effect: suppose the experimenter accidentally conveys the fact that the participants are expected to do well in this task. Well, there’s a thing called the “Pygmalion effect”: if you expect great things of people, they’ll rise to the occasion; but if you expect them to fail, they’ll do that too. In other words, the expectations become a self-fulfilling prophesy.</p>
<p>###Demand effects and reactivity</p>
<p>When talking about experimenter bias, the worry is that the experimenter’s knowledge or desires for the experiment are communicated to the participants, and that these effect people’s behaviour <span class="citation">(Rosenthal <a href="#ref-Rosenthal1966" role="doc-biblioref">1966</a>)</span>. However, even if you manage to stop this from happening, it’s almost impossible to stop people from knowing that they’re part of a psychological study. And the mere fact of knowing that someone is watching/studying you can have a pretty big effect on behaviour. This is generally referred to as <strong><em>reactivity</em></strong> or <strong><em>demand effects</em></strong>. The basic idea is captured by the Hawthorne effect: people alter their performance because of the attention that the study focuses on them. The effect takes its name from a the “Hawthorne Works” factory outside of Chicago <span class="citation">(see Adair <a href="#ref-Adair1984" role="doc-biblioref">1984</a>)</span>. A study done in the 1920s looking at the effects of lighting on worker productivity at the factory turned out to be an effect of the fact that the workers knew they were being studied, rather than the lighting.</p>
<p>To get a bit more specific about some of the ways in which the mere fact of being in a study can change how people behave, it helps to think like a social psychologist and look at some of the <em>roles</em> that people might adopt during an experiment, but might not adopt if the corresponding events were occurring in the real world:</p>
<ul>
<li>The <em>good participant</em> tries to be too helpful to the researcher: he or she seeks to figure out the experimenter’s hypotheses and confirm them.</li>
<li>The <em>negative participant</em> does the exact opposite of the good participant: he or she seeks to break or destroy the study or the hypothesis in some way.</li>
<li>The <em>faithful participant</em> is unnaturally obedient: he or she seeks to follow instructions perfectly, regardless of what might have happened in a more realistic setting.</li>
<li>The <em>apprehensive participant</em> gets nervous about being tested or studied, so much so that his or her behaviour becomes highly unnatural, or overly socially desirable.</li>
</ul>
<p>###Placebo effects</p>
<p>The <strong><em>placebo effect</em></strong> is a specific type of demand effect that we worry a lot about. It refers to the situation where the mere fact of being treated causes an improvement in outcomes. The classic example comes from clinical trials: if you give people a completely chemically inert drug and tell them that it’s a cure for a disease, they will tend to get better faster than people who aren’t treated at all. In other words, it is people’s belief that they are being treated that causes the improved outcomes, not the drug.</p>
<p>###Situation, measurement and subpopulation effects</p>
<p>In some respects, these terms are a catch-all term for “all other threats to external validity”. They refer to the fact that the choice of subpopulation from which you draw your participants, the location, timing and manner in which you run your study (including who collects the data) and the tools that you use to make your measurements might all be influencing the results. Specifically, the worry is that these things might be influencing the results in such a way that the results won’t generalise to a wider array of people, places and measures.</p>
<p>###Fraud, deception and self-deception</p>
<blockquote>
<p><em>It is difficult to get a man to understand something, when his salary depends on his not understanding it.</em></p>
<p>– Upton Sinclair</p>
</blockquote>
<p>One final thing that I feel like I should mention. While reading what the textbooks often have to say about assessing the validity of the study, I couldn’t help but notice that they seem to make the assumption that the researcher is honest. I find this hilarious. While the vast majority of scientists are honest, in my experience at least, some are not.<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a> Not only that, as I mentioned earlier, scientists are not immune to belief bias – it’s easy for a researcher to end up deceiving themselves into believing the wrong thing, and this can lead them to conduct subtly flawed research, and then hide those flaws when they write it up. So you need to consider not only the (probably unlikely) possibility of outright fraud, but also the (probably quite common) possibility that the research is unintentionally “slanted”. I opened a few standard textbooks and didn’t find much of a discussion of this problem, so here’s my own attempt to list a few ways in which these issues can arise are:</p>
<ul>
<li><strong><em>Data fabrication</em></strong>. Sometimes, people just make up the data. This is occasionally done with “good” intentions. For instance, the researcher believes that the fabricated data do reflect the truth, and may actually reflect “slightly cleaned up” versions of actual data. On other occasions, the fraud is deliberate and malicious. Some high-profile examples where data fabrication has been alleged or shown include Cyril Burt (a psychologist who is thought to have fabricated some of his data), Andrew Wakefield (who has been accused of fabricating his data connecting the MMR vaccine to autism) and Hwang Woo-suk (who falsified a lot of his data on stem cell research).<br />
</li>
<li><strong><em>Hoaxes</em></strong>. Hoaxes share a lot of similarities with data fabrication, but they differ in the intended purpose. A hoax is often a joke, and many of them are intended to be (eventually) discovered. Often, the point of a hoax is to discredit someone or some field. There’s quite a few well known scientific hoaxes that have occurred over the years (e.g., Piltdown man) some of were deliberate attempts to discredit particular fields of research (e.g., the Sokal affair).</li>
<li><strong><em>Data misrepresentation</em></strong>. While fraud gets most of the headlines, it’s much more common in my experience to see data being misrepresented. When I say this, I’m not referring to newspapers getting it wrong (which they do, almost always). I’m referring to the fact that often, the data don’t actually say what the researchers think they say. My guess is that, almost always, this isn’t the result of deliberate dishonesty, it’s due to a lack of sophistication in the data analyses. For instance, think back to the example of Simpson’s paradox that I discussed in the beginning of these notes. It’s very common to see people present “aggregated” data of some kind; and sometimes, when you dig deeper and find the raw data yourself, you find that the aggregated data tell a different story to the disaggregated data. Alternatively, you might find that some aspect of the data is being hidden, because it tells an inconvenient story (e.g., the researcher might choose not to refer to a particular variable). There’s a lot of variants on this; many of which are very hard to detect.</li>
<li><strong><em>Study “misdesign”</em></strong>. Okay, this one is subtle. Basically, the issue here is that a researcher designs a study that has built-in flaws, and those flaws are never reported in the paper. The data that are reported are completely real, and are correctly analysed, but they are produced by a study that is actually quite wrongly put together. The researcher really wants to find a particular effect, and so the study is set up in such a way as to make it “easy” to (artifactually) observe that effect. One sneaky way to do this – in case you’re feeling like dabbling in a bit of fraud yourself – is to design an experiment in which it’s obvious to the participants what they’re “supposed” to be doing, and then let reactivity work its magic for you. If you want, you can add all the trappings of double blind experimentation etc. It won’t make a difference, since the study materials themselves are subtly telling people what you want them to do. When you write up the results, the fraud won’t be obvious to the reader: what’s obvious to the participant when they’re in the experimental context isn’t always obvious to the person reading the paper. Of course, the way I’ve described this makes it sound like it’s always fraud: probably there are cases where this is done deliberately, but in my experience the bigger concern has been with unintentional misdesign. The researcher <em>believes</em> … and so the study just happens to end up with a built in flaw, and that flaw then magically erases itself when the study is written up for publication.</li>
<li><strong><em>Data mining &amp; post hoc hypothesising</em></strong>. Another way in which the authors of a study can more or less lie about what they found is by engaging in what’s referred to as “data mining”. As we’ll discuss later in the class, if you keep trying to analyse your data in lots of different ways, you’ll eventually find something that “looks” like a real effect but isn’t. This is referred to as “data mining”. It used to be quite rare because data analysis used to take weeks, but now that everyone has very powerful statistical software on their computers, it’s becoming very common. Data mining per se isn’t “wrong”, but the more that you do it, the bigger the risk you’re taking. The thing that is wrong, and I suspect is very common, is <em>unacknowledged</em> data mining. That is, the researcher run every possible analysis known to humanity, finds the one that works, and then pretends that this was the only analysis that they ever conducted. Worse yet, they often “invent” a hypothesis after looking at the data, to cover up the data mining. To be clear: it’s not wrong to change your beliefs after looking at the data, and to reanalyse your data using your new “post hoc” hypotheses. What is wrong (and, I suspect, common) is failing to acknowledge that you’ve done so. If you acknowledge that you did it, then other researchers are able to take your behaviour into account. If you don’t, then they can’t. And that makes your behaviour deceptive. Bad!</li>
<li><strong><em>Publication bias &amp; self-censoring</em></strong>. Finally, a pervasive bias is “non-reporting” of negative results. This is almost impossible to prevent. Journals don’t publish every article that is submitted to them: they prefer to publish articles that find “something”. So, if 20 people run an experiment looking at whether reading <em>Finnegans Wake</em> causes insanity in humans, and 19 of them find that it doesn’t, which one do you think is going to get published? Obviously, it’s the one study that did find that <em>Finnegans Wake</em> causes insanity.<a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a> This is an example of a <em>publication bias</em>: since no-one ever published the 19 studies that didn’t find an effect, a naive reader would never know that they existed. Worse yet, most researchers “internalise” this bias, and end up <em>self-censoring</em> their research. Knowing that negative results aren’t going to be accepted for publication, they never even try to report them. As a friend of mine says “for every experiment that you get published, you also have 10 failures”. And she’s right. The catch is, while some (maybe most) of those studies are failures for boring reasons (e.g. you stuffed something up) others might be genuine “null” results that you ought to acknowledge when you write up the “good” experiment. And telling which is which is often hard to do. A good place to start is a paper by <span class="citation">Ioannidis (<a href="#ref-Ioannidis2005" role="doc-biblioref">2005</a>)</span> with the depressing title “Why most published research findings are false”. I’d also suggest taking a look at work by <span class="citation">Kühberger, Fritz, and Scherndl (<a href="#ref-Kuhberger2014" role="doc-biblioref">2014</a>)</span> presenting statistical evidence that this actually happens in psychology.</li>
</ul>
<p>There’s probably a lot more issues like this to think about, but that’ll do to start with. What I really want to point out is the blindingly obvious truth that real world science is conducted by actual humans, and only the most gullible of people automatically assumes that everyone else is honest and impartial. Actual scientists aren’t usually <em>that</em> naive, but for some reason the world likes to pretend that we are, and the textbooks we usually write seem to reinforce that stereotype.</p>
<p>##Summary</p>
<p>This chapter isn’t really meant to provide a comprehensive discussion of psychological research methods: it would require another volume just as long as this one to do justice to the topic. However, in real life statistics and study design are tightly intertwined, so it’s very handy to discuss some of the key topics. In this chapter, I’ve briefly discussed the following topics:</p>
<ul>
<li><a href="#measurement">Introduction to psychological measurement</a>. What does it mean to operationalise a theoretical construct? What does it mean to have variables and take measurements?</li>
<li><a href="#scales">Scales of measurement and types of variables</a>. Remember that there are <em>two</em> different distinctions here: there’s the difference between discrete and continuous data, and there’s the difference between the four different scale types (nominal, ordinal, interval and ratio).</li>
<li><a href="#reliability">Reliability of a measurement</a>. If I measure the “same” thing twice, should I expect to see the same result? Only if my measure is reliable. But what does it mean to talk about doing the “same” thing? Well, that’s why we have different types of reliability. Make sure you remember what they are.</li>
<li><a href="#ivdv">Terminology: predictors and outcomes</a>. What roles do variables play in an analysis? Can you remember the difference between predictors and outcomes? Dependent and independent variables? Etc.</li>
<li><a href="#researchdesigns">Experimental and non-experimental research designs</a>. What makes an experiment an experiment? Is it a nice white lab coat, or does it have something to do with researcher control over variables?</li>
<li><a href="#validity">Validity and its threats</a>. Does your study measure what you want it to? How might things go wrong? And is it my imagination, or was that a very long list of possible ways in which things can go wrong?</li>
</ul>
<p>All this should make clear to you that study design is a critical part of research methodology. I built this chapter from the classic little book by <span class="citation">Campbell and Stanley (<a href="#ref-Campbell1963" role="doc-biblioref">1963</a>)</span>, but there are of course a large number of textbooks out there on research design. Spend a few minutes with your favourite search engine and you’ll find dozens.</p>
<!--chapter:end:01.02-studydesign.Rmd-->
</div>
</div>
<div id="part-ii.-an-introduction-to-r" class="section level1 unnumbered">
<h1>Part II. An introduction to R</h1>
<!--chapter:end:02.00-Part2.Rmd-->
</div>
<div id="introR" class="section level1">
<h1><span class="header-section-number">3</span> Getting started with R</h1>
<blockquote>
<p><em>Robots are nice to work with.</em></p>
<p>–Roger Zelazny<a href="#fn13" class="footnote-ref" id="fnref13"><sup>13</sup></a></p>
</blockquote>
<p>In this chapter I’ll discuss how to get started in R. I’ll briefly talk about how to download and install R, but most of the chapter will be focused on getting you started typing R commands. Our goal in this chapter is not to learn any statistical concepts: we’re just trying to learn the basics of how R works and get comfortable interacting with the system. To do this, we’ll spend a bit of time using R as a simple calculator, since that’s the easiest thing to do with R. In doing so, you’ll get a bit of a feel for what it’s like to work in R. From there I’ll introduce some very basic programming ideas: in particular, I’ll talk about the idea of defining <em>variables</em> to store information, and a few things that you can do with these variables.</p>
<p>However, before going into any of the specifics, it’s worth talking a little about why you might want to use R at all. Given that you’re reading this, you’ve probably got your own reasons. However, if those reasons are “because that’s what my stats class uses”, it might be worth explaining a little why your lecturer has chosen to use R for the class. Of course, I don’t really know why <em>other</em> people choose R, so I’m really talking about why I use it.</p>
<ul>
<li>It’s sort of obvious, but worth saying anyway: doing your statistics on a computer is faster, easier and more powerful than doing statistics by hand. Computers excel at mindless repetitive tasks, and a lot of statistical calculations are both mindless and repetitive. For most people, the only reason to ever do statistical calculations with pencil and paper is for learning purposes. In my class I do occasionally suggest doing some calculations that way, but the only real value to it is pedagogical. It does help you to get a “feel” for statistics to do some calculations yourself, so it’s worth doing it once. But only once!</li>
<li>Doing statistics in a spreadsheet (e.g., Microsoft Excel) is generally a bad idea in the long run. Although many people are likely feel more familiar with them, spreadsheets are very limited in terms of what analyses they allow you do. If you get into the habit of trying to do your real life data analysis using spreadsheets, then you’ve dug yourself into a very deep hole.</li>
<li>Avoiding proprietary software is a very good idea. There are a lot of commercial packages out there that you can buy, some of which I like and some of which I don’t. They’re usually very glossy in their appearance, and generally very powerful (much more powerful than spreadsheets). However, they’re also very expensive: usually, the company sells “student versions” (crippled versions of the real thing) very cheaply; they sell full powered “educational versions” at a price that makes me wince; and they sell commercial licences with a staggeringly high price tag. The business model here is to suck you in during your student days, and then leave you dependent on their tools when you go out into the real world. It’s hard to blame them for trying, but personally I’m not in favour of shelling out thousands of dollars if I can avoid it. And you can avoid it: if you make use of packages like R that are open source and free, you never get trapped having to pay exorbitant licensing fees.</li>
<li>Something that you might not appreciate now, but will love later on if you do anything involving data analysis, is the fact that R is highly extensible. When you download and install R, you get all the basic “packages”, and those are very powerful on their own. However, because R is so open and so widely used, it’s become something of a standard tool in statistics, and so lots of people write their own packages that extend the system. And these are freely available too. One of the consequences of this, I’ve noticed, is that if you open up an advanced textbook (a recent one, that is) rather than introductory textbooks, is that a <em>lot</em> of them use R. In other words, if you learn how to do your basic statistics in R, then you’re a lot closer to being able to use the state of the art methods than you would be if you’d started out with a “simpler” system: so if you want to become a genuine expert in psychological data analysis, learning R is a very good use of your time.</li>
<li>Related to the previous point: R is a real programming language. As you get better at using R for data analysis, you’re also learning to program. To some people this might seem like a bad thing, but in truth, programming is a core research skill across a lot of the social and behavioural sciences. Think about how many surveys and experiments are done online, or presented on computers. Think about all those online social environments which you might be interested in studying; and maybe collecting data from in an automated fashion. Think about artificial intelligence systems, computer vision and speech recognition. If any of these are things that you think you might want to be involved in – as someone “doing research in psychology”, that is – you’ll need to know a bit of programming. And if you don’t already know how to program, then learning how to do statistics using R is a nice way to start.</li>
</ul>
<p>Those are the main reasons I use R. It’s not without its flaws: it’s not easy to learn, and it has a few very annoying quirks to it that we’re all pretty much stuck with, but on the whole I think the strengths outweigh the weakness; more so than any other option I’ve encountered so far.</p>
<div id="gettingR" class="section level2">
<h2><span class="header-section-number">3.1</span> Installing R</h2>
<p>Okay, enough with the sales pitch. Let’s get started. Just as with any piece of software, R needs to be installed on a “computer”, which is a magical box that does cool things and delivers free ponies. Or something along those lines: I may be confusing computers with the iPad marketing campaigns. Anyway, R is freely distributed online, and you can download it from the R homepage, which is:</p>
<blockquote>
<p><a href="http://cran.r-project.org/" class="uri">http://cran.r-project.org/</a></p>
</blockquote>
<p>At the top of the page – under the heading “Download and Install R” – you’ll see separate links for Windows users, Mac users, and Linux users. If you follow the relevant link, you’ll see that the online instructions are pretty self-explanatory, but I’ll walk you through the installation anyway. As of this writing, the current version of R is 3.0.2 (``Frisbee Sailing"), but they usually issue updates every six months, so you’ll probably have a newer version.<a href="#fn14" class="footnote-ref" id="fnref14"><sup>14</sup></a></p>
<div id="installing-r-on-a-windows-computer" class="section level3">
<h3><span class="header-section-number">3.1.1</span> Installing R on a Windows computer</h3>
<p>The CRAN homepage changes from time to time, and it’s not particularly pretty, or all that well-designed quite frankly. But it’s not difficult to find what you’re after. In general you’ll find a link at the top of the page with the text “Download R for Windows”. If you click on that, it will take you to a page that offers you a few options. Again, at the very top of the page you’ll be told to click on a link that says to click here if you’re installing R for the first time. That’s probably what you want. This will take you to a page that has a prominent link at the top called “Download R 3.0.2 for Windows”. That’s the one you want. Click on that and your browser should start downloading a file called <code>R-3.0.2-win.exe</code>, or whatever the equivalent version number is by the time you read this. The file for version 3.0.2 is about 54MB in size, so it may take some time depending on how fast your internet connection is. Once you’ve downloaded the file, double click to install it. As with any software you download online, Windows will ask you some questions about whether you trust the file and so on. After you click through those, it’ll ask you where you want to install it, and what components you want to install. The default values should be fine for most people, so again, just click through. Once all that is done, you should have R installed on your system. You can access it from the Start menu, or from the desktop if you asked it to add a shortcut there. You can now open up R in the usual way if you want to, but what I’m going to suggest is that instead of doing that you should now install RStudio (see Section @ref(installingrstudio) for instructions).</p>
</div>
<div id="installing-r-on-a-mac" class="section level3">
<h3><span class="header-section-number">3.1.2</span> Installing R on a Mac</h3>
<p>When you click on the Mac OS X link, you should find yourself on a page with the title “R for Mac OS X”. The vast majority of Mac users will have a fairly recent version of the operating system: as long as you’re running Mac OS X 10.6 (Snow Leopard) or higher, then you’ll be fine.<a href="#fn15" class="footnote-ref" id="fnref15"><sup>15</sup></a> There’s a fairly prominent link on the page called “R-3.0.2.pkg”, which is the one you want. Click on that link and you’ll start downloading the installer file, which is (not surprisingly) called <code>R-3.0.2.pkg</code>. It’s about 61MB in size, so the download can take a while on slower internet connections.</p>
<p>Once you’ve downloaded <code>R-3.0.2.pkg</code>, all you need to do is open it by double clicking on the package file. The installation should go smoothly from there: just follow all the instructions just like you usually do when you install something. Once it’s finished, you’ll find a file called <code>R.app</code> in the Applications folder. You can now open up R in the usual way<a href="#fn16" class="footnote-ref" id="fnref16"><sup>16</sup></a> if you want to, but what I’m going to suggest is that instead of doing that you should now install RStudio (see Section @ref(installingrstudio) for instructions).</p>
</div>
<div id="installing-r-on-a-linux-computer" class="section level3">
<h3><span class="header-section-number">3.1.3</span> Installing R on a Linux computer</h3>
<p>If you’re successfully managing to run a Linux box, regardless of what distribution, then you should find the instructions on the website easy enough. You can compile R from source yourself if you want, or install it through your package management system, which will probably have R in it.
Alternatively, the CRAN site has precompiled binaries for Debian, Red Hat, Suse and Ubuntu and has separate instructions for each. Once you’ve got R installed, you can run it from the command line just by typing <code>R</code>. However, if you’re feeling envious of Windows and Mac users for their fancy GUIs, you can download RStudio too (see Section @ref(installingrstudio) for instructions).</p>
</div>
<div id="installingrstudio" class="section level3">
<h3><span class="header-section-number">3.1.4</span> Downloading and installing RStudio</h3>
<p>Okay, so regardless of what operating system you’re using, the last thing that I told you to do is to download RStudio. To understand why I’ve suggested this, you need to understand a little bit more about R itself. The term R doesn’t really refer to a specific application on your computer. Rather, it refers to the underlying statistical language. You can use this language through lots of different applications. When you install R initially, it comes with one application that lets you do this: it’s the R.exe application on a Windows machine, and the R.app application on a Mac. But that’s not the only way to do it. There are lots of different applications that you can use that will let you interact with R. One of those is called RStudio, and it’s the one I’m going to suggest that you use. RStudio provides a clean, professional interface to R that I find much nicer to work with than either the Windows or Mac defaults. Like R itself, RStudio is free software: you can find all the details on their webpage. In the meantime, you can download it here:</p>
<blockquote>
<p><a href="http://www.RStudio.org/" class="uri">http://www.RStudio.org/</a></p>
</blockquote>
<p>When you visit the RStudio website, you’ll probably be struck by how much cleaner and simpler it is than the CRAN website,<a href="#fn17" class="footnote-ref" id="fnref17"><sup>17</sup></a> and how obvious it is what you need to do: click the big green button that says “Download”.</p>
<p>When you click on the download button on the homepage it will ask you to choose whether you want the desktop version or the server version. You want the desktop version. After choosing the desktop version it will take you to a page <a href="http://www.RStudio.org/download/desktop" class="uri">http://www.RStudio.org/download/desktop</a>) that shows several possible downloads: there’s a different one for each operating system. However, the nice people at RStudio have designed the webpage so that it automatically recommends the download that is most appropriate for your computer. Click on the appropriate link, and the RStudio installer file will start downloading.</p>
<p>Once it’s finished downloading, open the installer file in the usual way to install RStudio. After it’s finished installing, you can start R by opening RStudio. You don’t need to open R.app or R.exe in order to access R. RStudio will take care of that for you. To illustrate what RStudio looks like, Figure @ref(fig:RStudio) shows a screenshot of an R session in progress. In this screenshot, you can see that it’s running on a Mac, but it looks almost identical no matter what operating system you have. The Windows version looks more like a Windows application (e.g., the menus are attached to the application window and the colour scheme is slightly different), but it’s more or less identical. There are a few minor differences in where things are located in the menus (I’ll point them out as we go along) and in the shortcut keys, because RStudio is trying to “feel” like a proper Mac application or a proper Windows application, and this means that it has to change its behaviour a little bit depending on what computer it’s running on. Even so, these differences are very small: I started out using the Mac version of RStudio and then started using the Windows version as well in order to write these notes.</p>
<div class="figure">
<img src="img/introR/Rstudio2.png" alt="An R session in progress running through RStudio. The picture shows RStudio running on a Mac, but the Windows interface is almost identical." width="881" />
<p class="caption">
(#fig:RStudio)An R session in progress running through RStudio. The picture shows RStudio running on a Mac, but the Windows interface is almost identical.
</p>
</div>
<p>The only “shortcoming” I’ve found with RStudio is that – as of this writing – it’s still a work in progress. The “problem” is that they keep improving it. New features keep turning up the more recent releases, so there’s a good chance that by the time you read this book there will be a version out that has some really neat things that weren’t in the version that I’m using now.</p>
</div>
<div id="startingR" class="section level3">
<h3><span class="header-section-number">3.1.5</span> Starting up R</h3>
<p>One way or another, regardless of what operating system you’re using and regardless of whether you’re using RStudio, or the default GUI, or even the command line, it’s time to open R and get started. When you do that, the first thing you’ll see (assuming that you’re looking at the <strong><em>R console</em></strong>, that is) is a whole lot of text that doesn’t make much sense. It should look something like this:</p>
<pre><code>R version 3.0.2 (2013-09-25) -- &quot;Frisbee Sailing&quot;
Copyright (C) 2013 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin10.8.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type &#39;license()&#39; or &#39;licence()&#39; for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type &#39;contributors()&#39; for more information and
&#39;citation()&#39; on how to cite R or R packages in publications.

Type &#39;demo()&#39; for some demos, &#39;help()&#39; for on-line help, or
&#39;help.start()&#39; for an HTML browser interface to help.
Type &#39;q()&#39; to quit R.

&gt; </code></pre>
<p>Most of this text is pretty uninteresting, and when doing real data analysis you’ll never really pay much attention to it. The important part of it is this…</p>
<pre><code>&gt;</code></pre>
<p>… which has a flashing cursor next to it. That’s the <strong><em>command prompt</em></strong>. When you see this, it means that R is waiting patiently for you to do something!</p>
</div>
</div>
<div id="firstcommand" class="section level2">
<h2><span class="header-section-number">3.2</span> Typing commands at the R console</h2>
<p>One of the easiest things you can do with R is use it as a simple calculator, so it’s a good place to start. For instance, try typing <code>10 + 20</code>, and hitting enter.<a href="#fn18" class="footnote-ref" id="fnref18"><sup>18</sup></a> When you do this, you’ve entered a <strong><em>command</em></strong>, and R will “execute” that command. What you see on screen now will be this:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" title="1"><span class="op">&gt;</span><span class="st"> </span><span class="dv">10</span> <span class="op">+</span><span class="st"> </span><span class="dv">20</span></a>
<a class="sourceLine" id="cb3-2" title="2">[<span class="dv">1</span>] <span class="dv">30</span></a></code></pre></div>
<p>Not a lot of surprises in this extract. But there’s a few things worth talking about, even with such a simple example. Firstly, it’s important that you understand how to read the extract. In this example, what <em>I</em> typed was the <code>10 + 20</code> part. I didn’t type the <code>&gt;</code> symbol: that’s just the R command prompt and isn’t part of the actual command. And neither did I type the <code>[1] 30</code> part. That’s what R printed out in response to my command.</p>
<p>Secondly, it’s important to understand how the output is formatted. Obviously, the correct answer to the sum <code>10 + 20</code> is <code>30</code>, and not surprisingly R has printed that out as part of its response. But it’s also printed out this <code>[1]</code> part, which probably doesn’t make a lot of sense to you right now. You’re going to see that a lot. I’ll talk about what this means in a bit more detail later on, but for now you can think of <code>[1] 30</code> as if R were saying “the answer to the 1st question you asked is 30”. That’s not quite the truth, but it’s close enough for now. And in any case it’s not really very interesting at the moment: we only asked R to calculate one thing, so obviously there’s only one answer printed on the screen. Later on this will change, and the <code>[1]</code> part will start to make a bit more sense. For now, I just don’t want you to get confused or concerned by it.</p>
<div id="an-important-digression-about-formatting" class="section level3">
<h3><span class="header-section-number">3.2.1</span> An important digression about formatting</h3>
<p>Now that I’ve taught you these rules I’m going to change them pretty much immediately. That is because I want you to be able to copy code from the book directly into R if if you want to test things or conduct your own analyses. However, if you copy this kind of code (that shows the command prompt and the results) directly into R you will get an error</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" title="1"><span class="op">&gt;</span><span class="st"> </span><span class="dv">10</span> <span class="op">+</span><span class="st"> </span><span class="dv">20</span></a>
<a class="sourceLine" id="cb4-2" title="2">[<span class="dv">1</span>] <span class="dv">30</span></a></code></pre></div>
<pre><code>## Error: &lt;text&gt;:1:1: unexpected &#39;&gt;&#39;
## 1: &gt;
##     ^</code></pre>
<p>So instead, I’m going to provide code in a slightly different format so that it looks like this…</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" title="1"><span class="dv">10</span> <span class="op">+</span><span class="st"> </span><span class="dv">20</span></a></code></pre></div>
<pre><code>## [1] 30</code></pre>
<p>There are two main differences.</p>
<ul>
<li>In your console, you type after the &gt;, but from now I I won’t show the command prompt in the book.<br />
</li>
<li>In the book, output is commented out with ##, in your console it appears directly after your code.</li>
</ul>
<p>These two differences mean that if you’re working with an electronic version of the book, you can easily copy code out of the book and into the console.</p>
<p>So for example if you copied the two lines of code from the book you’d get this</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" title="1"><span class="dv">10</span> <span class="op">+</span><span class="st"> </span><span class="dv">20</span></a></code></pre></div>
<pre><code>## [1] 30</code></pre>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" title="1"><span class="co">## [1] 30</span></a></code></pre></div>
</div>
<div id="be-very-careful-to-avoid-typos" class="section level3">
<h3><span class="header-section-number">3.2.2</span> Be very careful to avoid typos</h3>
<p>Before we go on to talk about other types of calculations that we can do with R, there’s a few other things I want to point out. The first thing is that, while R is good software, it’s still software. It’s pretty stupid, and because it’s stupid it can’t handle typos. It takes it on faith that you meant to type <em>exactly</em> what you did type. For example, suppose that you forgot to hit the shift key when trying to type <code>+</code>, and as a result your command ended up being <code>10 = 20</code> rather than <code>10 + 20</code>. Here’s what happens:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" title="1"><span class="dv">10</span> =<span class="st"> </span><span class="dv">20</span></a></code></pre></div>
<pre><code>## Error in 10 = 20: invalid (do_set) left-hand side to assignment</code></pre>
<p>What’s happened here is that R has attempted to interpret <code>10 = 20</code> as a command, and spits out an error message because the command doesn’t make any sense to it. When a <em>human</em> looks at this, and then looks down at his or her keyboard and sees that <code>+</code> and <code>=</code> are on the same key, it’s pretty obvious that the command was a typo. But R doesn’t know this, so it gets upset. And, if you look at it from its perspective, this makes sense. All that R “knows” is that <code>10</code> is a legitimate number, <code>20</code> is a legitimate number, and <code>=</code> is a legitimate part of the language too. In other words, from its perspective this really does look like the user meant to type <code>10 = 20</code>, since all the individual parts of that statement are legitimate and it’s too stupid to realise that this is probably a typo. Therefore, R takes it on faith that this is exactly what you meant… it only “discovers” that the command is nonsense when it tries to follow your instructions, typo and all. And then it whinges, and spits out an error.</p>
<p>Even more subtle is the fact that some typos won’t produce errors at all, because they happen to correspond to “well-formed” R commands. For instance, suppose that not only did I forget to hit the shift key when trying to type <code>10 + 20</code>, I also managed to press the key next to one I meant do. The resulting typo would produce the command <code>10 - 20</code>. Clearly, R has no way of knowing that you meant to <em>add</em> 20 to 10, not <em>subtract</em> 20 from 10, so what happens this time is this:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb13-1" title="1"><span class="dv">10</span> <span class="op">-</span><span class="st"> </span><span class="dv">20</span></a></code></pre></div>
<pre><code>## [1] -10</code></pre>
<p>In this case, R produces the right answer, but to the the wrong question.</p>
<p>To some extent, I’m stating the obvious here, but it’s important. The people who wrote R are smart. You, the user, are smart. But R itself is dumb. And because it’s dumb, it has to be mindlessly obedient. It does <em>exactly</em> what you ask it to do. There is no equivalent to “autocorrect” in R, and for good reason. When doing advanced stuff – and even the simplest of statistics is pretty advanced in a lot of ways – it’s dangerous to let a mindless automaton like R try to overrule the human user. But because of this, it’s your responsibility to be careful. Always make sure you type <em>exactly what you mean</em>. When dealing with computers, it’s not enough to type “approximately” the right thing. In general, you absolutely <em>must</em> be precise in what you say to R … like all machines it is too stupid to be anything other than absurdly literal in its interpretation.</p>
</div>
<div id="r-is-a-bit-flexible-with-spacing" class="section level3">
<h3><span class="header-section-number">3.2.3</span> R is (a bit) flexible with spacing</h3>
<p>Of course, now that I’ve been so uptight about the importance of always being precise, I should point out that there are some exceptions. Or, more accurately, there are some situations in which R does show a bit more flexibility than my previous description suggests. The first thing R is smart enough to do is ignore redundant spacing. What I mean by this is that, when I typed <code>10 + 20</code> before, I could equally have done this</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb15-1" title="1"><span class="dv">10</span>    <span class="op">+</span><span class="st"> </span><span class="dv">20</span></a></code></pre></div>
<pre><code>## [1] 30</code></pre>
<p>or this</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb17-1" title="1"><span class="dv">10</span><span class="op">+</span><span class="dv">20</span></a></code></pre></div>
<pre><code>## [1] 30</code></pre>
<p>and I would get exactly the same answer. However, that doesn’t mean that you can insert spaces in any old place. When we looked at the startup documentation in Section @ref(startingR) it suggested that you could type <code>citation()</code> to get some information about how to cite R. If I do so…</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb19-1" title="1"><span class="kw">citation</span>()</a></code></pre></div>
<pre><code>## 
## To cite R in publications use:
## 
##   R Core Team (2020). R: A language and environment for
##   statistical computing. R Foundation for Statistical Computing,
##   Vienna, Austria. URL https://www.R-project.org/.
## 
## A BibTeX entry for LaTeX users is
## 
##   @Manual{,
##     title = {R: A Language and Environment for Statistical Computing},
##     author = {{R Core Team}},
##     organization = {R Foundation for Statistical Computing},
##     address = {Vienna, Austria},
##     year = {2020},
##     url = {https://www.R-project.org/},
##   }
## 
## We have invested a lot of time and effort in creating R, please
## cite it when using it for data analysis. See also
## &#39;citation(&quot;pkgname&quot;)&#39; for citing R packages.</code></pre>
<p>… it tells me to cite the R manual <span class="citation">(R Core Team <a href="#ref-R2013" role="doc-biblioref">2013</a>)</span>. Let’s see what happens when I try changing the spacing. If I insert spaces in between the word and the parentheses, or inside the parentheses themselves, then all is well. That is, either of these two commands</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb21-1" title="1"><span class="kw">citation</span> ()</a></code></pre></div>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb22-1" title="1"><span class="kw">citation</span>(  )</a></code></pre></div>
<p>will produce exactly the same response. However, what I can’t do is insert spaces in the middle of the word. If I try to do this, R gets upset:</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb23-1" title="1">citat <span class="kw">ion</span>()</a></code></pre></div>
<pre><code>## Error: &lt;text&gt;:1:7: unexpected symbol
## 1: citat ion
##           ^</code></pre>
<p>Throughout this book I’ll vary the way I use spacing a little bit, just to give you a feel for the different ways in which spacing can be used. I’ll try not to do it too much though, since it’s generally considered to be good practice to be consistent in how you format your commands.</p>
</div>
<div id="r-can-sometimes-tell-that-youre-not-finished-yet-but-not-often" class="section level3">
<h3><span class="header-section-number">3.2.4</span> R can sometimes tell that you’re not finished yet (but not often)</h3>
<p>One more thing I should point out. If you hit enter in a situation where it’s “obvious” to R that you haven’t actually finished typing the command, R is just smart enough to keep waiting. For example, if you type <code>10 +</code> and then press enter, even R is smart enough to realise that you probably wanted to type in another number. So here’s what happens (for illustrative purposes I’m breaking my own code formatting rules in this section):</p>
<pre><code>&gt; 10+
+ </code></pre>
<p>and there’s a blinking cursor next to the plus sign. What this means is that R is still waiting for you to finish. It “thinks” you’re still typing your command, so it hasn’t tried to execute it yet. In other words, this plus sign is actually another command prompt. It’s different from the usual one (i.e., the <code>&gt;</code> symbol) to remind you that R is going to “add” whatever you type now to what you typed last time. For example, if I then go on to type <code>3</code> and hit enter, what I get is this:</p>
<pre><code>&gt; 10 +
+ 20
[1] 30</code></pre>
<p>And as far as R is concerned, this is <em>exactly</em> the same as if you had typed <code>10 + 20</code>. Similarly, consider the <code>citation()</code> command that we talked about in the previous section. Suppose you hit enter after typing <code>citation(</code>. Once again, R is smart enough to realise that there must be more coming – since you need to add the <code>)</code> character – so it waits. I can even hit enter several times and it will keep waiting:</p>
<pre><code>&gt; citation(
+ 
+ 
+ )</code></pre>
<p>I’ll make use of this a lot in this book. A lot of the commands that we’ll have to type are pretty long, and they’re visually a bit easier to read if I break it up over several lines. If you start doing this yourself, you’ll eventually get yourself in trouble (it happens to us all). Maybe you start typing a command, and then you realise you’ve screwed up. For example,</p>
<pre><code>&gt; citblation( 
+ 
+ </code></pre>
<p>You’d probably prefer R not to try running this command, right? If you want to get out of this situation, just hit the ‘escape’ key.<a href="#fn19" class="footnote-ref" id="fnref19"><sup>19</sup></a> R will return you to the normal command prompt (i.e. <code>&gt;</code>) <em>without</em> attempting to execute the botched command.</p>
<p>That being said, it’s not often the case that R is smart enough to tell that there’s more coming.
For instance, in the same way that I can’t add a space in the middle of a word, I can’t hit enter in the middle of a word either. If I hit enter after typing <code>citat</code> I get an error, because R thinks I’m interested in an “object” called <code>citat</code> and can’t find it:</p>
<pre><code>&gt; citat
Error: object &#39;citat&#39; not found</code></pre>
<p>What about if I typed <code>citation</code> and hit enter? In this case we get something very odd, something that we definitely <em>don’t</em> want, at least at this stage. Here’s what happens:</p>
<pre><code>citation
## function (package = &quot;base&quot;, lib.loc = NULL, auto = NULL) 
## {
##     dir &lt;- system.file(package = package, lib.loc = lib.loc)
##     if (dir == &quot;&quot;) 
##         stop(gettextf(&quot;package &#39;%s&#39; not found&quot;, package), domain = NA)

BLAH BLAH BLAH</code></pre>
<p>where the <code>BLAH BLAH BLAH</code> goes on for rather a long time, and you don’t know enough R yet to understand what all this gibberish actually means (of course, it doesn’t actually say BLAH BLAH BLAH - it says some other things we don’t understand or need to know that I’ve edited for length) This incomprehensible output can be quite intimidating to novice users, and unfortunately it’s very easy to forget to type the parentheses; so almost certainly you’ll do this by accident. Do not panic when this happens. Simply ignore the gibberish. As you become more experienced this gibberish will start to make sense, and you’ll find it quite handy to print this stuff out.<a href="#fn20" class="footnote-ref" id="fnref20"><sup>20</sup></a> But for now just try to remember to add the parentheses when typing your commands.</p>
</div>
</div>
<div id="arithmetic" class="section level2">
<h2><span class="header-section-number">3.3</span> Doing simple calculations with R</h2>
<p>Okay, now that we’ve discussed some of the tedious details associated with typing R commands, let’s get back to learning how to use the most powerful piece of statistical software in the world as a $2 calculator. So far, all we know how to do is addition. Clearly, a calculator that only did addition would be a bit stupid, so I should tell you about how to perform other simple calculations using R. But first, some more terminology. Addition is an example of an “operation” that you can perform (specifically, an arithmetic operation), and the <strong><em>operator</em></strong> that performs it is <code>+</code>. To people with a programming or mathematics background, this terminology probably feels pretty natural, but to other people it might feel like I’m trying to make something very simple (addition) sound more complicated than it is (by calling it an arithmetic operation). To some extent, that’s true: if addition was the only operation that we were interested in, it’d be a bit silly to introduce all this extra terminology. However, as we go along, we’ll start using more and more different kinds of operations, so it’s probably a good idea to get the language straight now, while we’re still talking about very familiar concepts like addition!</p>
<div id="adding-subtracting-multiplying-and-dividing" class="section level3">
<h3><span class="header-section-number">3.3.1</span> Adding, subtracting, multiplying and dividing</h3>
<p>So, now that we have the terminology, let’s learn how to perform some arithmetic operations in R. To that end, Table @ref(tab:arithmetic1) lists the operators that correspond to the basic arithmetic we learned in primary school: addition, subtraction, multiplication and division.</p>
<table>
<caption>(#tab:arithmetic1)Basic arithmetic operations in R. These five operators are used very frequently throughout the text, so it’s important to be familiar with them at the outset.</caption>
<thead>
<tr class="header">
<th align="left">operation</th>
<th align="center">operator</th>
<th align="center">example input</th>
<th align="center">example output</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">addition</td>
<td align="center"><code>+</code></td>
<td align="center">10 + 2</td>
<td align="center">12</td>
</tr>
<tr class="even">
<td align="left">subtraction</td>
<td align="center"><code>-</code></td>
<td align="center">9 - 3</td>
<td align="center">6</td>
</tr>
<tr class="odd">
<td align="left">multiplication</td>
<td align="center"><code>*</code></td>
<td align="center">5 * 5</td>
<td align="center">25</td>
</tr>
<tr class="even">
<td align="left">division</td>
<td align="center"><code>/</code></td>
<td align="center">10 / 3</td>
<td align="center">3</td>
</tr>
<tr class="odd">
<td align="left">power</td>
<td align="center"><code>^</code></td>
<td align="center">5 ^ 2</td>
<td align="center">25</td>
</tr>
</tbody>
</table>
<p>As you can see, R uses fairly standard symbols to denote each of the different operations you might want to perform: addition is done using the <code>+</code> operator, subtraction is performed by the <code>-</code> operator, and so on. So if I wanted to find out what 57 times 61 is (and who wouldn’t?), I can use R instead of a calculator, like so:</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb31-1" title="1"><span class="dv">57</span> <span class="op">*</span><span class="st"> </span><span class="dv">61</span></a></code></pre></div>
<pre><code>## [1] 3477</code></pre>
<p>So that’s handy.</p>
</div>
<div id="taking-powers" class="section level3">
<h3><span class="header-section-number">3.3.2</span> Taking powers</h3>
<p>The first four operations listed in Table @ref(tab:arithmetic1) are things we all learned in primary school, but they aren’t the only arithmetic operations built into R. There are three other arithmetic operations that I should probably mention: taking powers, doing integer division, and calculating a modulus. Of the three, the only one that is of any real importance for the purposes of this book is taking powers, so I’ll discuss that one here: the other two are discussed in Chapter @ref(datahandling).</p>
<p>For those of you who can still remember your high school maths, this should be familiar. But for some people high school maths was a long time ago, and others of us didn’t listen very hard in high school. It’s not complicated. As I’m sure everyone will probably remember the moment they read this, the act of multiplying a number <span class="math inline">\(x\)</span> by itself <span class="math inline">\(n\)</span> times is called “raising <span class="math inline">\(x\)</span> to the <span class="math inline">\(n\)</span>-th power”. Mathematically, this is written as <span class="math inline">\(x^n\)</span>. Some values of <span class="math inline">\(n\)</span> have special names: in particular <span class="math inline">\(x^2\)</span> is called <span class="math inline">\(x\)</span>-squared, and <span class="math inline">\(x^3\)</span> is called <span class="math inline">\(x\)</span>-cubed. So, the 4th power of 5 is calculated like this:
<span class="math display">\[
5^4 = 5 \times 5 \times 5 \times 5 
\]</span></p>
<p>One way that we could calculate <span class="math inline">\(5^4\)</span> in R would be to type in the complete multiplication as it is shown in the equation above. That is, we could do this</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb33-1" title="1"><span class="dv">5</span> <span class="op">*</span><span class="st"> </span><span class="dv">5</span> <span class="op">*</span><span class="st"> </span><span class="dv">5</span> <span class="op">*</span><span class="st"> </span><span class="dv">5</span></a></code></pre></div>
<pre><code>## [1] 625</code></pre>
<p>but it does seem a bit tedious. It would be very annoying indeed if you wanted to calculate <span class="math inline">\(5^{15}\)</span>, since the command would end up being quite long. Therefore, to make our lives easier, we use the power operator instead. When we do that, our command to calculate <span class="math inline">\(5^4\)</span> goes like this:</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb35-1" title="1"><span class="dv">5</span> <span class="op">^</span><span class="st"> </span><span class="dv">4</span></a></code></pre></div>
<pre><code>## [1] 625</code></pre>
<p>Much easier.</p>
</div>
<div id="bedmas" class="section level3">
<h3><span class="header-section-number">3.3.3</span> Doing calculations in the right order</h3>
<p>Okay. At this point, you know how to take one of the most powerful pieces of statistical software in the world, and use it as a $2 calculator. And as a bonus, you’ve learned a few very basic programming concepts. That’s not nothing (you could argue that you’ve just saved yourself $2) but on the other hand, it’s not very much either. In order to use R more effectively, we need to introduce more programming concepts.</p>
<p>In most situations where you would want to use a calculator, you might want to do multiple calculations. R lets you do this, just by typing in longer commands.<a href="#fn21" class="footnote-ref" id="fnref21"><sup>21</sup></a> In fact, we’ve already seen an example of this earlier, when I typed in <code>5 * 5 * 5 * 5</code>. However, let’s try a slightly different example:</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb37-1" title="1"><span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="dv">4</span></a></code></pre></div>
<pre><code>## [1] 9</code></pre>
<p>Clearly, this isn’t a problem for R either. However, it’s worth stopping for a second, and thinking about what R just did. Clearly, since it gave us an answer of <code>9</code> it must have multiplied <code>2 * 4</code> (to get an interim answer of 8) and then added 1 to that. But, suppose it had decided to just go from left to right: if R had decided instead to add <code>1+2</code> (to get an interim answer of 3) and then multiplied by 4, it would have come up with an answer of <code>12</code>.</p>
<p>To answer this, you need to know the <strong><em>order of operations</em></strong> that R uses. If you remember back to your high school maths classes, it’s actually the same order that you got taught when you were at school: the “<strong><em>BEDMAS</em></strong>” order.<a href="#fn22" class="footnote-ref" id="fnref22"><sup>22</sup></a> That is, first calculate things inside <strong>B</strong>rackets <code>()</code>, then calculate <strong>E</strong>xponents <code>^</code>, then <strong>D</strong>ivision <code>/</code> and <strong>M</strong>ultiplication <code>*</code>, then <strong>A</strong>ddition <code>+</code> and <strong>S</strong>ubtraction <code>-</code>. So, to continue the example above, if we want to force R to calculate the <code>1+2</code> part before the multiplication, all we would have to do is enclose it in brackets:</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb39-1" title="1">(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="dv">2</span>) <span class="op">*</span><span class="st"> </span><span class="dv">4</span> </a></code></pre></div>
<pre><code>## [1] 12</code></pre>
<p>This is a fairly useful thing to be able to do. The only other thing I should point out about order of operations is what to expect when you have two operations that have the same priority: that is, how does R resolve ties? For instance, multiplication and division are actually the same priority, but what should we expect when we give R a problem like <code>4 / 2 * 3</code> to solve? If it evaluates the multiplication first and then the division, it would calculate a value of two-thirds. But if it evaluates the division first it calculates a value of 6. The answer, in this case, is that R goes from <em>left to right</em>, so in this case the division step would come first:</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb41-1" title="1"><span class="dv">4</span> <span class="op">/</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="dv">3</span></a></code></pre></div>
<pre><code>## [1] 6</code></pre>
<p>All of the above being said, it’s helpful to remember that <em>brackets always come first</em>. So, if you’re ever unsure about what order R will do things in, an easy solution is to enclose the thing <em>you</em> want it to do first in brackets. There’s nothing stopping you from typing <code>(4 / 2) * 3</code>. By enclosing the division in brackets we make it clear which thing is supposed to happen first. In this instance you wouldn’t have needed to, since R would have done the division first anyway, but when you’re first starting out it’s better to make sure R does what you want!</p>
</div>
</div>
<div id="assign" class="section level2">
<h2><span class="header-section-number">3.4</span> Storing a number as a variable</h2>
<p>One of the most important things to be able to do in R (or any programming language, for that matter) is to store information in <strong><em>variables</em></strong>. Variables in R aren’t exactly the same thing as the variables we talked about in the last chapter on research methods, but they are similar. At a conceptual level you can think of a variable as <em>label</em> for a certain piece of information, or even several different pieces of information. When doing statistical analysis in R all of your data (the variables you measured in your study) will be stored as variables in R, but as well see later in the book you’ll find that you end up creating variables for other things too. However, before we delve into all the messy details of data sets and statistical analysis, let’s look at the very basics for how we create variables and work with them.</p>
<div id="variable-assignment-using---and--" class="section level3">
<h3><span class="header-section-number">3.4.1</span> Variable assignment using <code>&lt;-</code> and <code>-&gt;</code></h3>
<p>Since we’ve been working with numbers so far, let’s start by creating variables to store our numbers. And since most people like concrete examples, let’s invent one. Suppose I’m trying to calculate how much money I’m going to make from this book. There’s several different numbers I might want to store. Firstly, I need to figure out how many copies I’ll sell. This isn’t exactly <em>Harry Potter</em>, so let’s assume I’m only going to sell one copy per student in my class. That’s 350 sales, so let’s create a variable called <code>sales</code>. What I want to do is assign a <strong><em>value</em></strong> to my variable <code>sales</code>, and that value should be <code>350</code>. We do this by using the <strong><em>assignment operator</em></strong>, which is <code>&lt;-</code>. Here’s how we do it:</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb43-1" title="1">sales &lt;-<span class="st"> </span><span class="dv">350</span></a></code></pre></div>
<p>When you hit enter, R doesn’t print out any output.<a href="#fn23" class="footnote-ref" id="fnref23"><sup>23</sup></a> It just gives you another command prompt. However, behind the scenes R has created a variable called <code>sales</code> and given it a value of <code>350</code>. You can check that this has happened by asking R to print the variable on screen. And the simplest way to do <em>that</em> is to type the name of the variable and hit enter<a href="#fn24" class="footnote-ref" id="fnref24"><sup>24</sup></a>.</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb44-1" title="1">sales</a></code></pre></div>
<pre><code>## [1] 350</code></pre>
<p>So that’s nice to know. Anytime you can’t remember what R has got stored in a particular variable, you can just type the name of the variable and hit enter.</p>
<p>Okay, so now we know how to assign variables. Actually, there’s a bit more you should know. Firstly, one of the curious features of R is that there are several different ways of making assignments. In addition to the <code>&lt;-</code> operator, we can also use <code>-&gt;</code> and <code>=</code>, and it’s pretty important to understand the differences between them.<a href="#fn25" class="footnote-ref" id="fnref25"><sup>25</sup></a> Let’s start by considering <code>-&gt;</code>, since that’s the easy one (we’ll discuss the use of <code>=</code> in Section @ref(functionarguments). As you might expect from just looking at the symbol, it’s almost identical to <code>&lt;-</code>. It’s just that the arrow (i.e., the assignment) goes from left to right. So if I wanted to define my <code>sales</code> variable using <code>-&gt;</code>, I would write it like this:</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb46-1" title="1"><span class="dv">350</span> -&gt;<span class="st"> </span>sales</a></code></pre></div>
<p>This has the same effect: and it <em>still</em> means that I’m only going to sell <code>350</code> copies. Sigh. Apart from this superficial difference, <code>&lt;-</code> and <code>-&gt;</code> are identical. In fact, as far as R is concerned, they’re actually the same operator, just in a “left form” and a “right form.”<a href="#fn26" class="footnote-ref" id="fnref26"><sup>26</sup></a></p>
</div>
<div id="doing-calculations-using-variables" class="section level3">
<h3><span class="header-section-number">3.4.2</span> Doing calculations using variables</h3>
<p>Okay, let’s get back to my original story. In my quest to become rich, I’ve written this textbook. To figure out how good a strategy is, I’ve started creating some variables in R. In addition to defining a <code>sales</code> variable that counts the number of copies I’m going to sell, I can also create a variable called <code>royalty</code>, indicating how much money I get per copy. Let’s say that my royalties are about $7 per book:</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb47-1" title="1">sales &lt;-<span class="st"> </span><span class="dv">350</span></a>
<a class="sourceLine" id="cb47-2" title="2">royalty &lt;-<span class="st"> </span><span class="dv">7</span></a></code></pre></div>
<p>The nice thing about variables (in fact, the whole point of having variables) is that we can do anything with a variable that we ought to be able to do with the information that it stores. That is, since R allows me to multiply <code>350</code> by <code>7</code></p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb48-1" title="1"><span class="dv">350</span> <span class="op">*</span><span class="st"> </span><span class="dv">7</span></a></code></pre></div>
<pre><code>## [1] 2450</code></pre>
<p>it also allows me to multiply <code>sales</code> by <code>royalty</code></p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb50-1" title="1">sales <span class="op">*</span><span class="st"> </span>royalty</a></code></pre></div>
<pre><code>## [1] 2450</code></pre>
<p>As far as R is concerned, the <code>sales * royalty</code> command is the same as the <code>350 * 7</code> command. Not surprisingly, I can assign the output of this calculation to a new variable, which I’ll call <code>revenue</code>. And when we do this, the new variable <code>revenue</code> gets the value <code>2450</code>. So let’s do that, and then get R to print out the value of <code>revenue</code> so that we can verify that it’s done what we asked:</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb52-1" title="1">revenue &lt;-<span class="st"> </span>sales <span class="op">*</span><span class="st"> </span>royalty</a>
<a class="sourceLine" id="cb52-2" title="2">revenue</a></code></pre></div>
<pre><code>## [1] 2450</code></pre>
<p>That’s fairly straightforward. A slightly more subtle thing we can do is reassign the value of my variable, based on its current value. For instance, suppose that one of my students (no doubt under the influence of psychotropic drugs) loves the book so much that he or she donates me an extra $550. The simplest way to capture this is by a command like this:</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb54-1" title="1">revenue &lt;-<span class="st"> </span>revenue <span class="op">+</span><span class="st"> </span><span class="dv">550</span></a>
<a class="sourceLine" id="cb54-2" title="2">revenue</a></code></pre></div>
<pre><code>## [1] 3000</code></pre>
<p>In this calculation, R has taken the old value of <code>revenue</code> (i.e., 2450) and added 550 to that value, producing a value of 3000. This new value is assigned to the <code>revenue</code> variable, overwriting its previous value. In any case, we now know that I’m expecting to make $3000 off this. Pretty sweet, I thinks to myself. Or at least, that’s what I thinks until I do a few more calculation and work out what the implied hourly wage I’m making off this looks like.</p>
</div>
<div id="rules-and-conventions-for-naming-variables" class="section level3">
<h3><span class="header-section-number">3.4.3</span> Rules and conventions for naming variables</h3>
<p>In the examples that we’ve seen so far, my variable names (<code>sales</code> and <code>revenue</code>) have just been English-language words written using lowercase letters. However, R allows a lot more flexibility when it comes to naming your variables, as the following list of rules<a href="#fn27" class="footnote-ref" id="fnref27"><sup>27</sup></a> illustrates:</p>
<ul>
<li>Variable names can only use the upper case alphabetic characters <code>A</code>-<code>Z</code> as well as the lower case characters <code>a</code>-<code>z</code>. You can also include numeric characters <code>0</code>-<code>9</code> in the variable name, as well as the period <code>.</code> or underscore <code>_</code> character. In other words, you can use <code>SaL.e_s</code> as a variable name (though I can’t think why you would want to), but you can’t use <code>Sales?</code>.</li>
<li>Variable names cannot include spaces: therefore <code>my sales</code> is not a valid name, but <code>my.sales</code> is.</li>
<li>Variable names are case sensitive: that is, <code>Sales</code> and <code>sales</code> are <em>different</em> variable names.</li>
<li>Variable names must start with a letter or a period. You can’t use something like <code>_sales</code> or <code>1sales</code> as a variable name. You can use <code>.sales</code> as a variable name if you want, but it’s not usually a good idea. By convention, variables starting with a <code>.</code> are used for special purposes, so you should avoid doing so.</li>
<li>Variable names cannot be one of the reserved keywords. These are special names that R needs to keep “safe” from us mere users, so you can’t use them as the names of variables. The keywords are: <code>if</code>, <code>else</code>, <code>repeat</code>, <code>while</code>, <code>function</code>, <code>for</code>, <code>in</code>, <code>next</code>, <code>break</code>, <code>TRUE</code>, <code>FALSE</code>, <code>NULL</code>, <code>Inf</code>, <code>NaN</code>, <code>NA</code>, <code>NA_integer_</code>, <code>NA_real_</code>, <code>NA_complex_</code>, and finally, <code>NA_character_</code>. Don’t feel especially obliged to memorise these: if you make a mistake and try to use one of the keywords as a variable name, R will complain about it like the whiny little automaton it is.</li>
</ul>
<p>In addition to those rules that R enforces, there are some informal conventions that people tend to follow when naming variables. One of them you’ve already seen: i.e., don’t use variables that start with a period. But there are several others. You aren’t obliged to follow these conventions, and there are many situations in which it’s advisable to ignore them, but it’s generally a good idea to follow them when you can:</p>
<ul>
<li>Use informative variable names. As a general rule, using meaningful names like <code>sales</code> and <code>revenue</code> is preferred over arbitrary ones like <code>variable1</code> and <code>variable2</code>. Otherwise it’s very hard to remember what the contents of different variables are, and it becomes hard to understand what your commands actually do.</li>
<li>Use short variable names. Typing is a pain and no-one likes doing it. So we much prefer to use a name like <code>sales</code> over a name like <code>sales.for.this.book.that.you.are.reading</code>. Obviously there’s a bit of a tension between using informative names (which tend to be long) and using short names (which tend to be meaningless), so use a bit of common sense when trading off these two conventions.</li>
<li>Use one of the conventional naming styles for multi-word variable names. Suppose I want to name a variable that stores “my new salary”. Obviously I can’t include spaces in the variable name, so how should I do this? There are three different conventions that you sometimes see R users employing. Firstly, you can separate the words using periods, which would give you <code>my.new.salary</code> as the variable name. Alternatively, you could separate words using underscores, as in <code>my_new_salary</code>. Finally, you could use capital letters at the beginning of each word (except the first one), which gives you <code>myNewSalary</code> as the variable name. I don’t think there’s any strong reason to prefer one over the other,<a href="#fn28" class="footnote-ref" id="fnref28"><sup>28</sup></a> but it’s important to be consistent.</li>
</ul>
</div>
</div>
<div id="usingfunctions" class="section level2">
<h2><span class="header-section-number">3.5</span> Using functions to do calculations</h2>
<p>The symbols <code>+</code>, <code>-</code>, <code>*</code> and so on are examples of operators. As we’ve seen, you can do quite a lot of calculations just by using these operators. However, in order to do more advanced calculations (and later on, to do actual statistics), you’re going to need to start using <strong><em>functions</em></strong>.<a href="#fn29" class="footnote-ref" id="fnref29"><sup>29</sup></a> I’ll talk in more detail about functions and how they work in Section @ref(functions), but for now let’s just dive in and use a few. To get started, suppose I wanted to take the square root of 225. The square root, in case your high school maths is a bit rusty, is just the opposite of squaring a number. So, for instance, since “5 squared is 25” I can say that “5 is the square root of 25”. The usual notation for this is</p>
<p><span class="math display">\[
\sqrt{25} = 5
\]</span></p>
<p>though sometimes you’ll also see it written like this
<span class="math inline">\(25^{0.5} = 5.\)</span>
This second way of writing it is kind of useful to “remind” you of the mathematical fact that “square root of <span class="math inline">\(x\)</span>” is actually the same as “raising <span class="math inline">\(x\)</span> to the power of 0.5”. Personally, I’ve never found this to be terribly meaningful psychologically, though I have to admit it’s quite convenient mathematically. Anyway, it’s not important. What is important is that you remember what a square root is, since we’re going to need it later on.</p>
<p>To calculate the square root of 25, I can do it in my head pretty easily, since I memorised my multiplication tables when I was a kid. It gets harder when the numbers get bigger, and pretty much impossible if they’re not whole numbers. This is where something like R comes in very handy. Let’s say I wanted to calculate <span class="math inline">\(\sqrt{225}\)</span>, the square root of 225. There’s two ways I could do this using R. Firstly, since the square root of 255 is the same thing as raising 225 to the power of 0.5, I could use the power operator <code>^</code>, just like we did earlier:</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb56-1" title="1"><span class="dv">225</span> <span class="op">^</span><span class="st"> </span><span class="fl">0.5</span></a></code></pre></div>
<pre><code>## [1] 15</code></pre>
<p>However, there’s a second way that we can do this, since R also provides a <strong><em>square root function</em></strong>, <code>sqrt()</code>. To calculate the square root of 255 using this function, what I do is insert the number <code>225</code> in the parentheses. That is, the command I type is this:</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb58-1" title="1"><span class="kw">sqrt</span>( <span class="dv">225</span> )</a></code></pre></div>
<pre><code>## [1] 15</code></pre>
<p>and as you might expect from our previous discussion, the spaces in between the parentheses are purely cosmetic. I could have typed <code>sqrt(225)</code> or <code>sqrt( 225   )</code> and gotten the same result. When we use a function to do something, we generally refer to this as <strong><em>calling</em></strong> the function, and the values that we type into the function (there can be more than one) are referred to as the <strong><em>arguments</em></strong> of that function.</p>
<p>Obviously, the <code>sqrt()</code> function doesn’t really give us any new functionality, since we already knew how to do square root calculations by using the power operator <code>^</code>, though I do think it looks nicer when we use <code>sqrt()</code>. However, there are lots of other functions in R: in fact, almost everything of interest that I’ll talk about in this book is an R function of some kind. For example, one function that we will need to use in this book is the <strong><em>absolute value function</em></strong>. Compared to the square root function, it’s extremely simple: it just converts negative numbers to positive numbers, and leaves positive numbers alone. Mathematically, the absolute value of <span class="math inline">\(x\)</span> is written <span class="math inline">\(|x|\)</span> or sometimes <span class="math inline">\(\mbox{abs}(x)\)</span>. Calculating absolute values in R is pretty easy, since R provides the <code>abs()</code> function that you can use for this purpose. When you feed it a positive number…</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb60-1" title="1"><span class="kw">abs</span>( <span class="dv">21</span> )</a></code></pre></div>
<pre><code>## [1] 21</code></pre>
<p>the absolute value function does nothing to it at all. But when you feed it a negative number, it spits out the positive version of the same number, like this:</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb62-1" title="1"><span class="kw">abs</span>( <span class="dv">-13</span> )</a></code></pre></div>
<pre><code>## [1] 13</code></pre>
<p>In all honesty, there’s nothing that the absolute value function does that you couldn’t do just by looking at the number and erasing the minus sign if there is one. However, there’s a few places later in the book where we have to use absolute values, so I thought it might be a good idea to explain the meaning of the term early on.</p>
<p>Before moving on, it’s worth noting that – in the same way that R allows us to put multiple operations together into a longer command, like <code>1 + 2*4</code> for instance – it also lets us put functions together and even combine functions with operators if we so desire. For example, the following is a perfectly legitimate command:</p>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb64-1" title="1"><span class="kw">sqrt</span>( <span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">abs</span>(<span class="op">-</span><span class="dv">8</span>) )</a></code></pre></div>
<pre><code>## [1] 3</code></pre>
<p>When R executes this command, starts out by calculating the value of <code>abs(-8)</code>, which produces an intermediate value of <code>8</code>. Having done so, the command simplifies to <code>sqrt( 1 + 8 )</code>. To solve the square root<a href="#fn30" class="footnote-ref" id="fnref30"><sup>30</sup></a> it first needs to add <code>1 + 8</code> to get <code>9</code>, at which point it evaluates <code>sqrt(9)</code>, and so it finally outputs a value of <code>3</code>.</p>
<div id="functionarguments" class="section level3">
<h3><span class="header-section-number">3.5.1</span> Function arguments, their names and their defaults</h3>
<p>There’s two more fairly important things that you need to understand about how functions work in R, and that’s the use of “named” arguments, and default values" for arguments. Not surprisingly, that’s not to say that this is the last we’ll hear about how functions work, but they are the last things we desperately need to discuss in order to get you started. To understand what these two concepts are all about, I’ll introduce another function. The <code>round()</code> function can be used to round some value to the nearest whole number. For example, I could type this:</p>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb66-1" title="1"><span class="kw">round</span>( <span class="fl">3.1415</span> )</a></code></pre></div>
<pre><code>## [1] 3</code></pre>
<p>Pretty straightforward, really. However, suppose I only wanted to round it to two decimal places: that is, I want to get <code>3.14</code> as the output. The <code>round()</code> function supports this, by allowing you to input a second argument to the function that specifies the number of decimal places that you want to round the number to. In other words, I could do this:</p>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb68-1" title="1"><span class="kw">round</span>( <span class="fl">3.14165</span>, <span class="dv">2</span> )</a></code></pre></div>
<pre><code>## [1] 3.14</code></pre>
<p>What’s happening here is that I’ve specified <em>two</em> arguments: the first argument is the number that needs to be rounded (i.e., <code>3.1415</code>), the second argument is the number of decimal places that it should be rounded to (i.e., <code>2</code>), and the two arguments are separated by a comma. In this simple example, it’s quite easy to remember which one argument comes first and which one comes second, but for more complicated functions this is not easy. Fortunately, most R functions make use of <strong><em>argument names</em></strong>. For the <code>round()</code> function, for example the number that needs to be rounded is specified using the <code>x</code> argument, and the number of decimal points that you want it rounded to is specified using the <code>digits</code> argument. Because we have these names available to us, we can specify the arguments to the function by name. We do so like this:</p>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb70-1" title="1"><span class="kw">round</span>( <span class="dt">x =</span> <span class="fl">3.1415</span>, <span class="dt">digits =</span> <span class="dv">2</span> )</a></code></pre></div>
<pre><code>## [1] 3.14</code></pre>
<p>Notice that this is kind of similar in spirit to variable assignment (Section @ref(assign)), except that I used <code>=</code> here, rather than <code>&lt;-</code>. In both cases we’re specifying specific values to be associated with a label. However, there are some differences between what I was doing earlier on when creating variables, and what I’m doing here when specifying arguments, and so as a consequence it’s important that you use <code>=</code> in this context.</p>
<p>As you can see, specifying the arguments by name involves a lot more typing, but it’s also a lot easier to read. Because of this, the commands in this book will usually specify arguments by name,<a href="#fn31" class="footnote-ref" id="fnref31"><sup>31</sup></a> since that makes it clearer to you what I’m doing. However, one important thing to note is that when specifying the arguments using their names, it doesn’t matter what order you type them in. But if you don’t use the argument names, then you have to input the arguments in the correct order. In other words, these three commands all produce the same output…</p>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb72-1" title="1"><span class="kw">round</span>( <span class="fl">3.14165</span>, <span class="dv">2</span> )</a></code></pre></div>
<pre><code>## [1] 3.14</code></pre>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb74-1" title="1"><span class="kw">round</span>( <span class="dt">x =</span> <span class="fl">3.1415</span>, <span class="dt">digits =</span> <span class="dv">2</span> )</a></code></pre></div>
<pre><code>## [1] 3.14</code></pre>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb76-1" title="1"><span class="kw">round</span>( <span class="dt">digits =</span> <span class="dv">2</span>, <span class="dt">x =</span> <span class="fl">3.1415</span> )</a></code></pre></div>
<pre><code>## [1] 3.14</code></pre>
<p>but this one does not…</p>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb78-1" title="1"><span class="kw">round</span>( <span class="dv">2</span>, <span class="fl">3.14165</span> )</a></code></pre></div>
<pre><code>## [1] 2</code></pre>
<p>How do you find out what the correct order is? There’s a few different ways, but the easiest one is to look at the help documentation for the function (see Section @ref(help). However, if you’re ever unsure, it’s probably best to actually type in the argument name.</p>
<p>Okay, so that’s the first thing I said you’d need to know: argument names. The second thing you need to know about is default values. Notice that the first time I called the <code>round()</code> function I didn’t actually specify the <code>digits</code> argument at all, and yet R somehow knew that this meant it should round to the nearest whole number. How did that happen? The answer is that the <code>digits</code> argument has a <strong><em>default value</em></strong> of <code>0</code>, meaning that if you decide not to specify a value for <code>digits</code> then R will act as if you had typed <code>digits = 0</code>. This is quite handy: the vast majority of the time when you want to round a number you want to round it to the nearest whole number, and it would be pretty annoying to have to specify the <code>digits</code> argument every single time. On the other hand, sometimes you actually do want to round to something other than the nearest whole number, and it would be even more annoying if R didn’t allow this! Thus, by having <code>digits = 0</code> as the default value, we get the best of both worlds.</p>
</div>
</div>
<div id="RStudio1" class="section level2">
<h2><span class="header-section-number">3.6</span> Letting RStudio help you with your commands</h2>
<p>Time for a bit of a digression. At this stage you know how to type in basic commands, including how to use R functions. And it’s probably beginning to dawn on you that there are a <em>lot</em> of R functions, all of which have their own arguments. You’re probably also worried that you’re going to have to remember all of them! Thankfully, it’s not that bad. In fact, very few data analysts bother to try to remember all the commands. What they really do is use tricks to make their lives easier. The first (and arguably most important one) is to use the internet. If you don’t know how a particular R function works, Google it. Second, you can look up the R help documentation. I’ll talk more about these two tricks in Section @ref(help). But right now I want to call your attention to a couple of simple tricks that RStudio makes available to you.</p>
<div id="autocomplete-using-tab" class="section level3">
<h3><span class="header-section-number">3.6.1</span> Autocomplete using “tab”</h3>
<p>The first thing I want to call your attention to is the <em>autocomplete</em> ability in RStudio.<a href="#fn32" class="footnote-ref" id="fnref32"><sup>32</sup></a></p>
<p>Let’s stick to our example above and assume that what you want to do is to round a number. This time around, start typing the name of the function that you want, and then hit the “tab” key. RStudio will then display a little window like the one shown in Figure @ref(fig:RStudiotab). In this figure, I’ve typed the letters <code>ro</code> at the command line, and then hit tab. The window has two panels. On the left, there’s a list of variables and functions that start with the letters that I’ve typed shown in black text, and some grey text that tells you where that variable/function is stored. Ignore the grey text for now: it won’t make much sense to you until we’ve talked about packages in Section @ref(packageinstall). In Figure @ref(fig:RStudiotab) you can see that there’s quite a few things that start with the letters <code>ro</code>: there’s something called <code>rock</code>, something called <code>round</code>, something called <code>round.Date</code> and so on. The one we want is <code>round</code>, but if you’re typing this yourself you’ll notice that when you hit the tab key the window pops up with the top entry (i.e., <code>rock</code>) highlighted. You can use the up and down arrow keys to select the one that you want. Or, if none of the options look right to you, you can hit the escape key (“esc”) or the left arrow key to make the window go away.</p>
<div class="figure">
<img src="img/introR/Rstudio_tab.png" alt="Start typing the name of a function or a variable, and hit the &quot;tab&quot; key. RStudio brings up a little dialog box like this one that lets you select the one you want, and even prints out a little information about it." width="682" />
<p class="caption">
(#fig:RStudiotab)Start typing the name of a function or a variable, and hit the “tab” key. RStudio brings up a little dialog box like this one that lets you select the one you want, and even prints out a little information about it.
</p>
</div>
<p>In our case, the thing we want is the <code>round</code> option, so we’ll select that. When you do this, you’ll see that the panel on the right changes. Previously, it had been telling us something about the <code>rock</code> data set (i.e., “Measurements on 48 rock samples…”) that is distributed as part of R. But when we select <code>round</code>, it displays information about the <code>round()</code> function, exactly as it is shown in Figure @ref(fig:RStudiotab). This display is really handy. The very first thing it says is <code>round(x, digits = 0)</code>: what this is telling you is that the <code>round()</code> function has two arguments. The first argument is called <code>x</code>, and it doesn’t have a default value. The second argument is <code>digits</code>, and it has a default value of 0. In a lot of situations, that’s all the information you need. But RStudio goes a bit further, and provides some additional information about the function underneath. Sometimes that additional information is very helpful, sometimes it’s not: RStudio pulls that text from the R help documentation, and my experience is that the helpfulness of that documentation varies wildly. Anyway, if you’ve decided that <code>round()</code> is the function that you want to use, you can hit the right arrow or the enter key, and RStudio will finish typing the rest of the function name for you.</p>
<p>The RStudio autocomplete tool works slightly differently if you’ve already got the name of the function typed and you’re now trying to type the arguments. For instance, suppose I’ve typed <code>round(</code> into the console, and <em>then</em> I hit tab. RStudio is smart enough to recognise that I already know the name of the function that I want, because I’ve already typed it! Instead, it figures that what I’m interested in is the <em>arguments</em> to that function. So that’s what pops up in the little window. You can see this in Figure @ref(fig:RStudiotab2). Again, the window has two panels, and you can interact with this window in exactly the same way that you did with the window shown in Figure @ref(fig:RStudiotab). On the left hand panel, you can see a list of the argument names. On the right hand side, it displays some information about what the selected argument does.</p>
<div class="figure">
<img src="img/introR/Rstudio_tab2.png" alt="If you've typed the name of a function already along with the left parenthesis and then hit the &quot;tab&quot; key, RStudio brings up a different window to the one shown above. This one lists all the arguments to the function on the left, and information about each argument on the right." width="570" />
<p class="caption">
(#fig:RStudiotab2)If you’ve typed the name of a function already along with the left parenthesis and then hit the “tab” key, RStudio brings up a different window to the one shown above. This one lists all the arguments to the function on the left, and information about each argument on the right.
</p>
</div>
</div>
<div id="browsing-your-command-history" class="section level3">
<h3><span class="header-section-number">3.6.2</span> Browsing your command history</h3>
<p>One thing that R does automatically is keep track of your “command history”. That is, it remembers all the commands that you’ve previously typed. You can access this history in a few different ways. The simplest way is to use the up and down arrow keys. If you hit the up key, the R console will show you the most recent command that you’ve typed. Hit it again, and it will show you the command before that. If you want the text on the screen to go away, hit escape<a href="#fn33" class="footnote-ref" id="fnref33"><sup>33</sup></a> Using the up and down keys can be really handy if you’ve typed a long command that had one typo in it. Rather than having to type it all again from scratch, you can use the up key to bring up the command and fix it.</p>
<p>The second way to get access to your command history is to look at the history panel in RStudio. On the upper right hand side of the RStudio window you’ll see a tab labelled “History”. Click on that, and you’ll see a list of all your recent commands displayed in that panel: it should look something like Figure @ref(fig:RStudiohistory). If you double click on one of the commands, it will be copied to the R console. (You can achieve the same result by selecting the command you want with the mouse and then clicking the “To Console” button).<a href="#fn34" class="footnote-ref" id="fnref34"><sup>34</sup></a></p>
<div class="figure">
<img src="img/introR/historyTab.png" alt="The history panel is located in the top right hand side of the RStudio window. Click on the word &quot;History&quot; and it displays this panel." width="495" />
<p class="caption">
(#fig:RStudiohistory)The history panel is located in the top right hand side of the RStudio window. Click on the word “History” and it displays this panel.
</p>
</div>
</div>
</div>
<div id="vectors" class="section level2">
<h2><span class="header-section-number">3.7</span> Storing many numbers as a vector</h2>
<p>At this point we’ve covered functions in enough detail to get us safely through the next couple of chapters (with one small exception: see Section @ref(generics), so let’s return to our discussion of variables. When I introduced variables in Section @ref(assign) I showed you how we can use variables to store a single number. In this section, we’ll extend this idea and look at how to store multiple numbers within the one variable. In R, the name for a variable that can store multiple values is a <strong><em>vector</em></strong>. So let’s create one.</p>
<div id="creating-a-vector" class="section level3">
<h3><span class="header-section-number">3.7.1</span> Creating a vector</h3>
<p>Let’s stick to my silly “get rich quick by textbook writing” example. Suppose the textbook company (if I actually had one, that is) sends me sales data on a monthly basis. Since my class start in late February, we might expect most of the sales to occur towards the start of the year. Let’s suppose that I have 100 sales in February, 200 sales in March and 50 sales in April, and no other sales for the rest of the year. What I would like to do is have a variable – let’s call it <code>sales.by.month</code> – that stores all this sales data. The first number stored should be <code>0</code> since I had no sales in January, the second should be <code>100</code>, and so on. The simplest way to do this in R is to use the <strong><em>combine</em></strong> function, <code>c()</code>. To do so, all we have to do is type all the numbers you want to store in a comma separated list, like this:<a href="#fn35" class="footnote-ref" id="fnref35"><sup>35</sup></a></p>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb80-1" title="1">sales.by.month &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">100</span>, <span class="dv">200</span>, <span class="dv">50</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb80-2" title="2">sales.by.month</a></code></pre></div>
<pre><code>##  [1]   0 100 200  50   0   0   0   0   0   0   0   0</code></pre>
<p>To use the correct terminology here, we have a single variable here called <code>sales.by.month</code>: this variable is a vector that consists of 12 <strong><em>elements</em></strong>.</p>
</div>
<div id="a-handy-digression" class="section level3">
<h3><span class="header-section-number">3.7.2</span> A handy digression</h3>
<p>Now that we’ve learned how to put information into a vector, the next thing to understand is how to pull that information back out again. However, before I do so it’s worth taking a slight detour. If you’ve been following along, typing all the commands into R yourself, it’s possible that the output that you saw when we printed out the <code>sales.by.month</code> vector was slightly different to what I showed above. This would have happened if the window (or the RStudio panel) that contains the R console is really, really narrow. If that were the case, you might have seen output that looks something like this:</p>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb82-1" title="1">sales.by.month</a></code></pre></div>
<pre><code>##  [1]   0 100 200  50
##  [5]   0   0   0   0
##  [9]   0   0   0   0</code></pre>
<p>Because there wasn’t much room on the screen, R has printed out the results over three lines. But that’s not the important thing to notice. The important point is that the first line has a <code>[1]</code> in front of it, whereas the second line starts with <code>[5]</code> and the third with <code>[9]</code>. It’s pretty clear what’s happening here. For the first row, R has printed out the 1st element through to the 4th element, so it starts that row with a <code>[1]</code>. For the second row, R has printed out the 5th element of the vector through to the 8th one, and so it begins that row with a <code>[5]</code> so that you can tell where it’s up to at a glance. It might seem a bit odd to you that R does this, but in some ways it’s a kindness, especially when dealing with larger data sets!</p>
</div>
<div id="vectorsubset" class="section level3">
<h3><span class="header-section-number">3.7.3</span> Getting information out of vectors</h3>
<p>To get back to the main story, let’s consider the problem of how to get information out of a vector. At this point, you might have a sneaking suspicion that the answer has something to do with the <code>[1]</code> and <code>[9]</code> things that R has been printing out. And of course you are correct. Suppose I want to pull out the February sales data only. February is the second month of the year, so let’s try this:</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb84-1" title="1">sales.by.month[<span class="dv">2</span>]</a></code></pre></div>
<pre><code>## [1] 100</code></pre>
<p>Yep, that’s the February sales all right. But there’s a subtle detail to be aware of here: notice that R outputs <code>[1] 100</code>, <em>not</em> <code>[2] 100</code>. This is because R is being extremely literal. When we typed in <code>sales.by.month[2]</code>, we asked R to find exactly <em>one</em> thing, and that one thing happens to be the second element of our <code>sales.by.month</code> vector. So, when it outputs <code>[1] 100</code> what R is saying is that the first number <em>that we just asked for</em> is <code>100</code>. This behaviour makes more sense when you realise that we can use this trick to create new variables. For example, I could create a <code>february.sales</code> variable like this:</p>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb86-1" title="1">february.sales &lt;-<span class="st"> </span>sales.by.month[<span class="dv">2</span>]</a>
<a class="sourceLine" id="cb86-2" title="2">february.sales</a></code></pre></div>
<pre><code>## [1] 100</code></pre>
<p>Obviously, the new variable <code>february.sales</code> should only have one element and so when I print it out this new variable, the R output begins with a <code>[1]</code> because <code>100</code> is the value of the first (and only) element of <code>february.sales</code>. The fact that this also happens to be the value of the second element of <code>sales.by.month</code> is irrelevant. We’ll pick this topic up again shortly (Section @ref(indexing)).</p>
</div>
<div id="altering-the-elements-of-a-vector" class="section level3">
<h3><span class="header-section-number">3.7.4</span> Altering the elements of a vector</h3>
<p>Sometimes you’ll want to change the values stored in a vector. Imagine my surprise when the publisher rings me up to tell me that the sales data for May are wrong. There were actually an additional 25 books sold in May, but there was an error or something so they hadn’t told me about it. How can I fix my <code>sales.by.month</code> variable? One possibility would be to assign the whole vector again from the beginning, using <code>c()</code>. But that’s a lot of typing. Also, it’s a little wasteful: why should R have to redefine the sales figures for all 12 months, when only the 5th one is wrong? Fortunately, we can tell R to change only the 5th element, using this trick:</p>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb88-1" title="1">sales.by.month[<span class="dv">5</span>] &lt;-<span class="st"> </span><span class="dv">25</span></a>
<a class="sourceLine" id="cb88-2" title="2">sales.by.month</a></code></pre></div>
<pre><code>##  [1]   0 100 200  50  25   0   0   0   0   0   0   0</code></pre>
<p>Another way to edit variables is to use the <code>edit()</code> or <code>fix()</code> functions. I won’t discuss them in detail right now, but you can check them out on your own.</p>
</div>
<div id="veclength" class="section level3">
<h3><span class="header-section-number">3.7.5</span> Useful things to know about vectors</h3>
<p>Before moving on, I want to mention a couple of other things about vectors. Firstly, you often find yourself wanting to know how many elements there are in a vector (usually because you’ve forgotten). You can use the <code>length()</code> function to do this. It’s quite straightforward:</p>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb90-1" title="1"><span class="kw">length</span>( <span class="dt">x =</span> sales.by.month )</a></code></pre></div>
<pre><code>## [1] 12</code></pre>
<p>Secondly, you often want to alter all of the elements of a vector at once. For instance, suppose I wanted to figure out how much money I made in each month. Since I’m earning an exciting $7 per book (no seriously, that’s actually pretty close to what authors get on the very expensive textbooks that you’re expected to purchase), what I want to do is multiply each element in the <code>sales.by.month</code> vector by <code>7</code>. R makes this pretty easy, as the following example shows:</p>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb92-1" title="1">sales.by.month <span class="op">*</span><span class="st"> </span><span class="dv">7</span></a></code></pre></div>
<pre><code>##  [1]    0  700 1400  350  175    0    0    0    0    0    0    0</code></pre>
<p>In other words, when you multiply a vector by a single number, all elements in the vector get multiplied. The same is true for addition, subtraction, division and taking powers. So that’s neat. On the other hand, suppose I wanted to know how much money I was making per day, rather than per month. Since not every month has the same number of days, I need to do something slightly different. Firstly, I’ll create two new vectors:</p>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb94-1" title="1">days.per.month &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">31</span>, <span class="dv">28</span>, <span class="dv">31</span>, <span class="dv">30</span>, <span class="dv">31</span>, <span class="dv">30</span>, <span class="dv">31</span>, <span class="dv">31</span>, <span class="dv">30</span>, <span class="dv">31</span>, <span class="dv">30</span>, <span class="dv">31</span>)</a>
<a class="sourceLine" id="cb94-2" title="2">profit &lt;-<span class="st"> </span>sales.by.month <span class="op">*</span><span class="st"> </span><span class="dv">7</span></a></code></pre></div>
<p>Obviously, the <code>profit</code> variable is the same one we created earlier, and the <code>days.per.month</code> variable is pretty straightforward. What I want to do is divide every element of <code>profit</code> by the <em>corresponding</em> element of <code>days.per.month</code>. Again, R makes this pretty easy:</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb95-1" title="1">profit <span class="op">/</span><span class="st"> </span>days.per.month</a></code></pre></div>
<pre><code>##  [1]  0.000000 25.000000 45.161290 11.666667  5.645161  0.000000  0.000000
##  [8]  0.000000  0.000000  0.000000  0.000000  0.000000</code></pre>
<p>I still don’t like all those zeros, but that’s not what matters here. Notice that the second element of the output is 25, because R has divided the second element of <code>profit</code> (i.e. 700) by the second element of <code>days.per.month</code> (i.e. 28). Similarly, the third element of the output is equal to 1400 divided by 31, and so on. We’ll talk more about calculations involving vectors later on (and in particular a thing called the “recycling rule”; Section @ref(recycling)), but that’s enough detail for now.</p>
</div>
</div>
<div id="text" class="section level2">
<h2><span class="header-section-number">3.8</span> Storing text data</h2>
<p>A lot of the time your data will be numeric in nature, but not always. Sometimes your data really needs to be described using text, not using numbers. To address this, we need to consider the situation where our variables store text. To create a variable that stores the word “hello”, we can type this:</p>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb97-1" title="1">greeting &lt;-<span class="st"> &quot;hello&quot;</span></a>
<a class="sourceLine" id="cb97-2" title="2">greeting</a></code></pre></div>
<pre><code>## [1] &quot;hello&quot;</code></pre>
<p>When interpreting this, it’s important to recognise that the quote marks here <em>aren’t</em> part of the string itself. They’re just something that we use to make sure that R knows to treat the characters that they enclose as a piece of text data, known as a <strong><em>character string</em></strong>. In other words, R treats <code>"hello"</code> as a string containing the word “hello”; but if I had typed <code>hello</code> instead, R would go looking for a variable by that name! You can also use <code>'hello'</code> to specify a character string.</p>
<p>Okay, so that’s how we store the text. Next, it’s important to recognise that when we do this, R stores the entire word <code>"hello"</code> as a <em>single</em> element: our <code>greeting</code> variable is <em>not</em> a vector of five different letters. Rather, it has only the one element, and that element corresponds to the entire character string <code>"hello"</code>. To illustrate this, if I actually ask R to find the first element of <code>greeting</code>, it prints the whole string:</p>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb99-1" title="1">greeting[<span class="dv">1</span>]</a></code></pre></div>
<pre><code>## [1] &quot;hello&quot;</code></pre>
<p>Of course, there’s no reason why I can’t create a vector of character strings. For instance, if we were to continue with the example of my attempts to look at the monthly sales data for my book, one variable I might want would include the names of all 12 <code>months</code>.<a href="#fn36" class="footnote-ref" id="fnref36"><sup>36</sup></a> To do so, I could type in a command like this</p>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb101-1" title="1">months &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;January&quot;</span>, <span class="st">&quot;February&quot;</span>, <span class="st">&quot;March&quot;</span>, <span class="st">&quot;April&quot;</span>, <span class="st">&quot;May&quot;</span>, <span class="st">&quot;June&quot;</span>,</a>
<a class="sourceLine" id="cb101-2" title="2">            <span class="st">&quot;July&quot;</span>, <span class="st">&quot;August&quot;</span>, <span class="st">&quot;September&quot;</span>, <span class="st">&quot;October&quot;</span>, <span class="st">&quot;November&quot;</span>, </a>
<a class="sourceLine" id="cb101-3" title="3">            <span class="st">&quot;December&quot;</span>)</a></code></pre></div>
<p>This is a <strong><em>character vector</em></strong> containing 12 elements, each of which is the name of a month. So if I wanted R to tell me the name of the fourth month, all I would do is this:</p>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb102-1" title="1">months[<span class="dv">4</span>]</a></code></pre></div>
<pre><code>## [1] &quot;April&quot;</code></pre>
<div id="simpletext" class="section level3">
<h3><span class="header-section-number">3.8.1</span> Working with text</h3>
<p>Working with text data is somewhat more complicated than working with numeric data, and I discuss some of the basic ideas in Section @ref(textprocessing), but for purposes of the current chapter we only need this bare bones sketch. The only other thing I want to do before moving on is show you an example of a function that can be applied to text data. So far, most of the functions that we have seen (i.e., <code>sqrt()</code>, <code>abs()</code> and <code>round()</code>) only make sense when applied to numeric data (e.g., you can’t calculate the square root of “hello”), and we’ve seen one function that can be applied to pretty much any variable or vector (i.e., <code>length()</code>). So it might be nice to see an example of a function that can be applied to text.</p>
<p>The function I’m going to introduce you to is called <code>nchar()</code>, and what it does is count the number of individual characters that make up a string. Recall earlier that when we tried to calculate the <code>length()</code> of our <code>greeting</code> variable it returned a value of <code>1</code>: the <code>greeting</code> variable contains only the one string, which happens to be <code>"hello"</code>. But what if I want to know how many letters there are in the word? Sure, I could <em>count</em> them, but that’s boring, and more to the point it’s a terrible strategy if what I wanted to know was the number of letters in <em>War and Peace</em>. That’s where the <code>nchar()</code> function is helpful:</p>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb104-1" title="1"><span class="kw">nchar</span>( <span class="dt">x =</span> greeting )</a></code></pre></div>
<pre><code>## [1] 5</code></pre>
<p>That makes sense, since there are in fact 5 letters in the string <code>"hello"</code>. Better yet, you can apply <code>nchar()</code> to whole vectors. So, for instance, if I want R to tell me how many letters there are in the names of each of the 12 months, I can do this:</p>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb106-1" title="1"><span class="kw">nchar</span>( <span class="dt">x =</span> months )</a></code></pre></div>
<pre><code>##  [1] 7 8 5 5 3 4 4 6 9 7 8 8</code></pre>
<p>So that’s nice to know. The <code>nchar()</code> function can do a bit more than this, and there’s a lot of other functions that you can do to extract more information from text or do all sorts of fancy things. However, the goal here is not to teach any of that! The goal right now is just to see an example of a function that actually does work when applied to text.</p>
</div>
</div>
<div id="logicals" class="section level2">
<h2><span class="header-section-number">3.9</span> Storing “true or false” data</h2>
<p>Time to move onto a third kind of data. A key concept in that a lot of R relies on is the idea of a <strong><em>logical value</em></strong>. A logical value is an assertion about whether something is true or false. This is implemented in R in a pretty straightforward way. There are two logical values, namely <code>TRUE</code> and <code>FALSE</code>. Despite the simplicity, a logical values are very useful things. Let’s see how they work.</p>
<div id="assessing-mathematical-truths" class="section level3">
<h3><span class="header-section-number">3.9.1</span> Assessing mathematical truths</h3>
<p>In George Orwell’s classic book <em>1984</em>, one of the slogans used by the totalitarian Party was “two plus two equals five”, the idea being that the political domination of human freedom becomes complete when it is possible to subvert even the most basic of truths. It’s a terrifying thought, especially when the protagonist Winston Smith finally breaks down under torture and agrees to the proposition. “Man is infinitely malleable”, the book says. I’m pretty sure that this isn’t true of humans<a href="#fn37" class="footnote-ref" id="fnref37"><sup>37</sup></a> but it’s definitely not true of R. R is not infinitely malleable. It has rather firm opinions on the topic of what is and isn’t true, at least as regards basic mathematics. If I ask it to calculate <code>2 + 2</code>, it always gives the same answer, and it’s not bloody 5:</p>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb108-1" title="1"><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">2</span></a></code></pre></div>
<pre><code>## [1] 4</code></pre>
<p>Of course, so far R is just doing the calculations. I haven’t asked it to explicitly assert that <span class="math inline">\(2+2 = 4\)</span> is a true statement. If I want R to make an explicit judgement, I can use a command like this:</p>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb110-1" title="1"><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">2</span> <span class="op">==</span><span class="st"> </span><span class="dv">4</span></a></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<p>What I’ve done here is use the <strong><em>equality operator</em></strong>, <code>==</code>, to force R to make a “true or false” judgement.<a href="#fn38" class="footnote-ref" id="fnref38"><sup>38</sup></a> Okay, let’s see what R thinks of the Party slogan:</p>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb112-1" title="1"><span class="dv">2</span><span class="op">+</span><span class="dv">2</span> <span class="op">==</span><span class="st"> </span><span class="dv">5</span></a></code></pre></div>
<pre><code>## [1] FALSE</code></pre>
<p>Booyah! Freedom and ponies for all! Or something like that. Anyway, it’s worth having a look at what happens if I try to <em>force</em> R to believe that two plus two is five by making an assignment statement like <code>2 + 2 = 5</code> or <code>2 + 2 &lt;- 5</code>. When I do this, here’s what happens:</p>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb114-1" title="1"><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">2</span> =<span class="st"> </span><span class="dv">5</span></a></code></pre></div>
<pre><code>## Error in 2 + 2 = 5: target of assignment expands to non-language object</code></pre>
<p>R doesn’t like this very much. It recognises that <code>2 + 2</code> is <em>not</em> a variable (that’s what the “non-language object” part is saying), and it won’t let you try to “reassign” it. While R is pretty flexible, and actually does let you do some quite remarkable things to redefine parts of R itself, there are just some basic, primitive truths that it refuses to give up. It won’t change the laws of addition, and it won’t change the definition of the number <code>2</code>.</p>
<p>That’s probably for the best.</p>
</div>
<div id="logical-operations" class="section level3">
<h3><span class="header-section-number">3.9.2</span> Logical operations</h3>
<p>So now we’ve seen logical operations at work, but so far we’ve only seen the simplest possible example. You probably won’t be surprised to discover that we can combine logical operations with other operations and functions in a more complicated way, like this:</p>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb116-1" title="1"><span class="dv">3</span><span class="op">*</span><span class="dv">3</span> <span class="op">+</span><span class="st"> </span><span class="dv">4</span><span class="op">*</span><span class="dv">4</span> <span class="op">==</span><span class="st"> </span><span class="dv">5</span><span class="op">*</span><span class="dv">5</span></a></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<p>or this</p>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb118-1" title="1"><span class="kw">sqrt</span>( <span class="dv">25</span> ) <span class="op">==</span><span class="st"> </span><span class="dv">5</span></a></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<p>Not only that, but as Table @ref(tab:logicals) illustrates, there are several other logical operators that you can use, corresponding to some basic mathematical concepts.</p>
<table>
<caption>(#tab:logicals)Some logical operators. Technically I should be calling these “binary relational operators”, but quite frankly I don’t want to. It’s my book so no-one can make me.</caption>
<thead>
<tr class="header">
<th align="left">operation</th>
<th align="left">operator</th>
<th align="left">example input</th>
<th align="left">answer</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">less than</td>
<td align="left">&lt;</td>
<td align="left">2 &lt; 3</td>
<td align="left"><code>TRUE</code></td>
</tr>
<tr class="even">
<td align="left">less than or equal to</td>
<td align="left">&lt;=</td>
<td align="left">2 &lt;= 2</td>
<td align="left"><code>TRUE</code></td>
</tr>
<tr class="odd">
<td align="left">greater than</td>
<td align="left">&gt;</td>
<td align="left">2 &gt; 3</td>
<td align="left"><code>FALSE</code></td>
</tr>
<tr class="even">
<td align="left">greater than or equal to</td>
<td align="left">&gt;=</td>
<td align="left">2 &gt;= 2</td>
<td align="left"><code>TRUE</code></td>
</tr>
<tr class="odd">
<td align="left">equal to</td>
<td align="left">==</td>
<td align="left">2 == 3</td>
<td align="left"><code>FALSE</code></td>
</tr>
<tr class="even">
<td align="left">not equal to</td>
<td align="left">!=</td>
<td align="left">2 != 3</td>
<td align="left"><code>TRUE</code></td>
</tr>
</tbody>
</table>
<p>Hopefully these are all pretty self-explanatory: for example, the <strong><em>less than</em></strong> operator <code>&lt;</code> checks to see if the number on the left is less than the number on the right. If it’s less, then R returns an answer of <code>TRUE</code>:</p>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb120-1" title="1"><span class="dv">99</span> <span class="op">&lt;</span><span class="st"> </span><span class="dv">100</span></a></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<p>but if the two numbers are equal, or if the one on the right is larger, then R returns an answer of <code>FALSE</code>, as the following two examples illustrate:</p>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb122-1" title="1"><span class="dv">100</span> <span class="op">&lt;</span><span class="st"> </span><span class="dv">100</span></a></code></pre></div>
<pre><code>## [1] FALSE</code></pre>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb124-1" title="1"><span class="dv">100</span> <span class="op">&lt;</span><span class="st"> </span><span class="dv">99</span></a></code></pre></div>
<pre><code>## [1] FALSE</code></pre>
<p>In contrast, the <strong><em>less than or equal to</em></strong> operator <code>&lt;=</code> will do exactly what it says. It returns a value of <code>TRUE</code> if the number of the left hand side is less than or equal to the number on the right hand side. So if we repeat the previous two examples using <code>&lt;=</code>, here’s what we get:</p>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb126-1" title="1"><span class="dv">100</span> <span class="op">&lt;=</span><span class="st"> </span><span class="dv">100</span></a></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb128-1" title="1"><span class="dv">100</span> <span class="op">&lt;=</span><span class="st"> </span><span class="dv">99</span></a></code></pre></div>
<pre><code>## [1] FALSE</code></pre>
<p>And at this point I hope it’s pretty obvious what the <strong><em>greater than</em></strong> operator <code>&gt;</code> and the <strong><em>greater than or equal to</em></strong> operator <code>&gt;=</code> do! Next on the list of logical operators is the <strong><em>not equal to</em></strong> operator <code>!=</code> which – as with all the others – does what it says it does. It returns a value of <code>TRUE</code> when things on either side are not identical to each other. Therefore, since <span class="math inline">\(2+2\)</span> isn’t equal to <span class="math inline">\(5\)</span>, we get:</p>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb130-1" title="1"><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">2</span> <span class="op">!=</span><span class="st"> </span><span class="dv">5</span></a></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<p>We’re not quite done yet. There are three more logical operations that are worth knowing about, listed in Table @ref(tab:logicals2).</p>
<table>
<caption>(#tab:logicals2)Some more logical operators.</caption>
<thead>
<tr class="header">
<th align="left">operation</th>
<th align="left">operator</th>
<th align="left">example input</th>
<th align="left">answer</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">not</td>
<td align="left">!</td>
<td align="left">!(1==1)</td>
<td align="left"><code>FALSE</code></td>
</tr>
<tr class="even">
<td align="left">or</td>
<td align="left">|</td>
<td align="left">(1==1) | (2==3)</td>
<td align="left"><code>TRUE</code></td>
</tr>
<tr class="odd">
<td align="left">and</td>
<td align="left">&amp;</td>
<td align="left">(1==1) &amp; (2==3)</td>
<td align="left"><code>FALSE</code></td>
</tr>
</tbody>
</table>
<p>These are the <strong><em>not</em></strong> operator <code>!</code>, the <strong><em>and</em></strong> operator <code>&amp;</code>, and the <strong><em>or</em></strong> operator <code>|</code>. Like the other logical operators, their behaviour is more or less exactly what you’d expect given their names. For instance, if I ask you to assess the claim that “either <span class="math inline">\(2+2 = 4\)</span> <em>or</em> <span class="math inline">\(2+2 = 5\)</span>” you’d say that it’s true. Since it’s an “either-or” statement, all we need is for one of the two parts to be true. That’s what the <code>|</code> operator does:</p>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb132-1" title="1">(<span class="dv">2</span><span class="op">+</span><span class="dv">2</span> <span class="op">==</span><span class="st"> </span><span class="dv">4</span>) <span class="op">|</span><span class="st"> </span>(<span class="dv">2</span><span class="op">+</span><span class="dv">2</span> <span class="op">==</span><span class="st"> </span><span class="dv">5</span>)</a></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<p>On the other hand, if I ask you to assess the claim that “both <span class="math inline">\(2+2 = 4\)</span> <em>and</em> <span class="math inline">\(2+2 = 5\)</span>” you’d say that it’s false. Since this is an <em>and</em> statement we need both parts to be true. And that’s what the <code>&amp;</code> operator does:</p>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb134-1" title="1">(<span class="dv">2</span><span class="op">+</span><span class="dv">2</span> <span class="op">==</span><span class="st"> </span><span class="dv">4</span>) <span class="op">&amp;</span><span class="st"> </span>(<span class="dv">2</span><span class="op">+</span><span class="dv">2</span> <span class="op">==</span><span class="st"> </span><span class="dv">5</span>)</a></code></pre></div>
<pre><code>## [1] FALSE</code></pre>
<p>Finally, there’s the <em>not</em> operator, which is simple but annoying to describe in English. If I ask you to assess my claim that “it is not true that <span class="math inline">\(2+2 = 5\)</span>” then you would say that my claim is true; because my claim is that “<span class="math inline">\(2+2 = 5\)</span> is false”. And I’m right. If we write this as an R command we get this:</p>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb136-1" title="1"><span class="op">!</span><span class="st"> </span>(<span class="dv">2</span><span class="op">+</span><span class="dv">2</span> <span class="op">==</span><span class="st"> </span><span class="dv">5</span>)</a></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<p>In other words, since <code>2+2 == 5</code> is a <code>FALSE</code> statement, it must be the case that <code>!(2+2 == 5)</code> is a <code>TRUE</code> one. Essentially, what we’ve really done is claim that “not false” is the same thing as “true”. Obviously, this isn’t really quite right in real life. But R lives in a much more black or white world: for R everything is either true or false. No shades of gray are allowed. We can actually see this much more explicitly, like this:</p>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb138-1" title="1"><span class="op">!</span><span class="st"> </span><span class="ot">FALSE</span></a></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<p>Of course, in our <span class="math inline">\(2+2 = 5\)</span> example, we didn’t really need to use “not” <code>!</code> and “equals to” <code>==</code> as two separate operators. We could have just used the “not equals to” operator <code>!=</code> like this:</p>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb140-1" title="1"><span class="dv">2</span><span class="op">+</span><span class="dv">2</span> <span class="op">!=</span><span class="st"> </span><span class="dv">5</span></a></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<p>But there are many situations where you really do need to use the <code>!</code> operator. We’ll see some later on.<a href="#fn39" class="footnote-ref" id="fnref39"><sup>39</sup></a></p>
</div>
<div id="storing-and-using-logical-data" class="section level3">
<h3><span class="header-section-number">3.9.3</span> Storing and using logical data</h3>
<p>Up to this point, I’ve introduced <em>numeric data</em> (in Sections @ref(assign) and @ref(vectors)) and <em>character data</em> (in Section @ref(text)). So you might not be surprised to discover that these <code>TRUE</code> and <code>FALSE</code> values that R has been producing are actually a third kind of data, called <em>logical data</em>. That is, when I asked R if <code>2 + 2 == 5</code> and it said <code>[1] FALSE</code> in reply, it was actually producing information that we can store in variables. For instance, I could create a variable called <code>is.the.Party.correct</code>, which would store R’s opinion:</p>
<div class="sourceCode" id="cb142"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb142-1" title="1">is.the.Party.correct &lt;-<span class="st"> </span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">2</span> <span class="op">==</span><span class="st"> </span><span class="dv">5</span></a>
<a class="sourceLine" id="cb142-2" title="2">is.the.Party.correct</a></code></pre></div>
<pre><code>## [1] FALSE</code></pre>
<p>Alternatively, you can assign the value directly, by typing <code>TRUE</code> or <code>FALSE</code> in your command. Like this:</p>
<div class="sourceCode" id="cb144"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb144-1" title="1">is.the.Party.correct &lt;-<span class="st"> </span><span class="ot">FALSE</span></a>
<a class="sourceLine" id="cb144-2" title="2">is.the.Party.correct</a></code></pre></div>
<pre><code>## [1] FALSE</code></pre>
<p>Better yet, because it’s kind of tedious to type <code>TRUE</code> or <code>FALSE</code> over and over again, R provides you with a shortcut: you can use <code>T</code> and <code>F</code> instead (but it’s case sensitive: <code>t</code> and <code>f</code> won’t work).<a href="#fn40" class="footnote-ref" id="fnref40"><sup>40</sup></a> So this works:</p>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb146-1" title="1">is.the.Party.correct &lt;-<span class="st"> </span>F</a>
<a class="sourceLine" id="cb146-2" title="2">is.the.Party.correct</a></code></pre></div>
<pre><code>## [1] FALSE</code></pre>
<p>but this doesn’t:</p>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb148-1" title="1">is.the.Party.correct &lt;-<span class="st"> </span>f</a></code></pre></div>
</div>
<div id="vectors-of-logicals" class="section level3">
<h3><span class="header-section-number">3.9.4</span> Vectors of logicals</h3>
<p>The next thing to mention is that you can store vectors of logical values in exactly the same way that you can store vectors of numbers (Section @ref(vectors)) and vectors of text data (Section @ref(text)). Again, we can define them directly via the <code>c()</code> function, like this:</p>
<div class="sourceCode" id="cb149"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb149-1" title="1">x &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="ot">TRUE</span>, <span class="ot">TRUE</span>, <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb149-2" title="2">x</a></code></pre></div>
<pre><code>## [1]  TRUE  TRUE FALSE</code></pre>
<p>or you can produce a vector of logicals by applying a logical operator to a vector. This might not make a lot of sense to you, so let’s unpack it slowly. First, let’s suppose we have a vector of numbers (i.e., a “non-logical vector”). For instance, we could use the <code>sales.by.month</code> vector that we were using in Section @ref(vectors). Suppose I wanted R to tell me, for each month of the year, whether I actually sold a book in that month. I can do that by typing this:</p>
<div class="sourceCode" id="cb151"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb151-1" title="1">sales.by.month <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span></a></code></pre></div>
<pre><code>##  [1] FALSE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE
## [12] FALSE</code></pre>
<p>and again, I can store this in a vector if I want, as the example below illustrates:</p>
<div class="sourceCode" id="cb153"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb153-1" title="1">any.sales.this.month &lt;-<span class="st"> </span>sales.by.month <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb153-2" title="2">any.sales.this.month</a></code></pre></div>
<pre><code>##  [1] FALSE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE
## [12] FALSE</code></pre>
<p>In other words, <code>any.sales.this.month</code> is a logical vector whose elements are <code>TRUE</code> only if the corresponding element of <code>sales.by.month</code> is greater than zero. For instance, since I sold zero books in January, the first element is <code>FALSE</code>.</p>
</div>
<div id="logictext" class="section level3">
<h3><span class="header-section-number">3.9.5</span> Applying logical operation to text</h3>
<p>In a moment (Section @ref(indexing)) I’ll show you why these logical operations and logical vectors are so handy, but before I do so I want to very briefly point out that you can apply them to text as well as to logical data. It’s just that we need to be a bit more careful in understanding how R interprets the different operations. In this section I’ll talk about how the equal to operator <code>==</code> applies to text, since this is the most important one. Obviously, the not equal to operator <code>!=</code> gives the exact opposite answers to <code>==</code> so I’m implicitly talking about that one too, but I won’t give specific commands showing the use of <code>!=</code>. As for the other operators, I’ll defer a more detailed discussion of this topic to Section @ref(logictext2).</p>
<p>Okay, let’s see how it works. In one sense, it’s very simple. For instance, I can ask R if the word <code>"cat"</code> is the same as the word <code>"dog"</code>, like this:</p>
<div class="sourceCode" id="cb155"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb155-1" title="1"><span class="st">&quot;cat&quot;</span> <span class="op">==</span><span class="st"> &quot;dog&quot;</span></a></code></pre></div>
<pre><code>## [1] FALSE</code></pre>
<p>That’s pretty obvious, and it’s good to know that even R can figure that out. Similarly, R does recognise that a <code>"cat"</code> is a <code>"cat"</code>:</p>
<div class="sourceCode" id="cb157"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb157-1" title="1"><span class="st">&quot;cat&quot;</span> <span class="op">==</span><span class="st"> &quot;cat&quot;</span></a></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<p>Again, that’s exactly what we’d expect. However, what you need to keep in mind is that R is not at all tolerant when it comes to grammar and spacing. If two strings differ in any way whatsoever, R will say that they’re not equal to each other, as the following examples indicate:</p>
<div class="sourceCode" id="cb159"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb159-1" title="1"><span class="st">&quot; cat&quot;</span> <span class="op">==</span><span class="st"> &quot;cat&quot;</span></a></code></pre></div>
<pre><code>## [1] FALSE</code></pre>
<div class="sourceCode" id="cb161"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb161-1" title="1"><span class="st">&quot;cat&quot;</span> <span class="op">==</span><span class="st"> &quot;CAT&quot;</span></a></code></pre></div>
<pre><code>## [1] FALSE</code></pre>
<div class="sourceCode" id="cb163"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb163-1" title="1"><span class="st">&quot;cat&quot;</span> <span class="op">==</span><span class="st"> &quot;c a t&quot;</span></a></code></pre></div>
<pre><code>## [1] FALSE</code></pre>
</div>
</div>
<div id="indexing" class="section level2">
<h2><span class="header-section-number">3.10</span> Indexing vectors</h2>
<p>One last thing to add before finishing up this chapter. So far, whenever I’ve had to get information out of a vector, all I’ve done is typed something like <code>months[4]</code>; and when I do this R prints out the fourth element of the <code>months</code> vector. In this section, I’ll show you two additional tricks for getting information out of the vector.</p>
<div id="extracting-multiple-elements" class="section level3">
<h3><span class="header-section-number">3.10.1</span> Extracting multiple elements</h3>
<p>One very useful thing we can do is pull out more than one element at a time. In the previous example, we only used a single number (i.e., <code>2</code>) to indicate which element we wanted. Alternatively, we can use a vector. So, suppose I wanted the data for February, March and April. What I could do is use the vector <code>c(2,3,4)</code> to indicate which elements I want R to pull out. That is, I’d type this:</p>
<div class="sourceCode" id="cb165"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb165-1" title="1">sales.by.month[ <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>) ]</a></code></pre></div>
<pre><code>## [1] 100 200  50</code></pre>
<p>Notice that the order matters here. If I asked for the data in the reverse order (i.e., April first, then March, then February) by using the vector <code>c(4,3,2)</code>, then R outputs the data in the reverse order:</p>
<div class="sourceCode" id="cb167"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb167-1" title="1">sales.by.month[ <span class="kw">c</span>(<span class="dv">4</span>,<span class="dv">3</span>,<span class="dv">2</span>) ]</a></code></pre></div>
<pre><code>## [1]  50 200 100</code></pre>
<p>A second thing to be aware of is that R provides you with handy shortcuts for very common situations. For instance, suppose that I wanted to extract everything from the 2nd month through to the 8th month. One way to do this is to do the same thing I did above, and use the vector <code>c(2,3,4,5,6,7,8)</code> to indicate the elements that I want. That works just fine</p>
<div class="sourceCode" id="cb169"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb169-1" title="1">sales.by.month[ <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">7</span>,<span class="dv">8</span>) ]</a></code></pre></div>
<pre><code>## [1] 100 200  50  25   0   0   0</code></pre>
<p>but it’s kind of a lot of typing. To help make this easier, R lets you use <code>2:8</code> as shorthand for <code>c(2,3,4,5,6,7,8)</code>, which makes things a lot simpler. First, let’s just check that this is true:</p>
<div class="sourceCode" id="cb171"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb171-1" title="1"><span class="dv">2</span><span class="op">:</span><span class="dv">8</span></a></code></pre></div>
<pre><code>## [1] 2 3 4 5 6 7 8</code></pre>
<p>Next, let’s check that we can use the <code>2:8</code> shorthand as a way to pull out the 2nd through 8th elements of <code>sales.by.months</code>:</p>
<div class="sourceCode" id="cb173"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb173-1" title="1">sales.by.month[<span class="dv">2</span><span class="op">:</span><span class="dv">8</span>]</a></code></pre></div>
<pre><code>## [1] 100 200  50  25   0   0   0</code></pre>
<p>So that’s kind of neat.</p>
</div>
<div id="logical-indexing" class="section level3">
<h3><span class="header-section-number">3.10.2</span> Logical indexing</h3>
<p>At this point, I can introduce an extremely useful tool called <strong><em>logical indexing</em></strong>. In the last section, I created a logical vector <code>any.sales.this.month</code>, whose elements are <code>TRUE</code> for any month in which I sold at least one book, and <code>FALSE</code> for all the others. However, that big long list of <code>TRUE</code>s and <code>FALSE</code>s is a little bit hard to read, so what I’d like to do is to have R select the names of the <code>months</code> for which I sold any books. Earlier on, I created a vector <code>months</code> that contains the names of each of the months. This is where logical indexing is handy. What I need to do is this:</p>
<div class="sourceCode" id="cb175"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb175-1" title="1">months[ sales.by.month <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span> ]</a></code></pre></div>
<pre><code>## [1] &quot;February&quot; &quot;March&quot;    &quot;April&quot;    &quot;May&quot;</code></pre>
<p>To understand what’s happening here, it’s helpful to notice that <code>sales.by.month &gt; 0</code> is the same logical expression that we used to create the <code>any.sales.this.month</code> vector in the last section. In fact, I could have just done this:</p>
<div class="sourceCode" id="cb177"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb177-1" title="1">months[ any.sales.this.month ]</a></code></pre></div>
<pre><code>## [1] &quot;February&quot; &quot;March&quot;    &quot;April&quot;    &quot;May&quot;</code></pre>
<p>and gotten exactly the same result. In order to figure out which elements of <code>months</code> to include in the output, what R does is look to see if the corresponding element in <code>any.sales.this.month</code> is <code>TRUE</code>. Thus, since element 1 of <code>any.sales.this.month</code> is <code>FALSE</code>, R does not include <code>"January"</code> as part of the output; but since element 2 of <code>any.sales.this.month</code> is <code>TRUE</code>, R does include <code>"February"</code> in the output. Note that there’s no reason why I can’t use the same trick to find the actual sales numbers for those months. The command to do that would just be this:</p>
<div class="sourceCode" id="cb179"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb179-1" title="1">sales.by.month [ sales.by.month <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span> ]</a></code></pre></div>
<pre><code>## [1] 100 200  50  25</code></pre>
<p>In fact, we can do the same thing with text. Here’s an example. Suppose that – to continue the saga of the textbook sales – I later find out that the bookshop only had sufficient stocks for a few months of the year. They tell me that early in the year they had <code>"high"</code> stocks, which then dropped to <code>"low"</code> levels, and in fact for one month they were <code>"out"</code> of copies of the book for a while before they were able to replenish them. Thus I might have a variable called <code>stock.levels</code> which looks like this:</p>
<div class="sourceCode" id="cb181"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb181-1" title="1">stock.levels&lt;-<span class="kw">c</span>(<span class="st">&quot;high&quot;</span>, <span class="st">&quot;high&quot;</span>, <span class="st">&quot;low&quot;</span>, <span class="st">&quot;out&quot;</span>, <span class="st">&quot;out&quot;</span>, <span class="st">&quot;high&quot;</span>,</a>
<a class="sourceLine" id="cb181-2" title="2">                <span class="st">&quot;high&quot;</span>, <span class="st">&quot;high&quot;</span>, <span class="st">&quot;high&quot;</span>, <span class="st">&quot;high&quot;</span>, <span class="st">&quot;high&quot;</span>, <span class="st">&quot;high&quot;</span>)</a>
<a class="sourceLine" id="cb181-3" title="3"></a>
<a class="sourceLine" id="cb181-4" title="4">stock.levels</a></code></pre></div>
<pre><code>##  [1] &quot;high&quot; &quot;high&quot; &quot;low&quot;  &quot;out&quot;  &quot;out&quot;  &quot;high&quot; &quot;high&quot; &quot;high&quot; &quot;high&quot; &quot;high&quot;
## [11] &quot;high&quot; &quot;high&quot;</code></pre>
<p>Thus, if I want to know the months for which the bookshop was out of my book, I could apply the logical indexing trick, but with the character vector <code>stock.levels</code>, like this:</p>
<div class="sourceCode" id="cb183"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb183-1" title="1">months[stock.levels <span class="op">==</span><span class="st"> &quot;out&quot;</span>]</a></code></pre></div>
<pre><code>## [1] &quot;April&quot; &quot;May&quot;</code></pre>
<p>Alternatively, if I want to know when the bookshop was either low on copies or out of copies, I could do this:</p>
<div class="sourceCode" id="cb185"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb185-1" title="1">months[stock.levels <span class="op">==</span><span class="st"> &quot;out&quot;</span> <span class="op">|</span><span class="st"> </span>stock.levels <span class="op">==</span><span class="st"> &quot;low&quot;</span>]</a></code></pre></div>
<pre><code>## [1] &quot;March&quot; &quot;April&quot; &quot;May&quot;</code></pre>
<p>or this</p>
<div class="sourceCode" id="cb187"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb187-1" title="1">months[stock.levels <span class="op">!=</span><span class="st"> &quot;high&quot;</span> ]</a></code></pre></div>
<pre><code>## [1] &quot;March&quot; &quot;April&quot; &quot;May&quot;</code></pre>
<p>Either way, I get the answer I want.</p>
<p>At this point, I hope you can see why logical indexing is such a useful thing. It’s a very basic, yet very powerful way to manipulate data. We’ll talk a lot more about how to manipulate data in Chapter @ref(datahandling), since it’s a critical skill for real world research that is often overlooked in introductory research methods classes (or at least, that’s been my experience). It does take a bit of practice to become completely comfortable using logical indexing, so it’s a good idea to play around with these sorts of commands. Try creating a few different variables of your own, and then ask yourself questions like “how do I get R to spit out all the elements that are [blah]”. Practice makes perfect, and it’s only by practicing logical indexing that you’ll perfect the art of yelling frustrated insults at your computer.<a href="#fn41" class="footnote-ref" id="fnref41"><sup>41</sup></a></p>
</div>
</div>
<div id="quitting-r" class="section level2">
<h2><span class="header-section-number">3.11</span> Quitting R</h2>
<div class="figure">
<img src="img/introR/Rstudio_quit.png" alt="The dialog box that shows up when you try to close RStudio." width="501" />
<p class="caption">
(#fig:quitR)The dialog box that shows up when you try to close RStudio.
</p>
</div>
<p>There’s one last thing I should cover in this chapter: how to quit R. When I say this, I’m not trying to imply that R is some kind of pathological addition and that you need to call the R QuitLine or wear patches to control the cravings (although you certainly might argue that there’s something seriously pathological about being addicted to R). I just mean how to exit the program. Assuming you’re running R in the usual way (i.e., through RStudio or the default GUI on a Windows or Mac computer), then you can just shut down the application in the normal way. However, R also has a function, called <code>q()</code> that you can use to quit, which is pretty handy if you’re running R in a terminal window.</p>
<p>Regardless of what method you use to quit R, when you do so for the first time R will probably ask you if you want to save the “workspace image”. We’ll talk a lot more about loading and saving data in Section @ref(load), but I figured we’d better quickly cover this now otherwise you’re going to get annoyed when you close R at the end of the chapter. If you’re using RStudio, you’ll see a dialog box that looks like the one shown in Figure @ref(fig:quitR). If you’re using a text based interface you’ll see this:</p>
<div class="sourceCode" id="cb189"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb189-1" title="1"><span class="kw">q</span>()</a>
<a class="sourceLine" id="cb189-2" title="2"></a>
<a class="sourceLine" id="cb189-3" title="3"><span class="co">## Save workspace image? [y/n/c]: </span></a></code></pre></div>
<p>The <code>y/n/c</code> part here is short for “yes / no / cancel”. Type <code>y</code> if you want to save, <code>n</code> if you don’t, and <code>c</code> if you’ve changed your mind and you don’t want to quit after all.</p>
<p>What does this actually <em>mean</em>? What’s going on is that R wants to know if you want to save all those variables that you’ve been creating, so that you can use them later. This sounds like a great idea, so it’s really tempting to type <code>y</code> or click the “Save” button. To be honest though, I very rarely do this, and it kind of annoys me a little bit… what R is <em>really</em> asking is if you want it to store these variables in a “default” data file, which it will automatically reload for you next time you open R. And quite frankly, if I’d wanted to save the variables, then I’d have already saved them before trying to quit. Not only that, I’d have saved them to a location of <em>my</em> choice, so that I can find it again later. So I personally never bother with this.</p>
<p>In fact, every time I install R on a new machine one of the first things I do is change the settings so that it never asks me again. You can do this in RStudio really easily: use the menu system to find the RStudio option; the dialog box that comes up will give you an option to tell R never to whine about this again (see Figure @ref(fig:RStudiooptions). On a Mac, you can open this window by going to the “RStudio” menu and selecting “Preferences”. On a Windows machine you go to the “Tools” menu and select “Global Options”. Under the “General” tab you’ll see an option that reads “Save workspace to .Rdata on exit”. By default this is set to “ask”. If you want R to stop asking, change it to “never”.</p>
<div class="figure">
<img src="img/introR/Rstudio_options.png" alt="The options window in RStudio. On a Mac, you can open this window by going to the &quot;RStudio&quot; menu and selecting &quot;Preferences&quot;. On a Windows machine you go to the &quot;Tools&quot; menu and select &quot;Global Options&quot;" width="579" />
<p class="caption">
(#fig:RStudiooptions)The options window in RStudio. On a Mac, you can open this window by going to the “RStudio” menu and selecting “Preferences”. On a Windows machine you go to the “Tools” menu and select “Global Options”
</p>
</div>
</div>
<div id="summary" class="section level2">
<h2><span class="header-section-number">3.12</span> Summary</h2>
<p>Every book that tries to introduce basic programming ideas to novices has to cover roughly the same topics, and in roughly the same order. Mine is no exception, and so in the grand tradition of doing it just the same way everyone else did it, this chapter covered the following topics:</p>
<ul>
<li><a href="#gettingR">Getting started</a>. We downloaded and installed R and RStudio</li>
<li><a href="#arithmetic">Basic commands</a>. We talked a bit about the logic of how R works and in particular how to type commands into the R console (Section @ref(#firstcommand), and in doing so learned how to perform basic calculations using the arithmetic operators <code>+</code>, <code>-</code>, <code>*</code>, <code>/</code> and <code>^</code>.</li>
<li><a href="#usingfunctions">Introduction to functions</a>. We saw several different functions, three that are used to perform numeric calculations (<code>sqrt()</code>, <code>abs()</code>, <code>round()</code>, one that applies to text (<code>nchar()</code>; Section @ref(simpletext)), and one that works on any variable (<code>length()</code>; Section @ref(veclength)). In doing so, we talked a bit about how argument names work, and learned about default values for arguments. (Section @ref(functionarguments))</li>
<li>Introduction to variables. We learned the basic idea behind variables, and how to assign values to variables using the assignment operator <code>&lt;-</code> (Section @ref(assign)). We also learned how to create vectors using the combine function <code>c()</code> (Section @ref(vectors)).</li>
<li>Data types. Learned the distinction between numeric, character and logical data; including the basics of how to enter and use each of them. (Sections @ref(assign) to @ref(logicals))</li>
<li><a href="#logicals">Logical operations</a>. Learned how to use the logical operators <code>==</code>, <code>!=</code>, <code>&lt;</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>=&gt;</code>, <code>!</code>, <code>&amp;</code> and <code>|</code>. And learned how to use logical indexing. (Section @ref(indexing))</li>
</ul>
<p>We still haven’t arrived at anything that resembles a “data set”, of course. Maybe the next Chapter will get us a bit closer…</p>
<!--chapter:end:02.03-introR.Rmd-->
</div>
</div>
<div id="mechanics" class="section level1">
<h1><span class="header-section-number">4</span> Additional R concepts</h1>
<blockquote>
<p><em>Form follows function</em></p>
<p>– Louis Sullivan</p>
</blockquote>
<p>In Chapter @ref(introR) our main goal was to get started in R. As we go through the book we’ll run into a lot of new R concepts, which I’ll explain alongside the relevant data analysis concepts. However, there’s still quite a few things that I need to talk about now, otherwise we’ll run into problems when we start trying to work with data and do statistics. So that’s the goal in this chapter: to build on the introductory content from the last chapter, to get you to the point that we can start using R for statistics. Broadly speaking, the chapter comes in two parts. The first half of the chapter is devoted to the “mechanics” of R: installing and loading packages, managing the workspace, navigating the file system, and loading and saving data. In the second half, I’ll talk more about what kinds of variables exist in R, and introduce three new kinds of variables: factors, data frames and formulas. I’ll finish up by talking a little bit about the help documentation in R as well as some other avenues for finding assistance. In general, I’m not trying to be comprehensive in this chapter, I’m trying to make sure that you’ve got the basic foundations needed to tackle the content that comes later in the book. However, a lot of the topics are revisited in more detail later, especially in Chapters @ref(datahandling) and @ref(scripting).</p>
<div id="comments" class="section level2">
<h2><span class="header-section-number">4.1</span> Using comments</h2>
<p>Before discussing any of the more complicated stuff, I want to introduce the <strong><em>comment</em></strong> character, <code>#</code>. It has a simple meaning: it tells R to ignore everything else you’ve written on this line. You won’t have much need of the <code>#</code> character immediately, but it’s very useful later on when writing scripts (see Chapter @ref(scripting)). However, while you don’t need to use it, I want to be able to include comments in my R extracts. For instance, if you read this:<a href="#fn42" class="footnote-ref" id="fnref42"><sup>42</sup></a></p>
<div class="sourceCode" id="cb190"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb190-1" title="1">seeker &lt;-<span class="st"> </span><span class="fl">3.1415</span>           <span class="co"># create the first variable</span></a>
<a class="sourceLine" id="cb190-2" title="2">lover &lt;-<span class="st"> </span><span class="fl">2.7183</span>            <span class="co"># create the second variable</span></a>
<a class="sourceLine" id="cb190-3" title="3">keeper &lt;-<span class="st"> </span>seeker <span class="op">*</span><span class="st"> </span>lover   <span class="co"># now multiply them to create a third one</span></a>
<a class="sourceLine" id="cb190-4" title="4"><span class="kw">print</span>( keeper )            <span class="co"># print out the value of &#39;keeper&#39;</span></a></code></pre></div>
<pre><code>## [1] 8.539539</code></pre>
<p>it’s a lot easier to understand what I’m doing than if I just write this:</p>
<div class="sourceCode" id="cb192"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb192-1" title="1">seeker &lt;-<span class="st"> </span><span class="fl">3.1415</span></a>
<a class="sourceLine" id="cb192-2" title="2">lover &lt;-<span class="st"> </span><span class="fl">2.7183</span></a>
<a class="sourceLine" id="cb192-3" title="3">keeper &lt;-<span class="st"> </span>seeker <span class="op">*</span><span class="st"> </span>lover</a>
<a class="sourceLine" id="cb192-4" title="4"><span class="kw">print</span>( keeper )    </a></code></pre></div>
<pre><code>## [1] 8.539539</code></pre>
<p>You might have already noticed that the code extracts in Chapter @ref(introR) included the <code>#</code> character, but from now on, you’ll start seeing <code>#</code> characters appearing in the extracts, with some human-readable explanatory remarks next to them. These are still perfectly legitimate commands, since R knows that it should ignore the <code>#</code> character and everything after it. But hopefully they’ll help make things a little easier to understand.</p>
</div>
<div id="packageinstall" class="section level2">
<h2><span class="header-section-number">4.2</span> Installing and loading packages</h2>
<p>In this section I discuss R <strong><em>packages</em></strong>, since almost all of the functions you might want to use in R come in packages. A package is basically just a big collection of functions, data sets and other R objects that are all grouped together under a common name. Some packages are already installed when you put R on your computer, but the vast majority of them of R packages are out there on the internet, waiting for you to download, install and use them.</p>
<p>When I first started writing this book, RStudio didn’t really exist as a viable option for using R, and as a consequence I wrote a very lengthy section that explained how to do package management using raw R commands. It’s not actually terribly hard to work with packages that way, but it’s clunky and unpleasant. Fortunately, we don’t have to do things that way anymore. In this section, I’ll describe how to work with packages using the RStudio tools, because they’re so much simpler. Along the way, you’ll see that whenever you get RStudio to do something (e.g., install a package), you’ll actually see the R commands that get created. I’ll explain them as we go, because I think that helps you understand what’s going on.</p>
<p>However, before we get started, there’s a critical distinction that you need to understand, which is the difference between having a package <strong><em>installed</em></strong> on your computer, and having a package <strong><em>loaded</em></strong> in R. As of this writing, there are just over 5000 R packages freely available “out there” on the internet.<a href="#fn43" class="footnote-ref" id="fnref43"><sup>43</sup></a> When you install R on your computer, you don’t get all of them: only about 30 or so come bundled with the basic R installation. So right now there are about 30 packages “installed” on your computer, and another 5000 or so that are not installed. So that’s what installed means: it means “it’s on your computer somewhere”. The critical thing to remember is that just because something is on your computer doesn’t mean R can use it. In order for R to be able to <em>use</em> one of your 30 or so installed packages, that package must also be “loaded”. Generally, when you open up R, only a few of these packages (about 7 or 8) are actually loaded. Basically what it boils down to is this:</p>
<blockquote>
<p>A package must be installed before it can be loaded.</p>
</blockquote>
<blockquote>
<p>A package must be loaded before it can be used.</p>
</blockquote>
<p>This two step process might seem a little odd at first, but the designers of R had very good reasons to do it this way,<a href="#fn44" class="footnote-ref" id="fnref44"><sup>44</sup></a> and you get the hang of it pretty quickly.</p>
<div id="the-package-panel-in-rstudio" class="section level3">
<h3><span class="header-section-number">4.2.1</span> The package panel in RStudio</h3>
<div class="figure">
<img src="img/mechanics/Rstudiopackages.png" alt="The packages panel." width="497" />
<p class="caption">
(#fig:packagepanel)The packages panel.
</p>
</div>
<p>Right, lets get started. The first thing you need to do is look in the lower right hand panel in RStudio. You’ll see a tab labelled “Packages”. Click on the tab, and you’ll see a list of packages that looks something like Figure @ref(fig:packagepanel). Every row in the panel corresponds to a different package, and every column is a useful piece of information about that package.<a href="#fn45" class="footnote-ref" id="fnref45"><sup>45</sup></a> Going from left to right, here’s what each column is telling you:</p>
<ul>
<li>The check box on the far left column indicates whether or not the package is loaded.</li>
<li>The one word of text immediately to the right of the check box is the name of the package.</li>
<li>The short passage of text next to the name is a brief description of the package.</li>
<li>The number next to the description tells you what version of the package you have installed.</li>
<li>The little x-mark next to the version number is a button that you can push to uninstall the package from your computer (you almost never need this).</li>
</ul>
</div>
<div id="packageload" class="section level3">
<h3><span class="header-section-number">4.2.2</span> Loading a package</h3>
<p>That seems straightforward enough, so let’s try loading and unloading packades. For this example, I’ll use the <code>foreign</code> package. The <code>foreign</code> package is a collection of tools that are very handy when R needs to interact with files that are produced by other software packages (e.g., SPSS). It comes bundled with R, so it’s one of the ones that you have installed already, but it won’t be one of the ones loaded. Inside the <code>foreign</code> package is a function called <code>read.spss()</code>. It’s a handy little function that you can use to import an SPSS data file into R, so let’s pretend we want to use it. Currently, the <code>foreign</code> package isn’t loaded, so if I ask R to tell me if it knows about a function called <code>read.spss()</code> it tells me that there’s no such thing…</p>
<div class="sourceCode" id="cb194"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb194-1" title="1"><span class="kw">exists</span>( <span class="st">&quot;read.spss&quot;</span> )</a></code></pre></div>
<pre><code>## [1] FALSE</code></pre>
<p>Now let’s load the package. In RStudio, the process is dead simple: go to the package tab, find the entry for the <code>foreign</code> package, and check the box on the left hand side. The moment that you do this, you’ll see a command like this appear in the R console:</p>
<div class="sourceCode" id="cb196"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb196-1" title="1"><span class="kw">library</span>(<span class="st">&quot;foreign&quot;</span>, <span class="dt">lib.loc=</span><span class="st">&quot;/Library/Frameworks/R.framework/Versions/3.0/Resources/library&quot;</span>)</a></code></pre></div>
<p>The <code>lib.loc</code> bit will look slightly different on Macs versus on Windows, because that part of the command is just RStudio telling R where to look to find the installed packages. What I’ve shown you above is the Mac version. On a Windows machine, you’ll probably see something that looks like this:</p>
<div class="sourceCode" id="cb197"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb197-1" title="1"><span class="kw">library</span>(<span class="st">&quot;foreign&quot;</span>, <span class="dt">lib.loc=</span><span class="st">&quot;C:/Program Files/R/R-3.0.2/library&quot;</span>)</a></code></pre></div>
<p>But actually it doesn’t matter much. The <code>lib.loc</code> bit is almost always unnecessary. Unless you’ve taken to installing packages in idiosyncratic places (which is something that you can do if you really want) R already knows where to look. So in the vast majority of cases, the command to load the <code>foreign</code> package is just this:</p>
<div class="sourceCode" id="cb198"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb198-1" title="1"><span class="kw">library</span>(<span class="st">&quot;foreign&quot;</span>)</a></code></pre></div>
<p>Throughout this book, you’ll often see me typing in <code>library()</code> commands. You don’t actually have to type them in yourself: you can use the RStudio package panel to do all your package loading for you. The only reason I include the <code>library()</code> commands sometimes is as a reminder to you to make sure that you have the relevant package loaded. Oh, and I suppose we should check to see if our attempt to load the package actually worked. Let’s see if R now knows about the existence of the <code>read.spss()</code> function…</p>
<div class="sourceCode" id="cb199"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb199-1" title="1"><span class="kw">exists</span>( <span class="st">&quot;read.spss&quot;</span> )</a></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<p>Yep. All good.</p>
</div>
<div id="packageunload" class="section level3">
<h3><span class="header-section-number">4.2.3</span> Unloading a package</h3>
<p>Sometimes, especially after a long session of working with R, you find yourself wanting to get rid of some of those packages that you’ve loaded. The RStudio package panel makes this exactly as easy as loading the package in the first place. Find the entry corresponding to the package you want to unload, and uncheck the box. When you do that for the <code>foreign</code> package, you’ll see this command appear on screen:</p>
<div class="sourceCode" id="cb201"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb201-1" title="1"><span class="kw">detach</span>(<span class="st">&quot;package:foreign&quot;</span>, <span class="dt">unload=</span><span class="ot">TRUE</span>)</a></code></pre></div>
<pre><code>## Warning: &#39;foreign&#39; namespace cannot be unloaded:
##   namespace &#39;foreign&#39; is imported by &#39;rio&#39; so cannot be unloaded</code></pre>
<p>And the package is unloaded. We can verify this by seeing if the <code>read.spss()</code> function still <code>exists()</code>:</p>
<div class="sourceCode" id="cb203"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb203-1" title="1"><span class="kw">exists</span>( <span class="st">&quot;read.spss&quot;</span> )</a></code></pre></div>
<pre><code>## [1] FALSE</code></pre>
<p>Nope. Definitely gone.</p>
</div>
<div id="a-few-extra-comments" class="section level3">
<h3><span class="header-section-number">4.2.4</span> A few extra comments</h3>
<p>Sections @ref(packageload) and @ref(packageunload) cover the main things you need to know about loading and unloading packages. However, there’s a couple of other details that I want to draw your attention to. A concrete example is the best way to illustrate. One of the other packages that you already have installed on your computer is the <code>Matrix</code> package, so let’s load that one and see what happens:</p>
<div class="sourceCode" id="cb205"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb205-1" title="1"><span class="kw">library</span>( Matrix )</a>
<a class="sourceLine" id="cb205-2" title="2"></a>
<a class="sourceLine" id="cb205-3" title="3"><span class="co">## Loading required package: lattice</span></a></code></pre></div>
<p>This is slightly more complex than the output that we got last time, but it’s not too complicated. The <code>Matrix</code> package makes use of some of the tools in the <code>lattice</code> package, and R has kept track of this dependency. So when you try to load the <code>Matrix</code> package, R recognises that you’re also going to need to have the <code>lattice</code> package loaded too. As a consequence, <em>both</em> packages get loaded, and R prints out a helpful little note on screen to tell you that it’s done so.</p>
<p>R is pretty aggressive about enforcing these dependencies. Suppose, for example, I try to unload the <code>lattice</code> package while the <code>Matrix</code> package is still loaded. This is easy enough to try: all I have to do is uncheck the box next to “lattice” in the packages panel. But if I try this, here’s what happens:</p>
<div class="sourceCode" id="cb206"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb206-1" title="1"><span class="kw">detach</span>(<span class="st">&quot;package:lattice&quot;</span>, <span class="dt">unload=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb206-2" title="2"></a>
<a class="sourceLine" id="cb206-3" title="3"><span class="co">## Error: package `lattice&#39; is required by `Matrix&#39; so will not be detached</span></a></code></pre></div>
<p>R refuses to do it. This can be quite useful, since it stops you from accidentally removing something that you still need. So, if I want to remove both <code>Matrix</code> and <code>lattice</code>, I need to do it in the correct order</p>
<p>Something else you should be aware of. Sometimes you’ll attempt to load a package, and R will print out a message on screen telling you that something or other has been “masked”. This will be confusing to you if I don’t explain it now, and it actually ties very closely to the whole reason why R forces you to load packages separately from installing them. Here’s an example. Two of the package that I’ll refer to a lot in this book are called <code>car</code> and <code>psych</code>. The <code>car</code> package is short for “Companion to Applied Regression” (which is a really great book, I’ll add), and it has a lot of tools that I’m quite fond of. The <code>car</code> package was written by a guy called John Fox, who has written a lot of great statistical tools for social science applications. The <code>psych</code> package was written by William Revelle, and it has a lot of functions that are very useful for psychologists in particular, especially in regards to psychometric techniques. For the most part, <code>car</code> and <code>psych</code> are quite unrelated to each other. They do different things, so not surprisingly almost all of the function names are different. But… there’s one exception to that. The <code>car</code> package and the <code>psych</code> package <em>both</em> contain a function called <code>logit()</code>.<a href="#fn46" class="footnote-ref" id="fnref46"><sup>46</sup></a> This creates a naming conflict. If I load both packages into R, an ambiguity is created. If the user types in <code>logit(100)</code>, should R use the <code>logit()</code> function in the <code>car</code> package, or the one in the <code>psych</code> package? The answer is: R uses whichever package you loaded most recently, and it tells you this very explicitly. Here’s what happens when I load the <code>car</code> package, and then afterwards load the <code>psych</code> package:</p>
<div class="sourceCode" id="cb207"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb207-1" title="1"><span class="kw">library</span>(car)</a>
<a class="sourceLine" id="cb207-2" title="2"><span class="kw">library</span>(psych)</a></code></pre></div>
<p>The output here is telling you that the <code>logit</code> object (i.e., function) in the <code>car</code> package is no longer accessible to you. It’s been hidden (or “masked”) from you by the one in the <code>psych</code> package.<a href="#fn47" class="footnote-ref" id="fnref47"><sup>47</sup></a></p>
</div>
<div id="downloading-new-packages" class="section level3">
<h3><span class="header-section-number">4.2.5</span> Downloading new packages</h3>
<p>One of the main selling points for R is that there are thousands of packages that have been written for it, and these are all available online. So whereabouts online are these packages to be found, and how do we download and install them? There is a big repository of packages called the “Comprehensive R Archive Network” (CRAN), and the easiest way of getting and installing a new package is from one of the many CRAN mirror sites. Conveniently for us, R provides a function called <code>install.packages()</code> that you can use to do this. Even <em>more</em> conveniently, the RStudio team runs its own CRAN mirror and RStudio has a clean interface that lets you install packages without having to learn how to use the <code>install.packages()</code> command<a href="#fn48" class="footnote-ref" id="fnref48"><sup>48</sup></a></p>
<p>Using the RStudio tools is, again, dead simple. In the top left hand corner of the packages panel (Figure @ref(fig:packagepanel)) you’ll see a button called “Install Packages”. If you click on that, it will bring up a window like the one shown in Figure @ref(fig:packageinstalla).</p>
<div class="figure">
<img src="img/mechanics/installpackage.png" alt="The package installation dialog box in RStudio" width="388" />
<p class="caption">
(#fig:packageinstalla)The package installation dialog box in RStudio
</p>
</div>
<p>There are a few different buttons and boxes you can play with. Ignore most of them. Just go to the line that says “Packages” and start typing the name of the package that you want. As you type, you’ll see a dropdown menu appear (Figure @ref(fig:packageinstallb)), listing names of packages that start with the letters that you’ve typed so far.</p>
<div class="figure">
<img src="img/mechanics/installpackage2.png" alt="When you start typing, you'll see a dropdown menu suggest a list of possible packages that you might want to install" width="389" />
<p class="caption">
(#fig:packageinstallb)When you start typing, you’ll see a dropdown menu suggest a list of possible packages that you might want to install
</p>
</div>
<p>You can select from this list, or just keep typing. Either way, once you’ve got the package name that you want, click on the install button at the bottom of the window. When you do, you’ll see the following command appear in the R console:</p>
<div class="sourceCode" id="cb208"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb208-1" title="1"><span class="kw">install.packages</span>(<span class="st">&quot;psych&quot;</span>)</a></code></pre></div>
<p>This is the R command that does all the work. R then goes off to the internet, has a conversation with CRAN, downloads some stuff, and installs it on your computer. You probably don’t care about all the details of R’s little adventure on the web, but the <code>install.packages()</code> function is rather chatty, so it reports a bunch of gibberish that you really aren’t all that interested in:</p>
<pre><code>trying URL &#39;http://cran.rstudio.com/bin/macosx/contrib/3.0/psych_1.4.1.tgz&#39;
Content type &#39;application/x-gzip&#39; length 2737873 bytes (2.6 Mb)
opened URL
==================================================
downloaded 2.6 Mb


The downloaded binary packages are in
    /var/folders/cl/thhsyrz53g73q0w1kb5z3l_80000gn/T//RtmpmQ9VT3/downloaded_packages</code></pre>
<p>Despite the long and tedious response, all thar really means is “I’ve installed the psych package”. I find it best to humour the talkative little automaton. I don’t actually read any of this garbage, I just politely say “thanks” and go back to whatever I was doing.</p>
</div>
<div id="updating-r-and-r-packages" class="section level3">
<h3><span class="header-section-number">4.2.6</span> Updating R and R packages</h3>
<p>Every now and then the authors of packages release updated versions. The updated versions often add new functionality, fix bugs, and so on. It’s generally a good idea to update your packages periodically. There’s an <code>update.packages()</code> function that you can use to do this, but it’s probably easier to stick with the RStudio tool. In the packages panel, click on the “Update Packages” button. This will bring up a window that looks like the one shown in Figure @ref(fig:updatepackages). In this window, each row refers to a package that needs to be updated. You can to tell R which updates you want to install by checking the boxes on the left. If you’re feeling lazy and just want to update everything, click the “Select All” button, and then click the “Install Updates” button. R then prints out a <em>lot</em> of garbage on the screen, individually downloading and installing all the new packages. This might take a while to complete depending on how good your internet connection is. Go make a cup of coffee. Come back, and all will be well.</p>
<div class="figure">
<img src="img/mechanics/updatepackages.png" alt="The RStudio dialog box for updating packages" width="479" />
<p class="caption">
(#fig:updatepackages)The RStudio dialog box for updating packages
</p>
</div>
<p>About every six months or so, a new version of R is released. You can’t update R from within RStudio (not to my knowledge, at least): to get the new version you can go to the CRAN website and download the most recent version of R, and install it in the same way you did when you originally installed R on your computer. This used to be a slightly frustrating event, because whenever you downloaded the new version of R, you would lose all the packages that you’d downloaded and installed, and would have to repeat the process of re-installing them. This was pretty annoying, and there were some neat tricks you could use to get around this. However, newer versions of R don’t have this problem so I no longer bother explaining the workarounds for that issue.</p>
</div>
<div id="what-packages-does-this-book-use" class="section level3">
<h3><span class="header-section-number">4.2.7</span> What packages does this book use?</h3>
<p>There are several packages that I make use of in this book. The most prominent ones are:</p>
<ul>
<li><code>lsr</code>. This is the <em>Learning Statistics with R</em> package that accompanies this book. It doesn’t have a lot of interesting high-powered tools: it’s just a small collection of handy little things that I think can be useful to novice users. As you get more comfortable with R this package should start to feel pretty useless to you.</li>
<li><code>psych</code>. This package, written by William Revelle, includes a lot of tools that are of particular use to psychologists. In particular, there’s several functions that are particularly convenient for producing analyses or summaries that are very common in psych, but less common in other disciplines.</li>
<li><code>car</code>. This is the <em>Companion to Applied Regression</em> package, which accompanies the excellent book of the same name by <span class="citation">(Fox and Weisberg <a href="#ref-Fox2011" role="doc-biblioref">2011</a>)</span>. It provides a lot of very powerful tools, only some of which we’ll touch in this book.</li>
</ul>
<p>Besides these three, there are a number of packages that I use in a more limited fashion: <code>gplots</code>, <code>sciplot</code>, <code>foreign</code>, <code>effects</code>, <code>R.matlab</code>, <code>gdata</code>, <code>lmtest</code>, and probably one or two others that I’ve missed. There are also a number of packages that I refer to but don’t actually use in this book, such as <code>reshape</code>, <code>compute.es</code>, <code>HistData</code> and <code>multcomp</code> among others. Finally, there are a number of packages that provide more advanced tools that I hope to talk about in future versions of the book, such as <code>sem</code>, <code>ez</code>, <code>nlme</code> and <code>lme4</code>. In any case, whenever I’m using a function that isn’t in the core packages, I’ll make sure to note this in the text.</p>
</div>
</div>
<div id="workspace" class="section level2">
<h2><span class="header-section-number">4.3</span> Managing the workspace</h2>
<p>Let’s suppose that you’re reading through this book, and what you’re doing is sitting down with it once a week and working through a whole chapter in each sitting. Not only that, you’ve been following my advice and typing in all these commands into R. So far during this chapter, you’d have typed quite a few commands, although the only ones that actually involved creating variables were the ones you typed during Section @ref(comments). As a result, you currently have three variables; <code>seeker</code>, <code>lover</code>, and <code>keeper</code>. These three variables are the contents of your <strong><em>workspace</em></strong>, also referred to as the <strong>global environment</strong>. The workspace is a key concept in R, so in this section we’ll talk a lot about what it is and how to manage its contents.</p>
<div id="listing-the-contents-of-the-workspace" class="section level3">
<h3><span class="header-section-number">4.3.1</span> Listing the contents of the workspace</h3>
<div class="figure">
<img src="img/mechanics/workspacepanel.png" alt="The RStudio Environment panel shows you the contents of the workspace. The view shown above is the list view. To switch to the grid view, click on the menu item on the top right that currently reads list. Select grid from the dropdown menu, and then it will switch to a view like the one shown in the other workspace figure" width="531" />
<p class="caption">
(#fig:workspace)The RStudio Environment panel shows you the contents of the workspace. The view shown above is the list view. To switch to the grid view, click on the menu item on the top right that currently reads list. Select grid from the dropdown menu, and then it will switch to a view like the one shown in the other workspace figure
</p>
</div>
<div class="figure">
<img src="img/mechanics/workspacepanel2.png" alt="The RStudio &quot;Environment&quot; panel shows you the contents of the workspace. Compare this &quot;grid&quot; view to the &quot;list&quot; earlier" width="532" />
<p class="caption">
(#fig:workspace2)The RStudio “Environment” panel shows you the contents of the workspace. Compare this “grid” view to the “list” earlier
</p>
</div>
<p>The first thing that you need to know how to do is examine the contents of the workspace. If you’re using RStudio, you will probably find that the easiest way to do this is to use the “Environment” panel in the top right hand corner. Click on that, and you’ll see a list that looks very much like the one shown in Figures @ref(fig:workspace) and @ref(fig:workspace2). If you’re using the commmand line, then the <code>objects()</code> function may come in handy:</p>
<div class="sourceCode" id="cb210"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb210-1" title="1"><span class="kw">objects</span>()</a></code></pre></div>
<pre><code>##   [1] &quot;a&quot;                    &quot;addArrow&quot;             &quot;addDistPlot&quot;         
##   [4] &quot;afl&quot;                  &quot;afl.finalists&quot;        &quot;afl.margins&quot;         
##   [7] &quot;afl2&quot;                 &quot;age&quot;                  &quot;age.breaks&quot;          
##  [10] &quot;age.group&quot;            &quot;age.group2&quot;           &quot;age.group3&quot;          
##  [13] &quot;age.labels&quot;           &quot;agpp&quot;                 &quot;animals&quot;             
##  [16] &quot;anova.model&quot;          &quot;anovaImg&quot;             &quot;any.sales.this.month&quot;
##  [19] &quot;awesome&quot;              &quot;b&quot;                    &quot;bad.coef&quot;            
##  [22] &quot;balance&quot;              &quot;beers&quot;                &quot;berkeley&quot;            
##  [25] &quot;berkeley.small&quot;       &quot;binomPlot&quot;            &quot;bw&quot;                  
##  [28] &quot;cake.1&quot;               &quot;cake.2&quot;               &quot;cake.df&quot;             
##  [31] &quot;cake.mat1&quot;            &quot;cake.mat2&quot;            &quot;cakes&quot;               
##  [34] &quot;cakes.flipped&quot;        &quot;cardChoices&quot;          &quot;cards&quot;               
##  [37] &quot;chapek9&quot;              &quot;chapekFrequencies&quot;    &quot;chi.sq.20&quot;           
##  [40] &quot;chi.sq.3&quot;             &quot;chico&quot;                &quot;chico2&quot;              
##  [43] &quot;chico3&quot;               &quot;chiSqImg&quot;             &quot;choice&quot;              
##  [46] &quot;choice.2&quot;             &quot;clin.trial&quot;           &quot;clin.trial.2&quot;        
##  [49] &quot;coef&quot;                 &quot;coffee&quot;               &quot;colour&quot;              
##  [52] &quot;crit&quot;                 &quot;crit.hi&quot;              &quot;crit.lo&quot;             
##  [55] &quot;crit.val&quot;             &quot;crosstab&quot;             &quot;d.cor&quot;               
##  [58] &quot;dan.awake&quot;            &quot;data&quot;                 &quot;day&quot;                 
##  [61] &quot;days.per.month&quot;       &quot;def.par&quot;              &quot;describeImg&quot;         
##  [64] &quot;dev.from.gp.means&quot;    &quot;dev.from.grand.mean&quot;  &quot;df&quot;                  
##  [67] &quot;doubleMax&quot;            &quot;drawBasicScatterplot&quot; &quot;drug.anova&quot;          
##  [70] &quot;drug.lm&quot;              &quot;drug.means&quot;           &quot;drug.regression&quot;     
##  [73] &quot;druganxifree&quot;         &quot;drugs&quot;                &quot;drugs.2&quot;             
##  [76] &quot;eff&quot;                  &quot;effort&quot;               &quot;emphCol&quot;             
##  [79] &quot;emphColLight&quot;         &quot;emphGrey&quot;             &quot;eps&quot;                 
##  [82] &quot;es&quot;                   &quot;estImg&quot;               &quot;eta.squared&quot;         
##  [85] &quot;eventNames&quot;           &quot;expected&quot;             &quot;f&quot;                   
##  [88] &quot;F.3.20&quot;               &quot;F.stat&quot;               &quot;fac&quot;                 
##  [91] &quot;february.sales&quot;       &quot;fibonacci&quot;            &quot;Fibonacci&quot;           
##  [94] &quot;fileName&quot;             &quot;freq&quot;                 &quot;full.model&quot;          
##  [97] &quot;G&quot;                    &quot;garden&quot;               &quot;gender&quot;              
## [100] &quot;generateRLineTypes&quot;   &quot;generateRPointShapes&quot; &quot;good.coef&quot;           
## [103] &quot;gp.mean&quot;              &quot;gp.means&quot;             &quot;gp.sizes&quot;            
## [106] &quot;grades&quot;               &quot;grand.mean&quot;           &quot;greeting&quot;            
## [109] &quot;group&quot;                &quot;h&quot;                    &quot;happiness&quot;           
## [112] &quot;harpo&quot;                &quot;heavy.tailed.data&quot;    &quot;height&quot;              
## [115] &quot;hw&quot;                   &quot;i&quot;                    &quot;interest&quot;            
## [118] &quot;IQ&quot;                   &quot;is.MP.speaking&quot;       &quot;is.the.Party.correct&quot;
## [121] &quot;itng&quot;                 &quot;itng.table&quot;           &quot;keeper&quot;              
## [124] &quot;likert.centred&quot;       &quot;likert.ordinal&quot;       &quot;likert.raw&quot;          
## [127] &quot;lover&quot;                &quot;lower.area&quot;           &quot;m&quot;                   
## [130] &quot;M&quot;                    &quot;M0&quot;                   &quot;M1&quot;                  
## [133] &quot;makka.pakka&quot;          &quot;max.val&quot;              &quot;mod&quot;                 
## [136] &quot;mod.1&quot;                &quot;mod.2&quot;                &quot;mod.3&quot;               
## [139] &quot;mod.4&quot;                &quot;mod.H&quot;                &quot;mod.R&quot;               
## [142] &quot;model&quot;                &quot;model.1&quot;              &quot;model.2&quot;             
## [145] &quot;model.3&quot;              &quot;models&quot;               &quot;monkey&quot;              
## [148] &quot;monkey.1&quot;             &quot;month&quot;                &quot;monthly.multiplier&quot;  
## [151] &quot;months&quot;               &quot;ms.diff&quot;              &quot;ms.res&quot;              
## [154] &quot;msg&quot;                  &quot;mu&quot;                   &quot;mu.null&quot;             
## [157] &quot;my.anova&quot;             &quot;my.anova.residuals&quot;   &quot;my.contrasts&quot;        
## [160] &quot;my.var&quot;               &quot;n&quot;                    &quot;N&quot;                   
## [163] &quot;ng&quot;                   &quot;nhstImg&quot;              &quot;nodrug.regression&quot;   
## [166] &quot;normal.a&quot;             &quot;normal.b&quot;             &quot;normal.c&quot;            
## [169] &quot;normal.d&quot;             &quot;normal.data&quot;          &quot;null.model&quot;          
## [172] &quot;nullProbs&quot;            &quot;numbers&quot;              &quot;observed&quot;            
## [175] &quot;old&quot;                  &quot;old.text&quot;             &quot;old_par&quot;             
## [178] &quot;oneCorPlot&quot;           &quot;opinion.dir&quot;          &quot;opinion.strength&quot;    
## [181] &quot;out.0&quot;                &quot;out.1&quot;                &quot;out.2&quot;               
## [184] &quot;outcome&quot;              &quot;p.value&quot;              &quot;parenthood&quot;          
## [187] &quot;payments&quot;             &quot;PJ&quot;                   &quot;plotHist&quot;            
## [190] &quot;plotOne&quot;              &quot;plotSamples&quot;          &quot;plotTwo&quot;             
## [193] &quot;pow&quot;                  &quot;probabilities&quot;        &quot;profit&quot;              
## [196] &quot;projecthome&quot;          &quot;quadruple&quot;            &quot;r&quot;                   
## [199] &quot;R.squared&quot;            &quot;random.contrasts&quot;     &quot;regression.1&quot;        
## [202] &quot;regression.2&quot;         &quot;regression.3&quot;         &quot;regression.model&quot;    
## [205] &quot;regression.model.2&quot;   &quot;regression.model.3&quot;   &quot;regressionImg&quot;       
## [208] &quot;resid&quot;                &quot;revenue&quot;              &quot;right.table&quot;         
## [211] &quot;row.1&quot;                &quot;row.2&quot;                &quot;royalty&quot;             
## [214] &quot;rtfm.1&quot;               &quot;rtfm.2&quot;               &quot;rtfm.3&quot;              
## [217] &quot;s&quot;                    &quot;salem.tabs&quot;           &quot;sales&quot;               
## [220] &quot;sales.by.month&quot;       &quot;sample.mean&quot;          &quot;scaled.chi.sq.3&quot;     
## [223] &quot;score.A&quot;              &quot;score.B&quot;              &quot;sd.true&quot;             
## [226] &quot;sd1&quot;                  &quot;seeker&quot;               &quot;sem.true&quot;            
## [229] &quot;setUpPlot&quot;            &quot;sig&quot;                  &quot;sigEx&quot;               
## [232] &quot;simpson&quot;              &quot;skewed.data&quot;          &quot;some.data&quot;           
## [235] &quot;speaker&quot;              &quot;speech.by.char&quot;       &quot;squared.devs&quot;        
## [238] &quot;ss.diff&quot;              &quot;SS.drug&quot;              &quot;SS.res&quot;              
## [241] &quot;ss.res.full&quot;          &quot;ss.res.null&quot;          &quot;SS.resid&quot;            
## [244] &quot;SS.therapy&quot;           &quot;ss.tot&quot;               &quot;SS.tot&quot;              
## [247] &quot;SSb&quot;                  &quot;SStot&quot;                &quot;SSw&quot;                 
## [250] &quot;stock.levels&quot;         &quot;suspicious.cases&quot;     &quot;t.3&quot;                 
## [253] &quot;teams&quot;                &quot;text&quot;                 &quot;therapy.means&quot;       
## [256] &quot;theta&quot;                &quot;today&quot;                &quot;tombliboo&quot;           
## [259] &quot;total.paid&quot;           &quot;tp&quot;                   &quot;trial&quot;               
## [262] &quot;ttestImg&quot;             &quot;type.I.sum&quot;           &quot;type.II.sum&quot;         
## [265] &quot;upper.area&quot;           &quot;upsy.daisy&quot;           &quot;utterance&quot;           
## [268] &quot;w&quot;                    &quot;W&quot;                    &quot;w.length&quot;            
## [271] &quot;width&quot;                &quot;words&quot;                &quot;wt.squared.devs&quot;     
## [274] &quot;x&quot;                    &quot;X&quot;                    &quot;x1&quot;                  
## [277] &quot;X1&quot;                   &quot;x2&quot;                   &quot;X2&quot;                  
## [280] &quot;x3&quot;                   &quot;X3&quot;                   &quot;X4&quot;                  
## [283] &quot;xlu&quot;                  &quot;xtab.3d&quot;              &quot;xval&quot;                
## [286] &quot;y&quot;                    &quot;Y&quot;                    &quot;Y.pred&quot;              
## [289] &quot;y1&quot;                   &quot;Y1&quot;                   &quot;y2&quot;                  
## [292] &quot;Y2&quot;                   &quot;y3&quot;                   &quot;Y3&quot;                  
## [295] &quot;Y4&quot;                   &quot;Ybar&quot;                 &quot;yhat.2&quot;              
## [298] &quot;yval&quot;                 &quot;yval.1&quot;               &quot;yval.2&quot;              
## [301] &quot;z&quot;                    &quot;Z&quot;                    &quot;z.score&quot;</code></pre>
<p>Of course, in the true R tradition, the <code>objects()</code> function has a lot of fancy capabilities that I’m glossing over in this example. Moreover there are also several other functions that you can use, including <code>ls()</code> which is pretty much identical to <code>objects()</code>, and <code>ls.str()</code> which you can use to get a fairly detailed description of all the variables in the workspace. In fact, the <code>lsr</code> package actually includes its own function that you can use for this purpose, called <code>who()</code>. The reason for using the <code>who()</code> function is pretty straightforward: in my everyday work I find that the output produced by the <code>objects()</code> command isn’t <em>quite</em> informative enough, because the only thing it prints out is the name of each variable; but the <code>ls.str()</code> function is <em>too</em> informative, because it prints out a lot of additional information that I really don’t like to look at. The <code>who()</code> function is a compromise between the two. First, now that we’ve got the <code>lsr</code> package installed, we need to load it:</p>
<div class="sourceCode" id="cb212"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb212-1" title="1"><span class="kw">library</span>(lsr)</a></code></pre></div>
<p>and now we can use the <code>who()</code> function:</p>
<div class="sourceCode" id="cb213"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb213-1" title="1"><span class="kw">who</span>()</a></code></pre></div>
<pre><code>##    -- Name --             -- Class --     -- Size --
##    a                      numeric         1         
##    addArrow               function                  
##    addDistPlot            function                  
##    afl                    data.frame      4296 x 12 
##    afl.finalists          factor          400       
##    afl.margins            numeric         176       
##    afl2                   data.frame      4296 x 2  
##    age                    numeric         5         
##    age.breaks             numeric         4         
##    age.group              factor          11        
##    age.group2             factor          11        
##    age.group3             factor          11        
##    age.labels             character       3         
##    agpp                   data.frame      100 x 3   
##    animals                character       4         
##    anova.model            aov             13        
##    anovaImg               list            0         
##    any.sales.this.month   logical         12        
##    awesome                data.frame      10 x 2    
##    b                      numeric         1         
##    bad.coef               numeric         2         
##    balance                numeric         1         
##    beers                  character       3         
##    berkeley               data.frame      39 x 3    
##    berkeley.small         data.frame      46 x 2    
##    binomPlot              function                  
##    bw                     numeric         1         
##    cake.1                 numeric         5         
##    cake.2                 numeric         5         
##    cake.df                data.frame      5 x 2     
##    cake.mat1              matrix          5 x 2     
##    cake.mat2              matrix          2 x 5     
##    cakes                  matrix          4 x 5     
##    cakes.flipped          matrix          5 x 4     
##    cardChoices            xtabs           4 x 4     
##    cards                  data.frame      200 x 3   
##    chapek9                data.frame      180 x 2   
##    chapekFrequencies      xtabs           3 x 2     
##    chi.sq.20              numeric         1000      
##    chi.sq.3               numeric         1000      
##    chico                  data.frame      20 x 3    
##    chico2                 data.frame      40 x 4    
##    chico3                 data.frame      20 x 4    
##    chiSqImg               list            0         
##    choice                 data.frame      4 x 10    
##    choice.2               data.frame      16 x 6    
##    clin.trial             data.frame      18 x 3    
##    clin.trial.2           data.frame      18 x 5    
##    coef                   numeric         2         
##    coffee                 data.frame      18 x 3    
##    colour                 logical         1         
##    crit                   numeric         1         
##    crit.hi                numeric         1         
##    crit.lo                numeric         1         
##    crit.val               numeric         1         
##    crosstab               xtabs           2 x 3     
##    d.cor                  numeric         1         
##    dan.awake              logical         10        
##    data                   data.frame      12 x 4    
##    day                    character       1         
##    days.per.month         numeric         12        
##    def.par                list            66        
##    describeImg            list            0         
##    dev.from.gp.means      array           18        
##    dev.from.grand.mean    array           3         
##    df                     numeric         1         
##    doubleMax              function                  
##    drawBasicScatterplot   function                  
##    drug.anova             aov             13        
##    drug.lm                lm              13        
##    drug.means             numeric         3         
##    drug.regression        lm              12        
##    druganxifree           numeric         18        
##    drugs                  data.frame      10 x 8    
##    drugs.2                data.frame      30 x 5    
##    eff                    eff             22        
##    effort                 data.frame      10 x 2    
##    emphCol                character       1         
##    emphColLight           character       1         
##    emphGrey               character       1         
##    eps                    logical         1         
##    es                     matrix          4 x 7     
##    estImg                 list            0         
##    eta.squared            numeric         1         
##    eventNames             character       5         
##    expected               numeric         4         
##    f                      table           14        
##    F.3.20                 numeric         1000      
##    F.stat                 numeric         1         
##    fac                    factor          3         
##    february.sales         numeric         1         
##    fibonacci              numeric         6         
##    Fibonacci              numeric         7         
##    fileName               character       1         
##    freq                   integer         17        
##    full.model             lm              12        
##    G                      factor          18        
##    garden                 data.frame      5 x 3     
##    gender                 character       5         
##    generateRLineTypes     function                  
##    generateRPointShapes   function                  
##    good.coef              numeric         2         
##    gp.mean                array           3         
##    gp.means               array           3         
##    gp.sizes               array           3         
##    grades                 numeric         20        
##    grand.mean             numeric         1         
##    greeting               character       1         
##    group                  factor          18        
##    h                      numeric         1         
##    happiness              data.frame      10 x 3    
##    harpo                  data.frame      33 x 2    
##    heavy.tailed.data      numeric         100       
##    height                 numeric         1         
##    hw                     character       2         
##    i                      integer         1         
##    interest               numeric         1         
##    IQ                     numeric         10000     
##    is.MP.speaking         logical         5         
##    is.the.Party.correct   table           14        
##    itng                   data.frame      10 x 2    
##    itng.table             table           3 x 4     
##    keeper                 numeric         1         
##    likert.centred         numeric         10        
##    likert.ordinal         ordered         10        
##    likert.raw             numeric         10        
##    lover                  numeric         1         
##    lower.area             numeric         1         
##    m                      numeric         1         
##    M                      matrix          2 x 3     
##    M0                     lm              12        
##    M1                     lm              12        
##    makka.pakka            character       4         
##    max.val                numeric         1         
##    mod                    lm              13        
##    mod.1                  lm              11        
##    mod.2                  lm              13        
##    mod.3                  lm              13        
##    mod.4                  lm              13        
##    mod.H                  lm              13        
##    mod.R                  lm              13        
##    model                  aov             13        
##    model.1                aov             13        
##    model.2                aov             13        
##    model.3                aov             13        
##    models                 BFBayesFactor             
##    monkey                 character       1         
##    monkey.1               list            1         
##    month                  numeric         1         
##    monthly.multiplier     numeric         1         
##    months                 character       12        
##    ms.diff                numeric         1         
##    ms.res                 numeric         1         
##    msg                    character       1         
##    mu                     numeric         3         
##    mu.null                numeric         1         
##    my.anova               aov             13        
##    my.anova.residuals     numeric         18        
##    my.contrasts           list            2         
##    my.var                 numeric         1         
##    n                      numeric         1         
##    N                      integer         1         
##    ng                     character       2         
##    nhstImg                list            0         
##    nodrug.regression      lm              12        
##    normal.a               numeric         1000      
##    normal.b               numeric         1000      
##    normal.c               numeric         1000      
##    normal.d               numeric         1000      
##    normal.data            numeric         100       
##    null.model             lm              11        
##    nullProbs              numeric         4         
##    numbers                numeric         3         
##    observed               table           4         
##    old                    list            66        
##    old.text               character       1         
##    old_par                list            72        
##    oneCorPlot             function                  
##    opinion.dir            numeric         10        
##    opinion.strength       numeric         10        
##    out.0                  data.frame      100 x 2   
##    out.1                  data.frame      100 x 2   
##    out.2                  data.frame      100 x 2   
##    outcome                numeric         18        
##    p.value                numeric         1         
##    parenthood             data.frame      100 x 4   
##    payments               numeric         1         
##    PJ                     character       1         
##    plotHist               function                  
##    plotOne                function                  
##    plotSamples            function                  
##    plotTwo                function                  
##    pow                    numeric         100       
##    probabilities          numeric         4         
##    profit                 numeric         12        
##    projecthome            character       1         
##    quadruple              function                  
##    r                      numeric         1         
##    R.squared              numeric         1         
##    random.contrasts       matrix          3 x 2     
##    regression.1           lm              12        
##    regression.2           lm              12        
##    regression.3           lm              12        
##    regression.model       lm              12        
##    regression.model.2     lm              13        
##    regression.model.3     lm              13        
##    regressionImg          list            0         
##    resid                  numeric         18        
##    revenue                numeric         1         
##    right.table            xtabs           2 x 2     
##    row.1                  numeric         3         
##    row.2                  numeric         3         
##    royalty                numeric         1         
##    rtfm.1                 data.frame      8 x 3     
##    rtfm.2                 data.frame      8 x 3     
##    rtfm.3                 data.frame      8 x 3     
##    s                      numeric         1         
##    salem.tabs             table           2 x 2     
##    sales                  numeric         1         
##    sales.by.month         numeric         12        
##    sample.mean            numeric         1         
##    scaled.chi.sq.3        numeric         1000      
##    score.A                numeric         5         
##    score.B                numeric         5         
##    sd.true                numeric         1         
##    sd1                    numeric         2         
##    seeker                 numeric         1         
##    sem.true               numeric         1         
##    setUpPlot              function                  
##    sig                    numeric         1         
##    sigEx                  expression                
##    simpson                matrix          6 x 5     
##    skewed.data            numeric         100       
##    some.data              numeric         18        
##    speaker                character       10        
##    speech.by.char         list            3         
##    squared.devs           array           3         
##    ss.diff                numeric         1         
##    SS.drug                numeric         1         
##    SS.res                 numeric         1         
##    ss.res.full            numeric         1         
##    ss.res.null            numeric         1         
##    SS.resid               numeric         1         
##    SS.therapy             numeric         1         
##    ss.tot                 numeric         1         
##    SS.tot                 numeric         1         
##    SSb                    numeric         1         
##    SStot                  numeric         1         
##    SSw                    numeric         1         
##    stock.levels           character       12        
##    suspicious.cases       logical         176       
##    t.3                    numeric         1000      
##    teams                  character       17        
##    text                   character       2         
##    therapy.means          numeric         2         
##    theta                  numeric         1         
##    today                  Date            1         
##    tombliboo              character       2         
##    total.paid             numeric         1         
##    tp                     character       6         
##    trial                  data.frame      16 x 2    
##    ttestImg               list            0         
##    type.I.sum             numeric         1         
##    type.II.sum            numeric         1         
##    upper.area             numeric         1         
##    upsy.daisy             character       4         
##    utterance              character       10        
##    w                      character       1         
##    W                      character       1         
##    w.length               integer         1         
##    width                  numeric         1         
##    words                  character       6         
##    wt.squared.devs        array           3         
##    x                      logical         3         
##    X                      numeric         100       
##    x1                     numeric         61        
##    X1                     numeric         11        
##    x2                     numeric         61        
##    X2                     numeric         11        
##    x3                     numeric         61        
##    X3                     numeric         11        
##    X4                     numeric         11        
##    xlu                    numeric         1         
##    xtab.3d                table           3 x 4 x 2 
##    xval                   numeric         2         
##    y                      numeric         1         
##    Y                      numeric         100       
##    Y.pred                 numeric         100       
##    y1                     numeric         61        
##    Y1                     numeric         11        
##    y2                     numeric         61        
##    Y2                     numeric         11        
##    y3                     numeric         61        
##    Y3                     numeric         11        
##    Y4                     numeric         11        
##    Ybar                   array           18        
##    yhat.2                 numeric         100       
##    yval                   numeric         2         
##    yval.1                 numeric         1001      
##    yval.2                 numeric         1001      
##    z                      logical         101       
##    Z                      array           18        
##    z.score                numeric         1</code></pre>
<p>As you can see, the <code>who()</code> function lists all the variables and provides some basic information about what kind of variable each one is and how many elements it contains. Personally, I find this output much easier more useful than the very compact output of the <code>objects()</code> function, but less overwhelming than the extremely verbose <code>ls.str()</code> function. Throughout this book you’ll see me using the <code>who()</code> function a lot. You don’t have to use it yourself: in fact, I suspect you’ll find it easier to look at the RStudio environment panel. But for the purposes of writing a textbook I found it handy to have a nice text based description: otherwise there would be about another 100 or so screenshots added to the book.<a href="#fn49" class="footnote-ref" id="fnref49"><sup>49</sup></a></p>
</div>
<div id="removing-variables-from-the-workspace" class="section level3">
<h3><span class="header-section-number">4.3.2</span> Removing variables from the workspace</h3>
<p>Looking over that list of variables, it occurs to me that I really don’t need them any more. I created them originally just to make a point, but they don’t serve any useful purpose anymore, and now I want to get rid of them. I’ll show you how to do this, but first I want to warn you – there’s no “undo” option for variable removal. Once a variable is removed, it’s gone forever unless you save it to disk. I’ll show you how to do <em>that</em> in Section @ref(load), but quite clearly we have no need for these variables at all, so we can safely get rid of them.</p>
<p>In RStudio, the easiest way to remove variables is to use the environment panel. Assuming that you’re in grid view (i.e., Figure @ref(fig:workspace2)), check the boxes next to the variables that you want to delete, then click on the “Clear” button at the top of the panel. When you do this, RStudio will show a dialog box asking you to confirm that you really do want to delete the variables. It’s always worth checking that you really do, because as RStudio is at pains to point out, you can’t undo this. Once a variable is deleted, it’s gone.<a href="#fn50" class="footnote-ref" id="fnref50"><sup>50</sup></a> In any case, if you click “yes”, that variable will disappear from the workspace: it will no longer appear in the environment panel, and it won’t show up when you use the <code>who()</code> command.</p>
<p>Suppose you don’t access to RStudio, and you still want to remove variables. This is where the <strong><em>remove</em></strong> function <code>rm()</code> comes in handy. The simplest way to use <code>rm()</code> is just to type in a (comma separated) list of all the variables you want to remove. Let’s say I want to get rid of <code>seeker</code> and <code>lover</code>, but I would like to keep <code>keeper</code>. To do this, all I have to do is type:</p>
<div class="sourceCode" id="cb215"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb215-1" title="1"><span class="kw">rm</span>( seeker, lover )</a></code></pre></div>
<p>There’s no visible output, but if I now inspect the workspace</p>
<div class="sourceCode" id="cb216"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb216-1" title="1"><span class="kw">who</span>()</a></code></pre></div>
<pre><code>##    -- Name --             -- Class --     -- Size --
##    a                      numeric         1         
##    addArrow               function                  
##    addDistPlot            function                  
##    afl                    data.frame      4296 x 12 
##    afl.finalists          factor          400       
##    afl.margins            numeric         176       
##    afl2                   data.frame      4296 x 2  
##    age                    numeric         5         
##    age.breaks             numeric         4         
##    age.group              factor          11        
##    age.group2             factor          11        
##    age.group3             factor          11        
##    age.labels             character       3         
##    agpp                   data.frame      100 x 3   
##    animals                character       4         
##    anova.model            aov             13        
##    anovaImg               list            0         
##    any.sales.this.month   logical         12        
##    awesome                data.frame      10 x 2    
##    b                      numeric         1         
##    bad.coef               numeric         2         
##    balance                numeric         1         
##    beers                  character       3         
##    berkeley               data.frame      39 x 3    
##    berkeley.small         data.frame      46 x 2    
##    binomPlot              function                  
##    bw                     numeric         1         
##    cake.1                 numeric         5         
##    cake.2                 numeric         5         
##    cake.df                data.frame      5 x 2     
##    cake.mat1              matrix          5 x 2     
##    cake.mat2              matrix          2 x 5     
##    cakes                  matrix          4 x 5     
##    cakes.flipped          matrix          5 x 4     
##    cardChoices            xtabs           4 x 4     
##    cards                  data.frame      200 x 3   
##    chapek9                data.frame      180 x 2   
##    chapekFrequencies      xtabs           3 x 2     
##    chi.sq.20              numeric         1000      
##    chi.sq.3               numeric         1000      
##    chico                  data.frame      20 x 3    
##    chico2                 data.frame      40 x 4    
##    chico3                 data.frame      20 x 4    
##    chiSqImg               list            0         
##    choice                 data.frame      4 x 10    
##    choice.2               data.frame      16 x 6    
##    clin.trial             data.frame      18 x 3    
##    clin.trial.2           data.frame      18 x 5    
##    coef                   numeric         2         
##    coffee                 data.frame      18 x 3    
##    colour                 logical         1         
##    crit                   numeric         1         
##    crit.hi                numeric         1         
##    crit.lo                numeric         1         
##    crit.val               numeric         1         
##    crosstab               xtabs           2 x 3     
##    d.cor                  numeric         1         
##    dan.awake              logical         10        
##    data                   data.frame      12 x 4    
##    day                    character       1         
##    days.per.month         numeric         12        
##    def.par                list            66        
##    describeImg            list            0         
##    dev.from.gp.means      array           18        
##    dev.from.grand.mean    array           3         
##    df                     numeric         1         
##    doubleMax              function                  
##    drawBasicScatterplot   function                  
##    drug.anova             aov             13        
##    drug.lm                lm              13        
##    drug.means             numeric         3         
##    drug.regression        lm              12        
##    druganxifree           numeric         18        
##    drugs                  data.frame      10 x 8    
##    drugs.2                data.frame      30 x 5    
##    eff                    eff             22        
##    effort                 data.frame      10 x 2    
##    emphCol                character       1         
##    emphColLight           character       1         
##    emphGrey               character       1         
##    eps                    logical         1         
##    es                     matrix          4 x 7     
##    estImg                 list            0         
##    eta.squared            numeric         1         
##    eventNames             character       5         
##    expected               numeric         4         
##    f                      table           14        
##    F.3.20                 numeric         1000      
##    F.stat                 numeric         1         
##    fac                    factor          3         
##    february.sales         numeric         1         
##    fibonacci              numeric         6         
##    Fibonacci              numeric         7         
##    fileName               character       1         
##    freq                   integer         17        
##    full.model             lm              12        
##    G                      factor          18        
##    garden                 data.frame      5 x 3     
##    gender                 character       5         
##    generateRLineTypes     function                  
##    generateRPointShapes   function                  
##    good.coef              numeric         2         
##    gp.mean                array           3         
##    gp.means               array           3         
##    gp.sizes               array           3         
##    grades                 numeric         20        
##    grand.mean             numeric         1         
##    greeting               character       1         
##    group                  factor          18        
##    h                      numeric         1         
##    happiness              data.frame      10 x 3    
##    harpo                  data.frame      33 x 2    
##    heavy.tailed.data      numeric         100       
##    height                 numeric         1         
##    hw                     character       2         
##    i                      integer         1         
##    interest               numeric         1         
##    IQ                     numeric         10000     
##    is.MP.speaking         logical         5         
##    is.the.Party.correct   table           14        
##    itng                   data.frame      10 x 2    
##    itng.table             table           3 x 4     
##    keeper                 numeric         1         
##    likert.centred         numeric         10        
##    likert.ordinal         ordered         10        
##    likert.raw             numeric         10        
##    lower.area             numeric         1         
##    m                      numeric         1         
##    M                      matrix          2 x 3     
##    M0                     lm              12        
##    M1                     lm              12        
##    makka.pakka            character       4         
##    max.val                numeric         1         
##    mod                    lm              13        
##    mod.1                  lm              11        
##    mod.2                  lm              13        
##    mod.3                  lm              13        
##    mod.4                  lm              13        
##    mod.H                  lm              13        
##    mod.R                  lm              13        
##    model                  aov             13        
##    model.1                aov             13        
##    model.2                aov             13        
##    model.3                aov             13        
##    models                 BFBayesFactor             
##    monkey                 character       1         
##    monkey.1               list            1         
##    month                  numeric         1         
##    monthly.multiplier     numeric         1         
##    months                 character       12        
##    ms.diff                numeric         1         
##    ms.res                 numeric         1         
##    msg                    character       1         
##    mu                     numeric         3         
##    mu.null                numeric         1         
##    my.anova               aov             13        
##    my.anova.residuals     numeric         18        
##    my.contrasts           list            2         
##    my.var                 numeric         1         
##    n                      numeric         1         
##    N                      integer         1         
##    ng                     character       2         
##    nhstImg                list            0         
##    nodrug.regression      lm              12        
##    normal.a               numeric         1000      
##    normal.b               numeric         1000      
##    normal.c               numeric         1000      
##    normal.d               numeric         1000      
##    normal.data            numeric         100       
##    null.model             lm              11        
##    nullProbs              numeric         4         
##    numbers                numeric         3         
##    observed               table           4         
##    old                    list            66        
##    old.text               character       1         
##    old_par                list            72        
##    oneCorPlot             function                  
##    opinion.dir            numeric         10        
##    opinion.strength       numeric         10        
##    out.0                  data.frame      100 x 2   
##    out.1                  data.frame      100 x 2   
##    out.2                  data.frame      100 x 2   
##    outcome                numeric         18        
##    p.value                numeric         1         
##    parenthood             data.frame      100 x 4   
##    payments               numeric         1         
##    PJ                     character       1         
##    plotHist               function                  
##    plotOne                function                  
##    plotSamples            function                  
##    plotTwo                function                  
##    pow                    numeric         100       
##    probabilities          numeric         4         
##    profit                 numeric         12        
##    projecthome            character       1         
##    quadruple              function                  
##    r                      numeric         1         
##    R.squared              numeric         1         
##    random.contrasts       matrix          3 x 2     
##    regression.1           lm              12        
##    regression.2           lm              12        
##    regression.3           lm              12        
##    regression.model       lm              12        
##    regression.model.2     lm              13        
##    regression.model.3     lm              13        
##    regressionImg          list            0         
##    resid                  numeric         18        
##    revenue                numeric         1         
##    right.table            xtabs           2 x 2     
##    row.1                  numeric         3         
##    row.2                  numeric         3         
##    royalty                numeric         1         
##    rtfm.1                 data.frame      8 x 3     
##    rtfm.2                 data.frame      8 x 3     
##    rtfm.3                 data.frame      8 x 3     
##    s                      numeric         1         
##    salem.tabs             table           2 x 2     
##    sales                  numeric         1         
##    sales.by.month         numeric         12        
##    sample.mean            numeric         1         
##    scaled.chi.sq.3        numeric         1000      
##    score.A                numeric         5         
##    score.B                numeric         5         
##    sd.true                numeric         1         
##    sd1                    numeric         2         
##    sem.true               numeric         1         
##    setUpPlot              function                  
##    sig                    numeric         1         
##    sigEx                  expression                
##    simpson                matrix          6 x 5     
##    skewed.data            numeric         100       
##    some.data              numeric         18        
##    speaker                character       10        
##    speech.by.char         list            3         
##    squared.devs           array           3         
##    ss.diff                numeric         1         
##    SS.drug                numeric         1         
##    SS.res                 numeric         1         
##    ss.res.full            numeric         1         
##    ss.res.null            numeric         1         
##    SS.resid               numeric         1         
##    SS.therapy             numeric         1         
##    ss.tot                 numeric         1         
##    SS.tot                 numeric         1         
##    SSb                    numeric         1         
##    SStot                  numeric         1         
##    SSw                    numeric         1         
##    stock.levels           character       12        
##    suspicious.cases       logical         176       
##    t.3                    numeric         1000      
##    teams                  character       17        
##    text                   character       2         
##    therapy.means          numeric         2         
##    theta                  numeric         1         
##    today                  Date            1         
##    tombliboo              character       2         
##    total.paid             numeric         1         
##    tp                     character       6         
##    trial                  data.frame      16 x 2    
##    ttestImg               list            0         
##    type.I.sum             numeric         1         
##    type.II.sum            numeric         1         
##    upper.area             numeric         1         
##    upsy.daisy             character       4         
##    utterance              character       10        
##    w                      character       1         
##    W                      character       1         
##    w.length               integer         1         
##    width                  numeric         1         
##    words                  character       6         
##    wt.squared.devs        array           3         
##    x                      logical         3         
##    X                      numeric         100       
##    x1                     numeric         61        
##    X1                     numeric         11        
##    x2                     numeric         61        
##    X2                     numeric         11        
##    x3                     numeric         61        
##    X3                     numeric         11        
##    X4                     numeric         11        
##    xlu                    numeric         1         
##    xtab.3d                table           3 x 4 x 2 
##    xval                   numeric         2         
##    y                      numeric         1         
##    Y                      numeric         100       
##    Y.pred                 numeric         100       
##    y1                     numeric         61        
##    Y1                     numeric         11        
##    y2                     numeric         61        
##    Y2                     numeric         11        
##    y3                     numeric         61        
##    Y3                     numeric         11        
##    Y4                     numeric         11        
##    Ybar                   array           18        
##    yhat.2                 numeric         100       
##    yval                   numeric         2         
##    yval.1                 numeric         1001      
##    yval.2                 numeric         1001      
##    z                      logical         101       
##    Z                      array           18        
##    z.score                numeric         1</code></pre>
<p>I see that there’s only the <code>keeper</code> variable left. As you can see, <code>rm()</code> can be very handy for keeping the workspace tidy.</p>
</div>
</div>
<div id="navigation" class="section level2">
<h2><span class="header-section-number">4.4</span> Navigating the file system</h2>
<p>In this section I talk a little about how R interacts with the file system on your computer. It’s not a terribly interesting topic, but it’s useful. As background to this discussion, I’ll talk a bit about how file system locations work in Section @ref(filesystem). Once upon a time <em>everyone</em> who used computers could safely be assumed to understand how the file system worked, because it was impossible to successfully use a computer if you didn’t! However, modern operating systems are much more “user friendly”, and as a consequence of this they go to great lengths to hide the file system from users. So these days it’s not at all uncommon for people to have used computers most of their life and not be familiar with the way that computers organise files. If you already know this stuff, skip straight to Section @ref(navigationR). Otherwise, read on. I’ll try to give a brief introduction that will be useful for those of you who have never been forced to learn how to navigate around a computer using a DOS or UNIX shell.</p>
<div id="filesystem" class="section level3">
<h3><span class="header-section-number">4.4.1</span> The file system itself</h3>
<p>In this section I describe the basic idea behind file locations and file paths. Regardless of whether you’re using Window, Mac OS or Linux, every file on the computer is assigned a (fairly) human readable address, and every address has the same basic structure: it describes a <em>path</em> that starts from a <em>root</em> location , through as series of <em>folders</em> (or if you’re an old-school computer user, <em>directories</em>), and finally ends up at the file.</p>
<p>On a Windows computer the root is the physical drive<a href="#fn51" class="footnote-ref" id="fnref51"><sup>51</sup></a> on which the file is stored, and for most home computers the name of the hard drive that stores all your files is C: and therefore most file names on Windows begin with C:. After that comes the folders, and on Windows the folder names are separated by a <code>\</code> symbol. So, the complete path to this book on my Windows computer might be something like this:</p>
<pre><code>C:\Users\danRbook\LSR.pdf</code></pre>
<p>and what that <em>means</em> is that the book is called LSR.pdf, and it’s in a folder called <code>book</code> which itself is in a folder called dan which itself is … well, you get the idea. On Linux, Unix and Mac OS systems, the addresses look a little different, but they’re more or less identical in spirit. Instead of using the backslash, folders are separated using a forward slash, and unlike Windows, they don’t treat the physical drive as being the root of the file system. So, the path to this book on my Mac might be something like this:</p>
<pre><code>/Users/dan/Rbook/LSR.pdf</code></pre>
<p>So that’s what we mean by the “path” to a file. The next concept to grasp is the idea of a <strong><em>working directory</em></strong> and how to change it. For those of you who have used command line interfaces previously, this should be obvious already. But if not, here’s what I mean. The working directory is just “whatever folder I’m currently looking at”. Suppose that I’m currently looking for files in Explorer (if you’re using Windows) or using Finder (on a Mac). The folder I currently have open is my user directory (i.e., <code>C:\Users\dan</code> or <code>/Users/dan</code>). That’s my current working directory.</p>
<p>The fact that we can imagine that the program is “in” a particular directory means that we can talk about moving <em>from</em> our current location <em>to</em> a new one. What that means is that we might want to specify a new location in relation to our current location. To do so, we need to introduce two new conventions. Regardless of what operating system you’re using, we use <code>.</code> to refer to the current working directory, and <code>..</code> to refer to the directory above it. This allows us to specify a path to a new location in relation to our current location, as the following examples illustrate. Let’s assume that I’m using my Windows computer, and my working directory is <code>C:\Users\danRbook</code>). The table below shows several addresses in relation to my current one:</p>
<table>
<caption>(#tab:unnamed-chunk-109)Basic arithmetic operations in R. These five operators are used very frequently throughout the text, so it’s important to be familiar with them at the outset.</caption>
<thead>
<tr class="header">
<th align="left">absolute path (i.e., from root)</th>
<th align="left">relative path (i.e. from C:)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">C:\Users\dan</td>
<td align="left">..</td>
</tr>
<tr class="even">
<td align="left">C:\Users</td>
<td align="left">..\.. \</td>
</tr>
<tr class="odd">
<td align="left">C:\Users\danRbook\source</td>
<td align="left">.\source</td>
</tr>
<tr class="even">
<td align="left">C:\Users\dan\nerdstuff</td>
<td align="left">..\nerdstuff</td>
</tr>
</tbody>
</table>
<p>There’s one last thing I want to call attention to: the <code>~</code> directory. I normally wouldn’t bother, but R makes reference to this concept sometimes. It’s quite common on computers that have multiple users to define <code>~</code> to be the user’s home directory. On my Mac, for instance, the home directory <code>~</code> for the “dan” user is <code>\Users\dan\</code>. And so, not surprisingly, it is possible to define other directories in terms of their relationship to the home directory. For example, an alternative way to describe the location of the <code>LSR.pdf</code> file on my Mac would be</p>
<pre><code>~Rbook\LSR.pdf</code></pre>
<p>That’s about all you really need to know about file paths. And since this section already feels too long, it’s time to look at how to navigate the file system in R.</p>
</div>
<div id="navigationR" class="section level3">
<h3><span class="header-section-number">4.4.2</span> Navigating the file system using the R console</h3>
<p>In this section I’ll talk about how to navigate this file system from within R itself. It’s not particularly user friendly, and so you’ll probably be happy to know that RStudio provides you with an easier method, and I will describe it in Section @ref(nav3). So in practice, you won’t <em>really</em> need to use the commands that I babble on about in this section, but I do think it helps to see them in operation at least once before forgetting about them forever.</p>
<p>Okay, let’s get started. When you want to load or save a file in R it’s important to know what the working directory is. You can find out by using the <code>getwd()</code> command. For the moment, let’s assume that I’m using Mac OS or Linux, since there’s some subtleties to Windows. Here’s what happens:</p>
<pre><code>getwd()
## [1] &quot;/Users/dan&quot;</code></pre>
<p>We can change the working directory quite easily using <code>setwd()</code>. The <code>setwd()</code> function has only the one argument, <code>dir</code>, is a character string specifying a path to a directory, or a path relative to the working directory. Since I’m currently located at <code>/Users/dan</code>, the following two are equivalent:</p>
<pre><code>setwd(&quot;/Users/dan/Rbook/data&quot;)
setwd(&quot;./Rbook/data&quot;)</code></pre>
<p>Now that we’re here, we can type <code>list.files()</code> command to get a listing of all the files in that directory. Since this is the directory in which I store all of the data files that we’ll use in this book, here’s what we get as the result:</p>
<pre><code>list.files()
## [1] &quot;afl24.Rdata&quot;             &quot;aflsmall.Rdata&quot;          &quot;aflsmall2.Rdata&quot;        
## [4] &quot;agpp.Rdata&quot;              &quot;all.zip&quot;                 &quot;annoying.Rdata&quot;         
## [7] &quot;anscombesquartet.Rdata&quot;  &quot;awesome.Rdata&quot;           &quot;awesome2.Rdata&quot;         
## [10] &quot;booksales.csv&quot;           &quot;booksales.Rdata&quot;         &quot;booksales2.csv&quot;         
## [13] &quot;cakes.Rdata&quot;             &quot;cards.Rdata&quot;             &quot;chapek9.Rdata&quot;          
## [16] &quot;chico.Rdata&quot;             &quot;clinicaltrial_old.Rdata&quot; &quot;clinicaltrial.Rdata&quot;    
## [19] &quot;coffee.Rdata&quot;            &quot;drugs.wmc.rt.Rdata&quot;      &quot;dwr_all.Rdata&quot;          
## [22] &quot;effort.Rdata&quot;            &quot;happy.Rdata&quot;             &quot;harpo.Rdata&quot;            
## [25] &quot;harpo2.Rdata&quot;            &quot;likert.Rdata&quot;            &quot;nightgarden.Rdata&quot;      
## [28] &quot;nightgarden2.Rdata&quot;      &quot;parenthood.Rdata&quot;        &quot;parenthood2.Rdata&quot;      
## [31] &quot;randomness.Rdata&quot;        &quot;repeated.Rdata&quot;          &quot;rtfm.Rdata&quot;             
## [34] &quot;salem.Rdata&quot;             &quot;zeppo.Rdata&quot;</code></pre>
<p>Not terribly exciting, I’ll admit, but it’s useful to know about. In any case, there’s only one more thing I want to make a note of, which is that R also makes use of the home directory. You can find out what it is by using the <code>path.expand()</code> function, like this:</p>
<pre><code>path.expand(&quot;~&quot;)
## [1] &quot;/Users/dan&quot;</code></pre>
<p>You can change the user directory if you want, but we’re not going to make use of it very much so there’s no reason to. The only reason I’m even bothering to mention it at all is that when you use RStudio to open a file, you’ll see output on screen that defines the path to the file relative to the <code>~</code> directory. I’d prefer you not to be confused when you see it.<a href="#fn52" class="footnote-ref" id="fnref52"><sup>52</sup></a></p>
</div>
<div id="why-do-the-windows-paths-use-the-wrong-slash" class="section level3">
<h3><span class="header-section-number">4.4.3</span> Why do the Windows paths use the wrong slash?</h3>
<p>Let’s suppose I’m on Windows. As before, I can find out what my current working directory is like this:</p>
<pre><code>getwd()
## [1] &quot;C:/Users/dan/</code></pre>
<p>This seems about right, but you might be wondering why R is displaying a Windows path using the wrong type of slash. The answer is slightly complicated, and has to do with the fact that R treats the <code>\</code> character as “special” (see Section @ref(escapechars)). If you’re deeply wedded to the idea of specifying a path using the Windows style slashes, then what you need to do is to type <code>/</code> whenever you mean <code>\</code>. In other words, if you want to specify the working directory on a Windows computer, you need to use one of the following commands:</p>
<pre><code>setwd( &quot;C:/Users/dan&quot; )
setwd( &quot;C:\\Users\\dan&quot; )</code></pre>
<p>It’s kind of annoying to have to do it this way, but as you’ll see later on in Section @ref(escapechars) it’s a necessary evil. Fortunately, as we’ll see in the next section, RStudio provides a much simpler way of changing directories…</p>
</div>
<div id="nav3" class="section level3">
<h3><span class="header-section-number">4.4.4</span> Navigating the file system using the RStudio file panel</h3>
<p>Although I think it’s important to understand how all this command line stuff works, in many (maybe even most) situations there’s an easier way. For our purposes, the easiest way to navigate the file system is to make use of RStudio’s built in tools. The “file” panel – the lower right hand area in Figure @ref(fig:filepanel) – is actually a pretty decent file browser. Not only can you just point and click on the names to move around the file system, you can also use it to set the working directory, and even load files.</p>
<div class="figure">
<img src="img/mechanics/filepanel.png" alt="The &quot;file panel&quot; is the area shown in the lower right hand corner. It provides a very easy way to browse and navigate your computer using R. See main text for details." width="529" />
<p class="caption">
(#fig:filepanel)The “file panel” is the area shown in the lower right hand corner. It provides a very easy way to browse and navigate your computer using R. See main text for details.
</p>
</div>
<p>Here’s what you need to do to change the working directory using the file panel. Let’s say I’m looking at the actual screen shown in Figure @ref(fig:filepanel). At the top of the file panel you see some text that says “Home <span class="math inline">\(&gt;\)</span> Rbook <span class="math inline">\(&gt;\)</span> data”. What that means is that it’s <em>displaying</em> the files that are stored in the</p>
<pre><code>/Users/dan/Rbook/data</code></pre>
<p>directory on my computer. It does <em>not</em> mean that this is the R working directory. If you want to change the R working directory, using the file panel, you need to click on the button that reads “More”. This will bring up a little menu, and one of the options will be “Set as Working Directory”. If you select that option, then R really will change the working directory. You can tell that it has done so because this command appears in the console:</p>
<pre><code>setwd(&quot;~/Rbook/data&quot;)</code></pre>
<p>In other words, RStudio sends a command to the R console, exactly as if you’d typed it yourself. The file panel can be used to do other things too. If you want to move “up” to the parent folder (e.g., from <code>/Users/dan/Rbook/data</code> to <code>/Users/dan/Rbook</code> click on the “..” link in the file panel. To move to a subfolder, click on the name of the folder that you want to open. You can open some types of file by clicking on them. You can delete files from your computer using the “delete” button, rename them with the “rename” button, and so on.</p>
<p>As you can tell, the file panel is a very handy little tool for navigating the file system. But it can do more than just navigate. As we’ll see later, it can be used to open files. And if you look at the buttons and menu options that it presents, you can even use it to rename, delete, copy or move files, and create new folders. However, since most of that functionality isn’t critical to the basic goals of this book, I’ll let you discover those on your own.</p>
</div>
</div>
<div id="load" class="section level2">
<h2><span class="header-section-number">4.5</span> Loading and saving data</h2>
<p>There are several different types of files that are likely to be relevant to us when doing data analysis. There are three in particular that are especially important from the perspective of this book:</p>
<ul>
<li><em>Workspace files</em> are those with a .Rdata file extension. This is the standard kind of file that R uses to store data and variables. They’re called “workspace files” because you can use them to save your whole workspace.</li>
<li><em>Comma separated value (CSV) files</em> are those with a .csv file extension. These are just regular old text files, and they can be opened with almost any software. It’s quite typical for people to store data in CSV files, precisely because they’re so simple.</li>
<li><em>Script files</em> are those with a .R file extension. These aren’t data files at all; rather, they’re used to save a collection of commands that you want R to execute later. They’re just text files, but we won’t make use of them until Chapter @ref(scripting).</li>
</ul>
<p>There are also several other types of file that R makes use of,<a href="#fn53" class="footnote-ref" id="fnref53"><sup>53</sup></a> but they’re not really all that central to our interests. There are also several other kinds of data file that you might want to import into R. For instance, you might want to open Microsoft Excel spreadsheets (.xlsx files), or data files that have been saved in the native file formats for other statistics software, such as SPSS, SAS, Minitab, Stata or Systat. Finally, you might have to handle databases. R tries hard to play nicely with other software, so it has tools that let you open and work with any of these and many others. I’ll discuss some of these other possibilities elsewhere in this book (Section @ref(importing)), but for now I want to focus primarily on the two kinds of data file that you’re most likely to need: .Rdata files and .csv files.
In this section I’ll talk about how to load a workspace file, how to import data from a CSV file, and how to save your workspace to a workspace file. Throughout this section I’ll first describe the (sometimes awkward) R commands that do all the work, and then I’ll show you the (much easier) way to do it using RStudio.</p>
<div id="loading-workspace-files-using-r" class="section level3">
<h3><span class="header-section-number">4.5.1</span> Loading workspace files using R</h3>
<p>When I used the <code>list.files()</code> command to list the contents of the <code>/Users/dan/Rbook/data</code> directory (in Section @ref(navigationR)), the output referred to a file called booksales.Rdata. Let’s say I want to load the data from this file into my workspace. The way I do this is with the <code>load()</code> function. There are two arguments to this function, but the only one we’re interested in is</p>
<ul>
<li><code>file</code>. This should be a character string that specifies a path to the file that needs to be loaded. You can use an absolute path or a relative path to do so.</li>
</ul>
<p>Using the absolute file path, the command would look like this:</p>
<pre><code>load( file = &quot;/Users/dan/Rbook/data/booksales.Rdata&quot; )</code></pre>
<p>but this is pretty lengthy. Given that the working directory (remember, we changed the directory at the end of Section @ref(nav3)) is <code>/Users/dan/Rbook/data</code>, I could use a relative file path, like so:</p>
<pre><code>load( file = &quot;../data/booksales.Rdata&quot; )</code></pre>
<p>However, my preference is usually to change the working directory first, and <em>then</em> load the file. What that would look like is this:</p>
<pre><code>setwd( &quot;../data&quot; )         # move to the data directory
load( &quot;booksales.Rdata&quot; )  # load the data</code></pre>
<p>If I were then to type <code>who()</code> I’d see that there are several new variables in my workspace now. Throughout this book, whenever you see me loading a file, I will assume that the file is actually stored in the working directory, or that you’ve changed the working directory so that R is pointing at the directory that contains the file. Obviously, <em>you</em> don’t need type that command yourself: you can use the RStudio file panel to do the work.</p>
</div>
<div id="loading-workspace-files-using-rstudio" class="section level3">
<h3><span class="header-section-number">4.5.2</span> Loading workspace files using RStudio</h3>
<p>Okay, so how do we open an .Rdata file using the RStudio file panel? It’s terribly simple. First, use the file panel to find the folder that contains the file you want to load. If you look at Figure @ref(fig:filepanel), you can see that there are several .Rdata files listed. Let’s say I want to load the <code>booksales.Rdata</code> file. All I have to do is click on the file name. RStudio brings up a little dialog box asking me to confirm that I do want to load this file. I click yes. The following command then turns up in the console,</p>
<pre><code>load(&quot;~/Rbook/data/booksales.Rdata&quot;)</code></pre>
<p>and the new variables will appear in the workspace (you’ll see them in the Environment panel in RStudio, or if you type <code>who()</code>). So easy it barely warrants having its own section.</p>
</div>
<div id="importing-data-from-csv-files-using-loadingcsv" class="section level3">
<h3><span class="header-section-number">4.5.3</span> Importing data from CSV files using <code id="loadingcsv">loadingcsv</code></h3>
<p>One quite commonly used data format is the humble “comma separated value” file, also called a CSV file, and usually bearing the file extension .csv. CSV files are just plain old-fashioned text files, and what they store is basically just a table of data. This is illustrated in Figure @ref(fig:booksalescsv), which shows a file called booksales.csv that I’ve created. As you can see, each row corresponds to a variable, and each row represents the book sales data for one month. The first row doesn’t contain actual data though: it has the names of the variables.</p>
<div class="figure">
<img src="img/mechanics/booksalescsv.jpg" alt="The booksales.csv data file. On the left, I've opened the file in using a spreadsheet program (OpenOffice), which shows that the file is basically a table. On the right, the same file is open in a standard text editor (the TextEdit program on a Mac), which shows how the file is formatted. The entries in the table are wrapped in quote marks and separated by commas." width="418" />
<p class="caption">
(#fig:booksalescsv)The booksales.csv data file. On the left, I’ve opened the file in using a spreadsheet program (OpenOffice), which shows that the file is basically a table. On the right, the same file is open in a standard text editor (the TextEdit program on a Mac), which shows how the file is formatted. The entries in the table are wrapped in quote marks and separated by commas.
</p>
</div>
<p>If RStudio were not available to you, the easiest way to open this file would be to use the <code>read.csv()</code> function.<a href="#fn54" class="footnote-ref" id="fnref54"><sup>54</sup></a> This function is pretty flexible, and I’ll talk a lot more about it’s capabilities in Section @ref(importing) for more details, but for now there’s only two arguments to the function that I’ll mention:</p>
<ul>
<li><code>file</code>. This should be a character string that specifies a path to the file that needs to be loaded. You can use an absolute path or a relative path to do so.</li>
<li><code>header</code>. This is a logical value indicating whether or not the first row of the file contains variable names. The default value is <code>TRUE</code>.</li>
</ul>
<p>Therefore, to import the CSV file, the command I need is:</p>
<div class="sourceCode" id="cb233"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb233-1" title="1">books &lt;-<span class="st"> </span><span class="kw">read.csv</span>( <span class="dt">file =</span> <span class="st">&quot;booksales.csv&quot;</span> )</a></code></pre></div>
<p>There are two very important points to notice here. Firstly, notice that I <em>didn’t</em> try to use the <code>load()</code> function, because that function is only meant to be used for .Rdata files. If you try to use <code>load()</code> on other types of data, you get an error. Secondly, notice that when I imported the CSV file I assigned the result to a variable, which I imaginatively called <code>books</code>.<a href="#fn55" class="footnote-ref" id="fnref55"><sup>55</sup></a> file. There’s a reason for this. The idea behind an <code>.Rdata</code> file is that it stores a whole workspace. So, if you had the ability to look inside the file yourself you’d see that the data file keeps track of all the variables and their names. So when you <code>load()</code> the file, R restores all those original names. CSV files are treated differently: as far as R is concerned, the CSV only stores <em>one</em> variable, but that variable is big table. So when you import that table into the workspace, R expects <em>you</em> to give it a name.] Let’s have a look at what we’ve got:</p>
<div class="sourceCode" id="cb234"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb234-1" title="1"><span class="kw">print</span>( books )</a></code></pre></div>
<pre><code>##        Month Days Sales Stock.Levels
## 1    January   31     0         high
## 2   February   28   100         high
## 3      March   31   200          low
## 4      April   30    50          out
## 5        May   31     0          out
## 6       June   30     0         high
## 7       July   31     0         high
## 8     August   31     0         high
## 9  September   30     0         high
## 10   October   31     0         high
## 11  November   30     0         high
## 12  December   31     0         high</code></pre>
<p>Clearly, it’s worked, but the format of this output is a bit unfamiliar. We haven’t seen anything like this before. What you’re looking at is a <em>data frame</em>, which is a very important kind of variable in R, and one I’ll discuss in Section @ref(dataframes). For now, let’s just be happy that we imported the data and that it looks about right.</p>
</div>
<div id="importing-data-from-csv-files-using-rstudio" class="section level3">
<h3><span class="header-section-number">4.5.4</span> Importing data from CSV files using RStudio</h3>
<p>Yet again, it’s easier in RStudio. In the environment panel in RStudio you should see a button called “Import Dataset”. Click on that, and it will give you a couple of options: select the “From Text File…” option, and it will open up a very familiar dialog box asking you to select a file: if you’re on a Mac, it’ll look like the usual Finder window that you use to choose a file; on Windows it looks like an Explorer window. An example of what it looks like on a Mac is shown in Figure @ref(fig:fileopen). I’m assuming that you’re familiar with your own computer, so you should have no problem finding the CSV file that you want to import! Find the one you want, then click on the “Open” button. When you do this, you’ll see a window that looks like the one in Figure @ref(fig:import).</p>
<div class="figure">
<img src="img/mechanics/openscreen.png" alt="A dialog box on a Mac asking you to select the CSV file R should try to import. Mac users will recognise this immediately: it's the usual way in which a Mac asks you to find a file. Windows users won't see this: they'll see the usual explorer window that Windows always gives you when it wants you to select a file." width="824" />
<p class="caption">
(#fig:fileopen)A dialog box on a Mac asking you to select the CSV file R should try to import. Mac users will recognise this immediately: it’s the usual way in which a Mac asks you to find a file. Windows users won’t see this: they’ll see the usual explorer window that Windows always gives you when it wants you to select a file.
</p>
</div>
<p>The import data set window is relatively straightforward to understand.</p>
<div class="figure">
<img src="img/mechanics/import.png" alt="The RStudio window for importing a CSV file into R" width="661" />
<p class="caption">
(#fig:import)The RStudio window for importing a CSV file into R
</p>
</div>
<p>In the top left corner, you need to type the name of the variable you R to create. By default, that will be the same as the file name: our file is called <code>booksales.csv</code>, so RStudio suggests the name <code>booksales</code>. If you’re happy with that, leave it alone. If not, type something else. Immediately below this are a few things that you can tweak to make sure that the data gets imported correctly:</p>
<ul>
<li>Heading. Does the first row of the file contain raw data, or does it contain headings for each variable? The <code>booksales.csv</code> file has a header at the top, so I selected “yes”.</li>
<li>Separator. What character is used to separate different entries? In most CSV files this will be a comma (it is “comma separated” after all). But you can change this if your file is different.</li>
<li>Decimal. What character is used to specify the decimal point? In English speaking countries, this is almost always a period (i.e., <code>.</code>). That’s not universally true: many European countries use a comma. So you can change that if you need to.</li>
<li>Quote. What character is used to denote a block of text? That’s usually going to be a double quote mark. It is for the <code>booksales.csv</code> file, so that’s what I selected.</li>
</ul>
<p>The nice thing about the RStudio window is that it shows you the raw data file at the top of the window, and it shows you a preview of the data at the bottom. If the data at the bottom doesn’t look right, try changing some of the settings on the left hand side. Once you’re happy, click “Import”. When you do, two commands appear in the R console:</p>
<pre><code>booksales &lt;- read.csv(&quot;~/Rbook/data/booksales.csv&quot;)
View(booksales)</code></pre>
<p>The first of these commands is the one that loads the data. The second one will display a pretty table showing the data in RStudio.</p>
</div>
<div id="saving-a-workspace-file-using-save" class="section level3">
<h3><span class="header-section-number">4.5.5</span> Saving a workspace file using <code>save</code></h3>
<p>Not surprisingly, saving data is very similar to loading data. Although RStudio provides a simple way to save files (see below), it’s worth understanding the actual commands involved. There are two commands you can use to do this, <code>save()</code> and <code>save.image()</code>. If you’re happy to save <em>all</em> of the variables in your workspace into the data file, then you should use <code>save.image()</code>. And if you’re happy for R to save the file into the current working directory, all you have to do is this:</p>
<div class="sourceCode" id="cb237"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb237-1" title="1"><span class="kw">save.image</span>( <span class="dt">file =</span> <span class="st">&quot;myfile.Rdata&quot;</span> )</a></code></pre></div>
<p>Since <code>file</code> is the first argument, you can shorten this to <code>save.image("myfile.Rdata")</code>; and if you want to save to a different directory, then (as always) you need to be more explicit about specifying the path to the file, just as we discussed in Section @ref(navigation). Suppose, however, I have several variables in my workspace, and I only want to save some of them. For instance, I might have this as my workspace:</p>
<div class="sourceCode" id="cb238"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb238-1" title="1"><span class="kw">who</span>()</a>
<a class="sourceLine" id="cb238-2" title="2"><span class="co">##   -- Name --   -- Class --   -- Size --</span></a>
<a class="sourceLine" id="cb238-3" title="3"><span class="co">##   data         data.frame    3 x 2     </span></a>
<a class="sourceLine" id="cb238-4" title="4"><span class="co">##   handy        character     1         </span></a>
<a class="sourceLine" id="cb238-5" title="5"><span class="co">##   junk         numeric       1        </span></a></code></pre></div>
<p>I want to save <code>data</code> and <code>handy</code>, but not <code>junk</code>. But I don’t want to delete <code>junk</code> right now, because I want to use it for something else later on. This is where the <code>save()</code> function is useful, since it lets me indicate exactly which variables I want to save. Here is one way I can use the <code>save</code> function to solve my problem:</p>
<div class="sourceCode" id="cb239"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb239-1" title="1"><span class="kw">save</span>(data, handy, <span class="dt">file =</span> <span class="st">&quot;myfile.Rdata&quot;</span>)</a></code></pre></div>
<p>Importantly, you <em>must</em> specify the name of the <code>file</code> argument. The reason is that if you don’t do so, R will think that <code>"myfile.Rdata"</code> is actually a <em>variable</em> that you want to save, and you’ll get an error message. Finally, I should mention a second way to specify which variables the <code>save()</code> function should save, which is to use the <code>list</code> argument. You do so like this:</p>
<div class="sourceCode" id="cb240"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb240-1" title="1">save.me &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;data&quot;</span>, <span class="st">&quot;handy&quot;</span>)   <span class="co"># the variables to be saved</span></a>
<a class="sourceLine" id="cb240-2" title="2"><span class="kw">save</span>( <span class="dt">file =</span> <span class="st">&quot;booksales2.Rdata&quot;</span>, <span class="dt">list =</span> save.me )   <span class="co"># the command to save them</span></a></code></pre></div>
</div>
<div id="save1" class="section level3">
<h3><span class="header-section-number">4.5.6</span> Saving a workspace file using RStudio</h3>
<p>RStudio allows you to save the workspace pretty easily. In the environment panel (Figures @ref(fig:workspace) and @ref(fig:workspace2)) you can see the “save” button. There’s no text, but it’s the same icon that gets used on every computer everywhere: it’s the one that looks like a floppy disk. You know, those things that haven’t been used in about 20 years. Alternatively, go to the “Session” menu and click on the “Save Workspace As…” option.<a href="#fn56" class="footnote-ref" id="fnref56"><sup>56</sup></a> This will bring up the standard “save” dialog box for your operating system (e.g., on a Mac it’ll look a little bit like the loading dialog box in Figure @ref(fig:fileopen)). Type in the name of the file that you want to save it to, and all the variables in your workspace will be saved to disk. You’ll see an R command like this one</p>
<div class="sourceCode" id="cb241"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb241-1" title="1"><span class="kw">save.image</span>(<span class="st">&quot;~/Desktop/Untitled.RData&quot;</span>)</a></code></pre></div>
<p>Pretty straightforward, really.</p>
</div>
<div id="other-things-you-might-want-to-save" class="section level3">
<h3><span class="header-section-number">4.5.7</span> Other things you might want to save</h3>
<p>Until now, we’ve talked mostly about loading and saving <em>data</em>. Other things you might want to save include:</p>
<ul>
<li><p><em>The output</em>. Sometimes you might also want to keep a copy of all your interactions with R, including everything that you typed in and everything that R did in response. There are some functions that you can use to get R to write its output to a file rather than to print onscreen (e.g., <code>sink()</code>), but to be honest, if you do want to save the R output, the easiest thing to do is to use the mouse to select the relevant text in the R console, go to the “Edit” menu in RStudio and select “Copy”. The output has now been copied to the clipboard. Now open up your favourite text editor or word processing software, and paste it. And you’re done. However, this will only save the contents of the console, not the plots you’ve drawn (assuming you’ve drawn some). We’ll talk about saving images later on.</p></li>
<li><p><em>A script</em>. While it is possible – and sometimes handy – to save the R output as a method for keeping a copy of your statistical analyses, another option that people use a lot (especially when you move beyond simple “toy” analyses) is to write <em>scripts</em>. A script is a text file in which you write out all the commands that you want R to run. You can write your script using whatever software you like. In real world data analysis writing scripts is a key skill – and as you become familiar with R you’ll probably find that most of what you do involves scripting rather than typing commands at the R prompt. However, you won’t need to do much scripting initially, so we’ll leave that until Chapter @ref(scripting).</p></li>
</ul>
</div>
</div>
<div id="useful" class="section level2">
<h2><span class="header-section-number">4.6</span> Useful things to know about variables</h2>
<p>In Chapter @ref(introR) I talked a lot about variables, how they’re assigned and some of the things you can do with them, but there’s a lot of additional complexities. That’s not a surprise of course. However, some of those issues are worth drawing your attention to now. So that’s the goal of this section; to cover a few extra topics. As a consequence, this section is basically a bunch of things that I want to briefly mention, but don’t really fit in anywhere else. In short, I’ll talk about several different issues in this section, which are only loosely connected to one another.</p>
<div id="specials" class="section level3">
<h3><span class="header-section-number">4.6.1</span> Special values</h3>
<p>The first thing I want to mention are some of the “special” values that you might see R produce. Most likely you’ll see them in situations where you were expecting a number, but there are quite a few other ways you can encounter them. These values are <code>Inf</code>, <code>NaN</code>, <code>NA</code> and <code>NULL</code>. These values can crop up in various different places, and so it’s important to understand what they mean.</p>
<ul>
<li><em>Infinity</em> (<code>Inf</code>). The easiest of the special values to explain is <code>Inf</code>, since it corresponds to a value that is infinitely large. You can also have <code>-Inf</code>. The easiest way to get <code>Inf</code> is to divide a positive number by 0:</li>
</ul>
<div class="sourceCode" id="cb242"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb242-1" title="1"><span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="dv">0</span></a></code></pre></div>
<pre><code>## [1] Inf</code></pre>
<p>In most real world data analysis situations, if you’re ending up with infinite numbers in your data, then something has gone awry. Hopefully you’ll never have to see them.</p>
<ul>
<li><em>Not a Number</em> (<code>NaN</code>). The special value of <code>NaN</code> is short for “not a number”, and it’s basically a reserved keyword that means “there isn’t a mathematically defined number for this”. If you can remember your high school maths, remember that it is conventional to say that <span class="math inline">\(0/0\)</span> doesn’t have a proper answer: mathematicians would say that <span class="math inline">\(0/0\)</span> is <em>undefined</em>. R says that it’s not a number:</li>
</ul>
<div class="sourceCode" id="cb244"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb244-1" title="1"> <span class="dv">0</span> <span class="op">/</span><span class="st"> </span><span class="dv">0</span></a></code></pre></div>
<pre><code>## [1] NaN</code></pre>
<p>Nevertheless, it’s still treated as a “numeric” value. To oversimplify, <code>NaN</code> corresponds to cases where you asked a proper numerical question that genuinely has <em>no meaningful answer</em>.</p>
<ul>
<li><p><em>Not available</em> (<code>NA</code>).
<code>NA</code> indicates that the value that is “supposed” to be stored here is missing. To understand what this means, it helps to recognise that the <code>NA</code> value is something that you’re most likely to see when analysing data from real world experiments. Sometimes you get equipment failures, or you lose some of the data, or whatever. The point is that some of the information that you were “expecting” to get from your study is just plain missing. Note the difference between <code>NA</code> and <code>NaN</code>. For <code>NaN</code>, we really do know what’s supposed to be stored; it’s just that it happens to correspond to something like <span class="math inline">\(0/0\)</span> that doesn’t make any sense at all. In contrast, <code>NA</code> indicates that we actually don’t know what was supposed to be there. The information is <em>missing</em>.</p></li>
<li><p><em>No value</em> (<code>NULL</code>).
The <code>NULL</code> value takes this “absence” concept even further. It basically asserts that the variable genuinely has no value whatsoever. This is quite different to both <code>NaN</code> and <code>NA</code>. For <code>NaN</code> we actually know what the value is, because it’s something insane like <span class="math inline">\(0/0\)</span>. For <code>NA</code>, we believe that there is supposed to be a value “out there”, but a dog ate our homework and so we don’t quite know what it is. But for <code>NULL</code> we strongly believe that there is <em>no value at all</em>.</p></li>
</ul>
</div>
<div id="names" class="section level3">
<h3><span class="header-section-number">4.6.2</span> Assigning names to vector elements</h3>
<p>One thing that is sometimes a little unsatisfying about the way that R prints out a vector is that the elements come out unlabelled. Here’s what I mean. Suppose I’ve got data reporting the quarterly profits for some company. If I just create a no-frills vector, I have to rely on memory to know which element corresponds to which event. That is:</p>
<div class="sourceCode" id="cb246"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb246-1" title="1">profit &lt;-<span class="st"> </span><span class="kw">c</span>( <span class="fl">3.1</span>, <span class="fl">0.1</span>, <span class="fl">-1.4</span>, <span class="fl">1.1</span> )</a>
<a class="sourceLine" id="cb246-2" title="2">profit</a></code></pre></div>
<pre><code>## [1]  3.1  0.1 -1.4  1.1</code></pre>
<p>You can probably guess that the first element corresponds to the first quarter, the second element to the second quarter, and so on, but that’s only because I’ve told you the back story and because this happens to be a very simple example. In general, it can be quite difficult. This is where it can be helpful to assign <code>names</code> to each of the elements. Here’s how you do it:</p>
<div class="sourceCode" id="cb248"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb248-1" title="1"><span class="kw">names</span>(profit) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Q1&quot;</span>,<span class="st">&quot;Q2&quot;</span>,<span class="st">&quot;Q3&quot;</span>,<span class="st">&quot;Q4&quot;</span>)</a>
<a class="sourceLine" id="cb248-2" title="2">profit</a></code></pre></div>
<pre><code>##   Q1   Q2   Q3   Q4 
##  3.1  0.1 -1.4  1.1</code></pre>
<p>This is a slightly odd looking command, admittedly, but it’s not too difficult to follow. All we’re doing is assigning a vector of labels (character strings) to <code>names(profit)</code>. You can always delete the names again by using the command <code>names(profit) &lt;- NULL</code>. It’s also worth noting that you don’t have to do this as a two stage process. You can get the same result with this command:</p>
<div class="sourceCode" id="cb250"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb250-1" title="1">profit &lt;-<span class="st"> </span><span class="kw">c</span>( <span class="st">&quot;Q1&quot;</span> =<span class="st"> </span><span class="fl">3.1</span>, <span class="st">&quot;Q2&quot;</span> =<span class="st"> </span><span class="fl">0.1</span>, <span class="st">&quot;Q3&quot;</span> =<span class="st"> </span><span class="fl">-1.4</span>, <span class="st">&quot;Q4&quot;</span> =<span class="st"> </span><span class="fl">1.1</span> )</a>
<a class="sourceLine" id="cb250-2" title="2">profit</a></code></pre></div>
<pre><code>##   Q1   Q2   Q3   Q4 
##  3.1  0.1 -1.4  1.1</code></pre>
<p>The important things to notice are that (a) this does make things much easier to read, but (b) the names at the top aren’t the “real” data. The <em>value</em> of <code>profit[1]</code> is still <code>3.1</code>; all I’ve done is added a <em>name</em> to <code>profit[1]</code> as well. Nevertheless, names aren’t purely cosmetic, since R allows you to pull out particular elements of the vector by referring to their names:</p>
<div class="sourceCode" id="cb252"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb252-1" title="1">profit[<span class="st">&quot;Q1&quot;</span>]</a></code></pre></div>
<pre><code>##  Q1 
## 3.1</code></pre>
<p>And if I ever need to pull out the names themselves, then I just type <code>names(profit)</code>.</p>
</div>
<div id="variable-classes" class="section level3">
<h3><span class="header-section-number">4.6.3</span> Variable classes</h3>
<p>As we’ve seen, R allows you to store different kinds of data. In particular, the variables we’ve defined so far have either been character data (text), numeric data, or logical data.<a href="#fn57" class="footnote-ref" id="fnref57"><sup>57</sup></a> It’s important that we remember what kind of information each variable stores (and even more important that R remembers) since different kinds of variables allow you to do different things to them. For instance, if your variables have numerical information in them, then it’s okay to multiply them together:</p>
<div class="sourceCode" id="cb254"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb254-1" title="1">x &lt;-<span class="st"> </span><span class="dv">5</span>   <span class="co"># x is numeric</span></a>
<a class="sourceLine" id="cb254-2" title="2">y &lt;-<span class="st"> </span><span class="dv">4</span>   <span class="co"># y is numeric</span></a>
<a class="sourceLine" id="cb254-3" title="3">x <span class="op">*</span><span class="st"> </span>y    </a></code></pre></div>
<pre><code>## [1] 20</code></pre>
<p>But if they contain character data, multiplication makes no sense whatsoever, and R will complain if you try to do it:</p>
<div class="sourceCode" id="cb256"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb256-1" title="1">x &lt;-<span class="st"> &quot;apples&quot;</span>   <span class="co"># x is character</span></a>
<a class="sourceLine" id="cb256-2" title="2">y &lt;-<span class="st"> &quot;oranges&quot;</span>  <span class="co"># y is character</span></a>
<a class="sourceLine" id="cb256-3" title="3">x <span class="op">*</span><span class="st"> </span>y           </a></code></pre></div>
<pre><code>## Error in x * y: non-numeric argument to binary operator</code></pre>
<p>Even R is smart enough to know you can’t multiply <code>"apples"</code> by <code>"oranges"</code>. It knows this because the quote marks are indicators that the variable is supposed to be treated as text, not as a number.</p>
<p>This is quite useful, but notice that it means that R makes a big distinction between <code>5</code> and <code>"5"</code>. Without quote marks, R treats <code>5</code> as the number five, and will allow you to do calculations with it. With the quote marks, R treats <code>"5"</code> as the textual character five, and doesn’t recognise it as a number any more than it recognises <code>"p"</code> or <code>"five"</code> as numbers. As a consequence, there’s a big difference between typing <code>x &lt;- 5</code> and typing <code>x &lt;- "5"</code>. In the former, we’re storing the number <code>5</code>; in the latter, we’re storing the character <code>"5"</code>. Thus, if we try to do multiplication with the character versions, R gets stroppy:</p>
<div class="sourceCode" id="cb258"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb258-1" title="1">x &lt;-<span class="st"> &quot;5&quot;</span>   <span class="co"># x is character</span></a>
<a class="sourceLine" id="cb258-2" title="2">y &lt;-<span class="st"> &quot;4&quot;</span>   <span class="co"># y is character</span></a>
<a class="sourceLine" id="cb258-3" title="3">x <span class="op">*</span><span class="st"> </span>y     </a></code></pre></div>
<pre><code>## Error in x * y: non-numeric argument to binary operator</code></pre>
<p>Okay, let’s suppose that I’ve forgotten what kind of data I stored in the variable <code>x</code> (which happens depressingly often). R provides a function that will let us find out. Or, more precisely, it provides <em>three</em> functions: <code>class()</code>, <code>mode()</code> and <code>typeof()</code>. Why the heck does it provide three functions, you might be wondering? Basically, because R actually keeps track of three different kinds of information about a variable:</p>
<ol style="list-style-type: decimal">
<li>The <strong><em>class</em></strong> of a variable is a “high level” classification, and it captures psychologically (or statistically) meaningful distinctions. For instance <code>"2011-09-12"</code> and <code>"my birthday"</code> are both text strings, but there’s an important difference between the two: one of them is a date. So it would be nice if we could get R to recognise that <code>"2011-09-12"</code> is a date, and allow us to do things like add or subtract from it. The class of a variable is what R uses to keep track of things like that. Because the class of a variable is critical for determining what R can or can’t do with it, the <code>class()</code> function is very handy.</li>
<li>The <strong><em>mode</em></strong> of a variable refers to the format of the information that the variable stores. It tells you whether R has stored text data or numeric data, for instance, which is kind of useful, but it only makes these “simple” distinctions. It can be useful to know about, but it’s not the main thing we care about. So I’m not going to use the <code>mode()</code> function very much.<a href="#fn58" class="footnote-ref" id="fnref58"><sup>58</sup></a></li>
<li>The <strong><em>type</em></strong> of a variable is a very low level classification. We won’t use it in this book, but (for those of you that care about these details) this is where you can see the distinction between integer data, double precision numeric, etc. Almost none of you actually will care about this, so I’m not even going to bother demonstrating the <code>typeof()</code> function.</li>
</ol>
<p>For purposes, it’s the <code>class()</code> of the variable that we care most about. Later on, I’ll talk a bit about how you can convince R to “coerce” a variable to change from one class to another (Section @ref(coercion)). That’s a useful skill for real world data analysis, but it’s not something that we need right now. In the meantime, the following examples illustrate the use of the <code>class()</code> function:</p>
<div class="sourceCode" id="cb260"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb260-1" title="1">x &lt;-<span class="st"> &quot;hello world&quot;</span>     <span class="co"># x is text</span></a>
<a class="sourceLine" id="cb260-2" title="2"><span class="kw">class</span>(x)</a></code></pre></div>
<pre><code>## [1] &quot;character&quot;</code></pre>
<div class="sourceCode" id="cb262"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb262-1" title="1">x &lt;-<span class="st"> </span><span class="ot">TRUE</span>     <span class="co"># x is logical </span></a>
<a class="sourceLine" id="cb262-2" title="2"><span class="kw">class</span>(x)</a></code></pre></div>
<pre><code>## [1] &quot;logical&quot;</code></pre>
<div class="sourceCode" id="cb264"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb264-1" title="1">x &lt;-<span class="st"> </span><span class="dv">100</span>     <span class="co"># x is a number</span></a>
<a class="sourceLine" id="cb264-2" title="2"><span class="kw">class</span>(x)</a></code></pre></div>
<pre><code>## [1] &quot;numeric&quot;</code></pre>
<p>Exciting, no?</p>
</div>
</div>
<div id="factors" class="section level2">
<h2><span class="header-section-number">4.7</span> Factors</h2>
<p>Okay, it’s time to start introducing some of the data types that are somewhat more specific to statistics. If you remember back to Chapter @ref(studydesign), when we assign numbers to possible outcomes, these numbers can mean quite different things depending on what kind of variable we are attempting to measure. In particular, we commonly make the distinction between <em>nominal</em>, <em>ordinal</em>, <em>interval</em> and <em>ratio</em> scale data. How do we capture this distinction in R? Currently, we only seem to have a single numeric data type. That’s probably not going to be enough, is it?</p>
<p>A little thought suggests that the numeric variable class in R is perfectly suited for capturing ratio scale data. For instance, if I were to measure response time (RT) for five different events, I could store the data in R like this:</p>
<div class="sourceCode" id="cb266"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb266-1" title="1">RT &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">342</span>, <span class="dv">401</span>, <span class="dv">590</span>, <span class="dv">391</span>, <span class="dv">554</span>)</a></code></pre></div>
<p>where the data here are measured in milliseconds, as is conventional in the psychological literature. It’s perfectly sensible to talk about “twice the response time”, <span class="math inline">\(2 \times \mbox{RT}\)</span>, or the “response time plus 1 second”, <span class="math inline">\(\mbox{RT} + 1000\)</span>, and so both of the following are perfectly reasonable things for R to do:</p>
<div class="sourceCode" id="cb267"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb267-1" title="1"><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>RT</a></code></pre></div>
<pre><code>## [1]  684  802 1180  782 1108</code></pre>
<div class="sourceCode" id="cb269"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb269-1" title="1">RT <span class="op">+</span><span class="st"> </span><span class="dv">1000</span></a></code></pre></div>
<pre><code>## [1] 1342 1401 1590 1391 1554</code></pre>
<p>And to a lesser extent, the “numeric” class is okay for interval scale data, as long as we remember that multiplication and division aren’t terribly interesting for these sorts of variables. That is, if my IQ score is 110 and yours is 120, it’s perfectly okay to say that you’re 10 IQ points smarter than me<a href="#fn59" class="footnote-ref" id="fnref59"><sup>59</sup></a>, but it’s not okay to say that I’m only 92% as smart as you are, because intelligence doesn’t have a natural zero.<a href="#fn60" class="footnote-ref" id="fnref60"><sup>60</sup></a> We might even be willing to tolerate the use of numeric variables to represent ordinal scale variables, such as those that you typically get when you ask people to rank order items (e.g., like we do in Australian elections), though as we will see R actually has a built in tool for representing ordinal data (see Section @ref(orderedfactors)) However, when it comes to nominal scale data, it becomes completely unacceptable, because almost all of the “usual” rules for what you’re allowed to do with numbers don’t apply to nominal scale data. It is for this reason that R has <strong><em>factors</em></strong>.</p>
<div id="introducing-factors" class="section level3">
<h3><span class="header-section-number">4.7.1</span> Introducing factors</h3>
<p>Suppose, I was doing a study in which people could belong to one of three different treatment conditions. Each group of people were asked to complete the same task, but each group received different instructions. Not surprisingly, I might want to have a variable that keeps track of what group people were in. So I could type in something like this</p>
<div class="sourceCode" id="cb271"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb271-1" title="1">group &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">3</span>,<span class="dv">3</span>)</a></code></pre></div>
<p>so that <code>group[i]</code> contains the group membership of the <code>i</code>-th person in my study. Clearly, this is numeric data, but equally obviously this is a nominal scale variable. There’s no sense in which “group 1” plus “group 2” equals “group 3”, but nevertheless if I try to do that, R won’t stop me because it doesn’t know any better:</p>
<div class="sourceCode" id="cb272"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb272-1" title="1">group <span class="op">+</span><span class="st"> </span><span class="dv">2</span></a></code></pre></div>
<pre><code>## [1] 3 3 3 4 4 4 5 5 5</code></pre>
<p>Apparently R seems to think that it’s allowed to invent “group 4” and “group 5”, even though they didn’t actually exist. Unfortunately, R is too stupid to know any better: it thinks that <code>3</code> is an ordinary number in this context, so it sees no problem in calculating <code>3 + 2</code>. But since <em>we’re</em> not that stupid, we’d like to stop R from doing this. We can do so by instructing R to treat <code>group</code> as a factor. This is easy to do using the <code>as.factor()</code> function.<a href="#fn61" class="footnote-ref" id="fnref61"><sup>61</sup></a></p>
<div class="sourceCode" id="cb274"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb274-1" title="1">group &lt;-<span class="st"> </span><span class="kw">as.factor</span>(group)</a>
<a class="sourceLine" id="cb274-2" title="2">group</a></code></pre></div>
<pre><code>## [1] 1 1 1 2 2 2 3 3 3
## Levels: 1 2 3</code></pre>
<p>It looks more or less the same as before (though it’s not immediately obvious what all that <code>Levels</code> rubbish is about), but if we ask R to tell us what the class of the <code>group</code> variable is now, it’s clear that it has done what we asked:</p>
<div class="sourceCode" id="cb276"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb276-1" title="1"><span class="kw">class</span>(group)</a></code></pre></div>
<pre><code>## [1] &quot;factor&quot;</code></pre>
<p>Neat. Better yet, now that I’ve converted <code>group</code> to a factor, look what happens when I try to add 2 to it:</p>
<div class="sourceCode" id="cb278"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb278-1" title="1">group <span class="op">+</span><span class="st"> </span><span class="dv">2</span></a></code></pre></div>
<pre><code>## Warning in Ops.factor(group, 2): &#39;+&#39; not meaningful for factors</code></pre>
<pre><code>## [1] NA NA NA NA NA NA NA NA NA</code></pre>
<p>This time even R is smart enough to know that I’m being an idiot, so it tells me off and then produces a vector of missing values. (i.e., <code>NA</code>: see Section @ref(specials)).</p>
</div>
<div id="labelling-the-factor-levels" class="section level3">
<h3><span class="header-section-number">4.7.2</span> Labelling the factor levels</h3>
<p>I have a confession to make. My memory is not infinite in capacity; and it seems to be getting worse as I get older. So it kind of annoys me when I get data sets where there’s a nominal scale variable called <code>gender</code>, with two levels corresponding to males and females. But when I go to print out the variable I get something like this:</p>
<div class="sourceCode" id="cb281"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb281-1" title="1">gender</a></code></pre></div>
<pre><code>## [1] 1 1 1 1 1 2 2 2 2
## Levels: 1 2</code></pre>
<p>Okaaaay. That’s not helpful at all, and it makes me very sad. Which number corresponds to the males and which one corresponds to the females? Wouldn’t it be nice if R could actually keep track of this? It’s way too hard to remember which number corresponds to which gender. To fix this problem what we need to do is assign meaningful labels to the different <em>levels</em> of each factor. We can do that like this:</p>
<div class="sourceCode" id="cb283"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb283-1" title="1"><span class="kw">levels</span>(group) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;group 1&quot;</span>, <span class="st">&quot;group 2&quot;</span>, <span class="st">&quot;group 3&quot;</span>)</a>
<a class="sourceLine" id="cb283-2" title="2"><span class="kw">print</span>(group)</a></code></pre></div>
<pre><code>## [1] group 1 group 1 group 1 group 2 group 2 group 2 group 3 group 3 group 3
## Levels: group 1 group 2 group 3</code></pre>
<div class="sourceCode" id="cb285"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb285-1" title="1"><span class="kw">levels</span>(gender) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;male&quot;</span>, <span class="st">&quot;female&quot;</span>)</a>
<a class="sourceLine" id="cb285-2" title="2"><span class="kw">print</span>(gender)</a></code></pre></div>
<pre><code>## [1] male   male   male   male   male   female female female female
## Levels: male female</code></pre>
<p>That’s much easier on the eye.</p>
</div>
<div id="moving-on" class="section level3">
<h3><span class="header-section-number">4.7.3</span> Moving on…</h3>
<p>Factors are very useful things, and we’ll use them a lot in this book: they’re <em>the</em> main way to represent a nominal scale variable. And there are lots of nominal scale variables out there. I’ll talk more about factors in Section @ref(orderedfactors), but for now you know enough to be able to get started.</p>
</div>
</div>
<div id="dataframes" class="section level2">
<h2><span class="header-section-number">4.8</span> Data frames</h2>
<p>It’s now time to go back and deal with the somewhat confusing thing that happened in Section @ref(loadingcsv) when we tried to open up a CSV file. Apparently we succeeded in loading the data, but it came to us in a very odd looking format. At the time, I told you that this was a <strong><em>data frame</em></strong>. Now I’d better explain what that means.</p>
<div id="introducing-data-frames" class="section level3">
<h3><span class="header-section-number">4.8.1</span> Introducing data frames</h3>
<p>In order to understand why R has created this funny thing called a data frame, it helps to try to see what problem it solves. So let’s go back to the little scenario that I used when introducing factors in Section @ref(factors). In that section I recorded the <code>group</code> and <code>gender</code> for all 9 participants in my study. Let’s also suppose I recorded their ages and their <code>score</code> on “Dan’s Terribly Exciting Psychological Test”:</p>
<div class="sourceCode" id="cb287"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb287-1" title="1">age &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">17</span>, <span class="dv">19</span>, <span class="dv">21</span>, <span class="dv">37</span>, <span class="dv">18</span>, <span class="dv">19</span>, <span class="dv">47</span>, <span class="dv">18</span>, <span class="dv">19</span>)</a>
<a class="sourceLine" id="cb287-2" title="2">score &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">12</span>, <span class="dv">10</span>, <span class="dv">11</span>, <span class="dv">15</span>, <span class="dv">16</span>, <span class="dv">14</span>, <span class="dv">25</span>, <span class="dv">21</span>, <span class="dv">29</span>)</a></code></pre></div>
<p>Assuming no other variables are in the workspace, if I type <code>who()</code> I get this:</p>
<div class="sourceCode" id="cb288"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb288-1" title="1"><span class="kw">who</span>()</a></code></pre></div>
<pre><code>##    -- Name --             -- Class --     -- Size --
##    a                      numeric         1         
##    addArrow               function                  
##    addDistPlot            function                  
##    afl                    data.frame      4296 x 12 
##    afl.finalists          factor          400       
##    afl.margins            numeric         176       
##    afl2                   data.frame      4296 x 2  
##    age                    numeric         9         
##    age.breaks             numeric         4         
##    age.group              factor          11        
##    age.group2             factor          11        
##    age.group3             factor          11        
##    age.labels             character       3         
##    agpp                   data.frame      100 x 3   
##    animals                character       4         
##    anova.model            aov             13        
##    anovaImg               list            0         
##    any.sales.this.month   logical         12        
##    awesome                data.frame      10 x 2    
##    b                      numeric         1         
##    bad.coef               numeric         2         
##    balance                numeric         1         
##    beers                  character       3         
##    berkeley               data.frame      39 x 3    
##    berkeley.small         data.frame      46 x 2    
##    binomPlot              function                  
##    bw                     numeric         1         
##    cake.1                 numeric         5         
##    cake.2                 numeric         5         
##    cake.df                data.frame      5 x 2     
##    cake.mat1              matrix          5 x 2     
##    cake.mat2              matrix          2 x 5     
##    cakes                  matrix          4 x 5     
##    cakes.flipped          matrix          5 x 4     
##    cardChoices            xtabs           4 x 4     
##    cards                  data.frame      200 x 3   
##    chapek9                data.frame      180 x 2   
##    chapekFrequencies      xtabs           3 x 2     
##    chi.sq.20              numeric         1000      
##    chi.sq.3               numeric         1000      
##    chico                  data.frame      20 x 3    
##    chico2                 data.frame      40 x 4    
##    chico3                 data.frame      20 x 4    
##    chiSqImg               list            0         
##    choice                 data.frame      4 x 10    
##    choice.2               data.frame      16 x 6    
##    clin.trial             data.frame      18 x 3    
##    clin.trial.2           data.frame      18 x 5    
##    coef                   numeric         2         
##    coffee                 data.frame      18 x 3    
##    colour                 logical         1         
##    crit                   numeric         1         
##    crit.hi                numeric         1         
##    crit.lo                numeric         1         
##    crit.val               numeric         1         
##    crosstab               xtabs           2 x 3     
##    d.cor                  numeric         1         
##    dan.awake              logical         10        
##    data                   data.frame      12 x 4    
##    day                    character       1         
##    days.per.month         numeric         12        
##    def.par                list            66        
##    describeImg            list            0         
##    dev.from.gp.means      array           18        
##    dev.from.grand.mean    array           3         
##    df                     numeric         1         
##    doubleMax              function                  
##    drawBasicScatterplot   function                  
##    drug.anova             aov             13        
##    drug.lm                lm              13        
##    drug.means             numeric         3         
##    drug.regression        lm              12        
##    druganxifree           numeric         18        
##    drugs                  data.frame      10 x 8    
##    drugs.2                data.frame      30 x 5    
##    eff                    eff             22        
##    effort                 data.frame      10 x 2    
##    emphCol                character       1         
##    emphColLight           character       1         
##    emphGrey               character       1         
##    eps                    logical         1         
##    es                     matrix          4 x 7     
##    estImg                 list            0         
##    eta.squared            numeric         1         
##    eventNames             character       5         
##    expected               numeric         4         
##    f                      table           14        
##    F.3.20                 numeric         1000      
##    F.stat                 numeric         1         
##    fac                    factor          3         
##    february.sales         numeric         1         
##    fibonacci              numeric         6         
##    Fibonacci              numeric         7         
##    fileName               character       1         
##    freq                   integer         17        
##    full.model             lm              12        
##    G                      factor          18        
##    garden                 data.frame      5 x 3     
##    gender                 factor          9         
##    generateRLineTypes     function                  
##    generateRPointShapes   function                  
##    good.coef              numeric         2         
##    gp.mean                array           3         
##    gp.means               array           3         
##    gp.sizes               array           3         
##    grades                 numeric         20        
##    grand.mean             numeric         1         
##    greeting               character       1         
##    group                  factor          9         
##    h                      numeric         1         
##    happiness              data.frame      10 x 3    
##    harpo                  data.frame      33 x 2    
##    heavy.tailed.data      numeric         100       
##    height                 numeric         1         
##    hw                     character       2         
##    i                      integer         1         
##    interest               numeric         1         
##    IQ                     numeric         10000     
##    is.MP.speaking         logical         5         
##    is.the.Party.correct   table           14        
##    itng                   data.frame      10 x 2    
##    itng.table             table           3 x 4     
##    likert.centred         numeric         10        
##    likert.ordinal         ordered         10        
##    likert.raw             numeric         10        
##    lower.area             numeric         1         
##    m                      numeric         1         
##    M                      matrix          2 x 3     
##    M0                     lm              12        
##    M1                     lm              12        
##    makka.pakka            character       4         
##    max.val                numeric         1         
##    mod                    lm              13        
##    mod.1                  lm              11        
##    mod.2                  lm              13        
##    mod.3                  lm              13        
##    mod.4                  lm              13        
##    mod.H                  lm              13        
##    mod.R                  lm              13        
##    model                  aov             13        
##    model.1                aov             13        
##    model.2                aov             13        
##    model.3                aov             13        
##    models                 BFBayesFactor             
##    monkey                 character       1         
##    monkey.1               list            1         
##    month                  numeric         1         
##    monthly.multiplier     numeric         1         
##    months                 character       12        
##    ms.diff                numeric         1         
##    ms.res                 numeric         1         
##    msg                    character       1         
##    mu                     numeric         3         
##    mu.null                numeric         1         
##    my.anova               aov             13        
##    my.anova.residuals     numeric         18        
##    my.contrasts           list            2         
##    my.var                 numeric         1         
##    n                      numeric         1         
##    N                      integer         1         
##    ng                     character       2         
##    nhstImg                list            0         
##    nodrug.regression      lm              12        
##    normal.a               numeric         1000      
##    normal.b               numeric         1000      
##    normal.c               numeric         1000      
##    normal.d               numeric         1000      
##    normal.data            numeric         100       
##    null.model             lm              11        
##    nullProbs              numeric         4         
##    numbers                numeric         3         
##    observed               table           4         
##    old                    list            66        
##    old.text               character       1         
##    old_par                list            72        
##    oneCorPlot             function                  
##    opinion.dir            numeric         10        
##    opinion.strength       numeric         10        
##    out.0                  data.frame      100 x 2   
##    out.1                  data.frame      100 x 2   
##    out.2                  data.frame      100 x 2   
##    outcome                numeric         18        
##    p.value                numeric         1         
##    parenthood             data.frame      100 x 4   
##    payments               numeric         1         
##    PJ                     character       1         
##    plotHist               function                  
##    plotOne                function                  
##    plotSamples            function                  
##    plotTwo                function                  
##    pow                    numeric         100       
##    probabilities          numeric         4         
##    projecthome            character       1         
##    quadruple              function                  
##    r                      numeric         1         
##    R.squared              numeric         1         
##    random.contrasts       matrix          3 x 2     
##    regression.1           lm              12        
##    regression.2           lm              12        
##    regression.3           lm              12        
##    regression.model       lm              12        
##    regression.model.2     lm              13        
##    regression.model.3     lm              13        
##    regressionImg          list            0         
##    resid                  numeric         18        
##    revenue                numeric         1         
##    right.table            xtabs           2 x 2     
##    row.1                  numeric         3         
##    row.2                  numeric         3         
##    royalty                numeric         1         
##    rtfm.1                 data.frame      8 x 3     
##    rtfm.2                 data.frame      8 x 3     
##    rtfm.3                 data.frame      8 x 3     
##    s                      numeric         1         
##    salem.tabs             table           2 x 2     
##    sales                  numeric         1         
##    sales.by.month         numeric         12        
##    sample.mean            numeric         1         
##    scaled.chi.sq.3        numeric         1000      
##    score                  numeric         9         
##    score.A                numeric         5         
##    score.B                numeric         5         
##    sd.true                numeric         1         
##    sd1                    numeric         2         
##    sem.true               numeric         1         
##    setUpPlot              function                  
##    sig                    numeric         1         
##    sigEx                  expression                
##    simpson                matrix          6 x 5     
##    skewed.data            numeric         100       
##    some.data              numeric         18        
##    speaker                character       10        
##    speech.by.char         list            3         
##    squared.devs           array           3         
##    ss.diff                numeric         1         
##    SS.drug                numeric         1         
##    SS.res                 numeric         1         
##    ss.res.full            numeric         1         
##    ss.res.null            numeric         1         
##    SS.resid               numeric         1         
##    SS.therapy             numeric         1         
##    ss.tot                 numeric         1         
##    SS.tot                 numeric         1         
##    SSb                    numeric         1         
##    SStot                  numeric         1         
##    SSw                    numeric         1         
##    stock.levels           character       12        
##    suspicious.cases       logical         176       
##    t.3                    numeric         1000      
##    teams                  character       17        
##    text                   character       2         
##    therapy.means          numeric         2         
##    theta                  numeric         1         
##    today                  Date            1         
##    tombliboo              character       2         
##    total.paid             numeric         1         
##    tp                     character       6         
##    trial                  data.frame      16 x 2    
##    ttestImg               list            0         
##    type.I.sum             numeric         1         
##    type.II.sum            numeric         1         
##    upper.area             numeric         1         
##    upsy.daisy             character       4         
##    utterance              character       10        
##    w                      character       1         
##    W                      character       1         
##    w.length               integer         1         
##    width                  numeric         1         
##    words                  character       6         
##    wt.squared.devs        array           3         
##    X                      numeric         100       
##    x1                     numeric         61        
##    X1                     numeric         11        
##    x2                     numeric         61        
##    X2                     numeric         11        
##    x3                     numeric         61        
##    X3                     numeric         11        
##    X4                     numeric         11        
##    xlu                    numeric         1         
##    xtab.3d                table           3 x 4 x 2 
##    xval                   numeric         2         
##    Y                      numeric         100       
##    Y.pred                 numeric         100       
##    y1                     numeric         61        
##    Y1                     numeric         11        
##    y2                     numeric         61        
##    Y2                     numeric         11        
##    y3                     numeric         61        
##    Y3                     numeric         11        
##    Y4                     numeric         11        
##    Ybar                   array           18        
##    yhat.2                 numeric         100       
##    yval                   numeric         2         
##    yval.1                 numeric         1001      
##    yval.2                 numeric         1001      
##    z                      logical         101       
##    Z                      array           18        
##    z.score                numeric         1</code></pre>
<p>So there are four variables in the workspace, <code>age</code>, <code>gender</code>, <code>group</code> and <code>score</code>. And it just so happens that all four of them are the same size (i.e., they’re all vectors with 9 elements). Aaaand it just so happens that <code>age[1]</code> corresponds to the age of the first person, and <code>gender[1]</code> is the gender of that very same person, etc. In other words, you and I both know that all four of these variables correspond to the <em>same</em> data set, and all four of them are organised in exactly the same way.</p>
<p>However, R <em>doesn’t</em> know this! As far as it’s concerned, there’s no reason why the <code>age</code> variable has to be the same length as the <code>gender</code> variable; and there’s no particular reason to think that <code>age[1]</code> has any special relationship to <code>gender[1]</code> any more than it has a special relationship to <code>gender[4]</code>. In other words, when we store everything in separate variables like this, R doesn’t know anything about the relationships between things. It doesn’t even really know that these variables actually refer to a proper data set. The data frame fixes this: if we store our variables inside a data frame, we’re telling R to treat these variables as a single, fairly coherent data set.</p>
<p>To see how they do this, let’s create one. So how do we create a data frame? One way we’ve already seen: if we import our data from a CSV file, R will store it as a data frame. A second way is to create it directly from some existing variables using the <code>data.frame()</code> function. All you have to do is type a list of variables that you want to include in the data frame. The output of a <code>data.frame()</code> command is, well, a data frame. So, if I want to store all four variables from my experiment in a data frame called <code>expt</code> I can do so like this:</p>
<div class="sourceCode" id="cb290"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb290-1" title="1">expt &lt;-<span class="st"> </span><span class="kw">data.frame</span> ( age, gender, group, score ) </a>
<a class="sourceLine" id="cb290-2" title="2">expt </a></code></pre></div>
<pre><code>##   age gender   group score
## 1  17   male group 1    12
## 2  19   male group 1    10
## 3  21   male group 1    11
## 4  37   male group 2    15
## 5  18   male group 2    16
## 6  19 female group 2    14
## 7  47 female group 3    25
## 8  18 female group 3    21
## 9  19 female group 3    29</code></pre>
<p>Note that <code>expt</code> is a completely self-contained variable. Once you’ve created it, it no longer depends on the original variables from which it was constructed. That is, if we make changes to the original <code>age</code> variable, it will <em>not</em> lead to any changes to the age data stored in <code>expt</code>.</p>
</div>
<div id="pulling-out-the-contents-of-the-data-frame-using" class="section level3">
<h3><span class="header-section-number">4.8.2</span> Pulling out the contents of the data frame using <code>$</code></h3>
<p>At this point, our workspace contains only the one variable, a data frame called <code>expt</code>. But as we can see when we told R to print the variable out, this data frame contains 4 variables, each of which has 9 observations. So how do we get this information out again? After all, there’s no point in storing information if you don’t use it, and there’s no way to use information if you can’t access it. So let’s talk a bit about how to pull information out of a data frame.</p>
<p>The first thing we might want to do is pull out one of our stored variables, let’s say <code>score</code>. One thing you might try to do is ignore the fact that <code>score</code> is locked up inside the <code>expt</code> data frame. For instance, you might try to print it out like this:</p>
<div class="sourceCode" id="cb292"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb292-1" title="1">score</a></code></pre></div>
<pre><code>## Error in eval(expr, envir, enclos): object &#39;score&#39; not found</code></pre>
<p>This doesn’t work, because R doesn’t go “peeking” inside the data frame unless you explicitly tell it to do so. There’s actually a very good reason for this, which I’ll explain in a moment, but for now let’s just assume R knows what it’s doing. How do we tell R to look inside the data frame? As is always the case with R there are several ways. The simplest way is to use the <code>$</code> operator to extract the variable you’re interested in, like this:</p>
<div class="sourceCode" id="cb294"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb294-1" title="1">expt<span class="op">$</span>score</a></code></pre></div>
<pre><code>## [1] 12 10 11 15 16 14 25 21 29</code></pre>
</div>
<div id="getting-information-about-a-data-frame" class="section level3">
<h3><span class="header-section-number">4.8.3</span> Getting information about a data frame</h3>
<p>One problem that sometimes comes up in practice is that you forget what you called all your variables. Normally you might try to type <code>objects()</code> or <code>who()</code>, but neither of those commands will tell you what the names are for those variables inside a data frame! One way is to ask R to tell you what the <em>names</em> of all the variables stored in the data frame are, which you can do using the <code>names()</code> function:</p>
<div class="sourceCode" id="cb296"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb296-1" title="1"><span class="kw">names</span>(expt)</a></code></pre></div>
<pre><code>## [1] &quot;age&quot;    &quot;gender&quot; &quot;group&quot;  &quot;score&quot;</code></pre>
<p>An alternative method is to use the <code>who()</code> function, as long as you tell it to look at the variables inside data frames. If you set <code>expand = TRUE</code> then it will not only list the variables in the workspace, but it will “expand” any data frames that you’ve got in the workspace, so that you can see what they look like. That is:</p>
<div class="sourceCode" id="cb298"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb298-1" title="1"><span class="kw">who</span>(<span class="dt">expand =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<pre><code>##    -- Name --             -- Class --     -- Size --
##    a                      numeric         1         
##    addArrow               function                  
##    addDistPlot            function                  
##    afl                    data.frame      4296 x 12 
##     $home.team            factor          4296      
##     $away.team            factor          4296      
##     $home.score           numeric         4296      
##     $away.score           numeric         4296      
##     $year                 numeric         4296      
##     $round                numeric         4296      
##     $weekday              factor          4296      
##     $day                  numeric         4296      
##     $month                numeric         4296      
##     $is.final             logical         4296      
##     $venue                factor          4296      
##     $attendance           numeric         4296      
##    afl.finalists          factor          400       
##    afl.margins            numeric         176       
##    afl2                   data.frame      4296 x 2  
##     $margin               numeric         4296      
##     $year                 numeric         4296      
##    age.breaks             numeric         4         
##    age.group              factor          11        
##    age.group2             factor          11        
##    age.group3             factor          11        
##    age.labels             character       3         
##    agpp                   data.frame      100 x 3   
##     $id                   factor          100       
##     $response_before      factor          100       
##     $response_after       factor          100       
##    animals                character       4         
##    anova.model            aov             13        
##    anovaImg               list            0         
##    any.sales.this.month   logical         12        
##    awesome                data.frame      10 x 2    
##     $scores               numeric         10        
##     $group                factor          10        
##    b                      numeric         1         
##    bad.coef               numeric         2         
##    balance                numeric         1         
##    beers                  character       3         
##    berkeley               data.frame      39 x 3    
##     $women.apply          numeric         39        
##     $total.admit          numeric         39        
##     $number.apply         numeric         39        
##    berkeley.small         data.frame      46 x 2    
##     $women.apply          numeric         46        
##     $total.admit          numeric         46        
##    binomPlot              function                  
##    bw                     numeric         1         
##    cake.1                 numeric         5         
##    cake.2                 numeric         5         
##    cake.df                data.frame      5 x 2     
##     $cake.1               numeric         5         
##     $cake.2               numeric         5         
##    cake.mat1              matrix          5 x 2     
##    cake.mat2              matrix          2 x 5     
##    cakes                  matrix          4 x 5     
##    cakes.flipped          matrix          5 x 4     
##    cardChoices            xtabs           4 x 4     
##    cards                  data.frame      200 x 3   
##     $id                   factor          200       
##     $choice_1             factor          200       
##     $choice_2             factor          200       
##    chapek9                data.frame      180 x 2   
##     $species              factor          180       
##     $choice               factor          180       
##    chapekFrequencies      xtabs           3 x 2     
##    chi.sq.20              numeric         1000      
##    chi.sq.3               numeric         1000      
##    chico                  data.frame      20 x 3    
##     $id                   factor          20        
##     $grade_test1          numeric         20        
##     $grade_test2          numeric         20        
##    chico2                 data.frame      40 x 4    
##     $id                   factor          40        
##     $improvement          numeric         40        
##     $time                 factor          40        
##     $grade                numeric         40        
##    chico3                 data.frame      20 x 4    
##     $id                   factor          20        
##     $grade_test1          numeric         20        
##     $grade_test2          numeric         20        
##     $improvement          numeric         20        
##    chiSqImg               list            0         
##    choice                 data.frame      4 x 10    
##     $id                   integer         4         
##     $gender               factor          4         
##     $MRT/block1/day1      numeric         4         
##     $MRT/block1/day2      numeric         4         
##     $MRT/block2/day1      numeric         4         
##     $MRT/block2/day2      numeric         4         
##     $PC/block1/day1       numeric         4         
##     $PC/block1/day2       numeric         4         
##     $PC/block2/day1       numeric         4         
##     $PC/block2/day2       numeric         4         
##    choice.2               data.frame      16 x 6    
##     $id                   integer         16        
##     $gender               factor          16        
##     $MRT                  numeric         16        
##     $PC                   numeric         16        
##     $block                character       16        
##     $day                  character       16        
##    clin.trial             data.frame      18 x 3    
##     $drug                 factor          18        
##     $therapy              factor          18        
##     $mood.gain            numeric         18        
##    clin.trial.2           data.frame      18 x 5    
##     $druganxifree         numeric         18        
##     $drugjoyzepam         numeric         18        
##     $therapyCBT           numeric         18        
##     $mood.gain            numeric         18        
##     $druganxifree         numeric         18        
##    coef                   numeric         2         
##    coffee                 data.frame      18 x 3    
##     $milk                 factor          18        
##     $sugar                factor          18        
##     $babble               numeric         18        
##    colour                 logical         1         
##    crit                   numeric         1         
##    crit.hi                numeric         1         
##    crit.lo                numeric         1         
##    crit.val               numeric         1         
##    crosstab               xtabs           2 x 3     
##    d.cor                  numeric         1         
##    dan.awake              logical         10        
##    data                   data.frame      12 x 4    
##     $V1                   character       12        
##     $V2                   integer         12        
##     $V3                   integer         12        
##     $V4                   character       12        
##    day                    character       1         
##    days.per.month         numeric         12        
##    def.par                list            66        
##    describeImg            list            0         
##    dev.from.gp.means      array           18        
##    dev.from.grand.mean    array           3         
##    df                     numeric         1         
##    doubleMax              function                  
##    drawBasicScatterplot   function                  
##    drug.anova             aov             13        
##    drug.lm                lm              13        
##    drug.means             numeric         3         
##    drug.regression        lm              12        
##    druganxifree           numeric         18        
##    drugs                  data.frame      10 x 8    
##     $id                   factor          10        
##     $gender               factor          10        
##     $WMC_alcohol          numeric         10        
##     $WMC_caffeine         numeric         10        
##     $WMC_no.drug          numeric         10        
##     $RT_alcohol           numeric         10        
##     $RT_caffeine          numeric         10        
##     $RT_no.drug           numeric         10        
##    drugs.2                data.frame      30 x 5    
##     $id                   factor          30        
##     $gender               factor          30        
##     $drug                 factor          30        
##     $WMC                  numeric         30        
##     $RT                   numeric         30        
##    eff                    eff             22        
##    effort                 data.frame      10 x 2    
##     $hours                numeric         10        
##     $grade                numeric         10        
##    emphCol                character       1         
##    emphColLight           character       1         
##    emphGrey               character       1         
##    eps                    logical         1         
##    es                     matrix          4 x 7     
##    estImg                 list            0         
##    eta.squared            numeric         1         
##    eventNames             character       5         
##    expected               numeric         4         
##    expt                   data.frame      9 x 4     
##     $age                  numeric         9         
##     $gender               factor          9         
##     $group                factor          9         
##     $score                numeric         9         
##    f                      table           14        
##    F.3.20                 numeric         1000      
##    F.stat                 numeric         1         
##    fac                    factor          3         
##    february.sales         numeric         1         
##    fibonacci              numeric         6         
##    Fibonacci              numeric         7         
##    fileName               character       1         
##    freq                   integer         17        
##    full.model             lm              12        
##    G                      factor          18        
##    garden                 data.frame      5 x 3     
##     $speaker              factor          5         
##     $utterance            factor          5         
##     $line                 numeric         5         
##    generateRLineTypes     function                  
##    generateRPointShapes   function                  
##    good.coef              numeric         2         
##    gp.mean                array           3         
##    gp.means               array           3         
##    gp.sizes               array           3         
##    grades                 numeric         20        
##    grand.mean             numeric         1         
##    greeting               character       1         
##    h                      numeric         1         
##    happiness              data.frame      10 x 3    
##     $before               numeric         10        
##     $after                numeric         10        
##     $change               numeric         10        
##    harpo                  data.frame      33 x 2    
##     $grade                numeric         33        
##     $tutor                factor          33        
##    heavy.tailed.data      numeric         100       
##    height                 numeric         1         
##    hw                     character       2         
##    i                      integer         1         
##    interest               numeric         1         
##    IQ                     numeric         10000     
##    is.MP.speaking         logical         5         
##    is.the.Party.correct   table           14        
##    itng                   data.frame      10 x 2    
##     $speaker              character       10        
##     $utterance            character       10        
##    itng.table             table           3 x 4     
##    likert.centred         numeric         10        
##    likert.ordinal         ordered         10        
##    likert.raw             numeric         10        
##    lower.area             numeric         1         
##    m                      numeric         1         
##    M                      matrix          2 x 3     
##    M0                     lm              12        
##    M1                     lm              12        
##    makka.pakka            character       4         
##    max.val                numeric         1         
##    mod                    lm              13        
##    mod.1                  lm              11        
##    mod.2                  lm              13        
##    mod.3                  lm              13        
##    mod.4                  lm              13        
##    mod.H                  lm              13        
##    mod.R                  lm              13        
##    model                  aov             13        
##    model.1                aov             13        
##    model.2                aov             13        
##    model.3                aov             13        
##    models                 BFBayesFactor             
##    monkey                 character       1         
##    monkey.1               list            1         
##    month                  numeric         1         
##    monthly.multiplier     numeric         1         
##    months                 character       12        
##    ms.diff                numeric         1         
##    ms.res                 numeric         1         
##    msg                    character       1         
##    mu                     numeric         3         
##    mu.null                numeric         1         
##    my.anova               aov             13        
##    my.anova.residuals     numeric         18        
##    my.contrasts           list            2         
##    my.var                 numeric         1         
##    n                      numeric         1         
##    N                      integer         1         
##    ng                     character       2         
##    nhstImg                list            0         
##    nodrug.regression      lm              12        
##    normal.a               numeric         1000      
##    normal.b               numeric         1000      
##    normal.c               numeric         1000      
##    normal.d               numeric         1000      
##    normal.data            numeric         100       
##    null.model             lm              11        
##    nullProbs              numeric         4         
##    numbers                numeric         3         
##    observed               table           4         
##    old                    list            66        
##    old.text               character       1         
##    old_par                list            72        
##    oneCorPlot             function                  
##    opinion.dir            numeric         10        
##    opinion.strength       numeric         10        
##    out.0                  data.frame      100 x 2   
##     $V1                   numeric         100       
##     $V2                   numeric         100       
##    out.1                  data.frame      100 x 2   
##     $V1                   numeric         100       
##     $V2                   numeric         100       
##    out.2                  data.frame      100 x 2   
##     $V1                   numeric         100       
##     $V2                   numeric         100       
##    outcome                numeric         18        
##    p.value                numeric         1         
##    parenthood             data.frame      100 x 4   
##     $dan.sleep            numeric         100       
##     $baby.sleep           numeric         100       
##     $dan.grump            numeric         100       
##     $day                  integer         100       
##    payments               numeric         1         
##    PJ                     character       1         
##    plotHist               function                  
##    plotOne                function                  
##    plotSamples            function                  
##    plotTwo                function                  
##    pow                    numeric         100       
##    probabilities          numeric         4         
##    projecthome            character       1         
##    quadruple              function                  
##    r                      numeric         1         
##    R.squared              numeric         1         
##    random.contrasts       matrix          3 x 2     
##    regression.1           lm              12        
##    regression.2           lm              12        
##    regression.3           lm              12        
##    regression.model       lm              12        
##    regression.model.2     lm              13        
##    regression.model.3     lm              13        
##    regressionImg          list            0         
##    resid                  numeric         18        
##    revenue                numeric         1         
##    right.table            xtabs           2 x 2     
##    row.1                  numeric         3         
##    row.2                  numeric         3         
##    royalty                numeric         1         
##    rtfm.1                 data.frame      8 x 3     
##     $grade                numeric         8         
##     $attend               numeric         8         
##     $reading              numeric         8         
##    rtfm.2                 data.frame      8 x 3     
##     $grade                numeric         8         
##     $attend               factor          8         
##     $reading              factor          8         
##    rtfm.3                 data.frame      8 x 3     
##     $grade                numeric         8         
##     $attend               factor          8         
##     $reading              factor          8         
##    s                      numeric         1         
##  [ reached getOption(&quot;max.print&quot;) -- omitted 85 rows ]</code></pre>
<p>or, since <code>expand</code> is the first argument in the <code>who()</code> function you can just type <code>who(TRUE)</code>. I’ll do that a lot in this book.</p>
</div>
<div id="looking-for-more-on-data-frames" class="section level3">
<h3><span class="header-section-number">4.8.4</span> Looking for more on data frames?</h3>
<p>There’s a lot more that can be said about data frames: they’re fairly complicated beasts, and the longer you use R the more important it is to make sure you really understand them. We’ll talk a lot more about them in Chapter @ref(datahandling).</p>
</div>
</div>
<div id="lists" class="section level2">
<h2><span class="header-section-number">4.9</span> Lists</h2>
<p>The next kind of data I want to mention are <strong><em>lists</em></strong>. Lists are an extremely fundamental data structure in R, and as you start making the transition from a novice to a savvy R user you will use lists all the time. I don’t use lists very often in this book – not directly – but most of the advanced data structures in R are built from lists (e.g., data frames are actually a specific type of list). Because lists are so important to how R stores things, it’s useful to have a basic understanding of them. Okay, so what is a list, exactly? Like data frames, lists are just “collections of variables.” However, unlike data frames – which are basically supposed to look like a nice “rectangular” table of data – there are no constraints on what kinds of variables we include, and no requirement that the variables have any particular relationship to one another. In order to understand what this actually <em>means</em>, the best thing to do is create a list, which we can do using the <code>list()</code> function. If I type this as my command:</p>
<div class="sourceCode" id="cb300"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb300-1" title="1">Dan &lt;-<span class="st"> </span><span class="kw">list</span>( <span class="dt">age =</span> <span class="dv">34</span>,</a>
<a class="sourceLine" id="cb300-2" title="2">            <span class="dt">nerd =</span> <span class="ot">TRUE</span>,</a>
<a class="sourceLine" id="cb300-3" title="3">            <span class="dt">parents =</span> <span class="kw">c</span>(<span class="st">&quot;Joe&quot;</span>,<span class="st">&quot;Liz&quot;</span>) </a>
<a class="sourceLine" id="cb300-4" title="4">)</a></code></pre></div>
<p>R creates a new list variable called <code>Dan</code>, which is a bundle of three different variables: <code>age</code>, <code>nerd</code> and <code>parents</code>. Notice, that the <code>parents</code> variable is longer than the others. This is perfectly acceptable for a list, but it wouldn’t be for a data frame. If we now print out the variable, you can see the way that R stores the list:</p>
<div class="sourceCode" id="cb301"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb301-1" title="1"><span class="kw">print</span>( Dan )</a></code></pre></div>
<pre><code>## $age
## [1] 34
## 
## $nerd
## [1] TRUE
## 
## $parents
## [1] &quot;Joe&quot; &quot;Liz&quot;</code></pre>
<p>As you might have guessed from those <code>$</code> symbols everywhere, the variables are stored in exactly the same way that they are for a data frame (again, this is not surprising: data frames <em>are</em> a type of list). So you will (I hope) be entirely unsurprised and probably quite bored when I tell you that you can extract the variables from the list using the <code>$</code> operator, like so:</p>
<div class="sourceCode" id="cb303"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb303-1" title="1">Dan<span class="op">$</span>nerd</a></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<p>If you need to add new entries to the list, the easiest way to do so is to again use <code>$</code>, as the following example illustrates. If I type a command like this</p>
<div class="sourceCode" id="cb305"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb305-1" title="1">Dan<span class="op">$</span>children &lt;-<span class="st"> &quot;Alex&quot;</span></a></code></pre></div>
<p>then R creates a new entry to the end of the list called <code>children</code>, and assigns it a value of <code>"Alex"</code>. If I were now to <code>print()</code> this list out, you’d see a new entry at the bottom of the printout. Finally, it’s actually possible for lists to contain other lists, so it’s quite possible that I would end up using a command like <code>Dan$children$age</code> to find out how old my son is. Or I could try to remember it myself I suppose.</p>
</div>
<div id="formulas" class="section level2">
<h2><span class="header-section-number">4.10</span> Formulas</h2>
<p>The last kind of variable that I want to introduce before finally being able to start talking about statistics is the <strong><em>formula</em></strong>. Formulas were originally introduced into R as a convenient way to specify a particular type of statistical model (see Chapter @ref(regression)) but they’re such handy things that they’ve spread. Formulas are now used in a lot of different contexts, so it makes sense to introduce them early.</p>
<p>Stated simply, a formula object is a variable, but it’s a special type of variable that specifies a relationship between other variables. A formula is specified using the “tilde operator” <code>~</code>. A very simple example of a formula is shown below:<a href="#fn62" class="footnote-ref" id="fnref62"><sup>62</sup></a></p>
<div class="sourceCode" id="cb306"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb306-1" title="1">formula1 &lt;-<span class="st"> </span>out <span class="op">~</span><span class="st"> </span>pred</a>
<a class="sourceLine" id="cb306-2" title="2">formula1</a></code></pre></div>
<pre><code>## out ~ pred</code></pre>
<p>The <em>precise</em> meaning of this formula depends on exactly what you want to do with it, but in broad terms it means “the <code>out</code> (outcome) variable, analysed in terms of the <code>pred</code> (predictor) variable”. That said, although the simplest and most common form of a formula uses the “one variable on the left, one variable on the right” format, there are others. For instance, the following examples are all reasonably common</p>
<div class="sourceCode" id="cb308"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb308-1" title="1">formula2 &lt;-<span class="st">  </span>out <span class="op">~</span><span class="st"> </span>pred1 <span class="op">+</span><span class="st"> </span>pred2   <span class="co"># more than one variable on the right</span></a>
<a class="sourceLine" id="cb308-2" title="2">formula3 &lt;-<span class="st">  </span>out <span class="op">~</span><span class="st"> </span>pred1 <span class="op">*</span><span class="st"> </span>pred2   <span class="co"># different relationship between predictors </span></a>
<a class="sourceLine" id="cb308-3" title="3">formula4 &lt;-<span class="st">  </span><span class="er">~</span><span class="st"> </span>var1 <span class="op">+</span><span class="st"> </span>var2         <span class="co"># a &#39;one-sided&#39; formula</span></a></code></pre></div>
<p>and there are many more variants besides. Formulas are pretty flexible things, and so different functions will make use of different formats, depending on what the function is intended to do.</p>
</div>
<div id="generics" class="section level2">
<h2><span class="header-section-number">4.11</span> Generic functions</h2>
<p>There’s one really important thing that I omitted when I discussed functions earlier on in Section @ref(usingfunctions), and that’s the concept of a <strong><em>generic function</em></strong>. The two most notable examples that you’ll see in the next few chapters are <code>summary()</code> and <code>plot()</code>, although you’ve already seen an example of one working behind the scenes, and that’s the <code>print()</code> function. The thing that makes generics different from the other functions is that their behaviour changes, often quite dramatically, depending on the <code>class()</code> of the input you give it. The easiest way to explain the concept is with an example. With that in mind, lets take a closer look at what the <code>print()</code> function actually does. I’ll do this by creating a formula, and printing it out in a few different ways. First, let’s stick with what we know:</p>
<div class="sourceCode" id="cb309"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb309-1" title="1">my.formula &lt;-<span class="st"> </span>blah <span class="op">~</span><span class="st"> </span>blah.blah    <span class="co"># create a variable of class &quot;formula&quot;</span></a>
<a class="sourceLine" id="cb309-2" title="2"><span class="kw">print</span>( my.formula )               <span class="co"># print it out using the generic print() function</span></a></code></pre></div>
<pre><code>## blah ~ blah.blah</code></pre>
<p>So far, there’s nothing very surprising here. But there’s actually a lot going on behind the scenes here. When I type <code>print( my.formula )</code>, what actually happens is the <code>print()</code> function checks the class of the <code>my.formula</code> variable. When the function discovers that the variable it’s been given is a formula, it goes looking for a function called <code>print.formula()</code>, and then delegates the whole business of printing out the variable to the <code>print.formula()</code> function.<a href="#fn63" class="footnote-ref" id="fnref63"><sup>63</sup></a> For what it’s worth, the name for a “dedicated” function like <code>print.formula()</code> that exists only to be a special case of a generic function like <code>print()</code> is a <strong><em>method</em></strong>, and the name for the process in which the generic function passes off all the hard work onto a method is called <strong><em>method dispatch</em></strong>. You won’t need to understand the details at all for this book, but you do need to know the gist of it; if only because a lot of the functions we’ll use are actually generics. Anyway, to help expose a little more of the workings to you, let’s bypass the <code>print()</code> function entirely and call the formula method directly:</p>
<div class="sourceCode" id="cb311"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb311-1" title="1"><span class="kw">print.formula</span>( my.formula )       <span class="co"># print it out using the print.formula() method</span></a>
<a class="sourceLine" id="cb311-2" title="2"></a>
<a class="sourceLine" id="cb311-3" title="3"><span class="co">## Appears to be deprecated</span></a></code></pre></div>
<p>There’s no difference in the output at all. But this shouldn’t surprise you because it was actually the <code>print.formula()</code> method that was doing all the hard work in the first place. The <code>print()</code> function itself is a lazy bastard that doesn’t do anything other than select which of the methods is going to do the actual printing.</p>
<p>Okay, fair enough, but you might be wondering what would have happened if <code>print.formula()</code> didn’t exist? That is, what happens if there isn’t a specific method defined for the class of variable that you’re using? In that case, the generic function passes off the hard work to a “default” method, whose name in this case would be <code>print.default()</code>. Let’s see what happens if we bypass the <code>print()</code> formula, and try to print out <code>my.formula</code> using the <code>print.default()</code> function:</p>
<div class="sourceCode" id="cb312"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb312-1" title="1"><span class="kw">print.default</span>( my.formula )      <span class="co"># print it out using the print.default() method</span></a></code></pre></div>
<pre><code>## blah ~ blah.blah
## attr(,&quot;class&quot;)
## [1] &quot;formula&quot;
## attr(,&quot;.Environment&quot;)
## &lt;environment: R_GlobalEnv&gt;</code></pre>
<p>Hm. You can kind of see that it is trying to print out the same formula, but there’s a bunch of ugly low-level details that have also turned up on screen. This is because the <code>print.default()</code> method doesn’t know anything about formulas, and doesn’t know that it’s supposed to be hiding the obnoxious internal gibberish that R produces sometimes.</p>
<p>At this stage, this is about as much as we need to know about generic functions and their methods. In fact, you can get through the entire book without learning any more about them than this, so it’s probably a good idea to end this discussion here.</p>
</div>
<div id="help" class="section level2">
<h2><span class="header-section-number">4.12</span> Getting help</h2>
<p>The very last topic I want to mention in this chapter is where to go to find help. Obviously, I’ve tried to make this book as helpful as possible, but it’s not even close to being a comprehensive guide, and there’s thousands of things it doesn’t cover. So where should you go for help?</p>
<div id="how-to-read-the-help-documentation" class="section level3">
<h3><span class="header-section-number">4.12.1</span> How to read the help documentation</h3>
<p>I have somewhat mixed feelings about the help documentation in R. On the plus side, there’s a lot of it, and it’s very thorough. On the minus side, there’s a lot of it, and it’s very thorough. There’s so much help documentation that it sometimes doesn’t help, and most of it is written with an advanced user in mind. Often it feels like most of the help ﬁles work on the assumption that the reader already understands everything about R except for the speciﬁc topic that it’s providing help for. What that means is that, once you’ve been using R for a long time and are beginning to get a feel for how to use it, the help documentation is awesome. These days, I ﬁnd myself really liking the help ﬁles (most of them anyway). But when I ﬁrst started using R I found it very dense.</p>
<p>To some extent, there’s not much I can do to help you with this. You just have to work at it yourself; once you’re moving away from being a pure beginner and are becoming a skilled user, you’ll start ﬁnding the help documentation more and more helpful. In the meantime, I’ll help as much as I can by trying to explain to you what you’re looking at when you open a help ﬁle. To that end, let’s look at the help documentation for the <code>load()</code> function. To do so, I type either of the following:</p>
<div class="sourceCode" id="cb314"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb314-1" title="1">?load </a>
<a class="sourceLine" id="cb314-2" title="2"><span class="kw">help</span>(<span class="st">&quot;load&quot;</span>)</a></code></pre></div>
<p>When I do that, R goes looking for the help ﬁle for the “load” topic. If it ﬁnds one, Rstudio takes it and displays it in the help panel. Alternatively, you can try a fuzzy search for a help topic</p>
<div class="sourceCode" id="cb315"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb315-1" title="1">??load </a>
<a class="sourceLine" id="cb315-2" title="2"><span class="kw">help.search</span>(<span class="st">&quot;load&quot;</span>)</a></code></pre></div>
This will bring up a list of possible topics that you might want to follow up in. Regardless, at some point you’ll ﬁnd yourself looking at an actual help ﬁle. And when you do, you’ll see there’s a quite a lot of stuﬀ written down there, and it comes in a pretty standardised format. So let’s go through it slowly, using the “<code>load</code>” topic as our example. Firstly, at the very top we see this:

<div class="rmdnote">
<table width="100%" summary="page for load {base}">
<tr>
<td>
load {base}
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h4>
Reload Saved Datasets
</h4>
<h5>
Description
</h5>
<p>
Reload datasets written with the function <code>save</code>.
</p>
</div>

Fairly straightforward. The next section describes how the function is used:

<div class="rmdnote">
<h5>
Usage
</h5>
<pre>
load(file, envir = parent.frame(), verbose = FALSE)
</pre>
</div>

<p>In this instance, the usage section is actually pretty readable. It’s telling you that there are two arguments to the <code>load()</code> function: the ﬁrst one is called <code>file</code>, and the second one is called <code>envir</code>. It’s also telling you that there is a default value for the envir argument; so if the user doesn’t specify what the value of envir should be, then R will assume that <code>envir = parent.frame()</code>. In contrast, the file argument has no default value at all, so the user must specify a value for it. So in one sense, this section is very straightforward.</p>
<p>The problem, of course, is that you don’t know what the <code>parent.frame()</code> function actually does, so it’s hard for you to know what the <code>envir = parent.frame()</code> bit is all about. What you could do is then go look up the help documents for the <code>parent.frame()</code> function (and sometimes that’s actually a good idea), but often you’ll ﬁnd that the help documents for those functions are just as dense (if not more dense) than the help ﬁle that you’re currently reading. As an alternative, my general approach when faced with something like this is to skim over it, see if I can make any sense of it. If so, great. If not, I ﬁnd that the best thing to do is ignore it. In fact, the ﬁrst time I read the help ﬁle for the load() function, I had no idea what any of the <code>envir</code> related stuﬀ was about. But fortunately I didn’t have to: the default setting here (i.e., <code>envir = parent.frame()</code>) is actually the thing you want in about 99% of cases, so it’s safe to ignore it.</p>
<p>Basically, what I’m trying to say is: don’t let the scary, incomprehensible parts of the help ﬁle intimidate you. Especially because there’s often some parts of the help ﬁle that will make sense. Of course, I guarantee you that sometimes this strategy will lead you to make mistakes… often embarrassing mistakes. But it’s still better than getting paralysed with fear.</p>
So, let’s continue on. The next part of the help documentation discusses each of the arguments, and what they’re supposed to do:

<div class="rmdnote">
<h5>
Arguments
</h5>
<table summary="R argblock">
<tr valign="top">
<td>
<code>file</code>
</td>
<td>
<p>
a (readable binary-mode) <a href="../../base/help/connection">connection</a> or a character string
giving the name of the file to load (when <a href="../../base/help/tilde expansion">tilde expansion</a>
is done).
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>envir</code>
</td>
<td>
<p>
the environment where the data should be loaded.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>verbose</code>
</td>
<td>
<p>
should item names be printed during loading?
</p>
</td>
</tr>
</table>
</div>

<p>Okay, so what this is telling us is that the <code>file</code> argument needs to be a string (i.e., text data) which tells R the name of the ﬁle to load. It also seems to be hinting that there’s other possibilities too (e.g., a “binary mode connection”), and you probably aren’t quite sure what “tilde expansion” means<a href="#fn64" class="footnote-ref" id="fnref64"><sup>64</sup></a>. But overall, the meaning is pretty clear.</p>
<p>Turning to the <code>envir</code> argument, it’s now a little clearer what the Usage section was babbling about. The <code>envir</code> argument speciﬁes the name of an environment (see Section 4.3 if you’ve forgotten what environments are) into which R should place the variables when it loads the ﬁle. Almost always, this is a no-brainer: you want R to load the data into the same damn environment in which you’re invoking the <code>load()</code> command. That is, if you’re typing <code>load()</code> at the R prompt, then you want the data to be loaded into your workspace (i.e., the global environment). But if you’re writing your own function that needs to load some data, you want the data to be loaded inside that function’s private workspace. And in fact, that’s exactly what the <code>parent.frame()</code> thing is all about. It’s telling the <code>load()</code> function to send the data to the same place that the <code>load()</code> command itself was coming from. As it turns out, if we’d just ignored the envir bit we would have been totally safe. Which is nice to know.</p>
Moving on, next up we get a detailed description of what the function actually does:

<div class="rmdnote">
<h5>
Details
</h5>
<p>
<code>load</code> can load <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span> objects saved in the current or any earlier
format. It can read a compressed file (see <code><a href="../../base/help/save">save</a></code>)
directly from a file or from a suitable connection (including a call
to <code><a href="../../base/help/url">url</a></code>).
</p>
<p>
A not-open connection will be opened in mode <code>“rb”</code> and closed
after use. Any connection other than a <code><a href="../../base/help/gzfile">gzfile</a></code> or
<code><a href="../../base/help/gzcon">gzcon</a></code> connection will be wrapped in <code><a href="../../base/help/gzcon">gzcon</a></code>
to allow compressed saves to be handled: note that this leaves the
connection in an altered state (in particular, binary-only), and that
it needs to be closed explicitly (it will not be garbage-collected).
</p>
<p>
Only <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span> objects saved in the current format (used since <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span> 1.4.0)
can be read from a connection. If no input is available on a
connection a warning will be given, but any input not in the current
format will result in a error.
</p>
<p>
Loading from an earlier version will give a warning about the
‘magic number’: magic numbers <code>1971:1977</code> are from <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span> &lt;
0.99.0, and <code>RD[ABX]1</code> from <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span> 0.99.0 to <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span> 1.3.1. These are all
obsolete, and you are strongly recommended to re-save such files in a
current format.
</p>
<p>
The <code>verbose</code> argument is mainly intended for debugging. If it
is <code>TRUE</code>, then as objects from the file are loaded, their
names will be printed to the console. If <code>verbose</code> is set to
an integer value greater than one, additional names corresponding to
attributes and other parts of individual objects will also be printed.
Larger values will print names to a greater depth.
</p>
<p>
Objects can be saved with references to namespaces, usually as part of
the environment of a function or formula. Such objects can be loaded
even if the namespace is not available: it is replaced by a reference
to the global environment with a warning. The warning identifies the
first object with such a reference (but there may be more than one).
</p>
</div>

<p>Then it tells you what the output value of the function is:</p>

<div class="rmdnote">
<h5>
Value
</h5>
<p>
A character vector of the names of objects created, invisibly.
</p>
</div>

<p>This is usually a bit more interesting, but since the <code>load()</code> function is mainly used to load variables into the workspace rather than to return a value, it’s no surprise that this doesn’t do much or say much. Moving on, we sometimes see a few additional sections in the help ﬁle, which can be diﬀerent depending on what the function is:</p>

<div class="rmdnote">
<h5>
Warning
</h5>
<p>
Saved <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span> objects are binary files, even those saved with
<code>ascii = TRUE</code>, so ensure that they are transferred without
conversion of end of line markers. <code>load</code> tries to detect such a
conversion and gives an informative error message.
</p>
<p>
<code>load(&lt;file&gt;)</code> replaces all existing objects with the same names
in the current environment (typically your workspace,
<code><a href="../../base/help/.GlobalEnv">.GlobalEnv</a></code>) and hence potentially overwrites important data.
It is considerably safer to use <code>envir = </code> to load into a
different environment, or to <code><a href="../../base/help/attach">attach</a>(file)</code> which
<code>load()</code>s into a new entry in the <code><a href="../../base/help/search">search</a></code> path.
</p>
<h5>
Note
</h5>
<p>
<code>file</code> can be a UTF-8-encoded filepath that cannot be translated to
the current locale.
</p>
</div>

<p>Yeah, yeah. Warning, warning, blah blah blah. Towards the bottom of the help ﬁle, we see something like this, which suggests a bunch of related topics that you might want to look at. These can be quite helpful:</p>

<div class="rmdnote">
<h5>
See Also
</h5>
<p>
<code><a href="../../base/help/save">save</a></code>, <code><a href="../../base/help/download.file">download.file</a></code>; further
<code><a href="../../base/help/attach">attach</a></code> as wrapper for <code>load()</code>.
</p>
<p>
For other interfaces to the underlying serialization format, see
<code><a href="../../base/help/unserialize">unserialize</a></code> and <code><a href="../../base/help/readRDS">readRDS</a></code>.
</p>
</div>

Finally, it gives you some examples of how to use the function(s) that the help ﬁle describes. These are supposed to be proper R commands, meaning that you should be able to type them into the console yourself and they’ll actually work. Sometimes it can be quite helpful to try the examples yourself. Anyway, here they are for the “<code>load</code>” help ﬁle:

<div class="rmdnote">
<h5>
Examples
</h5>
<pre>


## save all data
xx &lt;- pi # to ensure there is some data
save(list = ls(all = TRUE), file= "all.rda")
rm(xx)

## restore the saved values to the current environment
local({
   load("all.rda")
   ls()
})

xx &lt;- exp(1:3)
## restore the saved values to the user's workspace
load("all.rda") ## which is here *equivalent* to
## load("all.rda", .GlobalEnv)
## This however annihilates all objects in .GlobalEnv with the same names !
xx # no longer exp(1:3)
rm(xx)
attach("all.rda") # safer and will warn about masked objects w/ same name in .GlobalEnv
ls(pos = 2)
##  also typically need to cleanup the search path:
detach("file:all.rda")

## clean up (the example):
unlink("all.rda")


## Not run: 
con &lt;- url("http://some.where.net/R/data/example.rda")
## print the value to see what objects were created.
print(load(con))
close(con) # url() always opens the connection

## End(Not run)</pre>
</div>

<p>As you can see, they’re pretty dense, and not at all obvious to the novice user. However, they do provide good examples of the various diﬀerent things that you can do with the <code>load()</code> function, so it’s not a bad idea to have a look at them, and to try not to ﬁnd them too intimidating.</p>
</div>
<div id="other-resources" class="section level3">
<h3><span class="header-section-number">4.12.2</span> Other resources</h3>
<ul>
<li>The Rseek website (www.rseek.org). One thing that I really find annoying about the R help documentation is that it’s hard to search properly. When coupled with the fact that the documentation is dense and highly technical, it’s often a better idea to search or ask online for answers to your questions. With that in mind, the Rseek website is great: it’s an R specific search engine. I find it really useful, and it’s almost always my first port of call when I’m looking around.</li>
<li>The R-help mailing list (see <a href="http://www.r-project.org/mail.html" class="uri">http://www.r-project.org/mail.html</a> for details). This is the official R help mailing list. It can be very helpful, but it’s <em>very</em> important that you do your homework before posting a question. The list gets a lot of traffic. While the people on the list try as hard as they can to answer questions, they do so for free, and you <em>really</em> don’t want to know how much money they could charge on an hourly rate if they wanted to apply market rates. In short, they are doing you a favour, so be polite. Don’t waste their time asking questions that can be easily answered by a quick search on Rseek (it’s rude), make sure your question is clear, and all of the relevant information is included. In short, read the posting guidelines carefully (<a href="http://www.r-project.org/posting-guide.html" class="uri">http://www.r-project.org/posting-guide.html</a>), and make use of the <code>help.request()</code> function that R provides to check that you’re actually doing what you’re expected.</li>
</ul>
</div>
</div>
<div id="summary-1" class="section level2">
<h2><span class="header-section-number">4.13</span> Summary</h2>
<p>This chapter continued where Chapter @ref(introR) left off. The focus was still primarily on introducing basic R concepts, but this time at least you can see how those concepts are related to data analysis:</p>
<ul>
<li><a href="#packageinstall">Installing, loading and updating packages</a>. Knowing how to extend the functionality of R by installing and using packages is critical to becoming an effective R user</li>
<li>Getting around. Section @ref(workspace) talked about how to manage your workspace and how to keep it tidy. Similarly, Section @ref(navigation) talked about how to get R to interact with the rest of the file system.</li>
<li><a href="#load">Loading and saving data</a>. Finally, we encountered actual data files. Loading and saving data is obviously a crucial skill, one we discussed in Section @ref(load).</li>
<li><a href="#useful">Useful things to know about variables</a>. In particular, we talked about special values, element names and classes.</li>
<li>More complex types of variables. R has a number of important variable types that will be useful when analysing real data. I talked about factors in Section @ref(factors), data frames in Section @ref(dataframes), lists in Section @ref(lists) and formulas in Section @ref(formulas).</li>
<li><a href="#generics">Generic functions</a>. How is it that some function seem to be able to do lots of different things? Section @ref(generics) tells you how.</li>
<li><a href="#help">Getting help</a>. Assuming that you’re not looking for counselling, Section @ref(help) covers several possibilities. If you are looking for counselling, well, this book really can’t help you there. Sorry.</li>
</ul>
<p>Taken together, Chapters @ref(introR) and @ref(mechanics) provide enough of a background that you can finally get started doing some statistics! Yes, there’s a lot more R concepts that you ought to know (and we’ll talk about some of them in Chapters@ref(datahandling) and@ref(scripting)), but I think that we’ve talked quite enough about programming for the moment. It’s time to see how your experience with programming can be used to do some data analysis…</p>
<!--chapter:end:02.04-mechanics.Rmd-->
</div>
</div>
<div id="part-iii.-working-with-data" class="section level1 unnumbered">
<h1>Part III. Working with data</h1>
<!--chapter:end:03.00-Part3.Rmd-->
</div>
<div id="descriptives" class="section level1">
<h1><span class="header-section-number">5</span> Descriptive statistics</h1>
<p>Any time that you get a new data set to look at, one of the first tasks that you have to do is find ways of summarising the data in a compact, easily understood fashion. This is what <strong><em>descriptive statistics</em></strong> (as opposed to inferential statistics) is all about. In fact, to many people the term “statistics” is synonymous with descriptive statistics. It is this topic that we’ll consider in this chapter, but before going into any details, let’s take a moment to get a sense of why we need descriptive statistics. To do this, let’s load the <code>aflsmall.Rdata</code> file, and use the <code>who()</code> function in the <code>lsr</code> package to see what variables are stored in the file:</p>
<div class="sourceCode" id="cb316"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb316-1" title="1"><span class="kw">load</span>( <span class="st">&quot;./data/aflsmall.Rdata&quot;</span> )</a>
<a class="sourceLine" id="cb316-2" title="2"><span class="kw">library</span>(lsr)</a>
<a class="sourceLine" id="cb316-3" title="3"><span class="kw">who</span>()</a></code></pre></div>
<pre><code>##    -- Name --             -- Class --     -- Size --
##    a                      numeric         1         
##    addArrow               function                  
##    addDistPlot            function                  
##    afl                    data.frame      4296 x 12 
##    afl.finalists          factor          400       
##    afl.margins            numeric         176       
##    afl2                   data.frame      4296 x 2  
##    age.breaks             numeric         4         
##    age.group              factor          11        
##    age.group2             factor          11        
##    age.group3             factor          11        
##    age.labels             character       3         
##    agpp                   data.frame      100 x 3   
##    animals                character       4         
##    anova.model            aov             13        
##    anovaImg               list            0         
##    any.sales.this.month   logical         12        
##    awesome                data.frame      10 x 2    
##    b                      numeric         1         
##    bad.coef               numeric         2         
##    balance                numeric         1         
##    beers                  character       3         
##    berkeley               data.frame      39 x 3    
##    berkeley.small         data.frame      46 x 2    
##    binomPlot              function                  
##    bw                     numeric         1         
##    cake.1                 numeric         5         
##    cake.2                 numeric         5         
##    cake.df                data.frame      5 x 2     
##    cake.mat1              matrix          5 x 2     
##    cake.mat2              matrix          2 x 5     
##    cakes                  matrix          4 x 5     
##    cakes.flipped          matrix          5 x 4     
##    cardChoices            xtabs           4 x 4     
##    cards                  data.frame      200 x 3   
##    chapek9                data.frame      180 x 2   
##    chapekFrequencies      xtabs           3 x 2     
##    chi.sq.20              numeric         1000      
##    chi.sq.3               numeric         1000      
##    chico                  data.frame      20 x 3    
##    chico2                 data.frame      40 x 4    
##    chico3                 data.frame      20 x 4    
##    chiSqImg               list            0         
##    choice                 data.frame      4 x 10    
##    choice.2               data.frame      16 x 6    
##    clin.trial             data.frame      18 x 3    
##    clin.trial.2           data.frame      18 x 5    
##    coef                   numeric         2         
##    coffee                 data.frame      18 x 3    
##    colour                 logical         1         
##    crit                   numeric         1         
##    crit.hi                numeric         1         
##    crit.lo                numeric         1         
##    crit.val               numeric         1         
##    crosstab               xtabs           2 x 3     
##    d.cor                  numeric         1         
##    Dan                    list            4         
##    dan.awake              logical         10        
##    data                   data.frame      12 x 4    
##    day                    character       1         
##    days.per.month         numeric         12        
##    def.par                list            66        
##    describeImg            list            0         
##    dev.from.gp.means      array           18        
##    dev.from.grand.mean    array           3         
##    df                     numeric         1         
##    doubleMax              function                  
##    drawBasicScatterplot   function                  
##    drug.anova             aov             13        
##    drug.lm                lm              13        
##    drug.means             numeric         3         
##    drug.regression        lm              12        
##    druganxifree           numeric         18        
##    drugs                  data.frame      10 x 8    
##    drugs.2                data.frame      30 x 5    
##    eff                    eff             22        
##    effort                 data.frame      10 x 2    
##    emphCol                character       1         
##    emphColLight           character       1         
##    emphGrey               character       1         
##    eps                    logical         1         
##    es                     matrix          4 x 7     
##    estImg                 list            0         
##    eta.squared            numeric         1         
##    eventNames             character       5         
##    expected               numeric         4         
##    expt                   data.frame      9 x 4     
##    f                      table           14        
##    F.3.20                 numeric         1000      
##    F.stat                 numeric         1         
##    fac                    factor          3         
##    february.sales         numeric         1         
##    fibonacci              numeric         6         
##    Fibonacci              numeric         7         
##    fileName               character       1         
##    formula1               formula                   
##    formula2               formula                   
##    formula3               formula                   
##    formula4               formula                   
##    freq                   integer         17        
##    full.model             lm              12        
##    G                      factor          18        
##    garden                 data.frame      5 x 3     
##    generateRLineTypes     function                  
##    generateRPointShapes   function                  
##    good.coef              numeric         2         
##    gp.mean                array           3         
##    gp.means               array           3         
##    gp.sizes               array           3         
##    grades                 numeric         20        
##    grand.mean             numeric         1         
##    greeting               character       1         
##    h                      numeric         1         
##    happiness              data.frame      10 x 3    
##    harpo                  data.frame      33 x 2    
##    heavy.tailed.data      numeric         100       
##    height                 numeric         1         
##    hw                     character       2         
##    i                      integer         1         
##    interest               numeric         1         
##    IQ                     numeric         10000     
##    is.MP.speaking         logical         5         
##    is.the.Party.correct   table           14        
##    itng                   data.frame      10 x 2    
##    itng.table             table           3 x 4     
##    likert.centred         numeric         10        
##    likert.ordinal         ordered         10        
##    likert.raw             numeric         10        
##    lower.area             numeric         1         
##    m                      numeric         1         
##    M                      matrix          2 x 3     
##    M0                     lm              12        
##    M1                     lm              12        
##    makka.pakka            character       4         
##    max.val                numeric         1         
##    mod                    lm              13        
##    mod.1                  lm              11        
##    mod.2                  lm              13        
##    mod.3                  lm              13        
##    mod.4                  lm              13        
##    mod.H                  lm              13        
##    mod.R                  lm              13        
##    model                  aov             13        
##    model.1                aov             13        
##    model.2                aov             13        
##    model.3                aov             13        
##    models                 BFBayesFactor             
##    monkey                 character       1         
##    monkey.1               list            1         
##    month                  numeric         1         
##    monthly.multiplier     numeric         1         
##    months                 character       12        
##    ms.diff                numeric         1         
##    ms.res                 numeric         1         
##    msg                    character       1         
##    mu                     numeric         3         
##    mu.null                numeric         1         
##    my.anova               aov             13        
##    my.anova.residuals     numeric         18        
##    my.contrasts           list            2         
##    my.formula             formula                   
##    my.var                 numeric         1         
##    n                      numeric         1         
##    N                      integer         1         
##    ng                     character       2         
##    nhstImg                list            0         
##    nodrug.regression      lm              12        
##    normal.a               numeric         1000      
##    normal.b               numeric         1000      
##    normal.c               numeric         1000      
##    normal.d               numeric         1000      
##    normal.data            numeric         100       
##    null.model             lm              11        
##    nullProbs              numeric         4         
##    numbers                numeric         3         
##    observed               table           4         
##    old                    list            66        
##    old.text               character       1         
##    old_par                list            72        
##    oneCorPlot             function                  
##    opinion.dir            numeric         10        
##    opinion.strength       numeric         10        
##    out.0                  data.frame      100 x 2   
##    out.1                  data.frame      100 x 2   
##    out.2                  data.frame      100 x 2   
##    outcome                numeric         18        
##    p.value                numeric         1         
##    parenthood             data.frame      100 x 4   
##    payments               numeric         1         
##    PJ                     character       1         
##    plotHist               function                  
##    plotOne                function                  
##    plotSamples            function                  
##    plotTwo                function                  
##    pow                    numeric         100       
##    probabilities          numeric         4         
##    projecthome            character       1         
##    quadruple              function                  
##    r                      numeric         1         
##    R.squared              numeric         1         
##    random.contrasts       matrix          3 x 2     
##    regression.1           lm              12        
##    regression.2           lm              12        
##    regression.3           lm              12        
##    regression.model       lm              12        
##    regression.model.2     lm              13        
##    regression.model.3     lm              13        
##    regressionImg          list            0         
##    resid                  numeric         18        
##    revenue                numeric         1         
##    right.table            xtabs           2 x 2     
##    row.1                  numeric         3         
##    row.2                  numeric         3         
##    royalty                numeric         1         
##    rtfm.1                 data.frame      8 x 3     
##    rtfm.2                 data.frame      8 x 3     
##    rtfm.3                 data.frame      8 x 3     
##    s                      numeric         1         
##    salem.tabs             table           2 x 2     
##    sales                  numeric         1         
##    sales.by.month         numeric         12        
##    sample.mean            numeric         1         
##    scaled.chi.sq.3        numeric         1000      
##    score.A                numeric         5         
##    score.B                numeric         5         
##    sd.true                numeric         1         
##    sd1                    numeric         2         
##    sem.true               numeric         1         
##    setUpPlot              function                  
##    sig                    numeric         1         
##    sigEx                  expression                
##    simpson                matrix          6 x 5     
##    skewed.data            numeric         100       
##    some.data              numeric         18        
##    speaker                character       10        
##    speech.by.char         list            3         
##    squared.devs           array           3         
##    ss.diff                numeric         1         
##    SS.drug                numeric         1         
##    SS.res                 numeric         1         
##    ss.res.full            numeric         1         
##    ss.res.null            numeric         1         
##    SS.resid               numeric         1         
##    SS.therapy             numeric         1         
##    ss.tot                 numeric         1         
##    SS.tot                 numeric         1         
##    SSb                    numeric         1         
##    SStot                  numeric         1         
##    SSw                    numeric         1         
##    stock.levels           character       12        
##    suspicious.cases       logical         176       
##    t.3                    numeric         1000      
##    teams                  character       17        
##    text                   character       2         
##    therapy.means          numeric         2         
##    theta                  numeric         1         
##    today                  Date            1         
##    tombliboo              character       2         
##    total.paid             numeric         1         
##    tp                     character       6         
##    trial                  data.frame      16 x 2    
##    ttestImg               list            0         
##    type.I.sum             numeric         1         
##    type.II.sum            numeric         1         
##    upper.area             numeric         1         
##    upsy.daisy             character       4         
##    utterance              character       10        
##    w                      character       1         
##    W                      character       1         
##    w.length               integer         1         
##    width                  numeric         1         
##    words                  character       6         
##    wt.squared.devs        array           3         
##    X                      numeric         100       
##    x1                     numeric         61        
##    X1                     numeric         11        
##    x2                     numeric         61        
##    X2                     numeric         11        
##    x3                     numeric         61        
##    X3                     numeric         11        
##    X4                     numeric         11        
##    xlu                    numeric         1         
##    xtab.3d                table           3 x 4 x 2 
##    xval                   numeric         2         
##    Y                      numeric         100       
##    Y.pred                 numeric         100       
##    y1                     numeric         61        
##    Y1                     numeric         11        
##    y2                     numeric         61        
##    Y2                     numeric         11        
##    y3                     numeric         61        
##    Y3                     numeric         11        
##    Y4                     numeric         11        
##    Ybar                   array           18        
##    yhat.2                 numeric         100       
##    yval                   numeric         2         
##    yval.1                 numeric         1001      
##    yval.2                 numeric         1001      
##    z                      logical         101       
##    Z                      array           18        
##    z.score                numeric         1</code></pre>
<p>There are two variables here, <code>afl.finalists</code> and <code>afl.margins</code>. We’ll focus a bit on these two variables in this chapter, so I’d better tell you what they are. Unlike most of data sets in this book, these are actually real data, relating to the Australian Football League (AFL)<a href="#fn65" class="footnote-ref" id="fnref65"><sup>65</sup></a> The <code>afl.margins</code> variable contains the winning margin (number of points) for all 176 home and away games played during the 2010 season. The <code>afl.finalists</code> variable contains the names of all 400 teams that played in all 200 finals matches played during the period 1987 to 2010. Let’s have a look at the <code>afl.margins</code> variable:</p>
<div class="sourceCode" id="cb318"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb318-1" title="1"><span class="kw">print</span>(afl.margins)</a></code></pre></div>
<pre><code>##   [1]  56  31  56   8  32  14  36  56  19   1   3 104  43  44  72   9  28
##  [18]  25  27  55  20  16  16   7  23  40  48  64  22  55  95  15  49  52
##  [35]  50  10  65  12  39  36   3  26  23  20  43 108  53  38   4   8   3
##  [52]  13  66  67  50  61  36  38  29   9  81   3  26  12  36  37  70   1
##  [69]  35  12  50  35   9  54  47   8  47   2  29  61  38  41  23  24   1
##  [86]   9  11  10  29  47  71  38  49  65  18   0  16   9  19  36  60  24
## [103]  25  44  55   3  57  83  84  35   4  35  26  22   2  14  19  30  19
## [120]  68  11  75  48  32  36  39  50  11   0  63  82  26   3  82  73  19
## [137]  33  48   8  10  53  20  71  75  76  54  44   5  22  94  29   8  98
## [154]   9  89   1 101   7  21  52  42  21 116   3  44  29  27  16   6  44
## [171]   3  28  38  29  10  10</code></pre>
<p>This output doesn’t make it easy to get a sense of what the data are actually saying. Just “looking at the data” isn’t a terribly effective way of understanding data. In order to get some idea about what’s going on, we need to calculate some descriptive statistics (this chapter) and draw some nice pictures (Chapter @ref(graphics). Since the descriptive statistics are the easier of the two topics, I’ll start with those, but nevertheless I’ll show you a histogram of the <code>afl.margins</code> data, since it should help you get a sense of what the data we’re trying to describe actually look like. But for what it’s worth, this histogram – which is shown in Figure @ref(fig:histogram1) – was generated using the <code>hist()</code> function. We’ll talk a lot more about how to draw histograms in Section @ref(hist). For now, it’s enough to look at the histogram and note that it provides a fairly interpretable representation of the <code>afl.margins</code> data.</p>
<div class="figure">
<img src="lsr_files/figure-html/histogram1-1.png" alt="A histogram of the AFL 2010 winning margin data (the `afl.margins` variable). As you might expect, the larger the margin the less frequently you tend to see it." width="672" />
<p class="caption">
(#fig:histogram1)A histogram of the AFL 2010 winning margin data (the <code>afl.margins</code> variable). As you might expect, the larger the margin the less frequently you tend to see it.
</p>
</div>
<div id="centraltendency" class="section level2">
<h2><span class="header-section-number">5.1</span> Measures of central tendency</h2>
<p>Drawing pictures of the data, as I did in Figure @ref(fig:histogram1) is an excellent way to convey the “gist” of what the data is trying to tell you, it’s often extremely useful to try to condense the data into a few simple “summary” statistics. In most situations, the first thing that you’ll want to calculate is a measure of <strong><em>central tendency</em></strong>. That is, you’d like to know something about the “average” or “middle” of your data lies. The two most commonly used measures are the mean, median and mode; occasionally people will also report a trimmed mean. I’ll explain each of these in turn, and then discuss when each of them is useful.</p>
<div id="mean" class="section level3">
<h3><span class="header-section-number">5.1.1</span> The mean</h3>
<p>The <strong><em>mean</em></strong> of a set of observations is just a normal, old-fashioned average: add all of the values up, and then divide by the total number of values. The first five AFL margins were 56, 31, 56, 8 and 32, so the mean of these observations is just:
<span class="math display">\[
\frac{56 + 31 + 56 + 8 + 32}{5} = \frac{183}{5} = 36.60
\]</span>
Of course, this definition of the mean isn’t news to anyone: averages (i.e., means) are used so often in everyday life that this is pretty familiar stuff. However, since the concept of a mean is something that everyone already understands, I’ll use this as an excuse to start introducing some of the mathematical notation that statisticians use to describe this calculation, and talk about how the calculations would be done in R.</p>
<p>The first piece of notation to introduce is <span class="math inline">\(N\)</span>, which we’ll use to refer to the number of observations that we’re averaging (in this case <span class="math inline">\(N = 5\)</span>). Next, we need to attach a label to the observations themselves. It’s traditional to use <span class="math inline">\(X\)</span> for this, and to use subscripts to indicate which observation we’re actually talking about. That is, we’ll use <span class="math inline">\(X_1\)</span> to refer to the first observation, <span class="math inline">\(X_2\)</span> to refer to the second observation, and so on, all the way up to <span class="math inline">\(X_N\)</span> for the last one. Or, to say the same thing in a slightly more abstract way, we use <span class="math inline">\(X_i\)</span> to refer to the <span class="math inline">\(i\)</span>-th observation. Just to make sure we’re clear on the notation, the following table lists the 5 observations in the <code>afl.margins</code> variable, along with the mathematical symbol used to refer to it, and the actual value that the observation corresponds to:</p>
<table>
<thead>
<tr class="header">
<th align="left">the observation</th>
<th align="left">its symbol</th>
<th align="left">the observed value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">winning margin, game 1</td>
<td align="left"><span class="math inline">\(X_1\)</span></td>
<td align="left">56 points</td>
</tr>
<tr class="even">
<td align="left">winning margin, game 2</td>
<td align="left"><span class="math inline">\(X_2\)</span></td>
<td align="left">31 points</td>
</tr>
<tr class="odd">
<td align="left">winning margin, game 3</td>
<td align="left"><span class="math inline">\(X_3\)</span></td>
<td align="left">56 points</td>
</tr>
<tr class="even">
<td align="left">winning margin, game 4</td>
<td align="left"><span class="math inline">\(X_4\)</span></td>
<td align="left">8 points</td>
</tr>
<tr class="odd">
<td align="left">winning margin, game 5</td>
<td align="left"><span class="math inline">\(X_5\)</span></td>
<td align="left">32 points</td>
</tr>
</tbody>
</table>
<p>Okay, now let’s try to write a formula for the mean. By tradition, we use <span class="math inline">\(\bar{X}\)</span> as the notation for the mean. So the calculation for the mean could be expressed using the following formula:
<span class="math display">\[
\bar{X} = \frac{X_1 + X_2 + ... + X_{N-1} + X_N}{N}
\]</span>
This formula is entirely correct, but it’s terribly long, so we make use of the <strong><em>summation symbol</em></strong> <span class="math inline">\(\scriptstyle\sum\)</span> to shorten it.<a href="#fn66" class="footnote-ref" id="fnref66"><sup>66</sup></a> If I want to add up the first five observations, I could write out the sum the long way, <span class="math inline">\(X_1 + X_2 + X_3 + X_4 +X_5\)</span> or I could use the summation symbol to shorten it to this:
<span class="math display">\[
\sum_{i=1}^5 X_i
\]</span>
Taken literally, this could be read as “the sum, taken over all <span class="math inline">\(i\)</span> values from 1 to 5, of the value <span class="math inline">\(X_i\)</span>”. But basically, what it means is “add up the first five observations”. In any case, we can use this notation to write out the formula for the mean, which looks like this:
<span class="math display">\[
\bar{X} = \frac{1}{N} \sum_{i=1}^N X_i 
\]</span></p>
<p>In all honesty, I can’t imagine that all this mathematical notation helps clarify the concept of the mean at all. In fact, it’s really just a fancy way of writing out the same thing I said in words: add all the values up, and then divide by the total number of items. However, that’s not really the reason I went into all that detail. My goal was to try to make sure that everyone reading this book is clear on the notation that we’ll be using throughout the book: <span class="math inline">\(\bar{X}\)</span> for the mean, <span class="math inline">\(\scriptstyle\sum\)</span> for the idea of summation, <span class="math inline">\(X_i\)</span> for the <span class="math inline">\(i\)</span>th observation, and <span class="math inline">\(N\)</span> for the total number of observations. We’re going to be re-using these symbols a fair bit, so it’s important that you understand them well enough to be able to “read” the equations, and to be able to see that it’s just saying “add up lots of things and then divide by another thing”.</p>
</div>
<div id="calculating-the-mean-in-r" class="section level3">
<h3><span class="header-section-number">5.1.2</span> Calculating the mean in R</h3>
<p>Okay that’s the maths, how do we get the magic computing box to do the work for us? If you really wanted to, you could do this calculation directly in R. For the first 5 AFL scores, do this just by typing it in as if R were a calculator…</p>
<div class="sourceCode" id="cb320"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb320-1" title="1">(<span class="dv">56</span> <span class="op">+</span><span class="st"> </span><span class="dv">31</span> <span class="op">+</span><span class="st"> </span><span class="dv">56</span> <span class="op">+</span><span class="st"> </span><span class="dv">8</span> <span class="op">+</span><span class="st"> </span><span class="dv">32</span>) <span class="op">/</span><span class="st"> </span><span class="dv">5</span></a></code></pre></div>
<pre><code>## [1] 36.6</code></pre>
<p>… in which case R outputs the answer 36.6, just as if it were a calculator. However, that’s not the only way to do the calculations, and when the number of observations starts to become large, it’s easily the most tedious. Besides, in almost every real world scenario, you’ve already got the actual numbers stored in a variable of some kind, just like we have with the <code>afl.margins</code> variable. Under those circumstances, what you want is a function that will just add up all the values stored in a numeric vector. That’s what the <code>sum()</code> function does. If we want to add up all 176 winning margins in the data set, we can do so using the following command:<a href="#fn67" class="footnote-ref" id="fnref67"><sup>67</sup></a></p>
<div class="sourceCode" id="cb322"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb322-1" title="1"><span class="kw">sum</span>( afl.margins )</a></code></pre></div>
<pre><code>## [1] 6213</code></pre>
<p>If we only want the sum of the first five observations, then we can use square brackets to pull out only the first five elements of the vector. So the command would now be:</p>
<div class="sourceCode" id="cb324"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb324-1" title="1"><span class="kw">sum</span>( afl.margins[<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>] )</a></code></pre></div>
<pre><code>## [1] 183</code></pre>
<p>To calculate the mean, we now tell R to divide the output of this summation by five, so the command that we need to type now becomes the following:</p>
<div class="sourceCode" id="cb326"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb326-1" title="1"><span class="kw">sum</span>( afl.margins[<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>] ) <span class="op">/</span><span class="st"> </span><span class="dv">5</span></a></code></pre></div>
<pre><code>## [1] 36.6</code></pre>
<p>Although it’s pretty easy to calculate the mean using the <code>sum()</code> function, we can do it in an even easier way, since R also provides us with the <code>mean()</code> function. To calculate the mean for all 176 games, we would use the following command:</p>
<div class="sourceCode" id="cb328"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb328-1" title="1"><span class="kw">mean</span>( <span class="dt">x =</span> afl.margins )</a></code></pre></div>
<pre><code>## [1] 35.30114</code></pre>
<p>However, since <code>x</code> is the first argument to the function, I could have omitted the argument name. In any case, just to show you that there’s nothing funny going on, here’s what we would do to calculate the mean for the first five observations:</p>
<div class="sourceCode" id="cb330"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb330-1" title="1"><span class="kw">mean</span>( afl.margins[<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>] )</a></code></pre></div>
<pre><code>## [1] 36.6</code></pre>
<p>As you can see, this gives exactly the same answers as the previous calculations.</p>
</div>
<div id="median" class="section level3">
<h3><span class="header-section-number">5.1.3</span> The median</h3>
<p>The second measure of central tendency that people use a lot is the <strong><em>median</em></strong>, and it’s even easier to describe than the mean. The median of a set of observations is just the middle value. As before let’s imagine we were interested only in the first 5 AFL winning margins: 56, 31, 56, 8 and 32. To figure out the median, we sort these numbers into ascending order:
<span class="math display">\[
8, 31, \mathbf{32}, 56, 56
\]</span>
From inspection, it’s obvious that the median value of these 5 observations is 32, since that’s the middle one in the sorted list (I’ve put it in bold to make it even more obvious). Easy stuff. But what should we do if we were interested in the first 6 games rather than the first 5? Since the sixth game in the season had a winning margin of 14 points, our sorted list is now
<span class="math display">\[
8, 14, \mathbf{31}, \mathbf{32}, 56, 56
\]</span>
and there are <em>two</em> middle numbers, 31 and 32. The median is defined as the average of those two numbers, which is of course 31.5. As before, it’s very tedious to do this by hand when you’ve got lots of numbers. To illustrate this, here’s what happens when you use R to sort all 176 winning margins. First, I’ll use the <code>sort()</code> function (discussed in Chapter @ref(datahandling)) to display the winning margins in increasing numerical order:</p>
<div class="sourceCode" id="cb332"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb332-1" title="1"><span class="kw">sort</span>( <span class="dt">x =</span> afl.margins )</a></code></pre></div>
<pre><code>##   [1]   0   0   1   1   1   1   2   2   3   3   3   3   3   3   3   3   4
##  [18]   4   5   6   7   7   8   8   8   8   8   9   9   9   9   9   9  10
##  [35]  10  10  10  10  11  11  11  12  12  12  13  14  14  15  16  16  16
##  [52]  16  18  19  19  19  19  19  20  20  20  21  21  22  22  22  23  23
##  [69]  23  24  24  25  25  26  26  26  26  27  27  28  28  29  29  29  29
##  [86]  29  29  30  31  32  32  33  35  35  35  35  36  36  36  36  36  36
## [103]  37  38  38  38  38  38  39  39  40  41  42  43  43  44  44  44  44
## [120]  44  47  47  47  48  48  48  49  49  50  50  50  50  52  52  53  53
## [137]  54  54  55  55  55  56  56  56  57  60  61  61  63  64  65  65  66
## [154]  67  68  70  71  71  72  73  75  75  76  81  82  82  83  84  89  94
## [171]  95  98 101 104 108 116</code></pre>
<p>The middle values are 30 and 31, so the median winning margin for 2010 was 30.5 points. In real life, of course, no-one actually calculates the median by sorting the data and then looking for the middle value. In real life, we use the median command:</p>
<div class="sourceCode" id="cb334"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb334-1" title="1"><span class="kw">median</span>( <span class="dt">x =</span> afl.margins )</a></code></pre></div>
<pre><code>## [1] 30.5</code></pre>
<p>which outputs the median value of 30.5.</p>
</div>
<div id="mean-or-median-whats-the-difference" class="section level3">
<h3><span class="header-section-number">5.1.4</span> Mean or median? What’s the difference?</h3>
<div class="figure">
<img src="img/descriptives2/meanmedian.png" alt="An illustration of the difference between how the mean and the median should be interpreted. The mean is basically the &quot;centre of gravity&quot; of the data set: if you imagine that the histogram of the data is a solid object, then the point on which you could balance it (as if on a see-saw) is the mean. In contrast, the median is the middle observation. Half of the observations are smaller, and half of the observations are larger." width="463" />
<p class="caption">
(#fig:meanmedian)An illustration of the difference between how the mean and the median should be interpreted. The mean is basically the “centre of gravity” of the data set: if you imagine that the histogram of the data is a solid object, then the point on which you could balance it (as if on a see-saw) is the mean. In contrast, the median is the middle observation. Half of the observations are smaller, and half of the observations are larger.
</p>
</div>
<p>Knowing how to calculate means and medians is only a part of the story. You also need to understand what each one is saying about the data, and what that implies for when you should use each one. This is illustrated in Figure @ref(fig:meanmedian) the mean is kind of like the “centre of gravity” of the data set, whereas the median is the “middle value” in the data. What this implies, as far as which one you should use, depends a little on what type of data you’ve got and what you’re trying to achieve. As a rough guide:</p>
<ul>
<li>If your data are nominal scale, you probably shouldn’t be using either the mean or the median. Both the mean and the median rely on the idea that the numbers assigned to values are meaningful. If the numbering scheme is arbitrary, then it’s probably best to use the mode (Section @ref(mode)) instead.</li>
<li>If your data are ordinal scale, you’re more likely to want to use the median than the mean. The median only makes use of the order information in your data (i.e., which numbers are bigger), but doesn’t depend on the precise numbers involved. That’s exactly the situation that applies when your data are ordinal scale. The mean, on the other hand, makes use of the precise numeric values assigned to the observations, so it’s not really appropriate for ordinal data.</li>
<li>For interval and ratio scale data, either one is generally acceptable. Which one you pick depends a bit on what you’re trying to achieve. The mean has the advantage that it uses all the information in the data (which is useful when you don’t have a lot of data), but it’s very sensitive to extreme values, as we’ll see in Section @ref(trimmedmean).</li>
</ul>
<p>Let’s expand on that last part a little. One consequence is that there’s systematic differences between the mean and the median when the histogram is asymmetric (skewed; see Section @ref(skewandkurtosis)). This is illustrated in Figure @ref(fig:meanmedian) notice that the median (right hand side) is located closer to the “body” of the histogram, whereas the mean (left hand side) gets dragged towards the “tail” (where the extreme values are). To give a concrete example, suppose Bob (income $50,000), Kate (income $60,000) and Jane (income $65,000) are sitting at a table: the average income at the table is $58,333 and the median income is $60,000. Then Bill sits down with them (income $100,000,000). The average income has now jumped to $25,043,750 but the median rises only to $62,500. If you’re interested in looking at the overall income at the table, the mean might be the right answer; but if you’re interested in what counts as a typical income at the table, the median would be a better choice here.</p>
</div>
<div id="housingpriceexample" class="section level3">
<h3><span class="header-section-number">5.1.5</span> A real life example</h3>
<p>To try to get a sense of why you need to pay attention to the differences between the mean and the median, let’s consider a real life example. Since I tend to mock journalists for their poor scientific and statistical knowledge, I should give credit where credit is due. This is from an excellent article on the ABC news website<a href="#fn68" class="footnote-ref" id="fnref68"><sup>68</sup></a> 24 September, 2010:</p>
<blockquote>
<p>Senior Commonwealth Bank executives have travelled the world in the past couple of weeks with a presentation showing how Australian house prices, and the key price to income ratios, compare favourably with similar countries. “Housing affordability has actually been going sideways for the last five to six years,” said Craig James, the chief economist of the bank’s trading arm, CommSec.</p>
</blockquote>
<p>This probably comes as a huge surprise to anyone with a mortgage, or who wants a mortgage, or pays rent, or isn’t completely oblivious to what’s been going on in the Australian housing market over the last several years. Back to the article:</p>
<blockquote>
<p>CBA has waged its war against what it believes are housing doomsayers with graphs, numbers and international comparisons. In its presentation, the bank rejects arguments that Australia’s housing is relatively expensive compared to incomes. It says Australia’s house price to household income ratio of 5.6 in the major cities, and 4.3 nationwide, is comparable to many other developed nations. It says San Francisco and New York have ratios of 7, Auckland’s is 6.7, and Vancouver comes in at 9.3.</p>
</blockquote>
<p>More excellent news! Except, the article goes on to make the observation that…</p>
<blockquote>
<p>Many analysts say that has led the bank to use misleading figures and comparisons. If you go to page four of CBA’s presentation and read the source information at the bottom of the graph and table, you would notice there is an additional source on the international comparison – Demographia. However, if the Commonwealth Bank had also used Demographia’s analysis of Australia’s house price to income ratio, it would have come up with a figure closer to 9 rather than 5.6 or 4.3</p>
</blockquote>
<p>That’s, um, a rather serious discrepancy. One group of people say 9, another says 4-5. Should we just split the difference, and say the truth lies somewhere in between? Absolutely not: this is a situation where there is a right answer and a wrong answer. Demographia are correct, and the Commonwealth Bank is incorrect. As the article points out</p>
<blockquote>
<p>[An] obvious problem with the Commonwealth Bank’s domestic price to income figures is they compare average incomes with median house prices (unlike the Demographia figures that compare median incomes to median prices). The median is the mid-point, effectively cutting out the highs and lows, and that means the average is generally higher when it comes to incomes and asset prices, because it includes the earnings of Australia’s wealthiest people. To put it another way: the Commonwealth Bank’s figures count Ralph Norris’ multi-million dollar pay packet on the income side, but not his (no doubt) very expensive house in the property price figures, thus understating the house price to income ratio for middle-income Australians.</p>
</blockquote>
<p>Couldn’t have put it better myself. The way that Demographia calculated the ratio is the right thing to do. The way that the Bank did it is incorrect. As for why an extremely quantitatively sophisticated organisation such as a major bank made such an elementary mistake, well… I can’t say for sure, since I have no special insight into their thinking, but the article itself does happen to mention the following facts, which may or may not be relevant:</p>
<blockquote>
<p>[As] Australia’s largest home lender, the Commonwealth Bank has one of the biggest vested interests in house prices rising. It effectively owns a massive swathe of Australian housing as security for its home loans as well as many small business loans.</p>
</blockquote>
<p>My, my.</p>
</div>
<div id="trimmedmean" class="section level3">
<h3><span class="header-section-number">5.1.6</span> Trimmed mean</h3>
<p>One of the fundamental rules of applied statistics is that the data are messy. Real life is never simple, and so the data sets that you obtain are never as straightforward as the statistical theory says.<a href="#fn69" class="footnote-ref" id="fnref69"><sup>69</sup></a> This can have awkward consequences. To illustrate, consider this rather strange looking data set:
<span class="math display">\[
-100,2,3,4,5,6,7,8,9,10
\]</span>
If you were to observe this in a real life data set, you’d probably suspect that something funny was going on with the <span class="math inline">\(-100\)</span> value. It’s probably an <strong><em>outlier</em></strong>, a value that doesn’t really belong with the others. You might consider removing it from the data set entirely, and in this particular case I’d probably agree with that course of action. In real life, however, you don’t always get such cut-and-dried examples. For instance, you might get this instead:
<span class="math display">\[
-15,2,3,4,5,6,7,8,9,12
\]</span>
The <span class="math inline">\(-15\)</span> looks a bit suspicious, but not anywhere near as much as that <span class="math inline">\(-100\)</span> did. In this case, it’s a little trickier. It <em>might</em> be a legitimate observation, it might not.</p>
<p>When faced with a situation where some of the most extreme-valued observations might not be quite trustworthy, the mean is not necessarily a good measure of central tendency. It is highly sensitive to one or two extreme values, and is thus not considered to be a <strong><em>robust</em></strong> measure. One remedy that we’ve seen is to use the median. A more general solution is to use a “trimmed mean”. To calculate a trimmed mean, what you do is “discard” the most extreme examples on both ends (i.e., the largest and the smallest), and then take the mean of everything else. The goal is to preserve the best characteristics of the mean and the median: just like a median, you aren’t highly influenced by extreme outliers, but like the mean, you “use” more than one of the observations. Generally, we describe a trimmed mean in terms of the percentage of observation on either side that are discarded. So, for instance, a 10% trimmed mean discards the largest 10% of the observations <em>and</em> the smallest 10% of the observations, and then takes the mean of the remaining 80% of the observations. Not surprisingly, the 0% trimmed mean is just the regular mean, and the 50% trimmed mean is the median. In that sense, trimmed means provide a whole family of central tendency measures that span the range from the mean to the median.</p>
<p>For our toy example above, we have 10 observations, and so a 10% trimmed mean is calculated by ignoring the largest value (i.e., <code>12</code>) and the smallest value (i.e., <code>-15</code>) and taking the mean of the remaining values. First, let’s enter the data</p>
<div class="sourceCode" id="cb336"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb336-1" title="1">dataset &lt;-<span class="st"> </span><span class="kw">c</span>( <span class="dv">-15</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">7</span>,<span class="dv">8</span>,<span class="dv">9</span>,<span class="dv">12</span> )</a></code></pre></div>
<p>Next, let’s calculate means and medians:</p>
<div class="sourceCode" id="cb337"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb337-1" title="1"><span class="kw">mean</span>( <span class="dt">x =</span> dataset )</a></code></pre></div>
<pre><code>## [1] 4.1</code></pre>
<div class="sourceCode" id="cb339"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb339-1" title="1"><span class="kw">median</span>( <span class="dt">x =</span> dataset )</a></code></pre></div>
<pre><code>## [1] 5.5</code></pre>
<p>That’s a fairly substantial difference, but I’m tempted to think that the mean is being influenced a bit too much by the extreme values at either end of the data set, especially the <span class="math inline">\(-15\)</span> one. So let’s just try trimming the mean a bit. If I take a 10% trimmed mean, we’ll drop the extreme values on either side, and take the mean of the rest:</p>
<div class="sourceCode" id="cb341"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb341-1" title="1"><span class="kw">mean</span>( <span class="dt">x =</span> dataset, <span class="dt">trim =</span> <span class="fl">.1</span>)</a></code></pre></div>
<pre><code>## [1] 5.5</code></pre>
<p>which in this case gives exactly the same answer as the median. Note that, to get a 10% trimmed mean you write <code>trim = .1</code>, not <code>trim = 10</code>. In any case, let’s finish up by calculating the 5% trimmed mean for the <code>afl.margins</code> data,</p>
<div class="sourceCode" id="cb343"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb343-1" title="1"><span class="kw">mean</span>( <span class="dt">x =</span> afl.margins, <span class="dt">trim =</span> <span class="fl">.05</span>)  </a></code></pre></div>
<pre><code>## [1] 33.75</code></pre>
</div>
<div id="mode" class="section level3">
<h3><span class="header-section-number">5.1.7</span> Mode</h3>
<p>The mode of a sample is very simple: it is the value that occurs most frequently. To illustrate the mode using the AFL data, let’s examine a different aspect to the data set. Who has played in the most finals? The <code>afl.finalists</code> variable is a factor that contains the name of every team that played in any AFL final from 1987-2010, so let’s have a look at it. To do this we will use the <code>head()</code> command. <code>head()</code> is useful when you’re working with a data.frame with a lot of rows since you can use it to tell you how many rows to return. There have been a lot of finals in this period so printing afl.finalists using <code>print(afl.finalists)</code> will just fill us the screen. The command below tells R we just want the first 25 rows of the data.frame.</p>
<div class="sourceCode" id="cb345"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb345-1" title="1"><span class="kw">head</span>(afl.finalists, <span class="dv">25</span>)</a></code></pre></div>
<pre><code>##  [1] Hawthorn    Melbourne   Carlton     Melbourne   Hawthorn   
##  [6] Carlton     Melbourne   Carlton     Hawthorn    Melbourne  
## [11] Melbourne   Hawthorn    Melbourne   Essendon    Hawthorn   
## [16] Geelong     Geelong     Hawthorn    Collingwood Melbourne  
## [21] Collingwood West Coast  Collingwood Essendon    Collingwood
## 17 Levels: Adelaide Brisbane Carlton Collingwood Essendon ... Western Bulldogs</code></pre>
<p>There are actually 400 entries (aren’t you glad we didn’t print them all?). We <em>could</em> read through all 400, and count the number of occasions on which each team name appears in our list of finalists, thereby producing a <strong><em>frequency table</em></strong>. However, that would be mindless and boring: exactly the sort of task that computers are great at. So let’s use the <code>table()</code> function (discussed in more detail in Section @ref(freqtables)) to do this task for us:</p>
<div class="sourceCode" id="cb347"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb347-1" title="1"><span class="kw">table</span>( afl.finalists )</a></code></pre></div>
<pre><code>## afl.finalists
##         Adelaide         Brisbane          Carlton      Collingwood 
##               26               25               26               28 
##         Essendon          Fitzroy        Fremantle          Geelong 
##               32                0                6               39 
##         Hawthorn        Melbourne  North Melbourne    Port Adelaide 
##               27               28               28               17 
##         Richmond         St Kilda           Sydney       West Coast 
##                6               24               26               38 
## Western Bulldogs 
##               24</code></pre>
<p>Now that we have our frequency table, we can just look at it and see that, over the 24 years for which we have data, Geelong has played in more finals than any other team. Thus, the mode of the <code>finalists</code> data is <code>"Geelong"</code>. The core packages in R don’t have a function for calculating the mode<a href="#fn70" class="footnote-ref" id="fnref70"><sup>70</sup></a>. However, I’ve included a function in the <code>lsr</code> package that does this. The function is called <code>modeOf()</code>, and here’s how you use it:</p>
<div class="sourceCode" id="cb349"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb349-1" title="1"><span class="kw">modeOf</span>( <span class="dt">x =</span> afl.finalists )</a></code></pre></div>
<pre><code>## [1] &quot;Geelong&quot;</code></pre>
<p>There’s also a function called <code>maxFreq()</code> that tells you what the modal frequency is. If we apply this function to our finalists data, we obtain the following:</p>
<div class="sourceCode" id="cb351"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb351-1" title="1"><span class="kw">maxFreq</span>( <span class="dt">x =</span> afl.finalists )</a></code></pre></div>
<pre><code>## [1] 39</code></pre>
<p>Taken together, we observe that Geelong (39 finals) played in more finals than any other team during the 1987-2010 period.</p>
<p>One last point to make with respect to the mode. While it’s generally true that the mode is most often calculated when you have nominal scale data (because means and medians are useless for those sorts of variables), there are some situations in which you really do want to know the mode of an ordinal, interval or ratio scale variable. For instance, let’s go back to thinking about our <code>afl.margins</code> variable. This variable is clearly ratio scale (if it’s not clear to you, it may help to re-read Section @ref(scales)), and so in most situations the mean or the median is the measure of central tendency that you want. But consider this scenario… a friend of yours is offering a bet. They pick a football game at random, and (without knowing who is playing) you have to guess the <em>exact</em> margin. If you guess correctly, you win $50. If you don’t, you lose $1. There are no consolation prizes for “almost” getting the right answer. You have to guess exactly the right margin<a href="#fn71" class="footnote-ref" id="fnref71"><sup>71</sup></a> For this bet, the mean and the median are completely useless to you. It is the mode that you should bet on. So, we calculate this modal value</p>
<div class="sourceCode" id="cb353"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb353-1" title="1"><span class="kw">modeOf</span>( <span class="dt">x =</span> afl.margins )</a></code></pre></div>
<pre><code>## [1] 3</code></pre>
<div class="sourceCode" id="cb355"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb355-1" title="1"><span class="kw">maxFreq</span>( <span class="dt">x =</span> afl.margins )</a></code></pre></div>
<pre><code>## [1] 8</code></pre>
<p>So the 2010 data suggest you should bet on a 3 point margin, and since this was observed in 8 of the 176 game (4.5% of games) the odds are firmly in your favour.</p>
</div>
</div>
<div id="var" class="section level2">
<h2><span class="header-section-number">5.2</span> Measures of variability</h2>
<p>The statistics that we’ve discussed so far all relate to <em>central tendency</em>. That is, they all talk about which values are “in the middle” or “popular” in the data. However, central tendency is not the only type of summary statistic that we want to calculate. The second thing that we really want is a measure of the <strong><em>variability</em></strong> of the data. That is, how “spread out” are the data? How “far” away from the mean or median do the observed values tend to be? For now, let’s assume that the data are interval or ratio scale, so we’ll continue to use the <code>afl.margins</code> data. We’ll use this data to discuss several different measures of spread, each with different strengths and weaknesses.</p>
<div id="range" class="section level3">
<h3><span class="header-section-number">5.2.1</span> Range</h3>
<p>The <strong><em>range</em></strong> of a variable is very simple: it’s the biggest value minus the smallest value. For the AFL winning margins data, the maximum value is 116, and the minimum value is 0. We can calculate these values in R using the <code>max()</code> and <code>min()</code> functions:</p>
<div class="sourceCode" id="cb357"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb357-1" title="1"><span class="kw">max</span>( afl.margins )</a></code></pre></div>
<pre><code>## [1] 116</code></pre>
<div class="sourceCode" id="cb359"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb359-1" title="1"><span class="kw">min</span>( afl.margins )</a></code></pre></div>
<pre><code>## [1] 0</code></pre>
<p>where I’ve omitted the output because it’s not interesting. The other possibility is to use the <code>range()</code> function; which outputs both the minimum value and the maximum value in a vector, like this:</p>
<div class="sourceCode" id="cb361"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb361-1" title="1"><span class="kw">range</span>( afl.margins )</a></code></pre></div>
<pre><code>## [1]   0 116</code></pre>
<p>Although the range is the simplest way to quantify the notion of “variability”, it’s one of the worst. Recall from our discussion of the mean that we want our summary measure to be robust. If the data set has one or two extremely bad values in it, we’d like our statistics not to be unduly influenced by these cases. If we look once again at our toy example of a data set containing very extreme outliers…
<span class="math display">\[
-100,2,3,4,5,6,7,8,9,10
\]</span>
… it is clear that the range is not robust, since this has a range of 110, but if the outlier were removed we would have a range of only 8.</p>
</div>
<div id="interquartile-range" class="section level3">
<h3><span class="header-section-number">5.2.2</span> Interquartile range</h3>
<p>The <strong><em>interquartile range</em></strong> (IQR) is like the range, but instead of calculating the difference between the biggest and smallest value, it calculates the difference between the 25th quantile and the 75th quantile. Probably you already know what a <strong><em>quantile</em></strong> is (they’re more commonly called percentiles), but if not: the 10th percentile of a data set is the smallest number <span class="math inline">\(x\)</span> such that 10% of the data is less than <span class="math inline">\(x\)</span>. In fact, we’ve already come across the idea: the median of a data set is its 50th quantile / percentile! R actually provides you with a way of calculating quantiles, using the (surprise, surprise) <code>quantile()</code> function. Let’s use it to calculate the median AFL winning margin:</p>
<div class="sourceCode" id="cb363"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb363-1" title="1"><span class="kw">quantile</span>( <span class="dt">x =</span> afl.margins, <span class="dt">probs =</span> <span class="fl">.5</span>)</a></code></pre></div>
<pre><code>##  50% 
## 30.5</code></pre>
<p>And not surprisingly, this agrees with the answer that we saw earlier with the <code>median()</code> function. Now, we can actually input lots of quantiles at once, by specifying a vector for the <code>probs</code> argument. So lets do that, and get the 25th and 75th percentile:</p>
<div class="sourceCode" id="cb365"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb365-1" title="1"><span class="kw">quantile</span>( <span class="dt">x =</span> afl.margins, <span class="dt">probs =</span> <span class="kw">c</span>(.<span class="dv">25</span>,.<span class="dv">75</span>) )</a></code></pre></div>
<pre><code>##   25%   75% 
## 12.75 50.50</code></pre>
<p>And, by noting that <span class="math inline">\(50.5 - 12.75 = 37.75\)</span>, we can see that the interquartile range for the 2010 AFL winning margins data is 37.75. Of course, that seems like too much work to do all that typing, so R has a built in function called <code>IQR()</code> that we can use:</p>
<div class="sourceCode" id="cb367"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb367-1" title="1"><span class="kw">IQR</span>( <span class="dt">x =</span> afl.margins )</a></code></pre></div>
<pre><code>## [1] 37.75</code></pre>
<p>While it’s obvious how to interpret the range, it’s a little less obvious how to interpret the IQR. The simplest way to think about it is like this: the interquartile range is the range spanned by the “middle half” of the data. That is, one quarter of the data falls below the 25th percentile, one quarter of the data is above the 75th percentile, leaving the “middle half” of the data lying in between the two. And the IQR is the range covered by that middle half.</p>
</div>
<div id="aad" class="section level3">
<h3><span class="header-section-number">5.2.3</span> Mean absolute deviation</h3>
<p>The two measures we’ve looked at so far, the range and the interquartile range, both rely on the idea that we can measure the spread of the data by looking at the quantiles of the data. However, this isn’t the only way to think about the problem. A different approach is to select a meaningful reference point (usually the mean or the median) and then report the “typical” deviations from that reference point. What do we mean by “typical” deviation? Usually, the mean or median value of these deviations! In practice, this leads to two different measures, the “mean absolute deviation (from the mean)” and the “median absolute deviation (from the median)”. From what I’ve read, the measure based on the median seems to be used in statistics, and does seem to be the better of the two, but to be honest I don’t think I’ve seen it used much in psychology. The measure based on the mean does occasionally show up in psychology though. In this section I’ll talk about the first one, and I’ll come back to talk about the second one later.</p>
<p>Since the previous paragraph might sound a little abstract, let’s go through the <strong><em>mean absolute deviation</em></strong> from the mean a little more slowly. One useful thing about this measure is that the name actually tells you exactly how to calculate it. Let’s think about our AFL winning margins data, and once again we’ll start by pretending that there’s only 5 games in total, with winning margins of 56, 31, 56, 8 and 32. Since our calculations rely on an examination of the deviation from some reference point (in this case the mean), the first thing we need to calculate is the mean, <span class="math inline">\(\bar{X}\)</span>. For these five observations, our mean is <span class="math inline">\(\bar{X} = 36.6\)</span>. The next step is to convert each of our observations <span class="math inline">\(X_i\)</span> into a deviation score. We do this by calculating the difference between the observation <span class="math inline">\(X_i\)</span> and the mean <span class="math inline">\(\bar{X}\)</span>. That is, the deviation score is defined to be <span class="math inline">\(X_i - \bar{X}\)</span>. For the first observation in our sample, this is equal to <span class="math inline">\(56 - 36.6 = 19.4\)</span>. Okay, that’s simple enough. The next step in the process is to convert these deviations to absolute deviations. As we discussed earlier when talking about the <code>abs()</code> function in R (Section @ref(usingfunctions)), we do this by converting any negative values to positive ones. Mathematically, we would denote the absolute value of <span class="math inline">\(-3\)</span> as <span class="math inline">\(|-3|\)</span>, and so we say that <span class="math inline">\(|-3| = 3\)</span>. We use the absolute value function here because we don’t really care whether the value is higher than the mean or lower than the mean, we’re just interested in how <em>close</em> it is to the mean. To help make this process as obvious as possible, the table below shows these calculations for all five observations:</p>
<table>
<thead>
<tr class="header">
<th align="left">the observation</th>
<th align="left">its symbol</th>
<th align="left">the observed value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">winning margin, game 1</td>
<td align="left"><span class="math inline">\(X_1\)</span></td>
<td align="left">56 points</td>
</tr>
<tr class="even">
<td align="left">winning margin, game 2</td>
<td align="left"><span class="math inline">\(X_2\)</span></td>
<td align="left">31 points</td>
</tr>
<tr class="odd">
<td align="left">winning margin, game 3</td>
<td align="left"><span class="math inline">\(X_3\)</span></td>
<td align="left">56 points</td>
</tr>
<tr class="even">
<td align="left">winning margin, game 4</td>
<td align="left"><span class="math inline">\(X_4\)</span></td>
<td align="left">8 points</td>
</tr>
<tr class="odd">
<td align="left">winning margin, game 5</td>
<td align="left"><span class="math inline">\(X_5\)</span></td>
<td align="left">32 points</td>
</tr>
</tbody>
</table>
<p>Now that we have calculated the absolute deviation score for every observation in the data set, all that we have to do to calculate the mean of these scores. Let’s do that:
<span class="math display">\[
\frac{19.4 + 5.6 + 19.4 + 28.6 + 4.6}{5} = 15.52
\]</span>
And we’re done. The mean absolute deviation for these five scores is 15.52.</p>
<p>However, while our calculations for this little example are at an end, we do have a couple of things left to talk about. Firstly, we should really try to write down a proper mathematical formula. But in order do to this I need some mathematical notation to refer to the mean absolute deviation. Irritatingly, “mean absolute deviation” and “median absolute deviation” have the same acronym (MAD), which leads to a certain amount of ambiguity, and since R tends to use MAD to refer to the median absolute deviation, I’d better come up with something different for the mean absolute deviation. Sigh. What I’ll do is use AAD instead, short for <em>average</em> absolute deviation. Now that we have some unambiguous notation, here’s the formula that describes what we just calculated:
<span class="math display">\[
\mbox{}(X) = \frac{1}{N} \sum_{i = 1}^N |X_i - \bar{X}|
\]</span></p>
<p>The last thing we need to talk about is how to calculate AAD in R. One possibility would be to do everything using low level commands, laboriously following the same steps that I used when describing the calculations above. However, that’s pretty tedious. You’d end up with a series of commands that might look like this:</p>
<div class="sourceCode" id="cb369"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb369-1" title="1">X &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">56</span>, <span class="dv">31</span>,<span class="dv">56</span>,<span class="dv">8</span>,<span class="dv">32</span>)   <span class="co"># enter the data</span></a>
<a class="sourceLine" id="cb369-2" title="2">X.bar &lt;-<span class="st"> </span><span class="kw">mean</span>( X )       <span class="co"># step 1. the mean of the data</span></a>
<a class="sourceLine" id="cb369-3" title="3">AD &lt;-<span class="st"> </span><span class="kw">abs</span>( X <span class="op">-</span><span class="st"> </span>X.bar )   <span class="co"># step 2. the absolute deviations from the mean</span></a>
<a class="sourceLine" id="cb369-4" title="4">AAD &lt;-<span class="st"> </span><span class="kw">mean</span>( AD )        <span class="co"># step 3. the mean absolute deviations</span></a>
<a class="sourceLine" id="cb369-5" title="5"><span class="kw">print</span>( AAD )             <span class="co"># print the results</span></a></code></pre></div>
<pre><code>## [1] 15.52</code></pre>
<p>Each of those commands is pretty simple, but there’s just too many of them. And because I find that to be too much typing, the <code>lsr</code> package has a very simple function called <code>aad()</code> that does the calculations for you. If we apply the <code>aad()</code> function to our data, we get this:</p>
<div class="sourceCode" id="cb371"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb371-1" title="1"><span class="kw">library</span>(lsr)</a>
<a class="sourceLine" id="cb371-2" title="2"><span class="kw">aad</span>( X )</a></code></pre></div>
<pre><code>## [1] 15.52</code></pre>
<p>No suprises there.</p>
</div>
<div id="variance" class="section level3">
<h3><span class="header-section-number">5.2.4</span> Variance</h3>
<p>Although the mean absolute deviation measure has its uses, it’s not the best measure of variability to use. From a purely mathematical perspective, there are some solid reasons to prefer squared deviations rather than absolute deviations. If we do that, we obtain a measure is called the <strong><em>variance</em></strong>, which has a lot of really nice statistical properties that I’m going to ignore,<a href="#fn72" class="footnote-ref" id="fnref72"><sup>72</sup></a>(X)$ and <span class="math inline">\(\mbox{Var}(Y)\)</span> respectively. Now imagine I want to define a new variable <span class="math inline">\(Z\)</span> that is the sum of the two, <span class="math inline">\(Z = X+Y\)</span>. As it turns out, the variance of <span class="math inline">\(Z\)</span> is equal to <span class="math inline">\(\mbox{Var}(X) + \mbox{Var}(Y)\)</span>. This is a <em>very</em> useful property, but it’s not true of the other measures that I talk about in this section.] and one massive psychological flaw that I’m going to make a big deal out of in a moment. The variance of a data set <span class="math inline">\(X\)</span> is sometimes written as <span class="math inline">\(\mbox{Var}(X)\)</span>, but it’s more commonly denoted <span class="math inline">\(s^2\)</span> (the reason for this will become clearer shortly). The formula that we use to calculate the variance of a set of observations is as follows:
<span class="math display">\[
\mbox{Var}(X) = \frac{1}{N} \sum_{i=1}^N \left( X_i - \bar{X} \right)^2
\]</span>
<span class="math display">\[\mbox{Var}(X) = \frac{\sum_{i=1}^N \left( X_i - \bar{X} \right)^2}{N}\]</span>
As you can see, it’s basically the same formula that we used to calculate the mean absolute deviation, except that instead of using “absolute deviations” we use “squared deviations”. It is for this reason that the variance is sometimes referred to as the “mean square deviation”.</p>
<p>Now that we’ve got the basic idea, let’s have a look at a concrete example. Once again, let’s use the first five AFL games as our data. If we follow the same approach that we took last time, we end up with the following table:</p>
<table>
<caption>(#tab:unnamed-chunk-194)Basic arithmetic operations in R. These five operators are used very frequently throughout the text, so it’s important to be familiar with them at the outset.</caption>
<thead>
<tr class="header">
<th align="left">Notation [English]</th>
<th align="left"><span class="math inline">\(i\)</span> [which game]</th>
<th align="left"><span class="math inline">\(X_i\)</span> [value]</th>
<th align="left"><span class="math inline">\(X_i - \bar{X}\)</span> [deviation from mean]</th>
<th align="left"><span class="math inline">\((X_i - \bar{X})^2\)</span> [absolute deviation]</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"></td>
<td align="left">1</td>
<td align="left">56</td>
<td align="left">19.4</td>
<td align="left">376.36</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">2</td>
<td align="left">31</td>
<td align="left">-5.6</td>
<td align="left">31.36</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left">3</td>
<td align="left">56</td>
<td align="left">19.4</td>
<td align="left">376.36</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">4</td>
<td align="left">8</td>
<td align="left">-28.6</td>
<td align="left">817.96</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left">5</td>
<td align="left">32</td>
<td align="left">-4.6</td>
<td align="left">21.16</td>
</tr>
</tbody>
</table>
<p>That last column contains all of our squared deviations, so all we have to do is average them. If we do that by typing all the numbers into R by hand…</p>
<div class="sourceCode" id="cb373"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb373-1" title="1">( <span class="fl">376.36</span> <span class="op">+</span><span class="st"> </span><span class="fl">31.36</span> <span class="op">+</span><span class="st"> </span><span class="fl">376.36</span> <span class="op">+</span><span class="st"> </span><span class="fl">817.96</span> <span class="op">+</span><span class="st"> </span><span class="fl">21.16</span> ) <span class="op">/</span><span class="st"> </span><span class="dv">5</span></a></code></pre></div>
<pre><code>## [1] 324.64</code></pre>
<p>… we end up with a variance of 324.64. Exciting, isn’t it? For the moment, let’s ignore the burning question that you’re all probably thinking (i.e., what the heck does a variance of 324.64 actually mean?) and instead talk a bit more about how to do the calculations in R, because this will reveal something very weird.</p>
<p>As always, we want to avoid having to type in a whole lot of numbers ourselves. And as it happens, we have the vector <code>X</code> lying around, which we created in the previous section. With this in mind, we can calculate the variance of <code>X</code> by using the following command,</p>
<div class="sourceCode" id="cb375"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb375-1" title="1"><span class="kw">mean</span>( (X <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(X) )<span class="op">^</span><span class="dv">2</span>)</a></code></pre></div>
<pre><code>## [1] 324.64</code></pre>
<p>and as usual we get the same answer as the one that we got when we did everything by hand. However, I <em>still</em> think that this is too much typing. Fortunately, R has a built in function called <code>var()</code> which does calculate variances. So we could also do this…</p>
<div class="sourceCode" id="cb377"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb377-1" title="1"><span class="kw">var</span>(X)</a></code></pre></div>
<pre><code>## [1] 405.8</code></pre>
<p>and you get the same… no, wait… you get a completely <em>different</em> answer. That’s just weird. Is R broken? Is this a typo? Is Dan an idiot?</p>
<p>As it happens, the answer is no.<a href="#fn73" class="footnote-ref" id="fnref73"><sup>73</sup></a> It’s not a typo, and R is not making a mistake. To get a feel for what’s happening, let’s stop using the tiny data set containing only 5 data points, and switch to the full set of 176 games that we’ve got stored in our <code>afl.margins</code> vector. First, let’s calculate the variance by using the formula that I described above:</p>
<div class="sourceCode" id="cb379"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb379-1" title="1"><span class="kw">mean</span>( (afl.margins <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(afl.margins) )<span class="op">^</span><span class="dv">2</span>)</a></code></pre></div>
<pre><code>## [1] 675.9718</code></pre>
<p>Now let’s use the <code>var()</code> function:</p>
<div class="sourceCode" id="cb381"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb381-1" title="1"><span class="kw">var</span>( afl.margins )</a></code></pre></div>
<pre><code>## [1] 679.8345</code></pre>
<p>Hm. These two numbers are very similar this time. That seems like too much of a coincidence to be a mistake. And of course it isn’t a mistake. In fact, it’s very simple to explain what R is doing here, but slightly trickier to explain <em>why</em> R is doing it. So let’s start with the “what”. What R is doing is evaluating a slightly different formula to the one I showed you above. Instead of averaging the squared deviations, which requires you to divide by the number of data points <span class="math inline">\(N\)</span>, R has chosen to divide by <span class="math inline">\(N-1\)</span>. In other words, the formula that R is using is this one<br />
<span class="math display">\[
\frac{1}{N-1} \sum_{i=1}^N \left( X_i - \bar{X} \right)^2
\]</span>
It’s easy enough to verify that this is what’s happening, as the following command illustrates:</p>
<div class="sourceCode" id="cb383"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb383-1" title="1"><span class="kw">sum</span>( (X<span class="op">-</span><span class="kw">mean</span>(X))<span class="op">^</span><span class="dv">2</span> ) <span class="op">/</span><span class="st"> </span><span class="dv">4</span></a></code></pre></div>
<pre><code>## [1] 405.8</code></pre>
<p>This is the same answer that R gave us originally when we calculated <code>var(X)</code> originally. So that’s the <em>what</em>. The real question is <em>why</em> R is dividing by <span class="math inline">\(N-1\)</span> and not by <span class="math inline">\(N\)</span>. After all, the variance is supposed to be the <em>mean</em> squared deviation, right? So shouldn’t we be dividing by <span class="math inline">\(N\)</span>, the actual number of observations in the sample? Well, yes, we should. However, as we’ll discuss in Chapter @ref(estimation), there’s a subtle distinction between “describing a sample” and “making guesses about the population from which the sample came”. Up to this point, it’s been a distinction without a difference. Regardless of whether you’re describing a sample or drawing inferences about the population, the mean is calculated exactly the same way. Not so for the variance, or the standard deviation, or for many other measures besides. What I outlined to you initially (i.e., take the actual average, and thus divide by <span class="math inline">\(N\)</span>) assumes that you literally intend to calculate the variance of the sample. Most of the time, however, you’re not terribly interested in the sample <em>in and of itself</em>. Rather, the sample exists to tell you something about the world. If so, you’re actually starting to move away from calculating a “sample statistic”, and towards the idea of estimating a “population parameter”. However, I’m getting ahead of myself. For now, let’s just take it on faith that R knows what it’s doing, and we’ll revisit the question later on when we talk about estimation in Chapter @ref(estimation).</p>
<p>Okay, one last thing. This section so far has read a bit like a mystery novel. I’ve shown you how to calculate the variance, described the weird “<span class="math inline">\(N-1\)</span>” thing that R does and hinted at the reason why it’s there, but I haven’t mentioned the single most important thing… how do you <em>interpret</em> the variance? Descriptive statistics are supposed to describe things, after all, and right now the variance is really just a gibberish number. Unfortunately, the reason why I haven’t given you the human-friendly interpretation of the variance is that there really isn’t one. This is the most serious problem with the variance. Although it has some elegant mathematical properties that suggest that it really is a fundamental quantity for expressing variation, it’s completely useless if you want to communicate with an actual human… variances are completely uninterpretable in terms of the original variable! All the numbers have been squared, and they don’t mean anything anymore. This is a huge issue. For instance, according to the table I presented earlier, the margin in game 1 was “376.36 points-squared higher than the average margin”. This is <em>exactly</em> as stupid as it sounds; and so when we calculate a variance of 324.64, we’re in the same situation. I’ve watched a lot of footy games, and never has anyone referred to “points squared”. It’s <em>not</em> a real unit of measurement, and since the variance is expressed in terms of this gibberish unit, it is totally meaningless to a human.</p>
</div>
<div id="sd" class="section level3">
<h3><span class="header-section-number">5.2.5</span> Standard deviation</h3>
<p>Okay, suppose that you like the idea of using the variance because of those nice mathematical properties that I haven’t talked about, but – since you’re a human and not a robot – you’d like to have a measure that is expressed in the same units as the data itself (i.e., points, not points-squared). What should you do? The solution to the problem is obvious: take the square root of the variance, known as the <strong><em>standard deviation</em></strong>, also called the “root mean squared deviation”, or RMSD. This solves out problem fairly neatly: while nobody has a clue what “a variance of 324.68 points-squared” really means, it’s much easier to understand “a standard deviation of 18.01 points”, since it’s expressed in the original units. It is traditional to refer to the standard deviation of a sample of data as <span class="math inline">\(s\)</span>, though “sd” and “std dev.” are also used at times. Because the standard deviation is equal to the square root of the variance, you probably won’t be surprised to see that the formula is:
<span class="math display">\[
s = \sqrt{ \frac{1}{N} \sum_{i=1}^N \left( X_i - \bar{X} \right)^2 }
\]</span>
and the R function that we use to calculate it is <code>sd()</code>. However, as you might have guessed from our discussion of the variance, what R actually calculates is slightly different to the formula given above. Just like the we saw with the variance, what R calculates is a version that divides by <span class="math inline">\(N-1\)</span> rather than <span class="math inline">\(N\)</span>. For reasons that will make sense when we return to this topic in <a href="mailto:Chapter@refch" class="email">Chapter@refch</a>:estimation I’ll refer to this new quantity as <span class="math inline">\(\hat\sigma\)</span> (read as: “sigma hat”), and the formula for this is
<span class="math display">\[
\hat\sigma = \sqrt{ \frac{1}{N-1} \sum_{i=1}^N \left( X_i - \bar{X} \right)^2 }
\]</span>
With that in mind, calculating standard deviations in R is simple:</p>
<div class="sourceCode" id="cb385"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb385-1" title="1"><span class="kw">sd</span>( afl.margins ) </a></code></pre></div>
<pre><code>## [1] 26.07364</code></pre>
<p>Interpreting standard deviations is slightly more complex. Because the standard deviation is derived from the variance, and the variance is a quantity that has little to no meaning that makes sense to us humans, the standard deviation doesn’t have a simple interpretation. As a consequence, most of us just rely on a simple rule of thumb: in general, you should expect 68% of the data to fall within 1 standard deviation of the mean, 95% of the data to fall within 2 standard deviation of the mean, and 99.7% of the data to fall within 3 standard deviations of the mean. This rule tends to work pretty well most of the time, but it’s not exact: it’s actually calculated based on an <em>assumption</em> that the histogram is symmetric and “bell shaped.”<a href="#fn74" class="footnote-ref" id="fnref74"><sup>74</sup></a> As you can tell from looking at the AFL winning margins histogram in Figure @ref(fig:histogram1), this isn’t exactly true of our data! Even so, the rule is approximately correct. As it turns out, 65.3% of the AFL margins data fall within one standard deviation of the mean. This is shown visually in Figure @ref(fig:aflsd).</p>
<div class="figure">
<img src="lsr_files/figure-html/aflsd-1.png" alt="An illustration of the standard deviation, applied to the AFL winning margins data. The shaded bars in the histogram show how much of the data fall within one standard deviation of the mean. In this case, 65.3% of the data set lies within this range, which is pretty consistent with the &quot;approximately 68% rule&quot; discussed in the main text." width="672" />
<p class="caption">
(#fig:aflsd)An illustration of the standard deviation, applied to the AFL winning margins data. The shaded bars in the histogram show how much of the data fall within one standard deviation of the mean. In this case, 65.3% of the data set lies within this range, which is pretty consistent with the “approximately 68% rule” discussed in the main text.
</p>
</div>
</div>
<div id="mad" class="section level3">
<h3><span class="header-section-number">5.2.6</span> Median absolute deviation</h3>
<p>The last measure of variability that I want to talk about is the <strong><em>median absolute deviation</em></strong> (MAD). The basic idea behind MAD is very simple, and is pretty much identical to the idea behind the mean absolute deviation (Section @ref(aad)). The difference is that you use the median everywhere. If we were to frame this idea as a pair of R commands, they would look like this:</p>
<div class="sourceCode" id="cb387"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb387-1" title="1"><span class="co"># mean absolute deviation from the mean:</span></a>
<a class="sourceLine" id="cb387-2" title="2"><span class="kw">mean</span>( <span class="kw">abs</span>(afl.margins <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(afl.margins)) )</a></code></pre></div>
<pre><code>## [1] 21.10124</code></pre>
<div class="sourceCode" id="cb389"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb389-1" title="1"><span class="co"># *median* absolute deviation from the *median*:</span></a>
<a class="sourceLine" id="cb389-2" title="2"><span class="kw">median</span>( <span class="kw">abs</span>(afl.margins <span class="op">-</span><span class="st"> </span><span class="kw">median</span>(afl.margins)) )</a></code></pre></div>
<pre><code>## [1] 19.5</code></pre>
<p>This has a straightforward interpretation: every observation in the data set lies some distance away from the typical value (the median). So the MAD is an attempt to describe a <em>typical deviation from a typical value</em> in the data set. It wouldn’t be unreasonable to interpret the MAD value of 19.5 for our AFL data by saying something like this:</p>
<blockquote>
<p>The median winning margin in 2010 was 30.5, indicating that a typical game involved a winning margin of about 30 points. However, there was a fair amount of variation from game to game: the MAD value was 19.5, indicating that a typical winning margin would differ from this median value by about 19-20 points.</p>
</blockquote>
<p>As you’d expect, R has a built in function for calculating MAD, and you will be shocked no doubt to hear that it’s called <code>mad()</code>. However, it’s a little bit more complicated than the functions that we’ve been using previously. If you want to use it to calculate MAD in the exact same way that I have described it above, the command that you need to use specifies two arguments: the data set itself <code>x</code>, and a <code>constant</code> that I’ll explain in a moment. For our purposes, the constant is 1, so our command becomes</p>
<div class="sourceCode" id="cb391"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb391-1" title="1"><span class="kw">mad</span>( <span class="dt">x =</span> afl.margins, <span class="dt">constant =</span> <span class="dv">1</span> )</a></code></pre></div>
<pre><code>## [1] 19.5</code></pre>
<p>Apart from the weirdness of having to type that <code>constant = 1</code> part, this is pretty straightforward.</p>
<p>Okay, so what exactly is this <code>constant = 1</code> argument? I won’t go into all the details here, but here’s the gist. Although the “raw” MAD value that I’ve described above is completely interpretable on its own terms, that’s not actually how it’s used in a lot of real world contexts. Instead, what happens a lot is that the researcher <em>actually</em> wants to calculate the standard deviation. However, in the same way that the mean is very sensitive to extreme values, the standard deviation is vulnerable to the exact same issue. So, in much the same way that people sometimes use the median as a “robust” way of calculating “something that is like the mean”, it’s not uncommon to use MAD as a method for calculating “something that is like the standard deviation”. Unfortunately, the <em>raw</em> MAD value doesn’t do this. Our raw MAD value is 19.5, and our standard deviation was 26.07. However, what some clever person has shown is that, under certain assumptions<a href="#fn75" class="footnote-ref" id="fnref75"><sup>75</sup></a>, you can multiply the raw MAD value by 1.4826 and obtain a number that is directly comparable to the standard deviation. As a consequence, the default value of <code>constant</code> is 1.4826, and so when you use the <code>mad()</code> command without manually setting a value, here’s what you get:</p>
<div class="sourceCode" id="cb393"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb393-1" title="1"><span class="kw">mad</span>( afl.margins )</a></code></pre></div>
<pre><code>## [1] 28.9107</code></pre>
<p>I should point out, though, that if you want to use this “corrected” MAD value as a robust version of the standard deviation, you really are relying on the assumption that the data are (or at least, are “supposed to be” in some sense) symmetric and basically shaped like a bell curve. That’s really <em>not</em> true for our <code>afl.margins</code> data, so in this case I wouldn’t try to use the MAD value this way.</p>
</div>
<div id="which-measure-to-use" class="section level3">
<h3><span class="header-section-number">5.2.7</span> Which measure to use?</h3>
<p>We’ve discussed quite a few measures of spread (range, IQR, MAD, variance and standard deviation), and hinted at their strengths and weaknesses. Here’s a quick summary:</p>
<ul>
<li><em>Range</em>. Gives you the full spread of the data. It’s very vulnerable to outliers, and as a consequence it isn’t often used unless you have good reasons to care about the extremes in the data.</li>
<li><em>Interquartile range</em>. Tells you where the “middle half” of the data sits. It’s pretty robust, and complements the median nicely. This is used a lot.</li>
<li><em>Mean absolute deviation</em>. Tells you how far “on average” the observations are from the mean. It’s very interpretable, but has a few minor issues (not discussed here) that make it less attractive to statisticians than the standard deviation. Used sometimes, but not often.</li>
<li><em>Variance</em>. Tells you the average squared deviation from the mean. It’s mathematically elegant, and is probably the “right” way to describe variation around the mean, but it’s completely uninterpretable because it doesn’t use the same units as the data. Almost never used except as a mathematical tool; but it’s buried “under the hood” of a very large number of statistical tools.</li>
<li><em>Standard deviation</em>. This is the square root of the variance. It’s fairly elegant mathematically, and it’s expressed in the same units as the data so it can be interpreted pretty well. In situations where the mean is the measure of central tendency, this is the default. This is by far the most popular measure of variation.</li>
<li><em>Median absolute deviation</em>. The typical (i.e., median) deviation from the median value. In the raw form it’s simple and interpretable; in the corrected form it’s a robust way to estimate the standard deviation, for some kinds of data sets. Not used very often, but it does get reported sometimes.</li>
</ul>
<p>In short, the IQR and the standard deviation are easily the two most common measures used to report the variability of the data; but there are situations in which the others are used. I’ve described all of them in this book because there’s a fair chance you’ll run into most of these somewhere.</p>
</div>
</div>
<div id="skewandkurtosis" class="section level2">
<h2><span class="header-section-number">5.3</span> Skew and kurtosis</h2>
<p>There are two more descriptive statistics that you will sometimes see reported in the psychological literature, known as skew and kurtosis. In practice, neither one is used anywhere near as frequently as the measures of central tendency and variability that we’ve been talking about. Skew is pretty important, so you do see it mentioned a fair bit; but I’ve actually never seen kurtosis reported in a scientific article to date.</p>
<pre><code>## [1] -0.9163279</code></pre>
<pre><code>## [1] 0.01079574</code></pre>
<div class="figure">
<img src="lsr_files/figure-html/skewness-1.png" alt="An illustration of skewness. On the left we have a negatively skewed data set (skewness $= -.93$), in the middle we have a data set with no skew (technically, skewness $= -.006$), and on the right we have a positively skewed data set (skewness $= .93$)." width="672" />
<p class="caption">
(#fig:skewness)An illustration of skewness. On the left we have a negatively skewed data set (skewness <span class="math inline">\(= -.93\)</span>), in the middle we have a data set with no skew (technically, skewness <span class="math inline">\(= -.006\)</span>), and on the right we have a positively skewed data set (skewness <span class="math inline">\(= .93\)</span>).
</p>
</div>
<pre><code>## [1] 0.9200568</code></pre>
<p>Since it’s the more interesting of the two, let’s start by talking about the <strong><em>skewness</em></strong>. Skewness is basically a measure of asymmetry, and the easiest way to explain it is by drawing some pictures. As Figure @ref(fig:skewness) illustrates, if the data tend to have a lot of extreme small values (i.e., the lower tail is “longer” than the upper tail) and not so many extremely large values (left panel), then we say that the data are <em>negatively skewed</em>. On the other hand, if there are more extremely large values than extremely small ones (right panel) we say that the data are <em>positively skewed</em>. That’s the qualitative idea behind skewness. The actual formula for the skewness of a data set is as follows
<span class="math display">\[
\mbox{skewness}(X) = \frac{1}{N \hat{\sigma}^3} \sum_{i=1}^N (X_i - \bar{X})^3
\]</span>
where <span class="math inline">\(N\)</span> is the number of observations, <span class="math inline">\(\bar{X}\)</span> is the sample mean, and <span class="math inline">\(\hat{\sigma}\)</span> is the standard deviation (the “divide by <span class="math inline">\(N-1\)</span>” version, that is). Perhaps more helpfully, it might be useful to point out that the <code>psych</code> package contains a <code>skew()</code> function that you can use to calculate skewness. So if we wanted to use this function to calculate the skewness of the <code>afl.margins</code> data, we’d first need to load the package</p>
<div class="sourceCode" id="cb398"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb398-1" title="1"><span class="kw">library</span>( psych )</a></code></pre></div>
<p>which now makes it possible to use the following command:</p>
<div class="sourceCode" id="cb399"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb399-1" title="1"><span class="kw">skew</span>( <span class="dt">x =</span> afl.margins )</a></code></pre></div>
<pre><code>## [1] 0.7671555</code></pre>
<p>Not surprisingly, it turns out that the AFL winning margins data is fairly skewed.</p>
<p>The final measure that is sometimes referred to, though very rarely in practice, is the <strong><em>kurtosis</em></strong> of a data set. Put simply, kurtosis is a measure of the “pointiness” of a data set, as illustrated in Figure @ref(fig:kurtosis).</p>
<pre><code>## [1] -0.9583355</code></pre>
<pre><code>## [1] -0.007391706</code></pre>
<div class="figure">
<img src="lsr_files/figure-html/kurtosis-1.png" alt="An illustration of kurtosis. On the left, we have a &quot;platykurtic&quot; data set (kurtosis = $-.95$), meaning that the data set is &quot;too flat&quot;. In the middle we have a &quot;mesokurtic&quot; data set (kurtosis is almost exactly 0), which means that the pointiness of the data is just about right. Finally, on the right, we have a &quot;leptokurtic&quot; data set (kurtosis $= 2.12$) indicating that the data set is &quot;too pointy&quot;. Note that kurtosis is measured with respect to a normal curve (black line)" width="672" />
<p class="caption">
(#fig:kurtosis)An illustration of kurtosis. On the left, we have a “platykurtic” data set (kurtosis = <span class="math inline">\(-.95\)</span>), meaning that the data set is “too flat”. In the middle we have a “mesokurtic” data set (kurtosis is almost exactly 0), which means that the pointiness of the data is just about right. Finally, on the right, we have a “leptokurtic” data set (kurtosis <span class="math inline">\(= 2.12\)</span>) indicating that the data set is “too pointy”. Note that kurtosis is measured with respect to a normal curve (black line)
</p>
</div>
<pre><code>## [1] 2.093175</code></pre>
<p>By convention, we say that the “normal curve” (black lines) has zero kurtosis, so the pointiness of a data set is assessed relative to this curve. In this Figure, the data on the left are not pointy enough, so the kurtosis is negative and we call the data <em>platykurtic</em>. The data on the right are too pointy, so the kurtosis is positive and we say that the data is <em>leptokurtic</em>. But the data in the middle are just pointy enough, so we say that it is <em>mesokurtic</em> and has kurtosis zero. This is summarised in the table below:</p>
<table>
<thead>
<tr class="header">
<th align="left">informal term</th>
<th align="left">technical name</th>
<th align="left">kurtosis value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">too flat</td>
<td align="left">platykurtic</td>
<td align="left">negative</td>
</tr>
<tr class="even">
<td align="left">just pointy enough</td>
<td align="left">mesokurtic</td>
<td align="left">zero</td>
</tr>
<tr class="odd">
<td align="left">too pointy</td>
<td align="left">leptokurtic</td>
<td align="left">positive</td>
</tr>
</tbody>
</table>
<p>The equation for kurtosis is pretty similar in spirit to the formulas we’ve seen already for the variance and the skewness; except that where the variance involved squared deviations and the skewness involved cubed deviations, the kurtosis involves raising the deviations to the fourth power:<a href="#fn76" class="footnote-ref" id="fnref76"><sup>76</sup></a>
<span class="math display">\[
\mbox{kurtosis}(X) = \frac{1}{N \hat\sigma^4} \sum_{i=1}^N \left( X_i - \bar{X} \right)^4  - 3
\]</span>
I know, it’s not terribly interesting to me either. More to the point, the <code>psych</code> package has a function called <code>kurtosi()</code> that you can use to calculate the kurtosis of your data. For instance, if we were to do this for the AFL margins,</p>
<div class="sourceCode" id="cb404"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb404-1" title="1"><span class="kw">kurtosi</span>( <span class="dt">x =</span> afl.margins )</a></code></pre></div>
<pre><code>## [1] 0.02962633</code></pre>
<p>we discover that the AFL winning margins data are just pointy enough.</p>
</div>
<div id="summary" class="section level2">
<h2><span class="header-section-number">5.4</span> Getting an overall summary of a variable</h2>
<p>Up to this point in the chapter I’ve explained several different summary statistics that are commonly used when analysing data, along with specific functions that you can use in R to calculate each one. However, it’s kind of annoying to have to separately calculate means, medians, standard deviations, skews etc. Wouldn’t it be nice if R had some helpful functions that would do all these tedious calculations at once? Something like <code>summary()</code> or <code>describe()</code>, perhaps? Why yes, yes it would. So much so that both of these functions exist. The <code>summary()</code> function is in the <code>base</code> package, so it comes with every installation of R. The <code>describe()</code> function is part of the <code>psych</code> package, which we loaded earlier in the chapter.</p>
<div id="summarising-a-variable" class="section level3">
<h3><span class="header-section-number">5.4.1</span> “Summarising” a variable</h3>
<p>The <code>summary()</code> function is an easy thing to use, but a tricky thing to understand in full, since it’s a generic function (see Section @ref(generics). The basic idea behind the <code>summary()</code> function is that it prints out some useful information about whatever object (i.e., variable, as far as we’re concerned) you specify as the <code>object</code> argument. As a consequence, the behaviour of the <code>summary()</code> function differs quite dramatically depending on the class of the object that you give it. Let’s start by giving it a <em>numeric</em> object:</p>
<div class="sourceCode" id="cb406"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb406-1" title="1"><span class="kw">summary</span>( <span class="dt">object =</span> afl.margins )  </a></code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    0.00   12.75   30.50   35.30   50.50  116.00</code></pre>
<p>For numeric variables, we get a whole bunch of useful descriptive statistics. It gives us the minimum and maximum values (i.e., the range), the first and third quartiles (25th and 75th percentiles; i.e., the IQR), the mean and the median. In other words, it gives us a pretty good collection of descriptive statistics related to the central tendency and the spread of the data.</p>
<p>Okay, what about if we feed it a logical vector instead? Let’s say I want to know something about how many “blowouts” there were in the 2010 AFL season. I operationalise the concept of a blowout (see Chapter @ref(studydesign)) as a game in which the winning margin exceeds 50 points. Let’s create a logical variable <code>blowouts</code> in which the <span class="math inline">\(i\)</span>-th element is <code>TRUE</code> if that game was a blowout according to my definition,</p>
<div class="sourceCode" id="cb408"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb408-1" title="1">blowouts &lt;-<span class="st">  </span>afl.margins <span class="op">&gt;</span><span class="st"> </span><span class="dv">50</span></a>
<a class="sourceLine" id="cb408-2" title="2">blowouts</a></code></pre></div>
<pre><code>##   [1]  TRUE FALSE  TRUE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE
##  [12]  TRUE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE
##  [23] FALSE FALSE FALSE FALSE FALSE  TRUE FALSE  TRUE  TRUE FALSE FALSE
##  [34]  TRUE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
##  [45] FALSE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE FALSE
##  [56]  TRUE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE
##  [67]  TRUE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE
##  [78] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
##  [89] FALSE FALSE  TRUE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE
## [100] FALSE  TRUE FALSE FALSE FALSE  TRUE FALSE  TRUE  TRUE  TRUE FALSE
## [111] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE
## [122]  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE FALSE
## [133] FALSE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE  TRUE
## [144]  TRUE  TRUE  TRUE FALSE FALSE FALSE  TRUE FALSE FALSE  TRUE FALSE
## [155]  TRUE FALSE  TRUE FALSE FALSE  TRUE FALSE FALSE  TRUE FALSE FALSE
## [166] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE</code></pre>
<p>So that’s what the <code>blowouts</code> variable looks like. Now let’s ask R for a <code>summary()</code></p>
<div class="sourceCode" id="cb410"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb410-1" title="1"><span class="kw">summary</span>( <span class="dt">object =</span> blowouts )</a></code></pre></div>
<pre><code>##    Mode   FALSE    TRUE 
## logical     132      44</code></pre>
<p>In this context, the <code>summary()</code> function gives us a count of the number of <code>TRUE</code> values, the number of <code>FALSE</code> values, and the number of missing values (i.e., the <code>NA</code>s). Pretty reasonable behaviour.</p>
<p>Next, let’s try to give it a factor. If you recall, I’ve defined the <code>afl.finalists</code> vector as a factor, so let’s use that:</p>
<div class="sourceCode" id="cb412"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb412-1" title="1"><span class="kw">summary</span>( <span class="dt">object =</span> afl.finalists )</a></code></pre></div>
<pre><code>##         Adelaide         Brisbane          Carlton      Collingwood 
##               26               25               26               28 
##         Essendon          Fitzroy        Fremantle          Geelong 
##               32                0                6               39 
##         Hawthorn        Melbourne  North Melbourne    Port Adelaide 
##               27               28               28               17 
##         Richmond         St Kilda           Sydney       West Coast 
##                6               24               26               38 
## Western Bulldogs 
##               24</code></pre>
<p>For factors, we get a frequency table, just like we got when we used the <code>table()</code> function. Interestingly, however, if we convert this to a character vector using the <code>as.character()</code> function (see Section @ref(coercion), we don’t get the same results:</p>
<div class="sourceCode" id="cb414"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb414-1" title="1">f2 &lt;-<span class="st"> </span><span class="kw">as.character</span>( afl.finalists )</a>
<a class="sourceLine" id="cb414-2" title="2"><span class="kw">summary</span>( <span class="dt">object =</span> f2 )</a></code></pre></div>
<pre><code>##    Length     Class      Mode 
##       400 character character</code></pre>
<p>This is one of those situations I was referring to in Section @ref(factors), in which it is helpful to declare your nominal scale variable as a factor rather than a character vector. Because I’ve defined <code>afl.finalists</code> as a factor, R <em>knows</em> that it should treat it as a nominal scale variable, and so it gives you a much more detailed (and helpful) summary than it would have if I’d left it as a character vector.</p>
</div>
<div id="summarising-a-data-frame" class="section level3">
<h3><span class="header-section-number">5.4.2</span> “Summarising” a data frame</h3>
<p>Okay what about data frames? When you pass a data frame to the <code>summary()</code> function, it produces a slightly condensed summary of each variable inside the data frame. To give you a sense of how this can be useful, let’s try this for a new data set, one that you’ve never seen before. The data is stored in the <code>clinicaltrial.Rdata</code> file, and we’ll use it a lot in Chapter @ref(anova) (you can find a complete description of the data at the start of that chapter). Let’s load it, and see what we’ve got:</p>
<div class="sourceCode" id="cb416"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb416-1" title="1"><span class="kw">load</span>( <span class="st">&quot;./data/clinicaltrial.Rdata&quot;</span> )</a>
<a class="sourceLine" id="cb416-2" title="2"><span class="kw">who</span>(<span class="ot">TRUE</span>)</a></code></pre></div>
<pre><code>##    -- Name --    -- Class --   -- Size --
##    clin.trial    data.frame    18 x 3    
##     $drug        factor        18        
##     $therapy     factor        18        
##     $mood.gain   numeric       18</code></pre>
<p>There’s a single data frame called <code>clin.trial</code> which contains three variables, <code>drug</code>, <code>therapy</code> and <code>mood.gain</code>. Presumably then, this data is from a clinical trial of some kind, in which people were administered different drugs; and the researchers looked to see what the drugs did to their mood. Let’s see if the <code>summary()</code> function sheds a little more light on this situation:</p>
<div class="sourceCode" id="cb418"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb418-1" title="1"><span class="kw">summary</span>( clin.trial )</a></code></pre></div>
<pre><code>##        drug         therapy    mood.gain     
##  placebo :6   no.therapy:9   Min.   :0.1000  
##  anxifree:6   CBT       :9   1st Qu.:0.4250  
##  joyzepam:6                  Median :0.8500  
##                              Mean   :0.8833  
##                              3rd Qu.:1.3000  
##                              Max.   :1.8000</code></pre>
<p>Evidently there were three drugs: a placebo, something called “anxifree” and something called “joyzepam”; and there were 6 people administered each drug. There were 9 people treated using cognitive behavioural therapy (CBT) and 9 people who received no psychological treatment. And we can see from looking at the summary of the <code>mood.gain</code> variable that most people did show a mood gain (mean <span class="math inline">\(=.88\)</span>), though without knowing what the scale is here it’s hard to say much more than that. Still, that’s not too bad. Overall, I feel that I learned something from that.</p>
</div>
<div id="describing-a-data-frame" class="section level3">
<h3><span class="header-section-number">5.4.3</span> “Describing” a data frame</h3>
<p>The <code>describe()</code> function (in the <code>psych</code> package) is a little different, and it’s really only intended to be useful when your data are interval or ratio scale. Unlike the <code>summary()</code> function, it calculates the same descriptive statistics for any type of variable you give it. By default, these are:</p>
<ul>
<li><code>var</code>. This is just an index: 1 for the first variable, 2 for the second variable, and so on.</li>
<li><code>n</code>. This is the sample size: more precisely, it’s the number of non-missing values.</li>
<li><code>mean</code>. This is the sample mean (Section @ref(mean)).</li>
<li><code>sd</code>. This is the (bias corrected) standard deviation (Section @ref(sd)).</li>
<li><code>median</code>. The median (Section @ref(median)).</li>
<li><code>trimmed</code>. This is trimmed mean. By default it’s the 10% trimmed mean (Section @ref(trimmedmean)).</li>
<li><code>mad</code>. The median absolute deviation (Section @ref(mad)).</li>
<li><code>min</code>. The minimum value.</li>
<li><code>max</code>. The maximum value.</li>
<li><code>range</code>. The range spanned by the data (Section @ref(range)).</li>
<li><code>skew</code>. The skewness (Section @ref(skewandkurtosis)).</li>
<li><code>kurtosis</code>. The kurtosis (Section @ref(skewandkurtosis)).</li>
<li><code>se</code>. The standard error of the mean (Chapter @ref(estimation)).</li>
</ul>
<p>Notice that these descriptive statistics generally only make sense for data that are interval or ratio scale (usually encoded as numeric vectors). For nominal or ordinal variables (usually encoded as factors), most of these descriptive statistics are not all that useful. What the <code>describe()</code> function does is convert factors and logical variables to numeric vectors in order to do the calculations. These variables are marked with <code>*</code> and most of the time, the descriptive statistics for those variables won’t make much sense. If you try to feed it a data frame that includes a character vector as a variable, it produces an error.</p>
<p>With those caveats in mind, let’s use the <code>describe()</code> function to have a look at the <code>clin.trial</code> data frame. Here’s what we get:</p>
<div class="sourceCode" id="cb420"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb420-1" title="1"><span class="kw">describe</span>( <span class="dt">x =</span> clin.trial )</a></code></pre></div>
<pre><code>##           vars  n mean   sd median trimmed  mad min max range skew
## drug*        1 18 2.00 0.84   2.00    2.00 1.48 1.0 3.0   2.0 0.00
## therapy*     2 18 1.50 0.51   1.50    1.50 0.74 1.0 2.0   1.0 0.00
## mood.gain    3 18 0.88 0.53   0.85    0.88 0.67 0.1 1.8   1.7 0.13
##           kurtosis   se
## drug*        -1.66 0.20
## therapy*     -2.11 0.12
## mood.gain    -1.44 0.13</code></pre>
<p>As you can see, the output for the asterisked variables is pretty meaningless, and should be ignored. However, for the <code>mood.gain</code> variable, there’s a lot of useful information.</p>
</div>
</div>
<div id="groupdescriptives" class="section level2">
<h2><span class="header-section-number">5.5</span> Descriptive statistics separately for each group</h2>
<p>It is very commonly the case that you find yourself needing to look at descriptive statistics, broken down by some grouping variable. This is pretty easy to do in R, and there are three functions in particular that are worth knowing about: <code>by()</code>, <code>describeBy()</code> and <code>aggregate()</code>. Let’s start with the <code>describeBy()</code> function, which is part of the <code>psych</code> package. The <code>describeBy()</code> function is very similar to the <code>describe()</code> function, except that it has an additional argument called <code>group</code> which specifies a grouping variable. For instance, let’s say, I want to look at the descriptive statistics for the <code>clin.trial</code> data, broken down separately by <code>therapy</code> type. The command I would use here is:</p>
<div class="sourceCode" id="cb422"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb422-1" title="1"><span class="kw">describeBy</span>( <span class="dt">x=</span>clin.trial, <span class="dt">group=</span>clin.trial<span class="op">$</span>therapy )</a></code></pre></div>
<pre><code>## 
##  Descriptive statistics by group 
## group: no.therapy
##           vars n mean   sd median trimmed  mad min max range skew kurtosis
## drug*        1 9 2.00 0.87    2.0    2.00 1.48 1.0 3.0   2.0 0.00    -1.81
## therapy*     2 9 1.00 0.00    1.0    1.00 0.00 1.0 1.0   0.0  NaN      NaN
## mood.gain    3 9 0.72 0.59    0.5    0.72 0.44 0.1 1.7   1.6 0.51    -1.59
##             se
## drug*     0.29
## therapy*  0.00
## mood.gain 0.20
## -------------------------------------------------------- 
## group: CBT
##           vars n mean   sd median trimmed  mad min max range  skew
## drug*        1 9 2.00 0.87    2.0    2.00 1.48 1.0 3.0   2.0  0.00
## therapy*     2 9 2.00 0.00    2.0    2.00 0.00 2.0 2.0   0.0   NaN
## mood.gain    3 9 1.04 0.45    1.1    1.04 0.44 0.3 1.8   1.5 -0.03
##           kurtosis   se
## drug*        -1.81 0.29
## therapy*       NaN 0.00
## mood.gain    -1.12 0.15</code></pre>
<p>As you can see, the output is essentially identical to the output that the <code>describe()</code> function produce, except that the output now gives you means, standard deviations etc separately for the <code>CBT</code> group and the <code>no.therapy</code> group. Notice that, as before, the output displays asterisks for factor variables, in order to draw your attention to the fact that the descriptive statistics that it has calculated won’t be very meaningful for those variables. Nevertheless, this command has given us some really useful descriptive statistics <code>mood.gain</code> variable, broken down as a function of <code>therapy</code>.</p>
<p>A somewhat more general solution is offered by the <code>by()</code> function. There are three arguments that you need to specify when using this function: the <code>data</code> argument specifies the data set, the <code>INDICES</code> argument specifies the grouping variable, and the <code>FUN</code> argument specifies the name of a function that you want to apply separately to each group. To give a sense of how powerful this is, you can reproduce the <code>describeBy()</code> function by using a command like this:</p>
<div class="sourceCode" id="cb424"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb424-1" title="1"><span class="kw">by</span>( <span class="dt">data=</span>clin.trial, <span class="dt">INDICES=</span>clin.trial<span class="op">$</span>therapy, <span class="dt">FUN=</span>describe )</a></code></pre></div>
<pre><code>## clin.trial$therapy: no.therapy
##           vars n mean   sd median trimmed  mad min max range skew kurtosis
## drug*        1 9 2.00 0.87    2.0    2.00 1.48 1.0 3.0   2.0 0.00    -1.81
## therapy*     2 9 1.00 0.00    1.0    1.00 0.00 1.0 1.0   0.0  NaN      NaN
## mood.gain    3 9 0.72 0.59    0.5    0.72 0.44 0.1 1.7   1.6 0.51    -1.59
##             se
## drug*     0.29
## therapy*  0.00
## mood.gain 0.20
## -------------------------------------------------------- 
## clin.trial$therapy: CBT
##           vars n mean   sd median trimmed  mad min max range  skew
## drug*        1 9 2.00 0.87    2.0    2.00 1.48 1.0 3.0   2.0  0.00
## therapy*     2 9 2.00 0.00    2.0    2.00 0.00 2.0 2.0   0.0   NaN
## mood.gain    3 9 1.04 0.45    1.1    1.04 0.44 0.3 1.8   1.5 -0.03
##           kurtosis   se
## drug*        -1.81 0.29
## therapy*       NaN 0.00
## mood.gain    -1.12 0.15</code></pre>
<p>This will produce the exact same output as the command shown earlier. However, there’s nothing special about the <code>describe()</code> function. You could just as easily use the <code>by()</code> function in conjunction with the <code>summary()</code> function. For example:</p>
<div class="sourceCode" id="cb426"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb426-1" title="1"><span class="kw">by</span>( <span class="dt">data=</span>clin.trial, <span class="dt">INDICES=</span>clin.trial<span class="op">$</span>therapy, <span class="dt">FUN=</span>summary )</a></code></pre></div>
<pre><code>## clin.trial$therapy: no.therapy
##        drug         therapy    mood.gain     
##  placebo :3   no.therapy:9   Min.   :0.1000  
##  anxifree:3   CBT       :0   1st Qu.:0.3000  
##  joyzepam:3                  Median :0.5000  
##                              Mean   :0.7222  
##                              3rd Qu.:1.3000  
##                              Max.   :1.7000  
## -------------------------------------------------------- 
## clin.trial$therapy: CBT
##        drug         therapy    mood.gain    
##  placebo :3   no.therapy:0   Min.   :0.300  
##  anxifree:3   CBT       :9   1st Qu.:0.800  
##  joyzepam:3                  Median :1.100  
##                              Mean   :1.044  
##                              3rd Qu.:1.300  
##                              Max.   :1.800</code></pre>
<p>Again, this output is pretty easy to interpret. It’s the output of the <code>summary()</code> function, applied separately to <code>CBT</code> group and the <code>no.therapy</code> group. For the two factors (<code>drug</code> and <code>therapy</code>) it prints out a frequency table, whereas for the numeric variable (<code>mood.gain</code>) it prints out the range, interquartile range, mean and median.</p>
<p>What if you have multiple grouping variables? Suppose, for example, you would like to look at the average mood gain separately for all possible combinations of drug and therapy. It is actually possible to do this using the <code>by()</code> and <code>describeBy()</code> functions, but I usually find it more convenient to use the <code>aggregate()</code> function in this situation. There are again three arguments that you need to specify. The <code>formula</code> argument is used to indicate which variable you want to analyse, and which variables are used to specify the groups. For instance, if you want to look at <code>mood.gain</code> separately for each possible combination of <code>drug</code> and <code>therapy</code>, the formula you want is <code>mood.gain ~ drug + therapy</code>. The <code>data</code> argument is used to specify the data frame containing all the data, and the <code>FUN</code> argument is used to indicate what function you want to calculate for each group (e.g., the <code>mean</code>). So, to obtain group means, use this command:</p>
<div class="sourceCode" id="cb428"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb428-1" title="1"> <span class="kw">aggregate</span>( <span class="dt">formula =</span> mood.gain <span class="op">~</span><span class="st"> </span>drug <span class="op">+</span><span class="st"> </span>therapy,  <span class="co"># mood.gain by drug/therapy combination</span></a>
<a class="sourceLine" id="cb428-2" title="2">            <span class="dt">data =</span> clin.trial,                     <span class="co"># data is in the clin.trial data frame</span></a>
<a class="sourceLine" id="cb428-3" title="3">            <span class="dt">FUN =</span> mean                             <span class="co"># print out group means</span></a>
<a class="sourceLine" id="cb428-4" title="4"> )</a></code></pre></div>
<pre><code>##       drug    therapy mood.gain
## 1  placebo no.therapy  0.300000
## 2 anxifree no.therapy  0.400000
## 3 joyzepam no.therapy  1.466667
## 4  placebo        CBT  0.600000
## 5 anxifree        CBT  1.033333
## 6 joyzepam        CBT  1.500000</code></pre>
<p>or, alternatively, if you want to calculate the standard deviations for each group, you would use the following command (argument names omitted this time):</p>
<div class="sourceCode" id="cb430"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb430-1" title="1"><span class="kw">aggregate</span>( mood.gain <span class="op">~</span><span class="st"> </span>drug <span class="op">+</span><span class="st"> </span>therapy, clin.trial, sd )</a></code></pre></div>
<pre><code>##       drug    therapy mood.gain
## 1  placebo no.therapy 0.2000000
## 2 anxifree no.therapy 0.2000000
## 3 joyzepam no.therapy 0.2081666
## 4  placebo        CBT 0.3000000
## 5 anxifree        CBT 0.2081666
## 6 joyzepam        CBT 0.2645751</code></pre>
</div>
<div id="zscore" class="section level2">
<h2><span class="header-section-number">5.6</span> Standard scores</h2>
<p>Suppose my friend is putting together a new questionnaire intended to measure “grumpiness”. The survey has 50 questions, which you can answer in a grumpy way or not. Across a big sample (hypothetically, let’s imagine a million people or so!) the data are fairly normally distributed, with the mean grumpiness score being 17 out of 50 questions answered in a grumpy way, and the standard deviation is 5. In contrast, when I take the questionnaire, I answer 35 out of 50 questions in a grumpy way. So, how grumpy am I? One way to think about would be to say that I have grumpiness of 35/50, so you might say that I’m 70% grumpy. But that’s a bit weird, when you think about it. If my friend had phrased her questions a bit differently, people might have answered them in a different way, so the overall distribution of answers could easily move up or down depending on the precise way in which the questions were asked. So, I’m only 70% grumpy <em>with respect to this set of survey questions</em>. Even if it’s a very good questionnaire, this isn’t very a informative statement.</p>
<p>A simpler way around this is to describe my grumpiness by comparing me to other people. Shockingly, out of my friend’s sample of 1,000,000 people, only 159 people were as grumpy as me (that’s not at all unrealistic, frankly), suggesting that I’m in the top 0.016% of people for grumpiness. This makes much more sense than trying to interpret the raw data. This idea – that we should describe my grumpiness in terms of the overall distribution of the grumpiness of humans – is the qualitative idea that standardisation attempts to get at. One way to do this is to do exactly what I just did, and describe everything in terms of percentiles. However, the problem with doing this is that “it’s lonely at the top”. Suppose that my friend had only collected a sample of 1000 people (still a pretty big sample for the purposes of testing a new questionnaire, I’d like to add), and this time gotten a mean of 16 out of 50 with a standard deviation of 5, let’s say. The problem is that almost certainly, not a single person in that sample would be as grumpy as me.</p>
<p>However, all is not lost. A different approach is to convert my grumpiness score into a <strong><em>standard score</em></strong>, also referred to as a <span class="math inline">\(z\)</span>-score. The standard score is defined as the number of standard deviations above the mean that my grumpiness score lies. To phrase it in “pseudo-maths” the standard score is calculated like this:
<span class="math display">\[
\mbox{standard score} = \frac{\mbox{raw score} - \mbox{mean}}{\mbox{standard deviation}}
\]</span>
In actual maths, the equation for the <span class="math inline">\(z\)</span>-score is
<span class="math display">\[
z_i = \frac{X_i - \bar{X}}{\hat\sigma}
\]</span>
So, going back to the grumpiness data, we can now transform Dan’s raw grumpiness into a standardised grumpiness score.<a href="#fn77" class="footnote-ref" id="fnref77"><sup>77</sup></a> If the mean is 17 and the standard deviation is 5 then my standardised grumpiness score would be<a href="#fn78" class="footnote-ref" id="fnref78"><sup>78</sup></a>
<span class="math display">\[
z = \frac{35 - 17}{5} = 3.6
\]</span>
To interpret this value, recall the rough heuristic that I provided in Section @ref(sd), in which I noted that 99.7% of values are expected to lie within 3 standard deviations of the mean. So the fact that my grumpiness corresponds to a <span class="math inline">\(z\)</span> score of 3.6 indicates that I’m very grumpy indeed. Later on, in Section @ref(normal), I’ll introduce a function called <code>pnorm()</code> that allows us to be a bit more precise than this. Specifically, it allows us to calculate a theoretical percentile rank for my grumpiness, as follows:</p>
<div class="sourceCode" id="cb432"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb432-1" title="1"><span class="kw">pnorm</span>( <span class="fl">3.6</span> )</a></code></pre></div>
<pre><code>## [1] 0.9998409</code></pre>
<p>At this stage, this command doesn’t make too much sense, but don’t worry too much about it. It’s not important for now. But the output is fairly straightforward: it suggests that I’m grumpier than 99.98% of people. Sounds about right.</p>
<p>In addition to allowing you to interpret a raw score in relation to a larger population (and thereby allowing you to make sense of variables that lie on arbitrary scales), standard scores serve a second useful function. Standard scores can be compared to one another in situations where the raw scores can’t. Suppose, for instance, my friend also had another questionnaire that measured extraversion using a 24 items questionnaire. The overall mean for this measure turns out to be 13 with standard deviation 4; and I scored a 2. As you can imagine, it doesn’t make a lot of sense to try to compare my raw score of 2 on the extraversion questionnaire to my raw score of 35 on the grumpiness questionnaire. The raw scores for the two variables are “about” fundamentally different things, so this would be like comparing apples to oranges.</p>
<p>What about the standard scores? Well, this is a little different. If we calculate the standard scores, we get <span class="math inline">\(z = (35-17)/5 = 3.6\)</span> for grumpiness and <span class="math inline">\(z = (2-13)/4 = -2.75\)</span> for extraversion. These two numbers <em>can</em> be compared to each other.<a href="#fn79" class="footnote-ref" id="fnref79"><sup>79</sup></a> I’m much less extraverted than most people (<span class="math inline">\(z = -2.75\)</span>) and much grumpier than most people (<span class="math inline">\(z = 3.6\)</span>): but the extent of my unusualness is much more extreme for grumpiness (since 3.6 is a bigger number than 2.75). Because each standardised score is a statement about where an observation falls <em>relative to its own population</em>, it <em>is</em> possible to compare standardised scores across completely different variables.</p>
</div>
<div id="correl" class="section level2">
<h2><span class="header-section-number">5.7</span> Correlations</h2>
<p>Up to this point we have focused entirely on how to construct descriptive statistics for a single variable. What we haven’t done is talked about how to describe the relationships <em>between</em> variables in the data. To do that, we want to talk mostly about the <strong><em>correlation</em></strong> between variables. But first, we need some data.</p>
<div id="the-data" class="section level3">
<h3><span class="header-section-number">5.7.1</span> The data</h3>
<p>After spending so much time looking at the AFL data, I’m starting to get bored with sports. Instead, let’s turn to a topic close to every parent’s heart: sleep. The following data set is fictitious, but based on real events. Suppose I’m curious to find out how much my infant son’s sleeping habits affect my mood. Let’s say that I can rate my grumpiness very precisely, on a scale from 0 (not at all grumpy) to 100 (grumpy as a very, very grumpy old man). And, lets also assume that I’ve been measuring my grumpiness, my sleeping patterns and my son’s sleeping patterns for quite some time now. Let’s say, for 100 days. And, being a nerd, I’ve saved the data as a file called <code>parenthood.Rdata</code>. If we load the data…</p>
<div class="sourceCode" id="cb434"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb434-1" title="1"><span class="kw">load</span>( <span class="st">&quot;./data/parenthood.Rdata&quot;</span> )</a>
<a class="sourceLine" id="cb434-2" title="2"><span class="kw">who</span>(<span class="ot">TRUE</span>)</a></code></pre></div>
<pre><code>##    -- Name --     -- Class --   -- Size --
##    parenthood     data.frame    100 x 4   
##     $dan.sleep    numeric       100       
##     $baby.sleep   numeric       100       
##     $dan.grump    numeric       100       
##     $day          integer       100</code></pre>
<p>… we see that the file contains a single data frame called <code>parenthood</code>, which contains four variables <code>dan.sleep</code>, <code>baby.sleep</code>, <code>dan.grump</code> and <code>day</code>. If we peek at the data using <code>head()</code> out the data, here’s what we get:</p>
<div class="sourceCode" id="cb436"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb436-1" title="1"><span class="kw">head</span>(parenthood,<span class="dv">10</span>)</a></code></pre></div>
<pre><code>##    dan.sleep baby.sleep dan.grump day
## 1       7.59      10.18        56   1
## 2       7.91      11.66        60   2
## 3       5.14       7.92        82   3
## 4       7.71       9.61        55   4
## 5       6.68       9.75        67   5
## 6       5.99       5.04        72   6
## 7       8.19      10.45        53   7
## 8       7.19       8.27        60   8
## 9       7.40       6.06        60   9
## 10      6.58       7.09        71  10</code></pre>
<p>Next, I’ll calculate some basic descriptive statistics:</p>
<div class="sourceCode" id="cb438"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb438-1" title="1"><span class="kw">describe</span>( parenthood )</a></code></pre></div>
<pre><code>##            vars   n  mean    sd median trimmed   mad   min    max range
## dan.sleep     1 100  6.97  1.02   7.03    7.00  1.09  4.84   9.00  4.16
## baby.sleep    2 100  8.05  2.07   7.95    8.05  2.33  3.25  12.07  8.82
## dan.grump     3 100 63.71 10.05  62.00   63.16  9.64 41.00  91.00 50.00
## day           4 100 50.50 29.01  50.50   50.50 37.06  1.00 100.00 99.00
##             skew kurtosis   se
## dan.sleep  -0.29    -0.72 0.10
## baby.sleep -0.02    -0.69 0.21
## dan.grump   0.43    -0.16 1.00
## day         0.00    -1.24 2.90</code></pre>
<p>Finally, to give a graphical depiction of what each of the three interesting variables looks like, Figure @ref(fig:parenthood) plots histograms.</p>
<div class="figure">
<img src="lsr_files/figure-html/parenthood-1.png" alt="Histograms for the three interesting variables in the `parenthood` data set" width="672" />
<p class="caption">
(#fig:parenthood)Histograms for the three interesting variables in the <code>parenthood</code> data set
</p>
</div>
<p>One thing to note: just because R can calculate dozens of different statistics doesn’t mean you should report all of them. If I were writing this up for a report, I’d probably pick out those statistics that are of most interest to me (and to my readership), and then put them into a nice, simple table like the one in Table @ref(tab:parenthood).<a href="#fn80" class="footnote-ref" id="fnref80"><sup>80</sup></a> Notice that when I put it into a table, I gave everything “human readable” names. This is always good practice. Notice also that I’m not getting enough sleep. This isn’t good practice, but other parents tell me that it’s standard practice.</p>
<table>
<caption>(#tab:parenthoodtab)Descriptive statistics for the parenthood data.</caption>
<thead>
<tr class="header">
<th align="left">variable</th>
<th align="left">min</th>
<th align="left">max</th>
<th align="left">mean</th>
<th align="left">median</th>
<th align="left">std. dev</th>
<th align="left">IQR</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Dan’s grumpiness</td>
<td align="left">41</td>
<td align="left">91</td>
<td align="left">63.71</td>
<td align="left">62</td>
<td align="left">10.05</td>
<td align="left">14</td>
</tr>
<tr class="even">
<td align="left">Dan’s hours slept</td>
<td align="left">4.84</td>
<td align="left">9</td>
<td align="left">6.97</td>
<td align="left">7.03</td>
<td align="left">1.02</td>
<td align="left">1.45</td>
</tr>
<tr class="odd">
<td align="left">Dan’s son’s hours slept</td>
<td align="left">3.25</td>
<td align="left">12.07</td>
<td align="left">8.05</td>
<td align="left">7.95</td>
<td align="left">2.07</td>
<td align="left">3.21</td>
</tr>
</tbody>
</table>
</div>
<div id="the-strength-and-direction-of-a-relationship" class="section level3">
<h3><span class="header-section-number">5.7.2</span> The strength and direction of a relationship</h3>
<div class="figure">
<img src="lsr_files/figure-html/scatterparent1a-1.png" alt="Scatterplot showing the relationship between `dan.sleep` and `dan.grump`" width="672" />
<p class="caption">
(#fig:scatterparent1a)Scatterplot showing the relationship between <code>dan.sleep</code> and <code>dan.grump</code>
</p>
</div>
<div class="figure">
<img src="lsr_files/figure-html/scatterparent1b-1.png" alt="Scatterplot showing the relationship between `baby.sleep` and `dan.grump`" width="672" />
<p class="caption">
(#fig:scatterparent1b)Scatterplot showing the relationship between <code>baby.sleep</code> and <code>dan.grump</code>
</p>
</div>
<p>We can draw scatterplots to give us a general sense of how closely related two variables are. Ideally though, we might want to say a bit more about it than that. For instance, let’s compare the relationship between <code>dan.sleep</code> and <code>dan.grump</code> (Figure @ref(fig:scatterparent1a) with that between <code>baby.sleep</code> and <code>dan.grump</code> (Figure @ref(fig:scatterparent1b). When looking at these two plots side by side, it’s clear that the relationship is <em>qualitatively</em> the same in both cases: more sleep equals less grump! However, it’s also pretty obvious that the relationship between <code>dan.sleep</code> and <code>dan.grump</code> is <em>stronger</em> than the relationship between <code>baby.sleep</code> and <code>dan.grump</code>. The plot on the left is “neater” than the one on the right. What it feels like is that if you want to predict what my mood is, it’d help you a little bit to know how many hours my son slept, but it’d be <em>more</em> helpful to know how many hours I slept.</p>
<p>In contrast, let’s consider Figure @ref(fig:scatterparent1b) vs. Figure @ref(fig:scatterparent2). If we compare the scatterplot of “<code>baby.sleep</code> v <code>dan.grump</code>” to the scatterplot of “`<code>baby.sleep</code> v <code>dan.sleep</code>”, the overall strength of the relationship is the same, but the direction is different. That is, if my son sleeps more, I get <em>more</em> sleep (positive relationship, but if he sleeps more then I get <em>less</em> grumpy (negative relationship).</p>
<div class="figure">
<img src="lsr_files/figure-html/scatterparent2-1.png" alt="Scatterplot showing the relationship between `baby.sleep` and `dan.sleep`" width="672" />
<p class="caption">
(#fig:scatterparent2)Scatterplot showing the relationship between <code>baby.sleep</code> and <code>dan.sleep</code>
</p>
</div>
</div>
<div id="the-correlation-coefficient" class="section level3">
<h3><span class="header-section-number">5.7.3</span> The correlation coefficient</h3>
<p>We can make these ideas a bit more explicit by introducing the idea of a <strong><em>correlation coefficient</em></strong> (or, more specifically, Pearson’s correlation coefficient), which is traditionally denoted by <span class="math inline">\(r\)</span>. The correlation coefficient between two variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> (sometimes denoted <span class="math inline">\(r_{XY}\)</span>), which we’ll define more precisely in the next section, is a measure that varies from <span class="math inline">\(-1\)</span> to <span class="math inline">\(1\)</span>. When <span class="math inline">\(r = -1\)</span> it means that we have a perfect negative relationship, and when <span class="math inline">\(r = 1\)</span> it means we have a perfect positive relationship. When <span class="math inline">\(r = 0\)</span>, there’s no relationship at all. If you look at Figure @ref(fig:corr), you can see several plots showing what different correlations look like.</p>
<div class="figure">
<img src="lsr_files/figure-html/corr-1.png" alt="Illustration of the effect of varying the strength and direction of a correlation" width="672" />
<p class="caption">
(#fig:corr)Illustration of the effect of varying the strength and direction of a correlation
</p>
</div>
<p>The formula for the Pearson’s correlation coefficient can be written in several different ways. I think the simplest way to write down the formula is to break it into two steps. Firstly, let’s introduce the idea of a <strong><em>covariance</em></strong>. The covariance between two variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is a generalisation of the notion of the variance; it’s a mathematically simple way of describing the relationship between two variables that isn’t terribly informative to humans:
<span class="math display">\[
\mbox{Cov}(X,Y) = \frac{1}{N-1} \sum_{i=1}^N \left( X_i - \bar{X} \right) \left( Y_i - \bar{Y} \right)
\]</span>
Because we’re multiplying (i.e., taking the “product” of) a quantity that depends on <span class="math inline">\(X\)</span> by a quantity that depends on <span class="math inline">\(Y\)</span> and then averaging<a href="#fn81" class="footnote-ref" id="fnref81"><sup>81</sup></a>, you can think of the formula for the covariance as an “average cross product” between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. The covariance has the nice property that, if <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are entirely unrelated, then the covariance is exactly zero. If the relationship between them is positive (in the sense shown in <a href="mailto:Figure@reffig" class="email">Figure@reffig</a>:corr) then the covariance is also positive; and if the relationship is negative then the covariance is also negative. In other words, the covariance captures the basic qualitative idea of correlation. Unfortunately, the raw magnitude of the covariance isn’t easy to interpret: it depends on the units in which <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are expressed, and worse yet, the actual units that the covariance itself is expressed in are really weird. For instance, if <span class="math inline">\(X\)</span> refers to the <code>dan.sleep</code> variable (units: hours) and <span class="math inline">\(Y\)</span> refers to the <code>dan.grump</code> variable (units: grumps), then the units for their covariance are “hours <span class="math inline">\(\times\)</span> grumps”. And I have no freaking idea what that would even mean.</p>
<p>The Pearson correlation coefficient <span class="math inline">\(r\)</span> fixes this interpretation problem by standardising the covariance, in pretty much the exact same way that the <span class="math inline">\(z\)</span>-score standardises a raw score: by dividing by the standard deviation. However, because we have two variables that contribute to the covariance, the standardisation only works if we divide by both standard deviations.<a href="#fn82" class="footnote-ref" id="fnref82"><sup>82</sup></a> In other words, the correlation between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> can be written as follows:
<span class="math display">\[
r_{XY}  = \frac{\mbox{Cov}(X,Y)}{ \hat{\sigma}_X \ \hat{\sigma}_Y}
\]</span>
By doing this standardisation, not only do we keep all of the nice properties of the covariance discussed earlier, but the actual values of <span class="math inline">\(r\)</span> are on a meaningful scale: <span class="math inline">\(r= 1\)</span> implies a perfect positive relationship, and <span class="math inline">\(r = -1\)</span> implies a perfect negative relationship. I’ll expand a little more on this point later, in <a href="mailto:Section@refsec" class="email">Section@refsec</a>:interpretingcorrelations. But before I do, let’s look at how to calculate correlations in R.</p>
</div>
<div id="calculating-correlations-in-r" class="section level3">
<h3><span class="header-section-number">5.7.4</span> Calculating correlations in R</h3>
<p>Calculating correlations in R can be done using the <code>cor()</code> command. The simplest way to use the command is to specify two input arguments <code>x</code> and <code>y</code>, each one corresponding to one of the variables. The following extract illustrates the basic usage of the function:<a href="#fn83" class="footnote-ref" id="fnref83"><sup>83</sup></a></p>
<div class="sourceCode" id="cb440"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb440-1" title="1"><span class="kw">cor</span>( <span class="dt">x =</span> parenthood<span class="op">$</span>dan.sleep, <span class="dt">y =</span> parenthood<span class="op">$</span>dan.grump )</a></code></pre></div>
<pre><code>## [1] -0.903384</code></pre>
<p>However, the <code>cor()</code> function is a bit more powerful than this simple example suggests. For example, you can also calculate a complete “correlation matrix”, between all pairs of variables in the data frame:<a href="#fn84" class="footnote-ref" id="fnref84"><sup>84</sup></a></p>
<div class="sourceCode" id="cb442"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb442-1" title="1"><span class="co"># correlate all pairs of variables in &quot;parenthood&quot;:</span></a>
<a class="sourceLine" id="cb442-2" title="2"><span class="kw">cor</span>( <span class="dt">x =</span> parenthood )  </a></code></pre></div>
<pre><code>##              dan.sleep  baby.sleep   dan.grump         day
## dan.sleep   1.00000000  0.62794934 -0.90338404 -0.09840768
## baby.sleep  0.62794934  1.00000000 -0.56596373 -0.01043394
## dan.grump  -0.90338404 -0.56596373  1.00000000  0.07647926
## day        -0.09840768 -0.01043394  0.07647926  1.00000000</code></pre>
</div>
<div id="interpretingcorrelations" class="section level3">
<h3><span class="header-section-number">5.7.5</span> Interpreting a correlation</h3>
<p>Naturally, in real life you don’t see many correlations of 1. So how should you interpret a correlation of, say <span class="math inline">\(r= .4\)</span>? The honest answer is that it really depends on what you want to use the data for, and on how strong the correlations in your field tend to be. A friend of mine in engineering once argued that any correlation less than <span class="math inline">\(.95\)</span> is completely useless (I think he was exaggerating, even for engineering). On the other hand there are real cases – even in psychology – where you should really expect correlations that strong. For instance, one of the benchmark data sets used to test theories of how people judge similarities is so clean that any theory that can’t achieve a correlation of at least <span class="math inline">\(.9\)</span> really isn’t deemed to be successful. However, when looking for (say) elementary correlates of intelligence (e.g., inspection time, response time), if you get a correlation above <span class="math inline">\(.3\)</span> you’re doing very very well. In short, the interpretation of a correlation depends a lot on the context. That said, the rough guide in Table @ref(tab:interpretingcorrelations) is pretty typical.</p>
<div class="sourceCode" id="cb444"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb444-1" title="1">knitr<span class="op">::</span><span class="kw">kable</span>(</a>
<a class="sourceLine" id="cb444-2" title="2"><span class="kw">rbind</span>(</a>
<a class="sourceLine" id="cb444-3" title="3"><span class="kw">c</span>(<span class="st">&quot;-1.0 to -0.9&quot;</span> ,<span class="st">&quot;Very strong&quot;</span>, <span class="st">&quot;Negative&quot;</span>),</a>
<a class="sourceLine" id="cb444-4" title="4"><span class="kw">c</span>(<span class="st">&quot;-0.9 to -0.7&quot;</span>, <span class="st">&quot;Strong&quot;</span>, <span class="st">&quot;Negative&quot;</span>) ,</a>
<a class="sourceLine" id="cb444-5" title="5"><span class="kw">c</span>(<span class="st">&quot;-0.7 to -0.4&quot;</span>, <span class="st">&quot;Moderate&quot;</span>, <span class="st">&quot;Negative&quot;</span>) ,</a>
<a class="sourceLine" id="cb444-6" title="6"><span class="kw">c</span>(<span class="st">&quot;-0.4 to -0.2&quot;</span>, <span class="st">&quot;Weak&quot;</span>, <span class="st">&quot;Negative&quot;</span>),</a>
<a class="sourceLine" id="cb444-7" title="7"><span class="kw">c</span>(<span class="st">&quot;-0.2 to 0&quot;</span>,<span class="st">&quot;Negligible&quot;</span>, <span class="st">&quot;Negative&quot;</span>) ,</a>
<a class="sourceLine" id="cb444-8" title="8"><span class="kw">c</span>(<span class="st">&quot;0 to 0.2&quot;</span>,<span class="st">&quot;Negligible&quot;</span>, <span class="st">&quot;Positive&quot;</span>),</a>
<a class="sourceLine" id="cb444-9" title="9"><span class="kw">c</span>(<span class="st">&quot;0.2 to 0.4&quot;</span>, <span class="st">&quot;Weak&quot;</span>, <span class="st">&quot;Positive&quot;</span>), </a>
<a class="sourceLine" id="cb444-10" title="10"><span class="kw">c</span>(<span class="st">&quot;0.4 to 0.7&quot;</span>, <span class="st">&quot;Moderate&quot;</span>, <span class="st">&quot;Positive&quot;</span>), </a>
<a class="sourceLine" id="cb444-11" title="11"><span class="kw">c</span>(<span class="st">&quot;0.7 to 0.9&quot;</span>, <span class="st">&quot;Strong&quot;</span>, <span class="st">&quot;Positive&quot;</span>), </a>
<a class="sourceLine" id="cb444-12" title="12"><span class="kw">c</span>(<span class="st">&quot;0.9 to 1.0&quot;</span>, <span class="st">&quot;Very strong&quot;</span>, <span class="st">&quot;Positive&quot;</span>)), <span class="dt">col.names=</span><span class="kw">c</span>(<span class="st">&quot;Correlation&quot;</span>, <span class="st">&quot;Strength&quot;</span>, <span class="st">&quot;Direction&quot;</span>),</a>
<a class="sourceLine" id="cb444-13" title="13">  <span class="dt">booktabs =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">Correlation</th>
<th align="left">Strength</th>
<th align="left">Direction</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">-1.0 to -0.9</td>
<td align="left">Very strong</td>
<td align="left">Negative</td>
</tr>
<tr class="even">
<td align="left">-0.9 to -0.7</td>
<td align="left">Strong</td>
<td align="left">Negative</td>
</tr>
<tr class="odd">
<td align="left">-0.7 to -0.4</td>
<td align="left">Moderate</td>
<td align="left">Negative</td>
</tr>
<tr class="even">
<td align="left">-0.4 to -0.2</td>
<td align="left">Weak</td>
<td align="left">Negative</td>
</tr>
<tr class="odd">
<td align="left">-0.2 to 0</td>
<td align="left">Negligible</td>
<td align="left">Negative</td>
</tr>
<tr class="even">
<td align="left">0 to 0.2</td>
<td align="left">Negligible</td>
<td align="left">Positive</td>
</tr>
<tr class="odd">
<td align="left">0.2 to 0.4</td>
<td align="left">Weak</td>
<td align="left">Positive</td>
</tr>
<tr class="even">
<td align="left">0.4 to 0.7</td>
<td align="left">Moderate</td>
<td align="left">Positive</td>
</tr>
<tr class="odd">
<td align="left">0.7 to 0.9</td>
<td align="left">Strong</td>
<td align="left">Positive</td>
</tr>
<tr class="even">
<td align="left">0.9 to 1.0</td>
<td align="left">Very strong</td>
<td align="left">Positive</td>
</tr>
</tbody>
</table>
<p>However, something that can never be stressed enough is that you should <em>always</em> look at the scatterplot before attaching any interpretation to the data. A correlation might not mean what you think it means. The classic illustration of this is “Anscombe’s Quartet” <span class="citation">(<span class="citeproc-not-found" data-reference-id="ref"><strong>???</strong></span>)</span>, which is a collection of four data sets. Each data set has two variables, an <span class="math inline">\(X\)</span> and a <span class="math inline">\(Y\)</span>. For all four data sets the mean value for <span class="math inline">\(X\)</span> is 9 and the mean for <span class="math inline">\(Y\)</span> is 7.5. The, standard deviations for all <span class="math inline">\(X\)</span> variables are almost identical, as are those for the the <span class="math inline">\(Y\)</span> variables. And in each case the correlation between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is <span class="math inline">\(r = 0.816\)</span>. You can verify this yourself, since the dataset comes distributed with R. The commands would be:</p>
<div class="sourceCode" id="cb445"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb445-1" title="1"><span class="kw">cor</span>( anscombe<span class="op">$</span>x1, anscombe<span class="op">$</span>y1 )</a></code></pre></div>
<pre><code>## [1] 0.8164205</code></pre>
<div class="sourceCode" id="cb447"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb447-1" title="1"><span class="kw">cor</span>( anscombe<span class="op">$</span>x2, anscombe<span class="op">$</span>y2 )</a></code></pre></div>
<pre><code>## [1] 0.8162365</code></pre>
<p>and so on.</p>
You’d think that these four data setswould look pretty similar to one another. They do not. If we draw scatterplots of <span class="math inline">\(X\)</span> against <span class="math inline">\(Y\)</span> for all four variables, as shown in Figure @ref(fig:anscombe) we see that all four of these are <em>spectacularly</em> different to each other.
<div class="figure">
<img src="lsr_files/figure-html/anscombe-1.png" alt="Anscombe's quartet. All four of these data sets have a Pearson correlation of $r = .816$, but they are qualitatively different from one another." width="672" />
<p class="caption">
(#fig:anscombe)Anscombe’s quartet. All four of these data sets have a Pearson correlation of <span class="math inline">\(r = .816\)</span>, but they are qualitatively different from one another.
</p>
</div>
<p>The lesson here, which so very many people seem to forget in real life is “<em>always graph your raw data</em>”. This will be the focus of Chapter @ref(graphics).</p>
</div>
<div id="spearmans-rank-correlations" class="section level3">
<h3><span class="header-section-number">5.7.6</span> Spearman’s rank correlations</h3>
<div class="figure">
<img src="lsr_files/figure-html/rankcorrpic-1.png" alt="The relationship between hours worked and grade received, for a toy data set consisting of only 10 students (each circle corresponds to one student). The dashed line through the middle shows the linear relationship between the two variables. This produces a strong Pearson correlation of $r = .91$. However, the interesting thing to note here is that there's actually a perfect monotonic relationship between the two variables: in this toy example at least, increasing the hours worked always increases the grade received, as illustrated by the solid line. This is reflected in a Spearman correlation of $rho = 1$. With such a small data set, however, it's an open question as to which version better describes the actual relationship involved. " width="672" />
<p class="caption">
(#fig:rankcorrpic)The relationship between hours worked and grade received, for a toy data set consisting of only 10 students (each circle corresponds to one student). The dashed line through the middle shows the linear relationship between the two variables. This produces a strong Pearson correlation of <span class="math inline">\(r = .91\)</span>. However, the interesting thing to note here is that there’s actually a perfect monotonic relationship between the two variables: in this toy example at least, increasing the hours worked always increases the grade received, as illustrated by the solid line. This is reflected in a Spearman correlation of <span class="math inline">\(rho = 1\)</span>. With such a small data set, however, it’s an open question as to which version better describes the actual relationship involved.
</p>
</div>
<p>The Pearson correlation coefficient is useful for a lot of things, but it does have shortcomings. One issue in particular stands out: what it actually measures is the strength of the <em>linear</em> relationship between two variables. In other words, what it gives you is a measure of the extent to which the data all tend to fall on a single, perfectly straight line. Often, this is a pretty good approximation to what we mean when we say “relationship”, and so the Pearson correlation is a good thing to calculation. Sometimes, it isn’t.</p>
<p>One very common situation where the Pearson correlation isn’t quite the right thing to use arises when an increase in one variable <span class="math inline">\(X\)</span> really is reflected in an increase in another variable <span class="math inline">\(Y\)</span>, but the nature of the relationship isn’t necessarily linear. An example of this might be the relationship between effort and reward when studying for an exam. If you put in zero effort (<span class="math inline">\(X\)</span>) into learning a subject, then you should expect a grade of 0% (<span class="math inline">\(Y\)</span>). However, a little bit of effort will cause a <em>massive</em> improvement: just turning up to lectures means that you learn a fair bit, and if you just turn up to classes, and scribble a few things down so your grade might rise to 35%, all without a lot of effort. However, you just don’t get the same effect at the other end of the scale. As everyone knows, it takes <em>a lot</em> more effort to get a grade of 90% than it takes to get a grade of 55%. What this means is that, if I’ve got data looking at study effort and grades, there’s a pretty good chance that Pearson correlations will be misleading.</p>
<p>To illustrate, consider the data plotted in Figure @ref(fig:rankcorrpic), showing the relationship between hours worked and grade received for 10 students taking some class. The curious thing about this – highly fictitious – data set is that increasing your effort <em>always</em> increases your grade. It might be by a lot or it might be by a little, but increasing effort will never decrease your grade. The data are stored in <code>effort.Rdata</code>:</p>
<pre><code>&gt; load( &quot;effort.Rdata&quot; )
&gt; who(TRUE)
   -- Name --   -- Class --   -- Size --
   effort       data.frame    10 x 2    
    $hours      numeric       10        
    $grade      numeric       10        </code></pre>
<p>The raw data look like this:</p>
<pre><code>&gt; effort
   hours grade
1      2    13
2     76    91
3     40    79
4      6    14
5     16    21
6     28    74
7     27    47
8     59    85
9     46    84
10    68    88</code></pre>
<p>If we run a standard Pearson correlation, it shows a strong relationship between hours worked and grade received,</p>
<pre><code>&gt; cor( effort$hours, effort$grade )
[1] 0.909402</code></pre>
<p>but this doesn’t actually capture the observation that increasing hours worked <em>always</em> increases the grade. There’s a sense here in which we want to be able to say that the correlation is <em>perfect</em> but for a somewhat different notion of what a “relationship” is. What we’re looking for is something that captures the fact that there is a perfect <strong><em>ordinal relationship</em></strong> here. That is, if student 1 works more hours than student 2, then we can guarantee that student 1 will get the better grade. That’s not what a correlation of <span class="math inline">\(r = .91\)</span> says at all.</p>
<p>How should we address this? Actually, it’s really easy: if we’re looking for ordinal relationships, all we have to do is treat the data as if it were ordinal scale! So, instead of measuring effort in terms of “hours worked”, lets rank all 10 of our students in order of hours worked. That is, student 1 did the least work out of anyone (2 hours) so they get the lowest rank (rank = 1). Student 4 was the next laziest, putting in only 6 hours of work in over the whole semester, so they get the next lowest rank (rank = 2). Notice that I’m using “rank =1” to mean “low rank”. Sometimes in everyday language we talk about “rank = 1” to mean “top rank” rather than “bottom rank”. So be careful: you can rank “from smallest value to largest value” (i.e., small equals rank 1) or you can rank “from largest value to smallest value” (i.e., large equals rank 1). In this case, I’m ranking from smallest to largest, because that’s the default way that R does it. But in real life, it’s really easy to forget which way you set things up, so you have to put a bit of effort into remembering!</p>
<p>Okay, so let’s have a look at our students when we rank them from worst to best in terms of effort and reward:</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>rank (hours worked)</th>
<th>rank (grade received)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>student</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="even">
<td>student</td>
<td>2</td>
<td>10</td>
</tr>
<tr class="odd">
<td>student</td>
<td>3</td>
<td>6</td>
</tr>
<tr class="even">
<td>student</td>
<td>4</td>
<td>2</td>
</tr>
<tr class="odd">
<td>student</td>
<td>5</td>
<td>3</td>
</tr>
<tr class="even">
<td>student</td>
<td>6</td>
<td>5</td>
</tr>
<tr class="odd">
<td>student</td>
<td>7</td>
<td>4</td>
</tr>
<tr class="even">
<td>student</td>
<td>8</td>
<td>8</td>
</tr>
<tr class="odd">
<td>student</td>
<td>9</td>
<td>7</td>
</tr>
<tr class="even">
<td>student</td>
<td>10</td>
<td>9</td>
</tr>
</tbody>
</table>
<p>Hm. These are <em>identical</em>. The student who put in the most effort got the best grade, the student with the least effort got the worst grade, etc. We can get R to construct these rankings using the <code>rank()</code> function, like this:</p>
<pre><code>&gt; hours.rank &lt;- rank( effort$hours )   # rank students by hours worked
&gt; grade.rank &lt;- rank( effort$grade )   # rank students by grade received</code></pre>
<p>As the table above shows, these two rankings are identical, so if we now correlate them we get a perfect relationship:</p>
<pre><code>&gt; cor( hours.rank, grade.rank )
[1] 1</code></pre>
<p>What we’ve just re-invented is <strong><em>Spearman’s rank order correlation</em></strong>, usually denoted <span class="math inline">\(\rho\)</span> to distinguish it from the Pearson correlation <span class="math inline">\(r\)</span>. We can calculate Spearman’s <span class="math inline">\(\rho\)</span> using R in two different ways. Firstly we could do it the way I just showed, using the <code>rank()</code> function to construct the rankings, and then calculate the Pearson correlation on these ranks. However, that’s way too much effort to do every time. It’s much easier to just specify the <code>method</code> argument of the <code>cor()</code> function.</p>
<pre><code>&gt; cor( effort$hours, effort$grade, method = &quot;spearman&quot;)
[1] 1</code></pre>
<p>The default value of the <code>method</code> argument is <code>"pearson"</code>, which is why we didn’t have to specify it earlier on when we were doing Pearson correlations.</p>
</div>
<div id="the-correlate-function" class="section level3">
<h3><span class="header-section-number">5.7.7</span> The <code>correlate()</code> function</h3>
<p>As we’ve seen, the <code>cor()</code> function works pretty well, and handles many of the situations that you might be interested in. One thing that many beginners find frustrating, however, is the fact that it’s not built to handle non-numeric variables. From a statistical perspective, this is perfectly sensible: Pearson and Spearman correlations are only designed to work for numeric variables, so the <code>cor()</code> function spits out an error.</p>
<p>Here’s what I mean. Suppose you were keeping track of how many <code>hours</code> you worked in any given day, and counted how many <code>tasks</code> you completed. If you were doing the tasks for money, you might also want to keep track of how much <code>pay</code> you got for each job. It would also be sensible to keep track of the <code>weekday</code> on which you actually did the work: most of us don’t work as much on Saturdays or Sundays. If you did this for 7 weeks, you might end up with a data set that looks like this one:</p>
<pre><code>&gt; load(&quot;work.Rdata&quot;)

&gt; who(TRUE)
   -- Name --   -- Class --   -- Size --
   work         data.frame    49 x 7    
    $hours      numeric       49        
    $tasks      numeric       49        
    $pay        numeric       49        
    $day        integer       49        
    $weekday    factor        49        
    $week       numeric       49        
    $day.type   factor        49   
    
&gt; head(work)
  hours tasks pay day   weekday week day.type
1   7.2    14  41   1   Tuesday    1  weekday
2   7.4    11  39   2 Wednesday    1  weekday
3   6.6    14  13   3  Thursday    1  weekday
4   6.5    22  47   4    Friday    1  weekday
5   3.1     5   4   5  Saturday    1  weekend
6   3.0     7  12   6    Sunday    1  weekend</code></pre>
<p>Obviously, I’d like to know something about how all these variables correlate with one another. I could correlate <code>hours</code> with <code>pay</code> quite using <code>cor()</code>, like so:</p>
<pre><code>&gt; cor(work$hours,work$pay)
[1] 0.7604283</code></pre>
<p>But what if I wanted a quick and easy way to calculate all pairwise correlations between the numeric variables? I can’t just input the <code>work</code> data frame, because it contains two factor variables, <code>weekday</code> and <code>day.type</code>. If I try this, I get an error:</p>
<pre><code>&gt; cor(work)
Error in cor(work) : &#39;x&#39; must be numeric</code></pre>
<p>It order to get the correlations that I want using the <code>cor()</code> function, is create a new data frame that doesn’t contain the factor variables, and then feed that new data frame into the <code>cor()</code> function. It’s not actually very hard to do that, and I’ll talk about how to do it properly in <a href="mailto:Section@refsec" class="email">Section@refsec</a>:subsetdataframe. But it would be nice to have some function that is smart enough to just ignore the factor variables. That’s where the <code>correlate()</code> function in the <code>lsr</code> package can be handy. If you feed it a data frame that contains factors, it knows to ignore them, and returns the pairwise correlations only between the numeric variables:</p>
<pre><code>&gt; correlate(work)

CORRELATIONS
============
- correlation type:  pearson 
- correlations shown only when both variables are numeric

          hours  tasks   pay    day weekday   week day.type
hours         .  0.800 0.760 -0.049       .  0.018        .
tasks     0.800      . 0.720 -0.072       . -0.013        .
pay       0.760  0.720     .  0.137       .  0.196        .
day      -0.049 -0.072 0.137      .       .  0.990        .
weekday       .      .     .      .       .      .        .
week      0.018 -0.013 0.196  0.990       .      .        .
day.type      .      .     .      .       .      .        .</code></pre>
<p>The output here shows a <code>.</code> whenever one of the variables is non-numeric. It also shows a <code>.</code> whenever a variable is correlated with itself (it’s not a meaningful thing to do). The <code>correlate()</code> function can also do Spearman correlations, by specifying the <code>corr.method</code> to use:</p>
<pre><code>&gt; correlate( work, corr.method=&quot;spearman&quot; )

CORRELATIONS
============
- correlation type:  spearman 
- correlations shown only when both variables are numeric

          hours  tasks   pay    day weekday   week day.type
hours         .  0.805 0.745 -0.047       .  0.010        .
tasks     0.805      . 0.730 -0.068       . -0.008        .
pay       0.745  0.730     .  0.094       .  0.154        .
day      -0.047 -0.068 0.094      .       .  0.990        .
weekday       .      .     .      .       .      .        .
week      0.010 -0.008 0.154  0.990       .      .        .
day.type      .      .     .      .       .      .        .</code></pre>
<p>Obviously, there’s no new functionality in the <code>correlate()</code> function, and any advanced R user would be perfectly capable of using the <code>cor()</code> function to get these numbers out. But if you’re not yet comfortable with extracting a subset of a data frame, the <code>correlate()</code> function is for you.</p>
</div>
</div>
<div id="missing" class="section level2">
<h2><span class="header-section-number">5.8</span> Handling missing values</h2>
<p>There’s one last topic that I want to discuss briefly in this chapter, and that’s the issue of <strong><em>missing data</em></strong>. Real data sets very frequently turn out to have missing values: perhaps someone forgot to fill in a particular survey question, for instance. Missing data can be the source of a lot of tricky issues, most of which I’m going to gloss over. However, at a minimum, you need to understand the basics of handling missing data in R.</p>
<div id="the-single-variable-case" class="section level3">
<h3><span class="header-section-number">5.8.1</span> The single variable case</h3>
<p>Let’s start with the simplest case, in which you’re trying to calculate descriptive statistics for a single variable which has missing data. In R, this means that there will be <code>NA</code> values in your data vector. Let’s create a variable like that:</p>
<pre><code>&gt; partial &lt;- c(10, 20, NA, 30)</code></pre>
<p>Let’s assume that you want to calculate the mean of this variable. By default, R assumes that you want to calculate the mean using all four elements of this vector, which is probably the safest thing for a dumb automaton to do, but it’s rarely what you actually want. Why not? Well, remember that the basic interpretation of <code>NA</code> is “I don’t know what this number is”. This means that <code>1 + NA = NA</code>: if I add 1 to some number that I don’t know (i.e., the <code>NA</code>) then the answer is <em>also</em> a number that I don’t know. As a consequence, if you don’t explicitly tell R to ignore the <code>NA</code> values, and the data set does have missing values, then the output will itself be a missing value. If I try to calculate the mean of the <code>partial</code> vector, without doing anything about the missing value, here’s what happens:</p>
<pre><code>&gt; mean( x = partial )
[1] NA</code></pre>
<p>Technically correct, but deeply unhelpful.</p>
<p>To fix this, all of the descriptive statistics functions that I’ve discussed in this chapter (with the exception of <code>cor()</code> which is a special case I’ll discuss below) have an optional argument called <code>na.rm</code>, which is shorthand for “remove NA values”. By default, <code>na.rm = FALSE</code>, so R does nothing about the missing data problem. Let’s try setting <code>na.rm = TRUE</code> and see what happens:</p>
<p>When calculating sums and means when missing data are present (i.e., when there are <code>NA</code> values) there’s actually an additional argument to the function that you should be aware of. This argument is called <code>na.rm</code>, and is a logical value indicating whether R should ignore (or “remove”) the missing data for the purposes of doing the calculations. By default, R assumes that you want to keep the missing values, so unless you say otherwise it will set <code>na.rm = FALSE</code>. However, R assumes that <code>1 + NA = NA</code>: if I add 1 to some number that I don’t know (i.e., the <code>NA</code>) then the answer is <em>also</em> a number that I don’t know. As a consequence, if you don’t explicitly tell R to ignore the <code>NA</code> values, and the data set does have missing values, then the output will itself be a missing value. This is illustrated in the following extract:</p>
<pre><code>&gt; mean( x = partial, na.rm = TRUE )
[1] 20</code></pre>
<p>Notice that the mean is <code>20</code> (i.e., <code>60 / 3</code>) and <em>not</em> <code>15</code>. When R ignores a <code>NA</code> value, it genuinely ignores it. In effect, the calculation above is identical to what you’d get if you asked for the mean of the three-element vector <code>c(10, 20, 30)</code>.</p>
<p>As indicated above, this isn’t unique to the <code>mean()</code> function. Pretty much all of the other functions that I’ve talked about in this chapter have an <code>na.rm</code> argument that indicates whether it should ignore missing values. However, its behaviour is the same for all these functions, so I won’t waste everyone’s time by demonstrating it separately for each one.</p>
</div>
<div id="missing-values-in-pairwise-calculations" class="section level3">
<h3><span class="header-section-number">5.8.2</span> Missing values in pairwise calculations</h3>
<p>I mentioned earlier that the <code>cor()</code> function is a special case. It doesn’t have an <code>na.rm</code> argument, because the story becomes a lot more complicated when more than one variable is involved. What it does have is an argument called <code>use</code> which does roughly the same thing, but you need to think little more carefully about what you want this time. To illustrate the issues, let’s open up a data set that has missing values, <code>parenthood2.Rdata</code>. This file contains the same data as the original parenthood data, but with some values deleted. It contains a single data frame, <code>parenthood2</code>:</p>
<pre><code>&gt; load( &quot;parenthood2.Rdata&quot; )
&gt; print( parenthood2 )
  dan.sleep baby.sleep dan.grump day
1      7.59         NA        56   1
2      7.91      11.66        60   2
3      5.14       7.92        82   3
4      7.71       9.61        55   4
5      6.68       9.75        NA   5
6      5.99       5.04        72   6
BLAH BLAH BLAH</code></pre>
<p>If I calculate my descriptive statistics using the <code>describe()</code> function</p>
<pre><code>&gt; describe( parenthood2 )
           var   n  mean    sd median trimmed   mad   min    max    BLAH
dan.sleep    1  91  6.98  1.02   7.03    7.02  1.13  4.84   9.00    BLAH
baby.sleep   2  89  8.11  2.05   8.20    8.13  2.28  3.25  12.07    BLAH
dan.grump    3  92 63.15  9.85  61.00   62.66 10.38 41.00  89.00    BLAH
day          4 100 50.50 29.01  50.50   50.50 37.06  1.00 100.00    BLAH</code></pre>
<p>we can see from the <code>n</code> column that there are 9 missing values for <code>dan.sleep</code>, 11 missing values for <code>baby.sleep</code> and 8 missing values for <code>dan.grump</code>.<a href="#fn85" class="footnote-ref" id="fnref85"><sup>85</sup></a> Suppose what I would like is a correlation matrix. And let’s also suppose that I don’t bother to tell R how to handle those missing values. Here’s what happens:</p>
<pre><code>&gt; cor( parenthood2 )
           dan.sleep baby.sleep dan.grump day
dan.sleep          1         NA        NA  NA
baby.sleep        NA          1        NA  NA
dan.grump         NA         NA         1  NA
day               NA         NA        NA   1</code></pre>
<p>Annoying, but it kind of makes sense. If I don’t <em>know</em> what some of the values of <code>dan.sleep</code> and <code>baby.sleep</code> actually are, then I can’t possibly <em>know</em> what the correlation between these two variables is either, since the formula for the correlation coefficient makes use of every single observation in the data set. Once again, it makes sense: it’s just not particularly <em>helpful</em>.</p>
<p>To make R behave more sensibly in this situation, you need to specify the <code>use</code> argument to the <code>cor()</code> function. There are several different values that you can specify for this, but the two that we care most about in practice tend to be <code>"complete.obs"</code> and <code>"pairwise.complete.obs"</code>. If we specify <code>use = "complete.obs"</code>, R will completely ignore all cases (i.e., all rows in our <code>parenthood2</code> data frame) that have any missing values at all. So, for instance, if you look back at the extract earlier when I used the <code>head()</code> function, notice that observation 1 (i.e., day 1) of the <code>parenthood2</code> data set is missing the value for <code>baby.sleep</code>, but is otherwise complete? Well, if you choose <code>use = "complete.obs"</code> R will ignore that row completely: that is, even when it’s trying to calculate the correlation between <code>dan.sleep</code> and <code>dan.grump</code>, observation 1 will be ignored, because the value of <code>baby.sleep</code> is missing for that observation. Here’s what we get:</p>
<pre><code>&gt; cor(parenthood2, use = &quot;complete.obs&quot;)
             dan.sleep baby.sleep   dan.grump         day
dan.sleep   1.00000000  0.6394985 -0.89951468  0.06132891
baby.sleep  0.63949845  1.0000000 -0.58656066  0.14555814
dan.grump  -0.89951468 -0.5865607  1.00000000 -0.06816586
day         0.06132891  0.1455581 -0.06816586  1.00000000</code></pre>
<p>The other possibility that we care about, and the one that tends to get used more often in practice, is to set <code>use = "pairwise.complete.obs"</code>. When we do that, R only looks at the variables that it’s trying to correlate when determining what to drop. So, for instance, since the only missing value for observation 1 of <code>parenthood2</code> is for <code>baby.sleep</code> R will only drop observation 1 when <code>baby.sleep</code> is one of the variables involved: and so R keeps observation 1 when trying to correlate <code>dan.sleep</code> and <code>dan.grump</code>. When we do it this way, here’s what we get:</p>
<pre><code>&gt; cor(parenthood2, use = &quot;pairwise.complete.obs&quot;) 
             dan.sleep  baby.sleep    dan.grump          day
dan.sleep   1.00000000  0.61472303 -0.903442442 -0.076796665
baby.sleep  0.61472303  1.00000000 -0.567802669  0.058309485
dan.grump  -0.90344244 -0.56780267  1.000000000  0.005833399
day        -0.07679667  0.05830949  0.005833399  1.000000000</code></pre>
<p>Similar, but not quite the same. It’s also worth noting that the <code>correlate()</code> function (in the <code>lsr</code> package) automatically uses the “pairwise complete” method:</p>
<pre><code>&gt; correlate(parenthood2)

CORRELATIONS
============
- correlation type:  pearson 
- correlations shown only when both variables are numeric

           dan.sleep baby.sleep dan.grump    day
dan.sleep          .      0.615    -0.903 -0.077
baby.sleep     0.615          .    -0.568  0.058
dan.grump     -0.903     -0.568         .  0.006
day           -0.077      0.058     0.006      .</code></pre>
<p>The two approaches have different strengths and weaknesses. The “pairwise complete” approach has the advantage that it keeps more observations, so you’re making use of more of your data and (as we’ll discuss in tedious detail in Chapter @ref(estimation) and it improves the reliability of your estimated correlation. On the other hand, it means that every correlation in your correlation matrix is being computed from a slightly different set of observations, which can be awkward when you want to compare the different correlations that you’ve got.</p>
<p>So which method should you use? It depends a lot on <em>why</em> you think your values are missing, and probably depends a little on how paranoid you are. For instance, if you think that the missing values were “chosen” completely randomly<a href="#fn86" class="footnote-ref" id="fnref86"><sup>86</sup></a> then you’ll probably want to use the pairwise method. If you think that missing data are a cue to thinking that the whole observation might be rubbish (e.g., someone just selecting arbitrary responses in your questionnaire), but that there’s no pattern to which observations are “rubbish” then it’s probably safer to keep only those observations that are complete. If you think there’s something systematic going on, in that some observations are more likely to be missing than others, then you have a much trickier problem to solve, and one that is beyond the scope of this book.</p>
</div>
</div>
<div id="summary-2" class="section level2">
<h2><span class="header-section-number">5.9</span> Summary</h2>
<p>Calculating some basic descriptive statistics is one of the very first things you do when analysing real data, and descriptive statistics are much simpler to understand than inferential statistics, so like every other statistics textbook I’ve started with descriptives. In this chapter, we talked about the following topics:</p>
<ul>
<li><em>Measures of central tendency</em>. Broadly speaking, central tendency measures tell you where the data are. There’s three measures that are typically reported in the literature: the mean, median and mode. (Section @ref(centraltendency))</li>
<li><em>Measures of variability</em>. In contrast, measures of variability tell you about how “spread out” the data are. The key measures are: range, standard deviation, interquartile reange (Section @ref(var))</li>
<li><em>Getting summaries of variables in R</em>. Since this book focuses on doing data analysis in R, we spent a bit of time talking about how descriptive statistics are computed in R. (Section @ref(summary) and @ref(groupdescriptives))</li>
<li><em>Standard scores</em>. The <span class="math inline">\(z\)</span>-score is a slightly unusual beast. It’s not quite a descriptive statistic, and not quite an inference. We talked about it in Section @ref(zscore). Make sure you understand that section: it’ll come up again later.</li>
<li><em>Correlations</em>. Want to know how strong the relationship is between two variables? Calculate a correlation. (Section @ref(correl))</li>
<li><em>Missing data</em>. Dealing with missing data is one of those frustrating things that data analysts really wish the didn’t have to think about. In real life it can be hard to do well. For the purpose of this book, we only touched on the basics in Section @ref(missing)</li>
</ul>
<p>In the next section we’ll move on to a discussion of how to draw pictures! Everyone loves a pretty picture, right? But before we do, I want to end on an important point. A traditional first course in statistics spends only a small proportion of the class on descriptive statistics, maybe one or two lectures at most. The vast majority of the lecturer’s time is spent on inferential statistics, because that’s where all the hard stuff is. That makes sense, but it hides the practical everyday importance of choosing good descriptives. With that in mind…</p>
</div>
<div id="epilogue-good-descriptive-statistics-are-descriptive" class="section level2">
<h2><span class="header-section-number">5.10</span> Epilogue: Good descriptive statistics are descriptive!</h2>
<blockquote>
<p><em>The death of one man is a tragedy.
The death of millions is a statistic.</em></p>
<p>– Josef Stalin, Potsdam 1945</p>
</blockquote>
<blockquote>
<p><em>950,000 – 1,200,000</em></p>
<p>– Estimate of Soviet repression deaths,
1937-1938 <span class="citation">(Ellman <a href="#ref-Ellman2002" role="doc-biblioref">2002</a>)</span></p>
</blockquote>
<p>Stalin’s infamous quote about the statistical character death of millions is worth giving some thought. The clear intent of his statement is that the death of an individual touches us personally and its force cannot be denied, but that the deaths of a multitude are incomprehensible, and as a consequence mere statistics, more easily ignored. I’d argue that Stalin was half right. A statistic is an abstraction, a description of events beyond our personal experience, and so hard to visualise. Few if any of us can imagine what the deaths of millions is “really” like, but we can imagine one death, and this gives the lone death its feeling of immediate tragedy, a feeling that is missing from Ellman’s cold statistical description.</p>
<p>Yet it is not so simple: without numbers, without counts, without a description of what happened, we have <em>no chance</em> of understanding what really happened, no opportunity event to try to summon the missing feeling. And in truth, as I write this, sitting in comfort on a Saturday morning, half a world and a whole lifetime away from the Gulags, when I put the Ellman estimate next to the Stalin quote a dull dread settles in my stomach and a chill settles over me. The Stalinist repression is something truly beyond my experience, but with a combination of statistical data and those recorded personal histories that have come down to us, it is not entirely beyond my comprehension. Because what Ellman’s numbers tell us is this: over a two year period, Stalinist repression wiped out the equivalent of every man, woman and child currently alive in the city where I live. Each one of those deaths had it’s own story, was it’s own tragedy, and only some of those are known to us now. Even so, with a few carefully chosen statistics, the scale of the atrocity starts to come into focus.</p>
<p>Thus it is no small thing to say that the first task of the statistician and the scientist is to summarise the data, to find some collection of numbers that can convey to an audience a sense of what has happened. This is the job of descriptive statistics, but it’s not a job that can be told solely using the numbers. You are a data analyst, not a statistical software package. Part of your job is to take these <em>statistics</em> and turn them into a <em>description</em>. When you analyse data, it is not sufficient to list off a collection of numbers. Always remember that what you’re really trying to do is communicate with a human audience. The numbers are important, but they need to be put together into a meaningful story that your audience can interpret. That means you need to think about framing. You need to think about context. And you need to think about the individual events that your statistics are summarising.</p>
<!--chapter:end:03.05-descriptives.Rmd-->
</div>
</div>
<div id="graphics" class="section level1">
<h1><span class="header-section-number">6</span> Drawing graphs</h1>
<blockquote>
<p><em>Above all else show the data.</em></p>
<p>–Edward Tufte<a href="#fn87" class="footnote-ref" id="fnref87"><sup>87</sup></a></p>
</blockquote>
<p>Visualising data is one of the most important tasks facing the data analyst. It’s important for two distinct but closely related reasons. Firstly, there’s the matter of drawing “presentation graphics”: displaying your data in a clean, visually appealing fashion makes it easier for your reader to understand what you’re trying to tell them. Equally important, perhaps even more important, is the fact that drawing graphs helps <em>you</em> to understand the data. To that end, it’s important to draw “exploratory graphics” that help you learn about the data as you go about analysing it. These points might seem pretty obvious, but I cannot count the number of times I’ve seen people forget them.</p>
<div class="figure">
<img src="lsr_files/figure-html/snowmap1-1.png" alt="A stylised redrawing of John Snow's original cholera map. Each small dot represents the location of a cholera case, and each large circle shows the location of a well. As the plot makes clear, the cholera outbreak is centred very closely on the Broad St pump.  This image uses the data from the `HistData` package, and was drawn using minor alterations to the commands provided in the help files. Note that Snow's original hand drawn map used different symbols and labels, but you get the idea." width="672" />
<p class="caption">
(#fig:snowmap1)A stylised redrawing of John Snow’s original cholera map. Each small dot represents the location of a cholera case, and each large circle shows the location of a well. As the plot makes clear, the cholera outbreak is centred very closely on the Broad St pump. This image uses the data from the <code>HistData</code> package, and was drawn using minor alterations to the commands provided in the help files. Note that Snow’s original hand drawn map used different symbols and labels, but you get the idea.
</p>
</div>
<p>To give a sense of the importance of this chapter, I want to start with a classic illustration of just how powerful a good graph can be. To that end, Figure @ref(fig:snowmap1) shows a redrawing of one of the most famous data visualisations of all time: John Snow’s 1854 map of cholera deaths. The map is elegant in its simplicity. In the background we have a street map, which helps orient the viewer. Over the top, we see a large number of small dots, each one representing the location of a cholera case. The larger symbols show the location of water pumps, labelled by name. Even the most casual inspection of the graph makes it very clear that the source of the outbreak is almost certainly the Broad Street pump. Upon viewing this graph, Dr Snow arranged to have the handle removed from the pump, ending the outbreak that had killed over 500 people. Such is the power of a good data visualisation.</p>
<p>The goals in this chapter are twofold: firstly, to discuss several fairly standard graphs that we use a lot when analysing and presenting data, and secondly, to show you how to create these graphs in R. The graphs themselves tend to be pretty straightforward, so in that respect this chapter is pretty simple. Where people usually struggle is learning how to produce graphs, and especially, learning how to produce good graphs.<a href="#fn88" class="footnote-ref" id="fnref88"><sup>88</sup></a> Fortunately, learning how to draw graphs in R is reasonably simple, as long as you’re not too picky about what your graph looks like. What I mean when I say this is that R has a lot of <em>very</em> good graphing functions, and most of the time you can produce a clean, high-quality graphic without having to learn very much about the low-level details of how R handles graphics. Unfortunately, on those occasions when you do want to do something non-standard, or if you need to make highly specific changes to the figure, you actually do need to learn a fair bit about the these details; and those details are both complicated and boring. With that in mind, the structure of this chapter is as follows: I’ll start out by giving you a very quick overview of how graphics work in R. I’ll then discuss several different kinds of graph and how to draw them, as well as showing the basics of how to customise these plots. I’ll then talk in more detail about R graphics, discussing some of those complicated and boring issues. In a future version of this book, I intend to finish this chapter off by talking about what makes a good or a bad graph, but I haven’t yet had the time to write that section.</p>
<div id="rgraphics" class="section level2">
<h2><span class="header-section-number">6.1</span> An overview of R graphics</h2>
<p>Reduced to its simplest form, you can think of an R graphic as being much like a painting. You start out with an empty canvas. Every time you use a graphics function, it paints some new things onto your canvas. Later on, you can paint more things over the top if you want; but just like painting, you can’t “undo” your strokes. If you make a mistake, you have to throw away your painting and start over. Fortunately, this is way more easy to do when using R than it is when painting a picture in real life: you delete the plot and then type a new set of commands.<a href="#fn89" class="footnote-ref" id="fnref89"><sup>89</sup></a> This way of thinking about drawing graphs is referred to as the <strong><em>painter’s model</em></strong>. So far, this probably doesn’t sound particularly complicated, and for the vast majority of graphs you’ll want to draw it’s exactly as simple as it sounds. Much like painting in real life, the headaches usually start when we dig into details. To see why, I’ll expand this “painting metaphor” a bit further just to show you the basics of what’s going on under the hood, but before I do I want to stress that you really don’t need to understand all these complexities in order to draw graphs. I’d been using R for years before I even realised that most of these issues existed! However, I don’t want you to go through the same pain I went through every time I inadvertently discovered one of these things, so here’s a quick overview.</p>
<p>Firstly, if you want to paint a picture, you need to paint it <strong>on</strong> something. In real life, you can paint on lots of different things. Painting onto canvas isn’t the same as painting onto paper, and neither one is the same as painting on a wall. In R, the thing that you paint your graphic onto is called a <strong><em>device</em></strong>. For most applications that we’ll look at in this book, this “device” will be a window on your computer. If you’re using Windows as your operating system, then the name for this device is <code>windows</code>; on a Mac it’s called <code>quartz</code> because that’s the name of the software that the Mac OS uses to draw pretty pictures; and on Linux/Unix, you’re probably using <code>X11</code>. On the other hand, if you’re using Rstudio (regardless of which operating system you’re on), there’s a separate device called <code>RStudioGD</code> that forces R to paint inside the “plots” panel in Rstudio. However, from the computers perspective there’s nothing terribly special about drawing pictures on screen: and so R is quite happy to paint pictures directly into a file. R can paint several different types of image files: <code>jpeg</code>, <code>png</code>, <code>pdf</code>, <code>postscript</code>, <code>tiff</code> and <code>bmp</code> files are all among the options that you have available to you. For the most part, these different devices all behave the same way, so you don’t really need to know much about the differences between them when learning how to draw pictures. But, just like real life painting, sometimes the specifics do matter. Unless stated otherwise, you can assume that I’m drawing a picture on screen, using the appropriate device (i.e., <code>windows</code>, <code>quartz</code>, <code>X11</code> or <code>RStudioGD</code>). One the rare occasions where these behave differently from one another, I’ll try to point it out in the text.</p>
<p>Secondly, when you paint a picture you need to paint it <strong>with</strong> something. Maybe you want to do an oil painting, but maybe you want to use watercolour. And, generally speaking, you pretty much have to pick one or the other. The analog to this in R is a “graphics system”. A graphics system defines a collection of very <strong><em>low-level graphics</em></strong> commands about what to draw and where to draw it. Something that surprises most new R users is the discovery that R actually has <em>two</em> completely independent graphics systems, known as <strong><em>traditional graphics</em></strong> (in the <code>graphics</code> package) and <strong><em>grid graphics</em></strong> (in the <code>grid</code> package).<a href="#fn90" class="footnote-ref" id="fnref90"><sup>90</sup></a> Not surprisingly, the traditional graphics system is the older of the two: in fact, it’s actually older than R since it has it’s origins in S, the system from which R is descended. Grid graphics are newer, and in some respects more powerful, so many of the more recent, fancier graphical tools in R make use of grid graphics. However, grid graphics are somewhat more complicated beasts, so most people start out by learning the traditional graphics system. Nevertheless, as long as you don’t want to use any low-level commands yourself, then you don’t really need to care about whether you’re using traditional graphics or grid graphics. However, the moment you do want to tweak your figure by using some low-level commands you do need to care. Because these two different systems are pretty much incompatible with each other, there’s a pretty big divide in R graphics universe. Unless stated otherwise, you can assume that everything I’m saying pertains to traditional graphics.</p>
<p>Thirdly, a painting is usually done in a particular <strong>style</strong>. Maybe it’s a still life, maybe it’s an impressionist piece, or maybe you’re trying to annoy me by pretending that cubism is a legitimate artistic style. Regardless, each artistic style imposes some overarching aesthetic and perhaps even constraints on what can (or should) be painted using that style. In the same vein, R has quite a number of different packages, each of which provide a collection of <strong><em>high-level graphics</em></strong> commands. A single high-level command is capable of drawing an entire graph, complete with a range of customisation options. Most but not all of the high-level commands that I’ll talk about in this book come from the <code>graphics</code> package itself, and so belong to the world of traditional graphics. These commands all tend to share a common visual style, although there are a few graphics that I’ll use that come from other packages that differ in style somewhat. On the other side of the great divide, the grid universe relies heavily on two different packages – <code>lattice</code> and <code>ggplots2</code> – each of which provides a quite different visual style. As you’ve probably guessed, there’s a whole separate bunch of functions that you’d need to learn if you want to use <code>lattice</code> graphics or make use of the <code>ggplots2</code>. However, for the purposes of this book I’ll restrict myself to talking about the basic <code>graphics</code> tools.</p>
<p>At this point, I think we’ve covered more than enough background material. The point that I’m trying to make by providing this discussion isn’t to scare you with all these horrible details, but rather to try to convey to you the fact that R doesn’t really provide a single coherent graphics system. Instead, R itself provides a platform, and different people have built different graphical tools using that platform. As a consequence of this fact, there’s two different universes of graphics, and a great multitude of packages that live in them. At this stage you don’t need to understand these complexities, but it’s useful to know that they’re there. But for now, I think we can be happy with a simpler view of things: we’ll draw pictures on screen using the traditional graphics system, and as much as possible we’ll stick to high level commands only.</p>
<p>So let’s start painting.</p>
</div>
<div id="introplotting" class="section level2">
<h2><span class="header-section-number">6.2</span> An introduction to plotting</h2>
<p>Before I discuss any specialised graphics, let’s start by drawing a few very simple graphs just to get a feel for what it’s like to draw pictures using R. To that end, let’s create a small vector <code>Fibonacci</code> that contains a few numbers we’d like R to draw for us. Then, we’ll ask R to <code>plot()</code> those numbers. The result is Figure @ref(fig:firstplot).</p>
<div class="sourceCode" id="cb469"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb469-1" title="1">Fibonacci &lt;-<span class="st"> </span><span class="kw">c</span>( <span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">5</span>,<span class="dv">8</span>,<span class="dv">13</span> )</a>
<a class="sourceLine" id="cb469-2" title="2"><span class="kw">plot</span>( Fibonacci )</a></code></pre></div>
<div class="figure">
<img src="lsr_files/figure-html/firstplot-1.png" alt="Our first plot" width="672" />
<p class="caption">
(#fig:firstplot)Our first plot
</p>
</div>
<p>As you can see, what R has done is plot the <em>values</em> stored in the <code>Fibonacci</code> variable on the vertical axis (y-axis) and the corresponding <em>index</em> on the horizontal axis (x-axis). In other words, since the 4th element of the vector has a value of 3, we get a dot plotted at the location (4,3). That’s pretty straightforward, and the image in Figure @ref(fig:firstplot) is probably pretty close to what you would have had in mind when I suggested that we plot the <code>Fibonacci</code> data. However, there’s quite a lot of customisation options available to you, so we should probably spend a bit of time looking at some of those options. So, be warned: this ends up being a fairly long section, because there’s so many possibilities open to you. Don’t let it overwhelm you though… while all of the options discussed here are handy to know about, you can get by just fine only knowing a few of them. The only reason I’ve included all this stuff right at the beginning is that it ends up making the rest of the chapter a lot more readable!</p>
<div id="a-tedious-digression" class="section level3">
<h3><span class="header-section-number">6.2.1</span> A tedious digression</h3>
<p>Before we go into any discussion of customising plots, we need a little more background. The important thing to note when using the <code>plot()</code> function, is that it’s another example of a <em>generic</em> function (Section @ref(generics), much like <code>print()</code> and <code>summary()</code>, and so its behaviour changes depending on what kind of input you give it. However, the <code>plot()</code> function is somewhat fancier than the other two, and its behaviour depends on <em>two</em> arguments, <code>x</code> (the first input, which is required) and <code>y</code> (which is optional). This makes it (a) extremely powerful once you get the hang of it, and (b) hilariously unpredictable, when you’re not sure what you’re doing. As much as possible, I’ll try to make clear what type of inputs produce what kinds of outputs. For now, however, it’s enough to note that I’m only doing very basic plotting, and as a consequence all of the work is being done by the <code>plot.default()</code> function.</p>
<p>What kinds of customisations might we be interested in? If you look at the help documentation for the default plotting method (i.e., type <code>?plot.default</code> or <code>help("plot.default")</code>) you’ll see a very long list of arguments that you can specify to customise your plot. I’ll talk about several of them in a moment, but first I want to point out something that might seem quite wacky. When you look at all the different options that the help file talks about, you’ll notice that <em>some</em> of the options that it refers to are “proper” arguments to the <code>plot.default()</code> function, but it also goes on to mention a bunch of things that <em>look</em> like they’re supposed to be arguments, but they’re not listed in the “Usage” section of the file, and the documentation calls them <strong><em>graphical parameters</em></strong> instead. Even so, it’s usually possible to treat them as if they were arguments of the plotting function. Very odd. In order to stop my readers trying to find a brick and look up my home address, I’d better explain what’s going on; or at least give the basic gist behind it.</p>
<p>What exactly is a graphical parameter? Basically, the idea is that there are some characteristics of a plot which are pretty universal: for instance, regardless of what kind of graph you’re drawing, you probably need to specify what colour to use for the plot, right? So you’d expect there to be something like a <code>col</code> argument to every single graphics function in R? Well, sort of. In order to avoid having hundreds of arguments for every single function, what R does is refer to a bunch of these “graphical parameters” which are pretty general purpose. Graphical parameters can be changed directly by using the low-level <code>par()</code> function, which I discuss briefly in Section @ref(par) though not in a lot of detail. If you look at the help files for graphical parameters (i.e., type <code>?par</code>) you’ll see that there’s <em>lots</em> of them. Fortunately, (a) the default settings are generally pretty good so you can ignore the majority of the parameters, and (b) as you’ll see as we go through this chapter, you very rarely need to use <code>par()</code> directly, because you can “pretend” that graphical parameters are just additional arguments to your high-level function (e.g. <code>plot.default()</code>). In short… yes, R does have these wacky “graphical parameters” which can be quite confusing. But in most basic uses of the plotting functions, you can act as if they were just undocumented additional arguments to your function.</p>
</div>
<div id="figtitles" class="section level3">
<h3><span class="header-section-number">6.2.2</span> Customising the title and the axis labels</h3>
<p>One of the first things that you’ll find yourself wanting to do when customising your plot is to label it better. You might want to specify more appropriate axis labels, add a title or add a subtitle. The arguments that you need to specify to make this happen are:</p>
<ul>
<li><code>main</code>. A character string containing the title.</li>
<li><code>sub</code>. A character string containing the subtitle.</li>
<li><code>xlab</code>. A character string containing the x-axis label.</li>
<li><code>ylab</code>. A character string containing the y-axis label.</li>
</ul>
<p>These aren’t graphical parameters, they’re arguments to the high-level function. However, because the high-level functions all rely on the same low-level function to do the drawing<a href="#fn91" class="footnote-ref" id="fnref91"><sup>91</sup></a> the names of these arguments are identical for pretty much every high-level function I’ve come across. Let’s have a look at what happens when we make use of all these arguments. Here’s the command. The picture that this draws is shown in Figure @ref(fig:secondplot).</p>
<div class="sourceCode" id="cb470"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb470-1" title="1"><span class="kw">plot</span>( <span class="dt">x =</span> Fibonacci,</a>
<a class="sourceLine" id="cb470-2" title="2">               <span class="dt">main =</span> <span class="st">&quot;You specify title using the &#39;main&#39; argument&quot;</span>,</a>
<a class="sourceLine" id="cb470-3" title="3">               <span class="dt">sub =</span> <span class="st">&quot;The subtitle appears here! (Use the &#39;sub&#39; argument for this)&quot;</span>,</a>
<a class="sourceLine" id="cb470-4" title="4">               <span class="dt">xlab =</span> <span class="st">&quot;The x-axis label is &#39;xlab&#39;&quot;</span>,</a>
<a class="sourceLine" id="cb470-5" title="5">                <span class="dt">ylab =</span> <span class="st">&quot;The y-axis label is &#39;ylab&#39;&quot;</span> </a>
<a class="sourceLine" id="cb470-6" title="6">            )</a></code></pre></div>
<div class="figure">
<img src="lsr_files/figure-html/secondplot-1.png" alt="How to add your own title, subtitle, x-axis label and y-axis label to the plot." width="672" />
<p class="caption">
(#fig:secondplot)How to add your own title, subtitle, x-axis label and y-axis label to the plot.
</p>
</div>
<p>It’s more or less as you’d expect. The plot itself is identical to the one we drew in Figure @ref(fig:firstplot), except for the fact that we’ve changed the axis labels, and added a title and a subtitle. Even so, there’s a couple of interesting features worth calling your attention to. Firstly, notice that the subtitle is drawn below the plot, which I personally find annoying; as a consequence I almost never use subtitles. You may have a different opinion, of course, but the important thing is that you remember where the subtitle actually goes. Secondly, notice that R has decided to use boldface text and a larger font size for the title. This is one of my most hated default settings in R graphics, since I feel that it draws too much attention to the title. Generally, while I do want my reader to look at the title, I find that the R defaults are a bit overpowering, so I often like to change the settings. To that end, there are a bunch of graphical parameters that you can use to customise the font style:</p>
<ul>
<li><em>Font styles:</em> <code>font.main</code>, <code>font.sub</code>, <code>font.lab</code>, <code>font.axis</code>. These four parameters control the font style used for the plot title (<code>font.main</code>), the subtitle (<code>font.sub</code>), the axis labels (<code>font.lab</code>: note that you can’t specify separate styles for the x-axis and y-axis without using low level commands), and the numbers next to the tick marks on the axis (<code>font.axis</code>). Somewhat irritatingly, these arguments are numbers instead of meaningful names: a value of 1 corresponds to plain text, 2 means boldface, 3 means italic and 4 means bold italic.</li>
<li><em>Font colours:</em> <code>col.main</code>, <code>col.sub</code>, <code>col.lab</code>, <code>col.axis</code>. These parameters do pretty much what the name says: each one specifies a <strong>col</strong>our in which to type each of the different bits of text. Conveniently, R has a very large number of named colours (type <code>colours()</code> to see a list of over 650 colour names that R knows), so you can use the English language name of the colour to select it.<a href="#fn92" class="footnote-ref" id="fnref92"><sup>92</sup></a> Thus, the parameter value here string like <code>"red"</code>, <code>"gray25"</code> or <code>"springgreen4"</code> (yes, R really does recognise four different shades of “spring green”).</li>
<li><em>Font size:</em> <code>cex.main</code>, <code>cex.sub</code>, <code>cex.lab</code>, <code>cex.axis</code>. Font size is handled in a slightly curious way in R. The “cex” part here is short for “<strong>c</strong>haracter <strong>ex</strong>pansion”, and it’s essentially a magnification value. By default, all of these are set to a value of 1, except for the font title: <code>cex.main</code> has a default magnification of 1.2, which is why the title font is 20% bigger than the others.</li>
<li><em>Font family:</em> <code>family</code>. This argument specifies a font family to use: the simplest way to use it is to set it to <code>"sans"</code>, <code>"serif"</code>, or <code>"mono"</code>, corresponding to a san serif font, a serif font, or a monospaced font. If you want to, you can give the name of a specific font, but keep in mind that different operating systems use different fonts, so it’s probably safest to keep it simple. Better yet, unless you have some deep objections to the R defaults, just ignore this parameter entirely. That’s what I usually do.</li>
</ul>
<p>To give you a sense of how you can use these parameters to customise your titles, the following command can be used to draw Figure @ref(fig:thirdplot):</p>
<div class="sourceCode" id="cb471"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb471-1" title="1"><span class="kw">plot</span>( <span class="dt">x =</span> Fibonacci,                           <span class="co"># the data to plot</span></a>
<a class="sourceLine" id="cb471-2" title="2">          <span class="dt">main =</span> <span class="st">&quot;The first 7 Fibonacci numbers&quot;</span>,  <span class="co"># the title</span></a>
<a class="sourceLine" id="cb471-3" title="3">          <span class="dt">xlab =</span> <span class="st">&quot;Position in the sequence&quot;</span>,       <span class="co"># x-axis label</span></a>
<a class="sourceLine" id="cb471-4" title="4">          <span class="dt">ylab =</span> <span class="st">&quot;The Fibonacci number&quot;</span>,           <span class="co"># y-axis </span></a>
<a class="sourceLine" id="cb471-5" title="5">          <span class="dt">font.main =</span> <span class="dv">1</span>,</a>
<a class="sourceLine" id="cb471-6" title="6">          <span class="dt">cex.main =</span> <span class="dv">1</span>,</a>
<a class="sourceLine" id="cb471-7" title="7">          <span class="dt">font.axis =</span> <span class="dv">2</span>,</a>
<a class="sourceLine" id="cb471-8" title="8">          <span class="dt">col.lab =</span> <span class="st">&quot;gray50&quot;</span> )</a></code></pre></div>
<div class="figure">
<img src="lsr_files/figure-html/thirdplot-1.png" alt="How to customise the appearance of the titles and labels." width="672" />
<p class="caption">
(#fig:thirdplot)How to customise the appearance of the titles and labels.
</p>
</div>
<p>Although this command is quite long, it’s not complicated: all it does is override a bunch of the default parameter values. The only difficult aspect to this is that you have to remember what each of these parameters is called, and what all the different values are. And in practice I never remember: I have to look up the help documentation every time, or else look it up in this book.</p>
</div>
<div id="changing-the-plot-type" class="section level3">
<h3><span class="header-section-number">6.2.3</span> Changing the plot type</h3>
<p>Adding and customising the titles associated with the plot is one way in which you can play around with what your picture looks like. Another thing that you’ll want to do is customise the appearance of the actual plot! To start with, let’s look at the single most important options that the <code>plot()</code> function (or, recalling that we’re dealing with a generic function, in this case the <code>plot.default()</code> function, since that’s the one doing all the work) provides for you to use, which is the <code>type</code> argument. The type argument specifies the visual style of the plot. The possible values for this are:</p>
<ul>
<li><code>type = "p"</code>. Draw the <strong>p</strong>oints only.</li>
<li><code>type = "l"</code>. Draw a <strong>l</strong>ine through the points.</li>
<li><code>type = "o"</code>. Draw the line <strong>o</strong>ver the top of the points.</li>
<li><code>type = "b"</code>. Draw <strong>b</strong>oth points and lines, but don’t overplot.</li>
<li><code>type = "h"</code>. Draw “<strong>h</strong>istogram-like” vertical bars.</li>
<li><code>type = "s"</code>. Draw a <strong>s</strong>taircase, going horizontally then vertically.</li>
<li><code>type = "S"</code>. Draw a <strong>S</strong>taircase, going vertically then horizontally.</li>
<li><code>type = "c"</code>. Draw only the <strong>c</strong>onnecting lines from the “b” version.</li>
<li><code>type = "n"</code>. Draw nothing. (Apparently this is useful sometimes?)</li>
</ul>
<p>The simplest way to illustrate what each of these really looks like is just to draw them. To that end, Figure @ref(fig:simpleplots) shows the same Fibonacci data, drawn using six different <code>types</code> of plot. As you can see, by altering the type argument you can get a qualitatively different appearance to your plot. In other words, as far as R is concerned, the only difference between a scatterplot (like the ones we drew in Section @ref(correl) and a line plot is that you draw a scatterplot by setting <code>type = "p"</code> and you draw a line plot by setting <code>type = "l"</code>. However, that doesn’t imply that <em>you</em> should think of them as begin equivalent to each other. As you can see by looking at Figure @ref(fig:simpleplots), a line plot implies that there is some notion of continuity from one point to the next, whereas a scatterplot does not.</p>
<div class="figure">
<img src="lsr_files/figure-html/simpleplots-1.png" alt="Changing the `type` of the plot." width="672" />
<p class="caption">
(#fig:simpleplots)Changing the <code>type</code> of the plot.
</p>
</div>
</div>
<div id="changing-other-features-of-the-plot" class="section level3">
<h3><span class="header-section-number">6.2.4</span> Changing other features of the plot</h3>
<p>In Section @ref(figtitles) we talked about a group of graphical parameters that are related to the formatting of titles, axis labels etc. The second group of parameters I want to discuss are those related to the formatting of the plot itself:</p>
<ul>
<li><em>Colour of the plot</em>: <code>col</code>. As we saw with the previous colour-related parameters, the simplest way to specify this parameter is using a character string: e.g., <code>col = "blue"</code>. It’s a pretty straightforward parameter to specify: the only real subtlety is that every high-level function tends to draw a different “thing” as it’s output, and so this parameter gets interpreted a little differently by different functions. However, for the <code>plot.default()</code> function it’s pretty simple: the <code>col</code> argument refers to the colour of the points and/or lines that get drawn!</li>
<li><em>Character used to plot points</em>: <code>pch</code>. The <strong>p</strong>lot <strong>ch</strong>aracter parameter is a number, usually between 1 and 25. What it does is tell R what symbol to use to draw the points that it plots. The simplest way to illustrate what the different values do is with a picture. Figure @ref(fig:pch) shows the first 25 plotting characters. The default plotting character is a hollow circle (i.e., <code>pch = 1</code>).</li>
</ul>
<div class="figure">
<img src="lsr_files/figure-html/pch-1.png" alt="Changing the plotted characters" width="672" />
<p class="caption">
(#fig:pch)Changing the plotted characters
</p>
</div>
<ul>
<li><em>Plot size</em>: <code>cex</code>. This parameter describes a <strong>c</strong>haracter <strong>ex</strong>pansion factor (i.e., magnification) for the plotted characters. By default <code>cex=1</code>, but if you want bigger symbols in your graph you should specify a larger value.</li>
<li><em>Line type</em>: <code>lty</code>. The <strong>l</strong>ine <strong>ty</strong>pe parameter describes the kind of line that R draws. It has seven values which you can specify using a number between <code>0</code> and <code>7</code>, or using a meaningful character string: <code>"blank"</code>, <code>"solid"</code>, <code>"dashed"</code>, <code>"dotted"</code>, <code>"dotdash"</code>, <code>"longdash"</code>, or <code>"twodash"</code>. Note that the “blank” version (value 0) just means that R doesn’t draw the lines at all. The other six versions are shown in Figure @ref(fig:lty).</li>
</ul>
<div class="figure">
<img src="lsr_files/figure-html/lty-1.png" alt="Line types" width="672" />
<p class="caption">
(#fig:lty)Line types
</p>
</div>
<ul>
<li><em>Line width</em>: <code>lwd</code>. The last graphical parameter in this category that I want to mention is the <strong>l</strong>ine <strong>w</strong>i<strong>d</strong>th parameter, which is just a number specifying the width of the line. The default value is 1. Not surprisingly, larger values produce thicker lines and smaller values produce thinner lines. Try playing around with different values of <code>lwd</code> to see what happens.</li>
</ul>
<p>To illustrate what you can do by altering these parameters, let’s try the following command, the output is shown in Figure @ref(fig:fifthplot).</p>
<div class="sourceCode" id="cb472"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb472-1" title="1"><span class="kw">plot</span>( <span class="dt">x =</span> Fibonacci,</a>
<a class="sourceLine" id="cb472-2" title="2">         <span class="dt">type =</span> <span class="st">&quot;b&quot;</span>,</a>
<a class="sourceLine" id="cb472-3" title="3">         <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>,</a>
<a class="sourceLine" id="cb472-4" title="4">         <span class="dt">pch =</span> <span class="dv">19</span>,</a>
<a class="sourceLine" id="cb472-5" title="5">         <span class="dt">cex=</span><span class="dv">5</span>,</a>
<a class="sourceLine" id="cb472-6" title="6">         <span class="dt">lty=</span><span class="dv">2</span>,</a>
<a class="sourceLine" id="cb472-7" title="7">         <span class="dt">lwd=</span><span class="dv">4</span>)</a></code></pre></div>
<div class="figure">
<img src="lsr_files/figure-html/fifthplot-1.png" alt="Customising various aspects to the plot itself." width="672" />
<p class="caption">
(#fig:fifthplot)Customising various aspects to the plot itself.
</p>
</div>
</div>
<div id="changing-the-appearance-of-the-axes" class="section level3">
<h3><span class="header-section-number">6.2.5</span> Changing the appearance of the axes</h3>
<p>There are several other possibilities worth discussing. Ignoring graphical parameters for the moment, there’s a few other arguments to the <code>plot.default()</code> function that you might want to use. As before, many of these are standard arguments that are used by a lot of high level graphics functions:</p>
<ul>
<li><em>Changing the axis scales</em>: <code>xlim</code>, <code>ylim</code>. Generally R does a pretty good job of figuring out where to set the edges of the plot. However, you can override its choices by setting the <code>xlim</code> and <code>ylim</code> arguments. For instance, if I decide I want the vertical scale of the plot to run from 0 to 100, then I’d set <code>ylim = c(0, 100)</code>.</li>
<li><em>Suppress labelling</em>: <code>ann</code>. This is a logical-valued argument that you can use if you don’t want R to include any text for a title, subtitle or axis label. To do so, set <code>ann = FALSE</code>. This will stop R from including any text that would normally appear in those places. Note that this will override any of your manual titles. For example, if you try to add a title using the <code>main</code> argument, but you also specify <code>ann = FALSE</code>, no title will appear.</li>
<li><em>Suppress axis drawing</em>: <code>axes</code>. Again, this is a logical valued argument. Suppose you don’t want R to draw any axes at all. To suppress the axes, all you have to do is add <code>axes = FALSE</code>. This will remove the axes and the numbering, but not the axis labels (i.e. the <code>xlab</code> and <code>ylab</code> text). Note that you can get finer grain control over this by specifying the <code>xaxt</code> and <code>yaxt</code> graphical parameters instead (see below).</li>
<li><em>Include a framing box</em>: <code>frame.plot</code>. Suppose you’ve removed the axes by setting <code>axes = FALSE</code>, but you still want to have a simple box drawn around the plot; that is, you only wanted to get rid of the numbering and the tick marks, but you want to keep the box. To do that, you set <code>frame.plot = TRUE</code>.</li>
</ul>
<p>Note that this list isn’t exhaustive. There are a few other arguments to the <code>plot.default</code> function that you can play with if you want to, but those are the ones you are probably most likely to want to use. As always, however, if these aren’t enough options for you, there’s also a number of other graphical parameters that you might want to play with as well. That’s the focus of the next section. In the meantime, here’s a command that makes use of all these different options. The output is shown in Figure @ref(fig:fourthplot), and it’s pretty much exactly as you’d expect. The axis scales on both the horizontal and vertical dimensions have been expanded, the axes have been suppressed as have the annotations, but I’ve kept a box around the plot.</p>
<div class="sourceCode" id="cb473"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb473-1" title="1"><span class="kw">plot</span>( <span class="dt">x =</span> Fibonacci,       <span class="co"># the data</span></a>
<a class="sourceLine" id="cb473-2" title="2">       <span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">15</span>),     <span class="co"># expand the x-scale</span></a>
<a class="sourceLine" id="cb473-3" title="3">       <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">15</span>),     <span class="co"># expand the y-scale</span></a>
<a class="sourceLine" id="cb473-4" title="4">       <span class="dt">ann =</span> <span class="ot">FALSE</span>,         <span class="co"># delete all annotations</span></a>
<a class="sourceLine" id="cb473-5" title="5">       <span class="dt">axes =</span> <span class="ot">FALSE</span>,        <span class="co"># delete the axes</span></a>
<a class="sourceLine" id="cb473-6" title="6">       <span class="dt">frame.plot =</span> <span class="ot">TRUE</span>    <span class="co"># but include a framing box</span></a>
<a class="sourceLine" id="cb473-7" title="7"> )</a></code></pre></div>
<div class="figure">
<img src="lsr_files/figure-html/fourthplot-1.png" alt="Altering the scale and appearance of the plot axes." width="672" />
<p class="caption">
(#fig:fourthplot)Altering the scale and appearance of the plot axes.
</p>
</div>
<p>Before moving on, I should point out that there are several graphical parameters relating to the axes, the box, and the general appearance of the plot which allow finer grain control over the appearance of the axes and the annotations.</p>
<ul>
<li><em>Suppressing the axes individually</em>: <code>xaxt</code>, <code>yaxt</code>. These graphical parameters are basically just fancier versions of the <code>axes</code> argument we discussed earlier. If you want to stop R from drawing the vertical axis but you’d like it to keep the horizontal axis, set <code>yaxt = "n"</code>. I trust that you can figure out how to keep the vertical axis and suppress the horizontal one!</li>
<li><em>Box type</em>: <code>bty</code>. In the same way that <code>xaxt</code>, <code>yaxt</code> are just fancy versions of <code>axes</code>, the <strong>b</strong>ox <strong>ty</strong>pe parameter is really just a fancier version of the <code>frame.plot</code> argument, allowing you to specify exactly which out of the four borders you want to keep. The way we specify this parameter is a bit stupid, in my opinion: the possible values are <code>"o"</code> (the default), <code>"l"</code>, <code>"7"</code>, <code>"c"</code>, <code>"u"</code>, or <code>"]"</code>, each of which will draw only those edges that the corresponding character suggests. That is, the letter <code>"c"</code> has a top, a bottom and a left, but is blank on the right hand side, whereas <code>"7"</code> has a top and a right, but is blank on the left and the bottom. Alternatively a value of <code>"n"</code> means that no box will be drawn.</li>
<li><em>Orientation of the axis labels</em> <code>las</code>. I presume that the name of this parameter is an acronym of <strong>la</strong>bel <strong>s</strong>tyle or something along those lines; but what it actually does is govern the orientation of the text used to label the individual tick marks (i.e., the numbering, not the <code>xlab</code> and <code>ylab</code> axis labels). There are four possible values for <code>las</code>: A value of 0 means that the labels of both axes are printed parallel to the axis itself (the default). A value of 1 means that the text is always horizontal. A value of 2 means that the labelling text is printed at right angles to the axis. Finally, a value of 3 means that the text is always vertical.</li>
</ul>
<p>Again, these aren’t the only possibilities. There are a few other graphical parameters that I haven’t mentioned that you could use to customise the appearance of the axes,<a href="#fn93" class="footnote-ref" id="fnref93"><sup>93</sup></a> but that’s probably enough (or more than enough) for now. To give a sense of how you could use these parameters, let’s try the following command. The output is shown in Figure @ref(fig:sixthplot). As you can see, this isn’t a very useful plot at all. However, it does illustrate the graphical parameters we’re talking about, so I suppose it serves its purpose.</p>
<div class="sourceCode" id="cb474"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb474-1" title="1">    <span class="kw">plot</span>( <span class="dt">x =</span> Fibonacci, <span class="co"># the data</span></a>
<a class="sourceLine" id="cb474-2" title="2">         <span class="dt">xaxt =</span> <span class="st">&quot;n&quot;</span>,       <span class="co"># don&#39;t draw the x-axis  </span></a>
<a class="sourceLine" id="cb474-3" title="3">         <span class="dt">bty =</span> <span class="st">&quot;]&quot;</span>,        <span class="co"># keep bottom, right and top of box only</span></a>
<a class="sourceLine" id="cb474-4" title="4">         <span class="dt">las =</span> <span class="dv">1</span> )         <span class="co"># rotate the text</span></a></code></pre></div>
<div class="figure">
<img src="lsr_files/figure-html/sixthplot-1.png" alt="Other ways to customise the axes" width="672" />
<p class="caption">
(#fig:sixthplot)Other ways to customise the axes
</p>
</div>
</div>
<div id="dont-panic" class="section level3">
<h3><span class="header-section-number">6.2.6</span> Don’t panic</h3>
<p>At this point, a lot of readers will be probably be thinking something along the lines of, “if there’s this much detail just for drawing a simple plot, how horrible is it going to get when we start looking at more complicated things?” Perhaps, contrary to my earlier pleas for mercy, you’ve found a brick to hurl and are right now leafing through an Adelaide phone book trying to find my address. Well, fear not! And please, put the brick down. In a lot of ways, we’ve gone through the hardest part: we’ve already covered vast majority of the plot customisations that you might want to do. As you’ll see, each of the other high level plotting commands we’ll talk about will only have a smallish number of additional options. Better yet, even though I’ve told you about a billion different ways of tweaking your plot, you don’t usually need them. So in practice, now that you’ve read over it once to get the gist, the majority of the content of this section is stuff you can safely forget: just remember to come back to this section later on when you want to tweak your plot.</p>
</div>
</div>
<div id="hist" class="section level2">
<h2><span class="header-section-number">6.3</span> Histograms</h2>
<p>Now that we’ve tamed (or possibly fled from) the beast that is R graphical parameters, let’s talk more seriously about some real life graphics that you’ll want to draw. We begin with the humble <strong><em>histogram</em></strong>. Histograms are one of the simplest and most useful ways of visualising data. They make most sense when you have an interval or ratio scale (e.g., the <code>afl.margins</code> data from Chapter @ref(descriptives) and what you want to do is get an overall impression of the data. Most of you probably know how histograms work, since they’re so widely used, but for the sake of completeness I’ll describe them. All you do is divide up the possible values into <strong><em>bins</em></strong>, and then count the number of observations that fall within each bin. This count is referred to as the frequency of the bin, and is displayed as a bar: in the AFL winning margins data, there are 33 games in which the winning margin was less than 10 points, and it is this fact that is represented by the height of the leftmost bar in Figure @ref(fig:hist1a). Drawing this histogram in R is pretty straightforward. The function you need to use is called <code>hist()</code>, and it has pretty reasonable default settings. In fact, Figure @ref(fig:hist1a) is exactly what you get if you just type this:</p>
<div class="sourceCode" id="cb475"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb475-1" title="1"><span class="kw">hist</span>( afl.margins )</a></code></pre></div>
<div class="figure">
<img src="lsr_files/figure-html/hist1a-1.png" alt="The default histogram that R produces" width="672" />
<p class="caption">
(#fig:hist1a)The default histogram that R produces
</p>
</div>
<p>Although this image would need a lot of cleaning up in order to make a good presentation graphic (i.e., one you’d include in a report), it nevertheless does a pretty good job of describing the data. In fact, the big strength of a histogram is that (properly used) it does show the entire spread of the data, so you can get a pretty good sense about what it looks like. The downside to histograms is that they aren’t very compact: unlike some of the other plots I’ll talk about it’s hard to cram 20-30 histograms into a single image without overwhelming the viewer. And of course, if your data are nominal scale (e.g., the <code>afl.finalists</code> data) then histograms are useless.</p>
<p>The main subtlety that you need to be aware of when drawing histograms is determining where the <code>breaks</code> that separate bins should be located, and (relatedly) how many breaks there should be. In Figure @ref(fig:hist1a), you can see that R has made pretty sensible choices all by itself: the breaks are located at 0, 10, 20, … 120, which is exactly what I would have done had I been forced to make a choice myself. On the other hand, consider the two histograms in Figure @ref(fig:hist1b) and @ref(fig:hist1c), which I produced using the following two commands:</p>
<div class="sourceCode" id="cb476"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb476-1" title="1"><span class="kw">hist</span>( <span class="dt">x =</span> afl.margins, <span class="dt">breaks =</span> <span class="dv">3</span> )</a></code></pre></div>
<div class="figure">
<img src="lsr_files/figure-html/hist1b-1.png" alt="A histogram with too few bins" width="672" />
<p class="caption">
(#fig:hist1b)A histogram with too few bins
</p>
</div>
<div class="sourceCode" id="cb477"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb477-1" title="1"><span class="kw">hist</span>( <span class="dt">x =</span> afl.margins, <span class="dt">breaks =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">116</span> )</a></code></pre></div>
<div class="figure">
<img src="lsr_files/figure-html/hist1c-1.png" alt="A histogram with too many bins" width="672" />
<p class="caption">
(#fig:hist1c)A histogram with too many bins
</p>
</div>
<p>In Figure @ref(fig:hist1c), the bins are only 1 point wide. As a result, although the plot is very informative (it displays the entire data set with no loss of information at all!) the plot is very hard to interpret, and feels quite cluttered. On the other hand, the plot in Figure @ref(fig:hist1b) has a bin width of 50 points, and has the opposite problem: it’s very easy to “read” this plot, but it doesn’t convey a lot of information. One gets the sense that this histogram is hiding too much. In short, the way in which you specify the breaks has a big effect on what the histogram looks like, so it’s important to make sure you choose the breaks sensibly. In general R does a pretty good job of selecting the breaks on its own, since it makes use of some quite clever tricks that statisticians have devised for automatically selecting the right bins for a histogram, but nevertheless it’s usually a good idea to play around with the breaks a bit to see what happens.</p>
<p>There is one fairly important thing to add regarding how the <code>breaks</code> argument works. There are two different ways you can specify the breaks. You can either specify <em>how many</em> breaks you want (which is what I did for panel b when I typed <code>breaks = 3</code>) and let R figure out where they should go, or you can provide a vector that tells R exactly where the breaks should be placed (which is what I did for panel c when I typed <code>breaks = 0:116</code>). The behaviour of the <code>hist()</code> function is slightly different depending on which version you use. If all you do is tell it <em>how many</em> breaks you want, R treats it as a “suggestion” not as a demand. It assumes you want “approximately 3” breaks, but if it doesn’t think that this would look very pretty on screen, it picks a different (but similar) number. It does this for a sensible reason – it tries to make sure that the breaks are located at sensible values (like 10) rather than stupid ones (like 7.224414). And most of the time R is right: usually, when a human researcher says “give me 3 breaks”, he or she really does mean “give me approximately 3 breaks, and don’t put them in stupid places”. However, sometimes R is dead wrong. Sometimes you really do mean “exactly 3 breaks”, and you know precisely where you want them to go. So you need to invoke “real person privilege”, and order R to do what it’s bloody well told. In order to do that, you <em>have</em> to input the full vector that tells R exactly where you want the breaks. If you do that, R will go back to behaving like the nice little obedient calculator that it’s supposed to be.</p>
<div id="visual-style-of-your-histogram" class="section level3">
<h3><span class="header-section-number">6.3.1</span> Visual style of your histogram</h3>
<p>Okay, so at this point we can draw a basic histogram, and we can alter the number and even the location of the <code>breaks</code>. However, the visual style of the histograms shown in Figures @ref(fig:hist1a), @ref(fig:hist1b), and @ref(fig:hist1c) could stand to be improved. We can fix this by making use of some of the other arguments to the <code>hist()</code> function. Most of the things you might want to try doing have already been covered in Section @ref(introplotting), but there’s a few new things:</p>
<ul>
<li><em>Shading lines</em>: <code>density</code>, <code>angle</code>. You can add diagonal lines to shade the bars: the <code>density</code> value is a number indicating how many lines per inch R should draw (the default value of <code>NULL</code> means no lines), and the <code>angle</code> is a number indicating how many degrees from horizontal the lines should be drawn at (default is <code>angle = 45</code> degrees).</li>
<li><em>Specifics regarding colours</em>: <code>col</code>, <code>border</code>. You can also change the colours: in this instance the <code>col</code> parameter sets the colour of the shading (either the shading lines if there are any, or else the colour of the interior of the bars if there are not), and the <code>border</code> argument sets the colour of the edges of the bars.</li>
<li><em>Labelling the bars</em>: <code>labels</code>. You can also attach labels to each of the bars using the <code>labels</code> argument. The simplest way to do this is to set <code>labels = TRUE</code>, in which case R will add a number just above each bar, that number being the exact number of observations in the bin. Alternatively, you can choose the labels yourself, by inputting a vector of strings, e.g., <code>labels = c("label 1","label 2","etc")</code></li>
</ul>
<p>Not surprisingly, this doesn’t exhaust the possibilities. If you type <code>help("hist")</code> or <code>?hist</code> and have a look at the help documentation for histograms, you’ll see a few more options. A histogram that makes use of the histogram-specific customisations as well as several of the options we discussed in Section @ref(introplotting) is shown in Figure @ref(fig:hist1d). The R command that I used to draw it is this:</p>
<div class="sourceCode" id="cb478"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb478-1" title="1"><span class="kw">hist</span>( <span class="dt">x =</span> afl.margins, </a>
<a class="sourceLine" id="cb478-2" title="2">      <span class="dt">main =</span> <span class="st">&quot;2010 AFL margins&quot;</span>, <span class="co"># title of the plot</span></a>
<a class="sourceLine" id="cb478-3" title="3">      <span class="dt">xlab =</span> <span class="st">&quot;Margin&quot;</span>,           <span class="co"># set the x-axis label</span></a>
<a class="sourceLine" id="cb478-4" title="4">      <span class="dt">density =</span> <span class="dv">10</span>,              <span class="co"># draw shading lines: 10 per inch</span></a>
<a class="sourceLine" id="cb478-5" title="5">      <span class="dt">angle =</span> <span class="dv">40</span>,                <span class="co"># set the angle of the shading lines is 40 degrees</span></a>
<a class="sourceLine" id="cb478-6" title="6">      <span class="dt">border =</span> <span class="st">&quot;gray20&quot;</span>,         <span class="co"># set the colour of the borders of the bars</span></a>
<a class="sourceLine" id="cb478-7" title="7">      <span class="dt">col =</span> <span class="st">&quot;gray80&quot;</span>,            <span class="co"># set the colour of the shading lines</span></a>
<a class="sourceLine" id="cb478-8" title="8">      <span class="dt">labels =</span> <span class="ot">TRUE</span>,             <span class="co"># add frequency labels to each bar</span></a>
<a class="sourceLine" id="cb478-9" title="9">      <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">40</span>)             <span class="co"># change the scale of the y-axis</span></a>
<a class="sourceLine" id="cb478-10" title="10">)</a></code></pre></div>
<div class="figure">
<img src="lsr_files/figure-html/hist1d-1.png" alt="A histogram with histogram specific customisations" width="672" />
<p class="caption">
(#fig:hist1d)A histogram with histogram specific customisations
</p>
</div>
<p>Overall, this is a much nicer histogram than the default ones.</p>
</div>
</div>
<div id="stem" class="section level2">
<h2><span class="header-section-number">6.4</span> Stem and leaf plots</h2>
<p>Histograms are one of the most widely used methods for displaying the observed values for a variable. They’re simple, pretty, and very informative. However, they do take a little bit of effort to draw. Sometimes it can be quite useful to make use of simpler, if less visually appealing, options. One such alternative is the <strong><em>stem and leaf plot</em></strong>. To a first approximation you can think of a stem and leaf plot as a kind of text-based histogram. Stem and leaf plots aren’t used as widely these days as they were 30 years ago, since it’s now just as easy to draw a histogram as it is to draw a stem and leaf plot. Not only that, they don’t work very well for larger data sets. As a consequence you probably won’t have as much of a need to use them yourself, though you may run into them in older publications. These days, the only real world situation where I use them is if I have a small data set with 20-30 data points and I don’t have a computer handy, because it’s pretty easy to quickly sketch a stem and leaf plot by hand.</p>
<p>With all that as background, lets have a look at stem and leaf plots. The AFL margins data contains 176 observations, which is at the upper end for what you can realistically plot this way. The function in R for drawing stem and leaf plots is called <code>stem()</code> and if we ask for a stem and leaf plot of the <code>afl.margins</code> data, here’s what we get:</p>
<div class="sourceCode" id="cb479"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb479-1" title="1"><span class="kw">stem</span>( afl.margins )</a></code></pre></div>
<pre><code>## 
##   The decimal point is 1 digit(s) to the right of the |
## 
##    0 | 001111223333333344567788888999999
##    1 | 0000011122234456666899999
##    2 | 00011222333445566667788999999
##    3 | 01223555566666678888899
##    4 | 012334444477788899
##    5 | 00002233445556667
##    6 | 0113455678
##    7 | 01123556
##    8 | 122349
##    9 | 458
##   10 | 148
##   11 | 6</code></pre>
<p>The values to the left of the <code>|</code> are called <strong><em>stems</em></strong> and the values to the right are called <strong><em>leaves</em></strong>. If you just look at the shape that the leaves make, you can see something that looks a lot like a histogram made out of numbers, just rotated by 90 degrees. But if you know how to read the plot, there’s quite a lot of additional information here. In fact, it’s also giving you the actual values of <em>all</em> of the observations in the data set. To illustrate, let’s have a look at the last line in the stem and leaf plot, namely <code>11 | 6</code>. Specifically, let’s compare this to the largest values of the <code>afl.margins</code> data set:</p>
<div class="sourceCode" id="cb481"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb481-1" title="1"><span class="kw">max</span>( afl.margins )</a></code></pre></div>
<pre><code>## [1] 116</code></pre>
<p>Hm… <code>11 | 6</code> versus <code>116</code>. Obviously the stem and leaf plot is trying to tell us that the largest value in the data set is 116. Similarly, when we look at the line that reads <code>10 | 148</code>, the way we interpret it to note that the stem and leaf plot is telling us that the data set contains observations with values 101, 104 and 108. Finally, when we see something like
<code>5 | 00002233445556667</code>
the four <code>0</code>s in the the stem and leaf plot are telling us that there are four observations with value 50.</p>
<p>I won’t talk about them in a lot of detail, but I should point out that some customisation options are available for stem and leaf plots in R. The two arguments that you can use to do this are:</p>
<ul>
<li><code>scale</code>. Changing the <code>scale</code> of the plot (default value is 1), which is analogous to changing the number of breaks in a histogram. Reducing the scale causes R to reduce the number of stem values (i.e., the number of breaks, if this were a histogram) that the plot uses.</li>
<li><code>width</code>. The second way that to can customise a stem and leaf plot is to alter the <code>width</code> (default value is 80). Changing the width alters the maximum number of leaf values that can be displayed for any given stem.</li>
</ul>
<p>However, since stem and leaf plots aren’t as important as they used to be, I’ll leave it to the interested reader to investigate these options. Try the following two commands to see what happens:</p>
<div class="sourceCode" id="cb483"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb483-1" title="1"><span class="kw">stem</span>( <span class="dt">x =</span> afl.margins, <span class="dt">scale =</span> <span class="fl">.25</span> )</a>
<a class="sourceLine" id="cb483-2" title="2"><span class="kw">stem</span>( <span class="dt">x =</span> afl.margins, <span class="dt">width =</span> <span class="dv">20</span> )</a></code></pre></div>
<p>The only other thing to note about stem and leaf plots is the line in which R tells you where the decimal point is. If our data set had included only the numbers .11, .15, .23, .35 and .59 and we’d drawn a stem and leaf plot of these data, then R would move the decimal point: the stem values would be 1,2,3,4 and 5, but R would tell you that the decimal point has moved to the left of the <code>|</code> symbol. If you want to see this in action, try the following command:</p>
<div class="sourceCode" id="cb484"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb484-1" title="1"><span class="kw">stem</span>( <span class="dt">x =</span> afl.margins <span class="op">/</span><span class="st"> </span><span class="dv">1000</span> )</a></code></pre></div>
<p>The stem and leaf plot itself will look identical to the original one we drew, except for the fact that R will tell you that the decimal point has moved.</p>
</div>
<div id="boxplots" class="section level2">
<h2><span class="header-section-number">6.5</span> Boxplots</h2>
<p>Another alternative to histograms is a <strong><em>boxplot</em></strong>, sometimes called a “box and whiskers” plot. Like histograms, they’re most suited to interval or ratio scale data. The idea behind a boxplot is to provide a simple visual depiction of the median, the interquartile range, and the range of the data. And because they do so in a fairly compact way, boxplots have become a very popular statistical graphic, especially during the exploratory stage of data analysis when you’re trying to understand the data yourself. Let’s have a look at how they work, again using the <code>afl.margins</code> data as our example. Firstly, let’s actually calculate these numbers ourselves using the <code>summary()</code> function:<a href="#fn94" class="footnote-ref" id="fnref94"><sup>94</sup></a></p>
<div class="sourceCode" id="cb485"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb485-1" title="1"><span class="kw">summary</span>( afl.margins )</a></code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    0.00   12.75   30.50   35.30   50.50  116.00</code></pre>
<p>So how does a boxplot capture these numbers? The easiest way to describe what a boxplot looks like is just to draw one. The function for doing this in R is (surprise, surprise) <code>boxplot()</code>. As always there’s a lot of optional arguments that you can specify if you want, but for the most part you can just let R choose the defaults for you. That said, I’m going to override one of the defaults to start with by specifying the <code>range</code> option, but for the most part you won’t want to do this (I’ll explain why in a minute). With that as preamble, let’s try the following command:</p>
<div class="sourceCode" id="cb487"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb487-1" title="1"><span class="kw">boxplot</span>( <span class="dt">x =</span> afl.margins, <span class="dt">range =</span> <span class="dv">100</span> )</a></code></pre></div>
<div class="figure">
<img src="lsr_files/figure-html/boxplot1a-1.png" alt="A basic boxplot" width="672" />
<p class="caption">
(#fig:boxplot1a)A basic boxplot
</p>
</div>
<p>What R draws is shown in Figure @ref(fig:boxplot1a), the most basic boxplot possible. When you look at this plot, this is how you should interpret it: the thick line in the middle of the box is the median; the box itself spans the range from the 25th percentile to the 75th percentile; and the “whiskers” cover the full range from the minimum value to the maximum value. This is summarised in the annotated plot in Figure @ref(fig:boxplot1b).</p>
<div class="figure">
<img src="img/graphics2/boxplot1_annotated.png" alt="An annotated boxplot" width="300" />
<p class="caption">
(#fig:boxplot1b)An annotated boxplot
</p>
</div>
<p>In practice, this isn’t quite how boxplots usually work. In most applications, the “whiskers” don’t cover the full range from minimum to maximum. Instead, they actually go out to the most extreme data point that doesn’t exceed a certain bound. By default, this value is 1.5 times the interquartile range, corresponding to a <code>range</code> value of 1.5. Any observation whose value falls outside this range is plotted as a circle instead of being covered by the whiskers, and is commonly referred to as an <strong><em>outlier</em></strong>. For our AFL margins data, there is one observation (a game with a margin of 116 points) that falls outside this range. As a consequence, the upper whisker is pulled back to the next largest observation (a value of 108), and the observation at 116 is plotted as a circle. This is illustrated in Figure @ref(fig:boxplot2a). Since the default value is <code>range = 1.5</code> we can draw this plot using the simple command</p>
<div class="sourceCode" id="cb488"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb488-1" title="1"><span class="kw">boxplot</span>( afl.margins )</a></code></pre></div>
<div class="figure">
<img src="lsr_files/figure-html/boxplot2a-1.png" alt="By default, R will only extent the whiskers a distance of 1.5 times the interquartile range, and will plot any points that fall outside that range separately" width="672" />
<p class="caption">
(#fig:boxplot2a)By default, R will only extent the whiskers a distance of 1.5 times the interquartile range, and will plot any points that fall outside that range separately
</p>
</div>
<div id="visual-style-of-your-boxplot" class="section level3">
<h3><span class="header-section-number">6.5.1</span> Visual style of your boxplot</h3>
<p>I’ll talk a little more about the relationship between boxplots and outliers in the Section @ref(boxplotoutliers), but before I do let’s take the time to clean this figure up. Boxplots in R are extremely customisable. In addition to the usual range of graphical parameters that you can tweak to make the plot look nice, you can also exercise nearly complete control over every element to the plot. Consider the boxplot in Figure @ref(fig:boxplot2b): in this version of the plot, not only have I added labels (<code>xlab</code>, <code>ylab</code>) and removed the stupid border (<code>frame.plot</code>), I’ve also dimmed all of the graphical elements of the boxplot except the central bar that plots the median (<code>border</code>) so as to draw more attention to the median rather than the rest of the boxplot.</p>
<div class="figure">
<img src="lsr_files/figure-html/boxplot2b-1.png" alt="A boxplot with boxplot specific customisations" width="672" />
<p class="caption">
(#fig:boxplot2b)A boxplot with boxplot specific customisations
</p>
</div>
<p>You’ve seen all these options in previous sections in this chapter, so hopefully those customisations won’t need any further explanation. However, I’ve done two new things as well: I’ve deleted the cross-bars at the top and bottom of the whiskers (known as the “staples” of the plot), and converted the whiskers themselves to solid lines. The arguments that I used to do this are called by the ridiculous names of <code>staplewex</code> and <code>whisklty</code>,<a href="#fn95" class="footnote-ref" id="fnref95"><sup>95</sup></a> and I’ll explain these in a moment.</p>
<p>But first, here’s the actual command I used to draw this figure:</p>
<div class="sourceCode" id="cb489"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb489-1" title="1"><span class="kw">boxplot</span>( <span class="dt">x =</span> afl.margins,           <span class="co"># the data</span></a>
<a class="sourceLine" id="cb489-2" title="2">          <span class="dt">xlab =</span> <span class="st">&quot;AFL games, 2010&quot;</span>,  <span class="co"># x-axis label</span></a>
<a class="sourceLine" id="cb489-3" title="3">          <span class="dt">ylab =</span> <span class="st">&quot;Winning Margin&quot;</span>,   <span class="co"># y-axis label</span></a>
<a class="sourceLine" id="cb489-4" title="4">          <span class="dt">border =</span> <span class="st">&quot;grey50&quot;</span>,         <span class="co"># dim the border of the box</span></a>
<a class="sourceLine" id="cb489-5" title="5">          <span class="dt">frame.plot =</span> <span class="ot">FALSE</span>,        <span class="co"># don&#39;t draw a frame</span></a>
<a class="sourceLine" id="cb489-6" title="6">          <span class="dt">staplewex =</span> <span class="dv">0</span>,             <span class="co"># don&#39;t draw staples</span></a>
<a class="sourceLine" id="cb489-7" title="7">          <span class="dt">whisklty =</span> <span class="dv">1</span>               <span class="co"># solid line for whisker </span></a>
<a class="sourceLine" id="cb489-8" title="8"> )</a></code></pre></div>
<p>Overall, I think the resulting boxplot is a huge improvement in visual design over the default version. In my opinion at least, there’s a fairly minimalist aesthetic that governs good statistical graphics. Ideally, every visual element that you add to a plot should convey part of the message. If your plot includes things that don’t actually help the reader learn anything new, you should consider removing them. Personally, I can’t see the point of the cross-bars on a standard boxplot, so I’ve deleted them.</p>
<p>Okay, what commands can we use to customise the boxplot? If you type <code>?boxplot</code> and flick through the help documentation, you’ll notice that it does mention <code>staplewex</code> as an argument, but there’s no mention of <code>whisklty</code>. The reason for this is that the function that handles the drawing is called <code>bxp()</code>, so if you type <code>?bxp</code> all the gory details appear. Here’s the short summary. In order to understand why these arguments have such stupid names, you need to recognise that they’re put together from two components. The first part of the argument name specifies one part of the box plot: <code>staple</code> refers to the staples of the plot (i.e., the cross-bars), and <code>whisk</code> refers to the whiskers. The second part of the name specifies a graphical parameter: <code>wex</code> is a width parameter, and <code>lty</code> is a line type parameter. The parts of the plot you can customise are:</p>
<ul>
<li><code>box</code>. The box that covers the interquartile range.</li>
<li><code>med</code>. The line used to show the median.</li>
<li><code>whisk</code>. The vertical lines used to draw the whiskers.</li>
<li><code>staple</code>. The cross bars at the ends of the whiskers.</li>
<li><code>out</code>. The points used to show the outliers.</li>
</ul>
<p>The actual graphical parameters that you might want to specify are slightly different for each visual element, just because they’re different shapes from each other. As a consequence, the following options are available:</p>
<ul>
<li><em>Width expansion:</em> <code>boxwex, staplewex, outwex</code>. These are scaling factors that govern the width of various parts of the plot. The default scaling factor is (usually) 0.8 for the box, and 0.5 for the other two. Note that in the case of the outliers this parameter is meaningless unless you decide to draw lines plotting the outliers rather than use points.</li>
<li><em>Line type:</em> <code>boxlty, medlty, whisklty, staplelty, outlty</code>. These govern the line type for the relevant elements. The values for this are exactly the same as those used for the regular <code>lty</code> parameter, with two exceptions. There’s an additional option where you can set <code>medlty = "blank"</code> to suppress the median line completely (useful if you want to draw a point for the median rather than plot a line). Similarly, by default the outlier line type is set to <code>outlty = "blank"</code>, because the default behaviour is to draw outliers as points instead of lines.</li>
<li><em>Line width:</em> <code>boxlwd, medlwd, whisklwd, staplelwd, outlwd</code>. These govern the line widths for the relevant elements, and behave the same way as the regular <code>lwd</code> parameter. The only thing to note is that the default value for <code>medlwd</code> value is three times the value of the others.</li>
<li><em>Line colour:</em> <code>boxcol, medcol, whiskcol, staplecol, outcol</code>. These govern the colour of the lines used to draw the relevant elements. Specify a colour in the same way that you usually do.</li>
<li><em>Fill colour:</em> <code>boxfill</code>. What colour should we use to fill the box?</li>
<li><em>Point character:</em> <code>medpch, outpch</code>. These behave like the regular <code>pch</code> parameter used to select the plot character. Note that you can set <code>outpch = NA</code> to stop R from plotting the outliers at all, and you can also set <code>medpch = NA</code> to stop it from drawing a character for the median (this is the default!)</li>
<li><em>Point expansion:</em> <code>medcex, outcex</code>. Size parameters for the points used to plot medians and outliers. These are only meaningful if the corresponding points are actually plotted. So for the default boxplot, which includes outlier points but uses a line rather than a point to draw the median, only the <code>outcex</code> parameter is meaningful.</li>
<li><em>Background colours:</em> <code>medbg, outbg</code>. Again, the background colours are only meaningful if the points are actually plotted.</li>
</ul>
<p>Taken as a group, these parameters allow you almost complete freedom to select the graphical style for your boxplot that you feel is most appropriate to the data set you’re trying to describe. That said, when you’re first starting out there’s no shame in using the default settings! But if you want to master the art of designing beautiful figures, it helps to try playing around with these parameters to see what works and what doesn’t. Finally, I should mention a few other arguments that you might want to make use of:</p>
<ul>
<li><code>horizontal</code>. Set this to <code>TRUE</code> to display the plot horizontally rather than vertically.</li>
<li><code>varwidth</code>. Set this to <code>TRUE</code> to get R to scale the width of each box so that the areas are proportional to the number of observations that contribute to the boxplot. This is only useful if you’re drawing multiple boxplots at once (see Section @ref(multipleboxplots).</li>
<li><code>show.names</code>. Set this to <code>TRUE</code> to get R to attach labels to the boxplots.</li>
<li><code>notch</code>. If you set <code>notch = TRUE</code>, R will draw little notches in the sides of each box. If the notches of two boxplots don’t overlap, then there is a “statistically significant” difference between the corresponding medians. If you haven’t read Chapter @ref(hypothesistesting), ignore this argument – we haven’t discussed statistical significance, so this doesn’t mean much to you. I’m mentioning it only because you might want to come back to the topic later on. (see also the <code>notch.frac</code> option when you type <code>?bxp</code>).</li>
</ul>
</div>
<div id="boxplotoutliers" class="section level3">
<h3><span class="header-section-number">6.5.2</span> Using box plots to detect outliers</h3>
<p>Because the boxplot automatically (unless you change the <code>range</code> argument) separates out those observations that lie within a certain range, people often use them as an informal method for detecting <strong><em>outliers</em></strong>: observations that are “suspiciously” distant from the rest of the data. Here’s an example. Suppose that I’d drawn the boxplot for the AFL margins data, and it came up looking like Figure @ref(fig:boxplotoutlier).</p>
<div class="figure">
<img src="lsr_files/figure-html/boxplotoutlier-1.png" alt="A boxplot showing one very suspicious outlier! I've drawn this plot in a similar, minimalist style to the one in Figure \@ref(fig:boxplot2b), but I've used the `horizontal` argument to draw it sideways in order to save space." width="672" />
<p class="caption">
(#fig:boxplotoutlier)A boxplot showing one very suspicious outlier! I’ve drawn this plot in a similar, minimalist style to the one in Figure @ref(fig:boxplot2b), but I’ve used the <code>horizontal</code> argument to draw it sideways in order to save space.
</p>
</div>
<p>It’s pretty clear that something funny is going on with one of the observations. Apparently, there was one game in which the margin was over 300 points! That doesn’t sound right to me. Now that I’ve become suspicious, it’s time to look a bit more closely at the data. One function that can be handy for this is the <code>which()</code> function; it takes as input a vector of logicals, and outputs the indices of the <code>TRUE</code> cases. This is particularly useful in the current context because it lets me do this:</p>
<div class="sourceCode" id="cb490"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb490-1" title="1">suspicious.cases &lt;-<span class="st"> </span>afl.margins <span class="op">&gt;</span><span class="st"> </span><span class="dv">300</span></a>
<a class="sourceLine" id="cb490-2" title="2"><span class="kw">which</span>( suspicious.cases )</a></code></pre></div>
<pre><code>## [1] 137</code></pre>
<p>although in real life I probably wouldn’t bother creating the <code>suspicious.cases</code> variable: I’d just cut out the middle man and use a command like <code>which( afl.margins &gt; 300 )</code>. In any case, what this has done is shown me that the outlier corresponds to game 137. Then, I find the recorded margin for that game:</p>
<div class="sourceCode" id="cb492"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb492-1" title="1">afl.margins[<span class="dv">137</span>]</a></code></pre></div>
<pre><code>## [1] 333</code></pre>
<p>Hm. That definitely doesn’t sound right. So then I go back to the original data source (the internet!) and I discover that the actual margin of that game was 33 points. Now it’s pretty clear what happened. Someone must have typed in the wrong number. Easily fixed, just by typing <code>afl.margins[137] &lt;- 33</code>. While this might seem like a silly example, I should stress that this kind of thing actually happens a lot. Real world data sets are often riddled with stupid errors, especially when someone had to type something into a computer at some point. In fact, there’s actually a name for this phase of data analysis, since in practice it can waste a huge chunk of our time: <strong><em>data cleaning</em></strong>. It involves searching for typos, missing data and all sorts of other obnoxious errors in raw data files.<a href="#fn96" class="footnote-ref" id="fnref96"><sup>96</sup></a></p>
<p>What about the real data? Does the value of 116 constitute a funny observation not? Possibly. As it turns out the game in question was Fremantle v Hawthorn, and was played in round 21 (the second last home and away round of the season). Fremantle had already qualified for the final series and for them the outcome of the game was irrelevant; and the team decided to rest several of their star players. As a consequence, Fremantle went into the game severely underpowered. In contrast, Hawthorn had started the season very poorly but had ended on a massive winning streak, and for them a win could secure a place in the finals. With the game played on Hawthorn’s home turf<a href="#fn97" class="footnote-ref" id="fnref97"><sup>97</sup></a> and with so many unusual factors at play, it is perhaps no surprise that Hawthorn annihilated Fremantle by 116 points. Two weeks later, however, the two teams met again in an elimination final on Fremantle’s home ground, and Fremantle won comfortably by 30 points.<a href="#fn98" class="footnote-ref" id="fnref98"><sup>98</sup></a></p>
<p>So, should we exclude the game from subsequent analyses? If this were a psychology experiment rather than an AFL season, I’d be quite tempted to exclude it because there’s pretty strong evidence that Fremantle weren’t really trying very hard: and to the extent that my research question is based on an assumption that participants are genuinely trying to do the task. On the other hand, in a lot of studies we’re actually interested in seeing the full range of possible behaviour, and that includes situations where people decide not to try very hard: so excluding that observation would be a bad idea. In the context of the AFL data, a similar distinction applies. If I’d been trying to make tips about who would perform well in the finals, I would have (and in fact did) disregard the Round 21 massacre, because it’s way too misleading. On the other hand, if my interest is solely in the home and away season itself, I think it would be a shame to throw away information pertaining to one of the most distinctive (if boring) games of the year. In other words, the decision about whether to include outliers or exclude them depends heavily on <em>why</em> you think the data look they way they do, and what you want to use the data <em>for</em>. Statistical tools can provide an automatic method for suggesting candidates for deletion, but you really need to exercise good judgment here. As I’ve said before, R is a mindless automaton. It doesn’t watch the footy, so it lacks the broader context to make an informed decision. You are <em>not</em> a mindless automaton, so you should exercise judgment: if the outlier looks legitimate to you, then keep it. In any case, I’ll return to the topic again in Section @ref(regressiondiagnostics), so let’s return to our discussion of how to draw boxplots.</p>
</div>
<div id="multipleboxplots" class="section level3">
<h3><span class="header-section-number">6.5.3</span> Drawing multiple boxplots</h3>
<p>One last thing. What if you want to draw multiple boxplots at once? Suppose, for instance, I wanted separate boxplots showing the AFL margins not just for 2010, but for every year between 1987 and 2010. To do that, the first thing we’ll have to do is find the data. These are stored in the <code>aflsmall2.Rdata</code> file. So let’s load it and take a quick peek at what’s inside:</p>
<div class="sourceCode" id="cb494"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb494-1" title="1"><span class="kw">load</span>( <span class="st">&quot;aflsmall2.Rdata&quot;</span> )</a>
<a class="sourceLine" id="cb494-2" title="2"><span class="kw">who</span>( <span class="ot">TRUE</span> )</a>
<a class="sourceLine" id="cb494-3" title="3"><span class="co">#   -- Name --   -- Class --   -- Size --</span></a>
<a class="sourceLine" id="cb494-4" title="4"><span class="co">#   afl2         data.frame    4296 x 2  </span></a>
<a class="sourceLine" id="cb494-5" title="5"><span class="co">#    $margin     numeric       4296      </span></a>
<a class="sourceLine" id="cb494-6" title="6"><span class="co">#    $year       numeric       4296     </span></a></code></pre></div>
<p>Notice that <code>afl2</code> data frame is pretty big. It contains 4296 games, which is far more than I want to see printed out on my computer screen. To that end, R provides you with a few useful functions to print out only a few of the row in the data frame. The first of these is <code>head()</code> which prints out the first 6 rows, of the data frame, like this:</p>
<div class="sourceCode" id="cb495"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb495-1" title="1"><span class="kw">head</span>( afl2 )</a></code></pre></div>
<pre><code>##   margin year
## 1     33 1987
## 2     59 1987
## 3     45 1987
## 4     91 1987
## 5     39 1987
## 6      1 1987</code></pre>
<p>You can also use the <code>tail()</code> function to print out the last 6 rows. The <code>car</code> package also provides a handy little function called <code>some()</code> which prints out a random subset of the rows.</p>
<p>In any case, the important thing is that we have the <code>afl2</code> data frame which contains the variables that we’re interested in. What we want to do is have R draw boxplots for the <code>margin</code> variable, plotted separately for each separate <code>year</code>. The way to do this using the <code>boxplot()</code> function is to input a <code>formula</code> rather than a variable as the input. In this case, the formula we want is <code>margin ~ year</code>. So our boxplot command now looks like this. The result is shown in Figure @ref(fig:multipleboxplots).<a href="#fn99" class="footnote-ref" id="fnref99"><sup>99</sup></a></p>
<div class="sourceCode" id="cb497"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb497-1" title="1"><span class="kw">boxplot</span>( <span class="dt">formula =</span> margin <span class="op">~</span><span class="st"> </span>year,</a>
<a class="sourceLine" id="cb497-2" title="2">         <span class="dt">data =</span> afl2</a>
<a class="sourceLine" id="cb497-3" title="3">)</a></code></pre></div>
<div class="figure">
<img src="lsr_files/figure-html/multipleboxplots-1.png" alt="Boxplots showing the AFL winning margins for the 24 years from 1987 to 2010 inclusive. This is the default plot created by R, with no annotations added and no changes to the visual design. It's pretty readable, though at a minimum you'd want to include some basic annotations labelling the axes. Compare and contrast with Figure \@ref(fig:multipleboxplots2)" width="672" />
<p class="caption">
(#fig:multipleboxplots)Boxplots showing the AFL winning margins for the 24 years from 1987 to 2010 inclusive. This is the default plot created by R, with no annotations added and no changes to the visual design. It’s pretty readable, though at a minimum you’d want to include some basic annotations labelling the axes. Compare and contrast with Figure @ref(fig:multipleboxplots2)
</p>
</div>
<p>Even this, the default version of the plot, gives a sense of why it’s sometimes useful to choose boxplots instead of histograms. Even before taking the time to turn this basic output into something more readable, it’s possible to get a good sense of what the data look like from year to year without getting overwhelmed with too much detail. Now imagine what would have happened if I’d tried to cram 24 histograms into this space: no chance at all that the reader is going to learn anything useful.</p>
<p>That being said, the default boxplot leaves a great deal to be desired in terms of visual clarity. The outliers are too visually prominent, the dotted lines look messy, and the interesting content (i.e., the behaviour of the median and the interquartile range across years) gets a little obscured. Fortunately, this is easy to fix, since we’ve already covered a lot of tools you can use to customise your output. After playing around with several different versions of the plot, the one I settled on is shown in Figure @ref(fig:multipleboxplots2). The command I used to produce it is long, but not complicated:</p>
<div class="sourceCode" id="cb498"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb498-1" title="1"><span class="kw">boxplot</span>( <span class="dt">formula =</span>  margin <span class="op">~</span><span class="st"> </span>year,   <span class="co"># the formula</span></a>
<a class="sourceLine" id="cb498-2" title="2">           <span class="dt">data =</span> afl2,                <span class="co"># the data set</span></a>
<a class="sourceLine" id="cb498-3" title="3">           <span class="dt">xlab =</span> <span class="st">&quot;AFL season&quot;</span>,        <span class="co"># x axis label</span></a>
<a class="sourceLine" id="cb498-4" title="4">           <span class="dt">ylab =</span> <span class="st">&quot;Winning Margin&quot;</span>,    <span class="co"># y axis label</span></a>
<a class="sourceLine" id="cb498-5" title="5">           <span class="dt">frame.plot =</span> <span class="ot">FALSE</span>,         <span class="co"># don&#39;t draw a frame</span></a>
<a class="sourceLine" id="cb498-6" title="6">           <span class="dt">staplewex =</span> <span class="dv">0</span>,              <span class="co"># don&#39;t draw staples</span></a>
<a class="sourceLine" id="cb498-7" title="7">           <span class="dt">staplecol =</span> <span class="st">&quot;white&quot;</span>,        <span class="co"># (fixes a tiny display issue)</span></a>
<a class="sourceLine" id="cb498-8" title="8">           <span class="dt">boxwex =</span> <span class="fl">.75</span>,               <span class="co"># narrow the boxes slightly</span></a>
<a class="sourceLine" id="cb498-9" title="9">           <span class="dt">boxfill =</span> <span class="st">&quot;grey80&quot;</span>,         <span class="co"># lightly shade the boxes</span></a>
<a class="sourceLine" id="cb498-10" title="10">           <span class="dt">whisklty =</span> <span class="dv">1</span>,               <span class="co"># solid line for whiskers </span></a>
<a class="sourceLine" id="cb498-11" title="11">           <span class="dt">whiskcol =</span> <span class="st">&quot;grey70&quot;</span>,        <span class="co"># dim the whiskers</span></a>
<a class="sourceLine" id="cb498-12" title="12">           <span class="dt">boxcol =</span> <span class="st">&quot;grey70&quot;</span>,          <span class="co"># dim the box borders</span></a>
<a class="sourceLine" id="cb498-13" title="13">           <span class="dt">outcol =</span> <span class="st">&quot;grey70&quot;</span>,          <span class="co"># dim the outliers</span></a>
<a class="sourceLine" id="cb498-14" title="14">           <span class="dt">outpch =</span> <span class="dv">20</span>,                <span class="co"># outliers as solid dots</span></a>
<a class="sourceLine" id="cb498-15" title="15">           <span class="dt">outcex =</span> <span class="fl">.5</span>,                <span class="co"># shrink the outliers</span></a>
<a class="sourceLine" id="cb498-16" title="16">           <span class="dt">medlty =</span> <span class="st">&quot;blank&quot;</span>,           <span class="co"># no line for the medians</span></a>
<a class="sourceLine" id="cb498-17" title="17">           <span class="dt">medpch =</span> <span class="dv">20</span>,                <span class="co"># instead, draw solid dots</span></a>
<a class="sourceLine" id="cb498-18" title="18">           <span class="dt">medlwd =</span> <span class="fl">1.5</span>                <span class="co"># make them larger</span></a>
<a class="sourceLine" id="cb498-19" title="19"> )</a></code></pre></div>
<div class="figure">
<img src="lsr_files/figure-html/multipleboxplots2-1.png" alt="A cleaned up version of Figure \@ref(fig:multipleboxplots). Notice that I've used a very minimalist design for the boxplots, so as to focus the eye on the medians. I've also converted the medians to solid dots, to convey a sense that year to year variation in the median should be thought of as a single coherent plot (similar to what we did when plotting the `Fibonacci` variable earlier). The size of outliers has been shrunk, because they aren't actually very interesting. In contrast, I've added a fill colour to the boxes, to make it easier to look at the trend in the interquartile range across years." width="672" />
<p class="caption">
(#fig:multipleboxplots2)A cleaned up version of Figure @ref(fig:multipleboxplots). Notice that I’ve used a very minimalist design for the boxplots, so as to focus the eye on the medians. I’ve also converted the medians to solid dots, to convey a sense that year to year variation in the median should be thought of as a single coherent plot (similar to what we did when plotting the <code>Fibonacci</code> variable earlier). The size of outliers has been shrunk, because they aren’t actually very interesting. In contrast, I’ve added a fill colour to the boxes, to make it easier to look at the trend in the interquartile range across years.
</p>
</div>
<p>Of course, given that the command is that long, you might have guessed that I didn’t spend ages typing all that rubbish in over and over again. Instead, I wrote a script, which I kept tweaking until it produced the figure that I wanted. We’ll talk about scripts later in Section @ref(scripts), but given the length of the command I thought I’d remind you that there’s an easier way of trying out different commands than typing them all in over and over.</p>
</div>
</div>
<div id="scatterplots" class="section level2">
<h2><span class="header-section-number">6.6</span> Scatterplots</h2>
<p><strong><em>Scatterplots</em></strong> are a simple but effective tool for visualising data. We’ve already seen scatterplots in this chapter, when using the <code>plot()</code> function to draw the <code>Fibonacci</code> variable as a collection of dots (Section @ref(introplotting). However, for the purposes of this section I have a slightly different notion in mind. Instead of just plotting one variable, what I want to do with my scatterplot is display the relationship between <em>two</em> variables, like we saw with the figures in the section on correlation (Section @ref(correl). It’s this latter application that we usually have in mind when we use the term “scatterplot”. In this kind of plot, each observation corresponds to one dot: the horizontal location of the dot plots the value of the observation on one variable, and the vertical location displays its value on the other variable. In many situations you don’t really have a clear opinions about what the <em>causal</em> relationship is (e.g., does A cause B, or does B cause A, or does some other variable C control both A and B). If that’s the case, it doesn’t really matter which variable you plot on the x-axis and which one you plot on the y-axis. However, in many situations you do have a pretty strong idea which variable you think is most likely to be causal, or at least you have some suspicions in that direction. If so, then it’s conventional to plot the cause variable on the x-axis, and the effect variable on the y-axis. With that in mind, let’s look at how to draw scatterplots in R, using the same <code>parenthood</code> data set (i.e. <code>parenthood.Rdata</code>) that I used when introducing the idea of correlations.</p>
<p>Suppose my goal is to draw a scatterplot displaying the relationship between the amount of sleep that I get (<code>dan.sleep</code>) and how grumpy I am the next day (<code>dan.grump</code>). As you might expect given our earlier use of <code>plot()</code> to display the <code>Fibonacci</code> data, the function that we use is the <code>plot()</code> function, but because it’s a generic function all the hard work is still being done by the <code>plot.default()</code> function. In any case, there are two different ways in which we can get the plot that we’re after. The first way is to specify the name of the variable to be plotted on the <code>x</code> axis and the variable to be plotted on the <code>y</code> axis. When we do it this way, the command looks like this:</p>
<div class="sourceCode" id="cb499"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb499-1" title="1"><span class="kw">plot</span>( <span class="dt">x =</span> parenthood<span class="op">$</span>dan.sleep,   <span class="co"># data on the x-axis</span></a>
<a class="sourceLine" id="cb499-2" title="2">      <span class="dt">y =</span> parenthood<span class="op">$</span>dan.grump    <span class="co"># data on the y-axis</span></a>
<a class="sourceLine" id="cb499-3" title="3"> )  </a></code></pre></div>
<div class="figure">
<img src="lsr_files/figure-html/scattera-1.png" alt="the default scatterplot that R produces" width="672" />
<p class="caption">
(#fig:scattera)the default scatterplot that R produces
</p>
</div>
<p>The second way do to it is to use a “formula and data frame” format, but I’m going to avoid using it.<a href="#fn100" class="footnote-ref" id="fnref100"><sup>100</sup></a> For now, let’s just stick with the <code>x</code> and <code>y</code> version. If we do this, the result is the very basic scatterplot shown in Figure @ref(fig:scattera). This serves fairly well, but there’s a few customisations that we probably want to make in order to have this work properly. As usual, we want to add some labels, but there’s a few other things we might want to do as well. Firstly, it’s sometimes useful to rescale the plots. In Figure @ref(fig:scattera) R has selected the scales so that the data fall neatly in the middle. But, in this case, we happen to know that the grumpiness measure falls on a scale from 0 to 100, and the hours slept falls on a natural scale between 0 hours and about 12 or so hours (the longest I can sleep in real life). So the command I might use to draw this is:</p>
<div class="sourceCode" id="cb500"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb500-1" title="1"><span class="kw">plot</span>( <span class="dt">x =</span> parenthood<span class="op">$</span>dan.sleep,          <span class="co"># data on the x-axis</span></a>
<a class="sourceLine" id="cb500-2" title="2">       <span class="dt">y =</span> parenthood<span class="op">$</span>dan.grump,         <span class="co"># data on the y-axis</span></a>
<a class="sourceLine" id="cb500-3" title="3">       <span class="dt">xlab =</span> <span class="st">&quot;My sleep (hours)&quot;</span>,        <span class="co"># x-axis label</span></a>
<a class="sourceLine" id="cb500-4" title="4">       <span class="dt">ylab =</span> <span class="st">&quot;My grumpiness (0-100)&quot;</span>,   <span class="co"># y-axis label</span></a>
<a class="sourceLine" id="cb500-5" title="5">       <span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">12</span>),                   <span class="co"># scale the x-axis</span></a>
<a class="sourceLine" id="cb500-6" title="6">       <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">100</span>),                  <span class="co"># scale the y-axis</span></a>
<a class="sourceLine" id="cb500-7" title="7">       <span class="dt">pch =</span> <span class="dv">20</span>,                         <span class="co"># change the plot type</span></a>
<a class="sourceLine" id="cb500-8" title="8">       <span class="dt">col =</span> <span class="st">&quot;gray50&quot;</span>,                   <span class="co"># dim the dots slightly</span></a>
<a class="sourceLine" id="cb500-9" title="9">       <span class="dt">frame.plot =</span> <span class="ot">FALSE</span>                <span class="co"># don&#39;t draw a box</span></a>
<a class="sourceLine" id="cb500-10" title="10"> )</a></code></pre></div>
<p>This command produces the scatterplot in Figure @ref(fig:scatterb), or at least very nearly. What it doesn’t do is draw the line through the middle of the points. Sometimes it can be very useful to do this, and I can do so using <code>lines()</code>, which is a low level plotting function. Better yet, the arguments that I need to specify are pretty much the exact same ones that I use when calling the <code>plot()</code> function. That is, suppose that I want to draw a line that goes from the point (4,93) to the point (9.5,37). Then the <code>x</code> locations can be specified by the vector <code>c(4,9.5)</code> and the <code>y</code> locations correspond to the vector <code>c(93,37)</code>. In other words, I use this command:</p>
<div class="sourceCode" id="cb501"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb501-1" title="1"><span class="kw">plot</span>( <span class="dt">x =</span> parenthood<span class="op">$</span>dan.sleep,          <span class="co"># data on the x-axis</span></a>
<a class="sourceLine" id="cb501-2" title="2">       <span class="dt">y =</span> parenthood<span class="op">$</span>dan.grump,         <span class="co"># data on the y-axis</span></a>
<a class="sourceLine" id="cb501-3" title="3">       <span class="dt">xlab =</span> <span class="st">&quot;My sleep (hours)&quot;</span>,        <span class="co"># x-axis label</span></a>
<a class="sourceLine" id="cb501-4" title="4">       <span class="dt">ylab =</span> <span class="st">&quot;My grumpiness (0-100)&quot;</span>,   <span class="co"># y-axis label</span></a>
<a class="sourceLine" id="cb501-5" title="5">       <span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">12</span>),                   <span class="co"># scale the x-axis</span></a>
<a class="sourceLine" id="cb501-6" title="6">       <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">100</span>),                  <span class="co"># scale the y-axis</span></a>
<a class="sourceLine" id="cb501-7" title="7">       <span class="dt">pch =</span> <span class="dv">20</span>,                         <span class="co"># change the plot type</span></a>
<a class="sourceLine" id="cb501-8" title="8">       <span class="dt">col =</span> <span class="st">&quot;gray50&quot;</span>,                   <span class="co"># dim the dots slightly</span></a>
<a class="sourceLine" id="cb501-9" title="9">       <span class="dt">frame.plot =</span> <span class="ot">FALSE</span>                <span class="co"># don&#39;t draw a box</span></a>
<a class="sourceLine" id="cb501-10" title="10">)</a>
<a class="sourceLine" id="cb501-11" title="11"> <span class="kw">lines</span>( <span class="dt">x =</span> <span class="kw">c</span>(<span class="dv">4</span>,<span class="fl">9.5</span>),   <span class="co"># the horizontal locations</span></a>
<a class="sourceLine" id="cb501-12" title="12">        <span class="dt">y =</span> <span class="kw">c</span>(<span class="dv">93</span>,<span class="dv">37</span>),   <span class="co"># the vertical locations</span></a>
<a class="sourceLine" id="cb501-13" title="13">        <span class="dt">lwd =</span> <span class="dv">2</span>         <span class="co"># line width</span></a>
<a class="sourceLine" id="cb501-14" title="14">)</a></code></pre></div>
<div class="figure">
<img src="lsr_files/figure-html/scatterb-1.png" alt="A scatterplot with scatter plot specific customisations" width="672" />
<p class="caption">
(#fig:scatterb)A scatterplot with scatter plot specific customisations
</p>
</div>
<p>And when I do so, R plots the line over the top of the plot that I drew using the previous command. In most realistic data analysis situations you absolutely don’t want to just guess where the line through the points goes, since there’s about a billion different ways in which you can get R to do a better job. However, it does at least illustrate the basic idea.</p>
<p>One possibility, if you do want to get R to draw nice clean lines through the data for you, is to use the <code>scatterplot()</code> function in the <code>car</code> package. Before we can use <code>scatterplot()</code> we need to load the package:</p>
<div class="sourceCode" id="cb502"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb502-1" title="1"><span class="kw">library</span>( car )</a></code></pre></div>
<p>Having done so, we can now use the function. The command we need is this one:</p>
<div class="sourceCode" id="cb503"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb503-1" title="1"><span class="kw">scatterplot</span>( dan.grump <span class="op">~</span><span class="st"> </span>dan.sleep,</a>
<a class="sourceLine" id="cb503-2" title="2">              <span class="dt">data =</span> parenthood, </a>
<a class="sourceLine" id="cb503-3" title="3">              <span class="dt">smooth =</span> <span class="ot">FALSE</span></a>
<a class="sourceLine" id="cb503-4" title="4">)</a></code></pre></div>
<div class="figure">
<img src="lsr_files/figure-html/fancyscatter-1.png" alt="A fancy scatterplot drawn using the `scatterplot()` function in the `car` package." width="672" />
<p class="caption">
(#fig:fancyscatter)A fancy scatterplot drawn using the <code>scatterplot()</code> function in the <code>car</code> package.
</p>
</div>
<p>The first two arguments should be familiar: the first input is a formula <code>dan.grump ~ dan.sleep</code> telling R what variables to plot,<a href="#fn101" class="footnote-ref" id="fnref101"><sup>101</sup></a> and the second specifies a <code>data</code> frame. The third argument <code>smooth</code> I’ve set to <code>FALSE</code> to stop the <code>scatterplot()</code> function from drawing a fancy “smoothed” trendline (since it’s a bit confusing to beginners). The scatterplot itself is shown in Figure @ref(fig:fancyscatter). As you can see, it’s not only drawn the scatterplot, but its also drawn boxplots for each of the two variables, as well as a simple line of best fit showing the relationship between the two variables.</p>
<div id="more-elaborate-options" class="section level3">
<h3><span class="header-section-number">6.6.1</span> More elaborate options</h3>
<p>Often you find yourself wanting to look at the relationships between several variables at once. One useful tool for doing so is to produce a <strong><em>scatterplot matrix</em></strong>, analogous to the correlation matrix.</p>
<div class="sourceCode" id="cb504"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb504-1" title="1"><span class="kw">cor</span>( <span class="dt">x =</span> parenthood ) <span class="co"># calculate correlation matrix</span></a></code></pre></div>
<pre><code>##              dan.sleep  baby.sleep   dan.grump         day
## dan.sleep   1.00000000  0.62794934 -0.90338404 -0.09840768
## baby.sleep  0.62794934  1.00000000 -0.56596373 -0.01043394
## dan.grump  -0.90338404 -0.56596373  1.00000000  0.07647926
## day        -0.09840768 -0.01043394  0.07647926  1.00000000</code></pre>
<p>We can get a the corresponding scatterplot matrix by using the <code>pairs()</code> function:<a href="#fn102" class="footnote-ref" id="fnref102"><sup>102</sup></a></p>
<div class="sourceCode" id="cb506"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb506-1" title="1"><span class="kw">pairs</span>( <span class="dt">x =</span> parenthood ) <span class="co"># draw corresponding scatterplot matrix  </span></a></code></pre></div>
<div class="figure">
<img src="lsr_files/figure-html/pairs-1.png" alt="A scatterplot matrix from the `pairs() function" width="672" />
<p class="caption">
(#fig:pairs)A scatterplot matrix from the `pairs() function
</p>
</div>
<p>The output of the <code>pairs()</code> command is shown in Figure @ref(fig:pairs). An alternative way of calling the <code>pairs()</code> function, which can be useful in some situations, is to specify the variables to include using a one-sided formula. For instance, this</p>
<div class="sourceCode" id="cb507"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb507-1" title="1"><span class="kw">pairs</span>( <span class="dt">formula =</span> <span class="op">~</span><span class="st"> </span>dan.sleep <span class="op">+</span><span class="st"> </span>baby.sleep <span class="op">+</span><span class="st"> </span>dan.grump,</a>
<a class="sourceLine" id="cb507-2" title="2">        <span class="dt">data =</span> parenthood</a>
<a class="sourceLine" id="cb507-3" title="3">)</a></code></pre></div>
<p>would produce a <span class="math inline">\(3 \times 3\)</span> scatterplot matrix that only compare <code>dan.sleep</code>, <code>dan.grump</code> and <code>baby.sleep</code>. Obviously, the first version is much easier, but there are cases where you really only want to look at a few of the variables, so it’s nice to use the formula interface.</p>
</div>
</div>
<div id="bargraph" class="section level2">
<h2><span class="header-section-number">6.7</span> Bar graphs</h2>
<p>Another form of graph that you often want to plot is the <strong><em>bar graph</em></strong>. The main function that you can use in R to draw them is the <code>barplot()</code> function.<a href="#fn103" class="footnote-ref" id="fnref103"><sup>103</sup></a> And to illustrate the use of the function, I’ll use the <code>finalists</code> variable that I introduced in Section @ref(mode). What I want to do is draw a bar graph that displays the number of finals that each team has played in over the time spanned by the <code>afl</code> data set. So, let’s start by creating a vector that contains this information. I’ll use the <code>tabulate()</code> function to do this (which will be discussed properly in Section @ref(freqtables), since it creates a simple numeric vector:</p>
<div class="sourceCode" id="cb508"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb508-1" title="1">freq &lt;-<span class="st"> </span><span class="kw">tabulate</span>( afl.finalists )</a>
<a class="sourceLine" id="cb508-2" title="2"><span class="kw">print</span>( freq )</a></code></pre></div>
<pre><code>##  [1] 26 25 26 28 32  0  6 39 27 28 28 17  6 24 26 38 24</code></pre>
<p>This isn’t exactly the prettiest of frequency tables, of course. I’m only doing it this way so that you can see the <code>barplot()</code> function in it’s “purest” form: when the input is just an ordinary numeric vector. That being said, I’m obviously going to need the team names to create some labels, so let’s create a variable with those. I’ll do this using the <code>levels()</code> function, which outputs the names of all the levels of a factor (see Section @ref(factors):</p>
<div class="sourceCode" id="cb510"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb510-1" title="1">teams &lt;-<span class="st"> </span><span class="kw">levels</span>( afl.finalists )</a>
<a class="sourceLine" id="cb510-2" title="2"><span class="kw">print</span>( teams )</a></code></pre></div>
<pre><code>##  [1] &quot;Adelaide&quot;         &quot;Brisbane&quot;         &quot;Carlton&quot;         
##  [4] &quot;Collingwood&quot;      &quot;Essendon&quot;         &quot;Fitzroy&quot;         
##  [7] &quot;Fremantle&quot;        &quot;Geelong&quot;          &quot;Hawthorn&quot;        
## [10] &quot;Melbourne&quot;        &quot;North Melbourne&quot;  &quot;Port Adelaide&quot;   
## [13] &quot;Richmond&quot;         &quot;St Kilda&quot;         &quot;Sydney&quot;          
## [16] &quot;West Coast&quot;       &quot;Western Bulldogs&quot;</code></pre>
<p>Okay, so now that we have the information we need, let’s draw our bar graph. The main argument that you need to specify for a bar graph is the <code>height</code> of the bars, which in our case correspond to the values stored in the <code>freq</code> variable:</p>
<div class="sourceCode" id="cb512"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb512-1" title="1"><span class="kw">barplot</span>( <span class="dt">height =</span> freq )  <span class="co"># specifying the argument name</span></a>
<a class="sourceLine" id="cb512-2" title="2"><span class="kw">barplot</span>( freq )           <span class="co"># the lazier version</span></a></code></pre></div>
<p>Either of these two commands will produce the simple bar graph shown in Figure @ref(fig:bar1a).</p>
<div class="figure">
<img src="lsr_files/figure-html/bar1a-1.png" alt="the simplest version of a bargraph, containing the data but no labels" width="672" />
<p class="caption">
(#fig:bar1a)the simplest version of a bargraph, containing the data but no labels
</p>
</div>
<p>As you can see, R has drawn a pretty minimal plot. It doesn’t have any labels, obviously, because we didn’t actually tell the <code>barplot()</code> function what the labels are! To do this, we need to specify the <code>names.arg</code> argument. The <code>names.arg</code> argument needs to be a vector of character strings containing the text that needs to be used as the label for each of the items. In this case, the <code>teams</code> vector is exactly what we need, so the command we’re looking for is:</p>
<div class="sourceCode" id="cb513"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb513-1" title="1">    <span class="kw">barplot</span>( <span class="dt">height =</span> freq, <span class="dt">names.arg =</span> teams ) </a></code></pre></div>
<div class="figure">
<img src="lsr_files/figure-html/bar1b-1.png" alt="we've added the labels, but because the text runs horizontally R only includes a few of them" width="672" />
<p class="caption">
(#fig:bar1b)we’ve added the labels, but because the text runs horizontally R only includes a few of them
</p>
</div>
<p>This is an improvement, but not much of an improvement. R has only included a few of the labels, because it can’t fit them in the plot. This is the same behaviour we saw earlier with the multiple-boxplot graph in Figure @ref(fig:multipleboxplots). However, in Figure @ref(fig:multipleboxplots) it wasn’t an issue: it’s pretty obvious from inspection that the two unlabelled plots in between 1987 and 1990 must correspond to the data from 1988 and 1989. However, the fact that <code>barplot()</code> has omitted the names of every team in between Adelaide and Fitzroy is a lot more problematic.</p>
<p>The simplest way to fix this is to rotate the labels, so that the text runs vertically not horizontally. To do this, we need to alter set the <code>las</code> parameter, which I discussed briefly in Section @ref(introplotting). What I’ll do is tell R to rotate the text so that it’s always perpendicular to the axes (i.e., I’ll set <code>las = 2</code>). When I do that, as per the following command…</p>
<div class="sourceCode" id="cb514"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb514-1" title="1">    <span class="kw">barplot</span>(<span class="dt">height =</span> freq,  <span class="co"># the frequencies</span></a>
<a class="sourceLine" id="cb514-2" title="2">            <span class="dt">names.arg =</span> teams,  <span class="co"># the label</span></a>
<a class="sourceLine" id="cb514-3" title="3">            <span class="dt">las =</span> <span class="dv">2</span>)            <span class="co"># rotate the labels</span></a></code></pre></div>
<div class="figure">
<img src="lsr_files/figure-html/bar1c-1.png" alt="we've rotated the labels, but now the text is too long to fit" width="672" />
<p class="caption">
(#fig:bar1c)we’ve rotated the labels, but now the text is too long to fit
</p>
</div>
<p>… the result is the bar graph shown in Figure @ref(fig:bar1c). We’ve fixed the problem, but we’ve created a new one: the axis labels don’t quite fit anymore. To fix this, we have to be a bit cleverer again. A simple fix would be to use shorter names rather than the full name of all teams, and in many situations that’s probably the right thing to do. However, at other times you really do need to create a bit more space to add your labels, so I’ll show you how to do that.</p>
<div id="par" class="section level3">
<h3><span class="header-section-number">6.7.1</span> Changing global settings using par()</h3>
<p>Altering the margins to the plot is actually a somewhat more complicated exercise than you might think. In principle it’s a very simple thing to do: the size of the margins is governed by a graphical parameter called <code>mar</code>, so all we need to do is alter this parameter. First, let’s look at what the <code>mar</code> argument specifies. The <code>mar</code> argument is a vector containing four numbers: specifying the amount of space at the bottom, the left, the top and then the right. The units are “number of ‘lines’”. The default value for <code>mar</code> is <code>c(5.1, 4.1, 4.1, 2.1)</code>, meaning that R leaves 5.1 “lines” empty at the bottom, 4.1 lines on the left and the bottom, and only 2.1 lines on the right. In order to make more room at the bottom, what I need to do is change the first of these numbers. A value of 10.1 should do the trick.</p>
<p>So far this doesn’t seem any different to the other graphical parameters that we’ve talked about. However, because of the way that the traditional graphics system in R works, you need to specify what the margins will be <em>before</em> calling your high-level plotting function. Unlike the other cases we’ve see, you can’t treat <code>mar</code> as if it were just another argument in your plotting function. Instead, you have to use the <code>par()</code> function to change the graphical parameters beforehand, and only then try to draw your figure. In other words, the first thing I would do is this:</p>
<div class="sourceCode" id="cb515"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb515-1" title="1"><span class="kw">par</span>( <span class="dt">mar =</span> <span class="kw">c</span>( <span class="fl">10.1</span>, <span class="fl">4.1</span>, <span class="fl">4.1</span>, <span class="fl">2.1</span>) )</a></code></pre></div>
<p>There’s no visible output here, but behind the scenes R has changed the graphical parameters associated with the current device (remember, in R terminology all graphics are drawn onto a “device”). Now that this is done, we could use the exact same command as before, but this time you’d see that the labels all fit, because R now leaves twice as much room for the labels at the bottom. However, since I’ve now figured out how to get the labels to display properly, I might as well play around with some of the other options, all of which are things you’ve seen before:</p>
<div class="sourceCode" id="cb516"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb516-1" title="1"><span class="kw">barplot</span>( <span class="dt">height =</span> freq,</a>
<a class="sourceLine" id="cb516-2" title="2">        <span class="dt">names.arg =</span> teams,</a>
<a class="sourceLine" id="cb516-3" title="3">        <span class="dt">las=</span><span class="dv">2</span>,</a>
<a class="sourceLine" id="cb516-4" title="4">        <span class="dt">ylab =</span> <span class="st">&quot;Number of Finals&quot;</span>,</a>
<a class="sourceLine" id="cb516-5" title="5">        <span class="dt">main =</span> <span class="st">&quot;Finals Played, 1987-2010&quot;</span>,  </a>
<a class="sourceLine" id="cb516-6" title="6">        <span class="dt">density =</span> <span class="dv">10</span>,</a>
<a class="sourceLine" id="cb516-7" title="7">        <span class="dt">angle =</span> <span class="dv">20</span>)</a></code></pre></div>
<div class="figure">
<img src="lsr_files/figure-html/bar1d-1.png" alt="we fix this by expanding the margin at the bottom, and add several other customisations to make the chart a bit nicer" width="672" />
<p class="caption">
(#fig:bar1d)we fix this by expanding the margin at the bottom, and add several other customisations to make the chart a bit nicer
</p>
</div>
<p>However, one thing to remember about the <code>par()</code> function is that it doesn’t just change the graphical parameters for the current <em>plot</em>. Rather, the changes pertain to any subsequent plot that you draw onto the same <em>device</em>. This might be exactly what you want, in which case there’s no problem. But if not, you need to reset the graphical parameters to their original settings. To do this, you can either close the device (e.g., close the window, or click the “Clear All” button in the Plots panel in Rstudio) or you can reset the graphical parameters to their original values, using a command like this:</p>
<div class="sourceCode" id="cb517"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb517-1" title="1"><span class="kw">par</span>( <span class="dt">mar =</span> <span class="kw">c</span>(<span class="fl">5.1</span>, <span class="fl">4.1</span>, <span class="fl">4.1</span>, <span class="fl">2.1</span>) )</a></code></pre></div>
</div>
</div>
<div id="saveimage" class="section level2">
<h2><span class="header-section-number">6.8</span> Saving image files using R and Rstudio</h2>
<p>Hold on, you might be thinking. What’s the good of being able to draw pretty pictures in R if I can’t save them and send them to friends to brag about how awesome my data is? How do I save the picture? This is another one of those situations where the easiest thing to do is to use the RStudio tools.</p>
<p>If you’re running R through Rstudio, then the easiest way to save your image is to click on the “Export” button in the Plot panel (i.e., the area in Rstudio where all the plots have been appearing). When you do that you’ll see a menu that contains the options “Save Plot as PDF” and “Save Plot as Image”. Either version works. Both will bring up dialog boxes that give you a few options that you can play with, but besides that it’s pretty simple.</p>
<p>This works pretty nicely for most situations. So, unless you’re filled with a burning desire to learn the low level details, feel free to skip the rest of this section.</p>
<div id="the-ugly-details-advanced" class="section level3">
<h3><span class="header-section-number">6.8.1</span> The ugly details (advanced)</h3>
<p>As I say, the menu-based options should be good enough for most people most of the time. However, one day you might want to be a bit more sophisticated, and make use of R’s image writing capabilities at a lower level. In this section I’ll give you a very basic introduction to this. In all honesty, this barely scratches the surface, but it will help a little bit in getting you started if you want to learn the details.</p>
<p>Okay, as I hinted earlier, whenever you’re drawing pictures in R you’re deemed to be drawing <em>to</em> a device of some kind. There are devices that correspond to a figure drawn on screen, and there are devices that correspond to graphics files that R will produce for you. For the purposes of this section I’ll assume that you’re using the default application in either Windows or Mac OS, not Rstudio. The reason for this is that my experience with the graphical device provided by Rstudio has led me to suspect that it still has a bunch on non-standard (or possibly just undocumented) features, and so I don’t quite trust that it always does what I expect. I’ve no doubt they’ll smooth it out later, but I can honestly say that I don’t quite get what’s going on with the <code>RStudioGD</code> device. In any case, we can ask R to list all of the graphics devices that currently exist, simply by using the command <code>dev.list()</code>. If there are no figure windows open, then you’ll see this:</p>
<div class="sourceCode" id="cb518"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb518-1" title="1"><span class="kw">dev.list</span>()</a>
<a class="sourceLine" id="cb518-2" title="2"><span class="co"># NULL</span></a></code></pre></div>
<p>which just means that R doesn’t have any graphics devices open. However, suppose if you’ve just drawn a histogram and you type the same command, R will now give you a different answer. For instance, if you’re using Windows:</p>
<div class="sourceCode" id="cb519"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb519-1" title="1"><span class="kw">hist</span>( afl.margins )</a>
<a class="sourceLine" id="cb519-2" title="2"><span class="kw">dev.list</span>()</a>
<a class="sourceLine" id="cb519-3" title="3"><span class="co"># windows </span></a>
<a class="sourceLine" id="cb519-4" title="4"><span class="co">#      2</span></a></code></pre></div>
<p>What this means is that there is one graphics device (device 2) that is currently open, and it’s a figure window. If you did the same thing on a Mac, you get basically the same answer, except that the name of the device would be <code>quartz</code> rather than <code>windows</code>. If you had several graphics windows open (which, incidentally, you can do by using the <code>dev.new()</code> command) then you’d see something like this:</p>
<div class="sourceCode" id="cb520"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb520-1" title="1"><span class="kw">dev.list</span>()</a>
<a class="sourceLine" id="cb520-2" title="2"><span class="co"># windows windows windows  </span></a>
<a class="sourceLine" id="cb520-3" title="3"><span class="co">#       2       3       4 </span></a></code></pre></div>
<p>Okay, so that’s the basic idea behind graphics devices. The key idea here is that graphics files (like JPEG images etc) are <em>also</em> graphics devices as far as R is concerned. So what you want to do is to <em>copy</em> the contents of one graphics device to another one. There’s a command called <code>dev.copy()</code> that does this, but what I’ll explain to you is a simpler one called <code>dev.print()</code>. It’s pretty simple:</p>
<div class="sourceCode" id="cb521"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb521-1" title="1"><span class="kw">dev.print</span>( <span class="dt">device =</span> jpeg,              <span class="co"># what are we printing to?</span></a>
<a class="sourceLine" id="cb521-2" title="2">            <span class="dt">filename =</span> <span class="st">&quot;thisfile.jpg&quot;</span>,  <span class="co"># name of the image file</span></a>
<a class="sourceLine" id="cb521-3" title="3">            <span class="dt">width =</span> <span class="dv">480</span>,                <span class="co"># how many pixels wide should it be</span></a>
<a class="sourceLine" id="cb521-4" title="4">            <span class="dt">height =</span> <span class="dv">300</span>                <span class="co"># how many pixels high should it be</span></a>
<a class="sourceLine" id="cb521-5" title="5">)</a></code></pre></div>
<p>This takes the “active” figure window, copies it to a jpeg file (which R treats as a device) and then closes that device. The <code>filename = "thisfile.jpg"</code> part tells R what to name the graphics file, and the <code>width = 480</code> and <code>height = 300</code> arguments tell R to draw an image that is 300 pixels high and 480 pixels wide. If you want a different kind of file, just change the device argument from <code>jpeg</code> to something else. R has devices for <code>png</code>, <code>tiff</code> and <code>bmp</code> that all work in exactly the same way as the <code>jpeg</code> command, but produce different kinds of files. Actually, for simple cartoonish graphics like this histogram, you’d be better advised to use PNG or TIFF over JPEG. The JPEG format is very good for natural images, but is wasteful for simple line drawings. The information above probably covers most things you might want to. However, if you want more information about what kinds of options you can specify using R, have a look at the help documentation by typing <code>?jpeg</code> or <code>?tiff</code> or whatever.</p>
</div>
</div>
<div id="summary-3" class="section level2">
<h2><span class="header-section-number">6.9</span> Summary</h2>
<p>Perhaps I’m a simple minded person, but I love pictures. Every time I write a new scientific paper, one of the first things I do is sit down and think about what the pictures will be. In my head, an article is really just a sequence of pictures, linked together by a story. All the rest of it is just window dressing. What I’m really trying to say here is that the human visual system is a very powerful data analysis tool. Give it the right kind of information and it will supply a human reader with a massive amount of knowledge very quickly. Not for nothing do we have the saying “a picture is worth a thousand words”. With that in mind, I think that this is one of the most important chapters in the book. The topics covered were:</p>
<ul>
<li><em>Basic overview to R graphics</em>. In Section @ref(rgraphics) we talked about how graphics in R are organised, and then moved on to the basics of how they’re drawn in Section @ref(introplotting).</li>
<li><em>Common plots</em>. Much of the chapter was focused on standard graphs that statisticians like to produce: histograms (Section @ref(hist)), stem and leaf plots (Section @ref(stem)), boxplots (Section @ref(boxplots)), scatterplots (Section @ref(scatterplots)) and bar graphs (Section @ref(bargraph)).</li>
<li><em>Saving image files</em>. The last part of the chapter talked about how to export your pictures (Section @ref(saveimage))</li>
</ul>
<p>One final thing to point out. At the start of the chapter I mentioned that R has several completely distinct systems for drawing figures. In this chapter I’ve focused on the <em>traditional</em> graphics system. It’s the easiest one to get started with: you can draw a histogram with a command as simple as <code>hist(x)</code>. However, it’s not the most powerful tool for the job, and after a while most R users start looking to shift to fancier systems. One of the most popular graphics systems is provided by the <code>ggplot2</code> package (see ), which is loosely based on “The grammar of graphics” <span class="citation">(Wilkinson et al. <a href="#ref-Wilkinson2006" role="doc-biblioref">2006</a>)</span>. It’s not for novices: you need to have a pretty good grasp of R before you can start using it, and even then it takes a while to really get the hang of it. But when you’re finally at that stage, it’s worth taking the time to teach yourself, because it’s a much cleaner system.</p>
<!--chapter:end:03.06-graphics.Rmd-->
</div>
</div>
<div id="datahandling" class="section level1">
<h1><span class="header-section-number">7</span> Pragmatic matters</h1>
<blockquote>
<p><em>The garden of life never seems to confine itself to the plots philosophers have
laid out for its convenience. Maybe a few more tractors would do the trick.</em></p>
<p>–Roger Zelazny<a href="#fn104" class="footnote-ref" id="fnref104"><sup>104</sup></a></p>
</blockquote>
<p>This is a somewhat strange chapter, even by my standards. My goal in this chapter is to talk a bit more honestly about the realities of working with data than you’ll see anywhere else in the book. The problem with real world data sets is that they are <em>messy</em>. Very often the data file that you start out with doesn’t have the variables stored in the right format for the analysis you want to do. Sometimes might be a lot of missing values in your data set. Sometimes you only want to analyse a subset of the data. Et cetera. In other words, there’s a lot of <strong><em>data manipulation</em></strong> that you need to do, just to get all your data set into the format that you need it. The purpose of this chapter is to provide a basic introduction to all these pragmatic topics. Although the chapter is motivated by the kinds of practical issues that arise when manipulating real data, I’ll stick with the practice that I’ve adopted through most of the book and rely on very small, toy data sets that illustrate the underlying issue. Because this chapter is essentially a collection of “tricks” and doesn’t tell a single coherent story, it may be useful to start with a list of topics:</p>
<ul>
<li>Section @ref(freqtables). Tabulating data.</li>
<li>Section @ref(transform). Transforming or recoding a variable.</li>
<li>Section @ref(mathfunc). Some useful mathematical functions.</li>
<li>Section @ref(subset). Extracting a subset of a vector.</li>
<li>Section @ref(subsetdataframe). Extracting a subset of a data frame.</li>
<li>Section @ref(sort). Sorting, flipping or merging data sets.</li>
<li>Section @ref(reshape). Reshaping a data frame.</li>
<li>Section @ref(textprocessing). Manipulating text.</li>
<li>Section @ref(importing). Opening data from different file types.</li>
<li>Section @ref(coercion). Coercing data from one type to another.</li>
<li>Section @ref(datastructures). Other important data types.</li>
<li>Section @ref(miscdatahandling). Miscellaneous topics.</li>
</ul>
<p>As you can see, the list of topics that the chapter covers is pretty broad, and there’s a <em>lot</em> of content there. Even though this is one of the longest and hardest chapters in the book, I’m really only scratching the surface of several fairly different and important topics. My advice, as usual, is to read through the chapter once and try to follow as much of it as you can. Don’t worry too much if you can’t grasp it all at once, especially the later sections. The rest of the book is only lightly reliant on this chapter, so you can get away with just understanding the basics. However, what you’ll probably find is that later on you’ll need to flick back to this chapter in order to understand some of the concepts that I refer to here.</p>
<div id="freqtables" class="section level2">
<h2><span class="header-section-number">7.1</span> Tabulating and cross-tabulating data</h2>
<p>A very common task when analysing data is the construction of frequency tables, or cross-tabulation of one variable against another. There are several functions that you can use in R for that purpose. In this section I’ll illustrate the use of three functions – <code>table()</code>, <code>xtabs()</code> and <code>tabulate()</code> – though there are other options (e.g., <code>ftable()</code>) available.</p>
<div id="creating-tables-from-vectors" class="section level3">
<h3><span class="header-section-number">7.1.1</span> Creating tables from vectors</h3>
<p>Let’s start with a simple example. As the father of a small child, I naturally spend a lot of time watching TV shows like <em>In the Night Garden</em>. In the <code>nightgarden.Rdata</code> file, I’ve transcribed a short section of the dialogue. The file contains two variables, <code>speaker</code> and <code>utterance</code>, and when we take a look at the data, it becomes very clear what happened to my sanity.</p>
<div class="sourceCode" id="cb522"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb522-1" title="1"><span class="kw">library</span>(lsr)</a>
<a class="sourceLine" id="cb522-2" title="2"><span class="kw">load</span>(<span class="kw">file.path</span>(projecthome,<span class="st">&quot;data&quot;</span>,<span class="st">&quot;nightgarden.Rdata&quot;</span>))</a>
<a class="sourceLine" id="cb522-3" title="3"><span class="kw">who</span>()</a></code></pre></div>
<pre><code>##    -- Name --             -- Class --   -- Size --
##    afl.finalists          factor        400       
##    afl.margins            numeric       176       
##    afl2                   data.frame    4296 x 2  
##    colour                 logical       1         
##    d.cor                  numeric       1         
##    describeImg            list          0         
##    effort                 data.frame    10 x 2    
##    emphCol                character     1         
##    emphColLight           character     1         
##    emphGrey               character     1         
##    eps                    logical       1         
##    Fibonacci              numeric       7         
##    freq                   integer       17        
##    generateRLineTypes     function                
##    generateRPointShapes   function                
##    height                 numeric       1         
##    i                      character     1         
##    old                    list          66        
##    oneCorPlot             function                
##    out.0                  data.frame    100 x 2   
##    out.1                  data.frame    100 x 2   
##    out.2                  data.frame    100 x 2   
##    parenthood             data.frame    100 x 4   
##    plotOne                function                
##    projecthome            character     1         
##    speaker                character     10        
##    suspicious.cases       logical       176       
##    teams                  character     17        
##    tp                     character     6         
##    utterance              character     10        
##    width                  numeric       1         
##    X1                     numeric       11        
##    X2                     numeric       11        
##    X3                     numeric       11        
##    X4                     numeric       11        
##    Y1                     numeric       11        
##    Y2                     numeric       11        
##    Y3                     numeric       11        
##    Y4                     numeric       11</code></pre>
<div class="sourceCode" id="cb524"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb524-1" title="1"><span class="kw">print</span>( speaker )</a></code></pre></div>
<pre><code>##  [1] &quot;upsy-daisy&quot;  &quot;upsy-daisy&quot;  &quot;upsy-daisy&quot;  &quot;upsy-daisy&quot;  &quot;tombliboo&quot;  
##  [6] &quot;tombliboo&quot;   &quot;makka-pakka&quot; &quot;makka-pakka&quot; &quot;makka-pakka&quot; &quot;makka-pakka&quot;</code></pre>
<div class="sourceCode" id="cb526"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb526-1" title="1"><span class="kw">print</span>( utterance )</a></code></pre></div>
<pre><code>##  [1] &quot;pip&quot; &quot;pip&quot; &quot;onk&quot; &quot;onk&quot; &quot;ee&quot;  &quot;oo&quot;  &quot;pip&quot; &quot;pip&quot; &quot;onk&quot; &quot;onk&quot;</code></pre>
<p>With these as my data, one task I might find myself needing to do is construct a frequency count of the number of words each character speaks during the show. The <code>table()</code> function provides a simple way do to this. The basic usage of the <code>table()</code> function is as follows:</p>
<div class="sourceCode" id="cb528"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb528-1" title="1"><span class="kw">table</span>(speaker)</a></code></pre></div>
<pre><code>## speaker
## makka-pakka   tombliboo  upsy-daisy 
##           4           2           4</code></pre>
<p>The output here tells us on the first line that what we’re looking at is a tabulation of the <code>speaker</code> variable. On the second line it lists all the different speakers that exist in the data, and on the third line it tells you how many times that speaker appears in the data. In other words, it’s a frequency table<a href="#fn105" class="footnote-ref" id="fnref105"><sup>105</sup></a> Notice that in the command above I didn’t name the argument, since <code>table()</code> is another function that makes use of unnamed arguments. You just type in a list of the variables that you want R to tabulate, and it tabulates them. For instance, if I type in the name of two variables, what I get as the output is a cross-tabulation:</p>
<div class="sourceCode" id="cb530"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb530-1" title="1"><span class="kw">table</span>(speaker, utterance)</a></code></pre></div>
<pre><code>##              utterance
## speaker       ee onk oo pip
##   makka-pakka  0   2  0   2
##   tombliboo    1   0  1   0
##   upsy-daisy   0   2  0   2</code></pre>
<p>When interpreting this table, remember that these are counts: so the fact that the first row and second column corresponds to a value of 2 indicates that Makka-Pakka (row 1) says “onk” (column 2) twice in this data set. As you’d expect, you can produce three way or higher order cross tabulations just by adding more objects to the list of inputs. However, I won’t discuss that in this section.</p>
</div>
<div id="creating-tables-from-data-frames" class="section level3">
<h3><span class="header-section-number">7.1.2</span> Creating tables from data frames</h3>
<p>Most of the time your data are stored in a data frame, not kept as separate variables in the workspace. Let’s create one:</p>
<div class="sourceCode" id="cb532"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb532-1" title="1">itng &lt;-<span class="st"> </span><span class="kw">data.frame</span>( speaker, utterance )</a>
<a class="sourceLine" id="cb532-2" title="2">itng</a></code></pre></div>
<pre><code>##        speaker utterance
## 1   upsy-daisy       pip
## 2   upsy-daisy       pip
## 3   upsy-daisy       onk
## 4   upsy-daisy       onk
## 5    tombliboo        ee
## 6    tombliboo        oo
## 7  makka-pakka       pip
## 8  makka-pakka       pip
## 9  makka-pakka       onk
## 10 makka-pakka       onk</code></pre>
<p>There’s a couple of options under these circumstances. Firstly, if you just want to cross-tabulate all of the variables in the data frame, then it’s really easy:</p>
<div class="sourceCode" id="cb534"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb534-1" title="1"><span class="kw">table</span>(itng)</a></code></pre></div>
<pre><code>##              utterance
## speaker       ee onk oo pip
##   makka-pakka  0   2  0   2
##   tombliboo    1   0  1   0
##   upsy-daisy   0   2  0   2</code></pre>
<p>However, it’s often the case that you want to select particular variables from the data frame to tabulate. This is where the <code>xtabs()</code> function is useful. In this function, you input a one sided <code>formula</code> in order to list all the variables you want to cross-tabulate, and the name of the <code>data</code> frame that stores the data:</p>
<div class="sourceCode" id="cb536"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb536-1" title="1"><span class="kw">xtabs</span>( <span class="dt">formula =</span> <span class="op">~</span><span class="st"> </span>speaker <span class="op">+</span><span class="st"> </span>utterance, <span class="dt">data =</span> itng )</a></code></pre></div>
<pre><code>##              utterance
## speaker       ee onk oo pip
##   makka-pakka  0   2  0   2
##   tombliboo    1   0  1   0
##   upsy-daisy   0   2  0   2</code></pre>
<p>Clearly, this is a totally unnecessary command in the context of the <code>itng</code> data frame, but in most situations when you’re analysing real data this is actually extremely useful, since your data set will almost certainly contain lots of variables and you’ll only want to tabulate a few of them at a time.</p>
</div>
<div id="converting-a-table-of-counts-to-a-table-of-proportions" class="section level3">
<h3><span class="header-section-number">7.1.3</span> Converting a table of counts to a table of proportions</h3>
<p>The tabulation commands discussed so far all construct a table of raw frequencies: that is, a count of the total number of cases that satisfy certain conditions. However, often you want your data to be organised in terms of proportions rather than counts. This is where the <code>prop.table()</code> function comes in handy. It has two arguments:</p>
<ul>
<li><code>x</code>. The frequency table that you want to convert.</li>
<li><code>margin</code>. Which “dimension” do you want to calculate proportions for. By default, R assumes you want the proportion to be expressed as a fraction of all possible events. See examples for details.</li>
</ul>
<p>To see how this works:</p>
<div class="sourceCode" id="cb538"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb538-1" title="1">itng.table &lt;-<span class="st"> </span><span class="kw">table</span>(itng)  <span class="co"># create the table, and assign it to a variable</span></a>
<a class="sourceLine" id="cb538-2" title="2">itng.table                   <span class="co"># display the table again, as a reminder</span></a></code></pre></div>
<pre><code>##              utterance
## speaker       ee onk oo pip
##   makka-pakka  0   2  0   2
##   tombliboo    1   0  1   0
##   upsy-daisy   0   2  0   2</code></pre>
<div class="sourceCode" id="cb540"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb540-1" title="1"><span class="kw">prop.table</span>( <span class="dt">x =</span> itng.table ) <span class="co"># express as proportion:</span></a></code></pre></div>
<pre><code>##              utterance
## speaker        ee onk  oo pip
##   makka-pakka 0.0 0.2 0.0 0.2
##   tombliboo   0.1 0.0 0.1 0.0
##   upsy-daisy  0.0 0.2 0.0 0.2</code></pre>
<p>Notice that there were 10 observations in our original data set, so all that R has done here is divide all our raw frequencies by 10. That’s a sensible default, but more often you actually want to calculate the proportions separately by row (<code>margin = 1</code>) or by column (<code>margin = 2</code>). Again, this is most clearly seen by looking at examples:</p>
<div class="sourceCode" id="cb542"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb542-1" title="1"><span class="kw">prop.table</span>( <span class="dt">x =</span> itng.table, <span class="dt">margin =</span> <span class="dv">1</span>)</a></code></pre></div>
<pre><code>##              utterance
## speaker        ee onk  oo pip
##   makka-pakka 0.0 0.5 0.0 0.5
##   tombliboo   0.5 0.0 0.5 0.0
##   upsy-daisy  0.0 0.5 0.0 0.5</code></pre>
<p>Notice that each row now sums to 1, but that’s not true for each column. What we’re looking at here is the proportions of utterances made by each character. In other words, 50% of Makka-Pakka’s utterances are “pip”, and the other 50% are “onk”. Let’s contrast this with the following command:</p>
<div class="sourceCode" id="cb544"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb544-1" title="1"><span class="kw">prop.table</span>( <span class="dt">x =</span> itng.table, <span class="dt">margin =</span> <span class="dv">2</span>)</a></code></pre></div>
<pre><code>##              utterance
## speaker        ee onk  oo pip
##   makka-pakka 0.0 0.5 0.0 0.5
##   tombliboo   1.0 0.0 1.0 0.0
##   upsy-daisy  0.0 0.5 0.0 0.5</code></pre>
<p>Now the columns all sum to 1 but the rows don’t. In this version, what we’re seeing is the proportion of characters associated with each utterance. For instance, whenever the utterance “ee” is made (in this data set), 100% of the time it’s a Tombliboo saying it.</p>
</div>
<div id="low-level-tabulation" class="section level3">
<h3><span class="header-section-number">7.1.4</span> Low level tabulation</h3>
<p>One final function I want to mention is the <code>tabulate()</code> function, since this is actually the low-level function that does most of the hard work. It takes a numeric vector as input, and outputs frequencies as outputs:</p>
<div class="sourceCode" id="cb546"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb546-1" title="1">some.data &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">8</span>,<span class="dv">3</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">4</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">5</span>,<span class="dv">2</span>)</a>
<a class="sourceLine" id="cb546-2" title="2"><span class="kw">tabulate</span>(some.data)</a></code></pre></div>
<pre><code>## [1] 6 5 4 1 1 0 0 1</code></pre>
</div>
</div>
<div id="transform" class="section level2">
<h2><span class="header-section-number">7.2</span> Transforming and recoding a variable</h2>
<p>It’s not uncommon in real world data analysis to find that one of your variables isn’t quite equivalent to the variable that you really want. For instance, it’s often convenient to take a continuous-valued variable (e.g., age) and break it up into a smallish number of categories (e.g., younger, middle, older). At other times, you may need to convert a numeric variable into a different numeric variable (e.g., you may want to analyse at the absolute value of the original variable). In this section I’ll describe a few key tricks that you can make use of to do this.</p>
<div id="creating-a-transformed-variable" class="section level3">
<h3><span class="header-section-number">7.2.1</span> Creating a transformed variable</h3>
<p>The first trick to discuss is the idea of <strong><em>transforming</em></strong> a variable. Taken literally, <em>anything</em> you do to a variable is a transformation, but in practice what it usually means is that you apply a relatively simple mathematical function to the original variable, in order to create new variable that either (a) provides a better way of describing the thing you’re actually interested in or (b) is more closely in agreement with the assumptions of the statistical tests you want to do. Since – at this stage – I haven’t talked about statistical tests or their assumptions, I’ll show you an example based on the first case.</p>
<p>To keep the explanation simple, the variable we’ll try to transform (<code>likert.raw</code>) isn’t inside a data frame, though in real life it almost certainly would be. However, I think it’s useful to start with an example that doesn’t use data frames because it illustrates the fact that you already know how to do variable transformations. To see this, let’s go through an example. Suppose I’ve run a short study in which I ask 10 people a single question:</p>
<blockquote>
<p>On a scale of 1 (strongly disagree) to 7 (strongly agree), to what extent do you agree with the proposition that “Dinosaurs are awesome”?</p>
</blockquote>
<p>Now let’s load and look at the data. The data file <code>likert.Rdata</code> contains a single variable that contains the raw Likert-scale responses:</p>
<div class="sourceCode" id="cb548"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb548-1" title="1"><span class="kw">load</span>(<span class="kw">file.path</span>(projecthome,<span class="st">&quot;data&quot;</span>,<span class="st">&quot;likert.Rdata&quot;</span>))</a>
<a class="sourceLine" id="cb548-2" title="2">likert.raw</a></code></pre></div>
<pre><code>##  [1] 1 7 3 4 4 4 2 6 5 5</code></pre>
<p>However, if you think about it, this isn’t the best way to represent these responses. Because of the fairly symmetric way that we set up the response scale, there’s a sense in which the midpoint of the scale should have been coded as 0 (no opinion), and the two endpoints should be <span class="math inline">\(+3\)</span> (strong agree) and <span class="math inline">\(-3\)</span> (strong disagree). By recoding the data in this way, it’s a bit more reflective of how we really think about the responses. The recoding here is trivially easy: we just subtract 4 from the raw scores:</p>
<div class="sourceCode" id="cb550"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb550-1" title="1">likert.centred &lt;-<span class="st"> </span>likert.raw <span class="op">-</span><span class="st"> </span><span class="dv">4</span></a>
<a class="sourceLine" id="cb550-2" title="2">likert.centred</a></code></pre></div>
<pre><code>##  [1] -3  3 -1  0  0  0 -2  2  1  1</code></pre>
<p>One reason why it might be useful to have the data in this format is that there are a lot of situations where you might prefer to analyse the <em>strength</em> of the opinion separately from the <em>direction</em> of the opinion. We can do two different transformations on this <code>likert.centred</code> variable in order to distinguish between these two different concepts. Firstly, to compute an <code>opinion.strength</code> variable, we want to take the absolute value of the centred data (using the <code>abs()</code> function that we’ve seen previously), like so:</p>
<div class="sourceCode" id="cb552"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb552-1" title="1">opinion.strength &lt;-<span class="st"> </span><span class="kw">abs</span>( likert.centred )</a>
<a class="sourceLine" id="cb552-2" title="2">opinion.strength</a></code></pre></div>
<pre><code>##  [1] 3 3 1 0 0 0 2 2 1 1</code></pre>
<p>Secondly, to compute a variable that contains only the direction of the opinion and ignores the strength, we can use the <code>sign()</code> function to do this. If you type <code>?sign</code> you’ll see that this function is really simple: all negative numbers are converted to <span class="math inline">\(-1\)</span>, all positive numbers are converted to <span class="math inline">\(1\)</span> and zero stays as <span class="math inline">\(0\)</span>. So, when we apply the <code>sign()</code> function we obtain the following:</p>
<div class="sourceCode" id="cb554"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb554-1" title="1">opinion.dir &lt;-<span class="st"> </span><span class="kw">sign</span>( likert.centred )</a>
<a class="sourceLine" id="cb554-2" title="2">opinion.dir</a></code></pre></div>
<pre><code>##  [1] -1  1 -1  0  0  0 -1  1  1  1</code></pre>
<p>And we’re done. We now have three shiny new variables, all of which are useful transformations of the original <code>likert.raw</code> data. All of this should seem pretty familiar to you. The tools that you use to do regular calculations in R (e.g., Chapters @ref(introR) and @ref(mechanics)) are very much the same ones that you use to transform your variables! To that end, in Section @ref(mathfunc) I’ll revisit the topic of doing calculations in R because there’s a lot of other functions and operations that are worth knowing about.</p>
<p>Before moving on, you might be curious to see what these calculations look like if the data had started out in a data frame. To that end, it may help to note that the following example does all of the calculations using variables inside a data frame, and stores the variables created inside it:</p>
<div class="sourceCode" id="cb556"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb556-1" title="1">df &lt;-<span class="st"> </span><span class="kw">data.frame</span>( likert.raw )                   <span class="co"># create data frame</span></a>
<a class="sourceLine" id="cb556-2" title="2">df<span class="op">$</span>likert.centred &lt;-<span class="st"> </span>df<span class="op">$</span>likert.raw <span class="op">-</span><span class="st"> </span><span class="dv">4</span>           <span class="co"># create centred data</span></a>
<a class="sourceLine" id="cb556-3" title="3">df<span class="op">$</span>opinion.strength &lt;-<span class="st"> </span><span class="kw">abs</span>( df<span class="op">$</span>likert.centred )  <span class="co"># create strength variable</span></a>
<a class="sourceLine" id="cb556-4" title="4">df<span class="op">$</span>opinion.dir &lt;-<span class="st"> </span><span class="kw">sign</span>( df<span class="op">$</span>likert.centred )      <span class="co"># create direction variable</span></a>
<a class="sourceLine" id="cb556-5" title="5">df                                               <span class="co"># print the final data frame:</span></a></code></pre></div>
<pre><code>##    likert.raw likert.centred opinion.strength opinion.dir
## 1           1             -3                3          -1
## 2           7              3                3           1
## 3           3             -1                1          -1
## 4           4              0                0           0
## 5           4              0                0           0
## 6           4              0                0           0
## 7           2             -2                2          -1
## 8           6              2                2           1
## 9           5              1                1           1
## 10          5              1                1           1</code></pre>
<p>In other words, the commands you use are basically ones as before: it’s just that every time you want to read a variable from the data frame or write to the data frame, you use the <code>$</code> operator. That’s the easiest way to do it, though I should make note of the fact that people sometimes make use of the <code>within()</code> function to do the same thing. However, since (a) I don’t use the <code>within()</code> function anywhere else in this book, and (b) the <code>$</code> operator works just fine, I won’t discuss it any further.</p>
</div>
<div id="cutting-a-numeric-variable-into-categories" class="section level3">
<h3><span class="header-section-number">7.2.2</span> Cutting a numeric variable into categories</h3>
<p>One pragmatic task that arises more often than you’d think is the problem of cutting a numeric variable up into discrete categories. For instance, suppose I’m interested in looking at the age distribution of people at a social gathering:</p>
<div class="sourceCode" id="cb558"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb558-1" title="1">age &lt;-<span class="st"> </span><span class="kw">c</span>( <span class="dv">60</span>,<span class="dv">58</span>,<span class="dv">24</span>,<span class="dv">26</span>,<span class="dv">34</span>,<span class="dv">42</span>,<span class="dv">31</span>,<span class="dv">30</span>,<span class="dv">33</span>,<span class="dv">2</span>,<span class="dv">9</span> )</a></code></pre></div>
<p>In some situations it can be quite helpful to group these into a smallish number of categories. For example, we could group the data into three broad categories: young (0-20), adult (21-40) and older (41-60). This is a quite coarse-grained classification, and the labels that I’ve attached only make sense in the context of this data set (e.g., viewed more generally, a 42 year old wouldn’t consider themselves as “older”). We can slice this variable up quite easily using the <code>cut()</code> function.<a href="#fn106" class="footnote-ref" id="fnref106"><sup>106</sup></a> To make things a little cleaner, I’ll start by creating a variable that defines the boundaries for the categories:</p>
<div class="sourceCode" id="cb559"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb559-1" title="1">age.breaks &lt;-<span class="st"> </span><span class="kw">seq</span>( <span class="dt">from =</span> <span class="dv">0</span>, <span class="dt">to =</span> <span class="dv">60</span>, <span class="dt">by =</span> <span class="dv">20</span> )</a>
<a class="sourceLine" id="cb559-2" title="2">age.breaks</a></code></pre></div>
<pre><code>## [1]  0 20 40 60</code></pre>
<p>and another one for the labels:</p>
<div class="sourceCode" id="cb561"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb561-1" title="1">age.labels &lt;-<span class="st"> </span><span class="kw">c</span>( <span class="st">&quot;young&quot;</span>, <span class="st">&quot;adult&quot;</span>, <span class="st">&quot;older&quot;</span> )</a>
<a class="sourceLine" id="cb561-2" title="2">age.labels</a></code></pre></div>
<pre><code>## [1] &quot;young&quot; &quot;adult&quot; &quot;older&quot;</code></pre>
<p>Note that there are four numbers in the <code>age.breaks</code> variable, but only three labels in the <code>age.labels</code> variable; I’ve done this because the <code>cut()</code> function requires that you specify the <em>edges</em> of the categories rather than the mid-points. In any case, now that we’ve done this, we can use the <code>cut()</code> function to assign each observation to one of these three categories. There are several arguments to the <code>cut()</code> function, but the three that we need to care about are:</p>
<ul>
<li><code>x</code>. The variable that needs to be categorised.</li>
<li><code>breaks</code>. This is either a vector containing the locations of the breaks separating the categories, or a number indicating how many categories you want.</li>
<li><code>labels</code>. The labels attached to the categories. This is optional: if you don’t specify this R will attach a boring label showing the range associated with each category.</li>
</ul>
<p>Since we’ve already created variables corresponding to the breaks and the labels, the command we need is just:</p>
<div class="sourceCode" id="cb563"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb563-1" title="1">age.group &lt;-<span class="st"> </span><span class="kw">cut</span>( <span class="dt">x =</span> age,               <span class="co"># the variable to be categorised</span></a>
<a class="sourceLine" id="cb563-2" title="2">                   <span class="dt">breaks =</span> age.breaks,   <span class="co"># the edges of the categories</span></a>
<a class="sourceLine" id="cb563-3" title="3">                   <span class="dt">labels =</span> age.labels )  <span class="co"># the labels for the categories</span></a></code></pre></div>
<p>Note that the output variable here is a factor. In order to see what this command has actually done, we could just print out the <code>age.group</code> variable, but I think it’s actually more helpful to create a data frame that includes both the original variable and the categorised one, so that you can see the two side by side:</p>
<div class="sourceCode" id="cb564"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb564-1" title="1"><span class="kw">data.frame</span>(age, age.group)</a></code></pre></div>
<pre><code>##    age age.group
## 1   60     older
## 2   58     older
## 3   24     adult
## 4   26     adult
## 5   34     adult
## 6   42     older
## 7   31     adult
## 8   30     adult
## 9   33     adult
## 10   2     young
## 11   9     young</code></pre>
<p>It can also be useful to tabulate the output, just to see if you’ve got a nice even division of the sample:</p>
<div class="sourceCode" id="cb566"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb566-1" title="1"><span class="kw">table</span>( age.group )</a></code></pre></div>
<pre><code>## age.group
## young adult older 
##     2     6     3</code></pre>
<p>In the example above, I made all the decisions myself. Much like the <code>hist()</code> function that we saw in Chapter @ref(graphics), if you want to you can delegate a lot of the choices to R. For instance, if you want you can specify the <em>number</em> of categories you want, rather than giving explicit ranges for them, and you can allow R to come up with some labels for the categories. To give you a sense of how this works, have a look at the following example:</p>
<div class="sourceCode" id="cb568"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb568-1" title="1">age.group2 &lt;-<span class="st"> </span><span class="kw">cut</span>( <span class="dt">x =</span> age, <span class="dt">breaks =</span> <span class="dv">3</span> )</a></code></pre></div>
<p>With this command, I’ve asked for three categories, but let R make the choices for where the boundaries should be. I won’t bother to print out the <code>age.group2</code> variable, because it’s not terribly pretty or very interesting. Instead, all of the important information can be extracted by looking at the tabulated data:</p>
<div class="sourceCode" id="cb569"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb569-1" title="1"><span class="kw">table</span>( age.group2 )</a></code></pre></div>
<pre><code>## age.group2
## (1.94,21.3] (21.3,40.7] (40.7,60.1] 
##           2           6           3</code></pre>
<p>This output takes a little bit of interpretation, but it’s not complicated. What R has done is determined that the lowest age category should run from 1.94 years up to 21.3 years, the second category should run from 21.3 years to 40.7 years, and so on. The formatting on those labels might look a bit funny to those of you who haven’t studied a lot of maths, but it’s pretty simple. When R describes the first category as corresponding to the range <span class="math inline">\((1.94, 21.3]\)</span> what it’s saying is that the range consists of those numbers that are larger than 1.94 but less than <em>or equal to</em> 21.3. In other words, the weird asymmetric brackets is R s way of telling you that if there happens to be a value that is exactly equal to 21.3, then it belongs to the first category, not the second one. Obviously, this isn’t actually possible since I’ve only specified the ages to the nearest whole number, but R doesn’t know this and so it’s trying to be precise just in case. This notation is actually pretty standard, but I suspect not everyone reading the book will have seen it before. In any case, those labels are pretty ugly, so it’s usually a good idea to specify your own, meaningful labels to the categories.</p>
<p>Before moving on, I should take a moment to talk a little about the mechanics of the <code>cut()</code> function. Notice that R has tried to divide the <code>age</code> variable into three roughly equal sized bins. Unless you specify the particular breaks you want, that’s what it will do. But suppose you want to divide the <code>age</code> variable into three categories of different size, but with approximately identical numbers of people. How would you do that? Well, if that’s the case, then what you want to do is have the breaks correspond to the 0th, 33rd, 66th and 100th percentiles of the data. One way to do this would be to calculate those values using the <code>quantiles()</code> function and then use those quantiles as input to the <code>cut()</code> function. That’s pretty easy to do, but it does take a couple of lines to type. So instead, the <code>lsr</code> package has a function called <code>quantileCut()</code> that does exactly this:</p>
<div class="sourceCode" id="cb571"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb571-1" title="1">age.group3 &lt;-<span class="st"> </span><span class="kw">quantileCut</span>( <span class="dt">x =</span> age, <span class="dt">n =</span> <span class="dv">3</span> )</a>
<a class="sourceLine" id="cb571-2" title="2"><span class="kw">table</span>( age.group3 )</a></code></pre></div>
<pre><code>## age.group3
## (1.94,27.3] (27.3,33.7] (33.7,60.1] 
##           4           3           4</code></pre>
<p>Notice the difference in the boundaries that the <code>quantileCut()</code> function selects. The first and third categories now span an age range of about 25 years each, whereas the middle category has shrunk to a span of only 6 years. There are some situations where this is genuinely what you want (that’s why I wrote the function!), but in general you should be careful. Usually the numeric variable that you’re trying to cut into categories is already expressed in meaningful units (i.e., it’s interval scale), but if you cut it into unequal bin sizes then it’s often very difficult to attach meaningful interpretations to the resulting categories.</p>
<p>More generally, regardless of whether you’re using the original <code>cut()</code> function or the <code>quantileCut()</code> version, it’s important to take the time to figure out whether or not the resulting categories make any sense at all in terms of your research project. If they don’t make any sense to you as meaningful categories, then any data analysis that uses those categories is likely to be just as meaningless. More generally, in practice I’ve noticed that people have a very strong desire to carve their (continuous and messy) data into a few (discrete and simple) categories; and then run analysis using the categorised data instead of the original one.<a href="#fn107" class="footnote-ref" id="fnref107"><sup>107</sup></a> I wouldn’t go so far as to say that this is an inherently bad idea, but it does have some fairly serious drawbacks at times, so I would advise some caution if you are thinking about doing it.</p>
</div>
</div>
<div id="mathfunc" class="section level2">
<h2><span class="header-section-number">7.3</span> A few more mathematical functions and operations</h2>
<p>In Section @ref(transform) I discussed the ideas behind variable transformations, and showed that a lot of the transformations that you might want to apply to your data are based on fairly simple mathematical functions and operations, of the kind that we discussed in Chapter @ref(introR). In this section I want to return to that discussion, and mention several other mathematical functions and arithmetic operations that I didn’t bother to mention when introducing you to R, but are actually quite useful for a lot of real world data analysis. Table @ref(tab:mathfunctab) gives a brief overview of the various mathematical functions I want to talk about (and some that I already have talked about). Obviously this doesn’t even come close to cataloging the range of possibilities available in R, but it does cover a very wide range of functions that are used in day to day data analysis.</p>
<table>
<caption>(#tab:mathfunctab)Some of the mathematical functions available in R.</caption>
<thead>
<tr class="header">
<th align="left">mathematical.function</th>
<th align="left">R.function</th>
<th align="left">example.input</th>
<th align="left">answer</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">square root</td>
<td align="left">sqrt()</td>
<td align="left">sqrt(25)</td>
<td align="left">5</td>
</tr>
<tr class="even">
<td align="left">absolute value</td>
<td align="left">abs()</td>
<td align="left">abs(-23)</td>
<td align="left">23</td>
</tr>
<tr class="odd">
<td align="left">logarithm (base 10)</td>
<td align="left">log10()</td>
<td align="left">log10(1000)</td>
<td align="left">3</td>
</tr>
<tr class="even">
<td align="left">logarithm (base e)</td>
<td align="left">log()</td>
<td align="left">log(1000)</td>
<td align="left">6.908</td>
</tr>
<tr class="odd">
<td align="left">exponentiation</td>
<td align="left">exp()</td>
<td align="left">exp(6.908)</td>
<td align="left">1000.245</td>
</tr>
<tr class="even">
<td align="left">rounding to nearest</td>
<td align="left">round()</td>
<td align="left">round(1.32)</td>
<td align="left">1</td>
</tr>
<tr class="odd">
<td align="left">rounding down</td>
<td align="left">floor()</td>
<td align="left">floor(1.32)</td>
<td align="left">1</td>
</tr>
<tr class="even">
<td align="left">rounding up</td>
<td align="left">ceiling()</td>
<td align="left">ceiling(1.32)</td>
<td align="left">2</td>
</tr>
</tbody>
</table>
<div id="rounding-a-number" class="section level3">
<h3><span class="header-section-number">7.3.1</span> Rounding a number</h3>
<p>One very simple transformation that crops up surprisingly often is the need to round a number to the nearest whole number, or to a certain number of significant digits. To start with, let’s assume that we want to round to a whole number. To that end, there are three useful functions in R you want to know about: <code>round()</code>, <code>floor()</code> and <code>ceiling()</code>. The <code>round()</code> function just rounds to the <em>nearest</em> whole number. So if you round the number 4.3, it “rounds down” to <code>4</code>, like so:</p>
<div class="sourceCode" id="cb573"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb573-1" title="1"><span class="kw">round</span>( <span class="dt">x =</span> <span class="fl">4.3</span> )</a></code></pre></div>
<pre><code>## [1] 4</code></pre>
<p>In contrast, if we want to round the number 4.7, we would round upwards to 5.
In everyday life, when someone talks about “rounding”, they usually mean “round to nearest”, so this is the function we use most of the time. However sometimes you have reasons to want to always round up or always round down. If you want to always round down, use the <code>floor()</code> function instead; and if you want to force R to round up, then use <code>ceiling()</code>. That’s the only difference between the three functions. What if you want to round to a certain number of digits? Let’s suppose you want to round to a fixed number of decimal places, say 2 decimal places. If so, what you need to do is specify the <code>digits</code> argument to the <code>round()</code> function. That’s pretty straightforward:</p>
<div class="sourceCode" id="cb575"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb575-1" title="1"><span class="kw">round</span>( <span class="dt">x =</span> <span class="fl">0.0123</span>, <span class="dt">digits =</span> <span class="dv">2</span> )</a></code></pre></div>
<pre><code>## [1] 0.01</code></pre>
<p>The only subtlety that you need to keep in mind is that sometimes what you want to do is round to 2 <strong><em>significant digits</em></strong> and not to two decimal places. The difference is that, when determining the number of significant digits, zeros don’t count. To see this, let’s apply the <code>signif()</code> function instead of the <code>round()</code> function:</p>
<div class="sourceCode" id="cb577"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb577-1" title="1"><span class="kw">signif</span>( <span class="dt">x =</span> <span class="fl">0.0123</span>, <span class="dt">digits =</span> <span class="dv">2</span> )</a></code></pre></div>
<pre><code>## [1] 0.012</code></pre>
<p>This time around, we get an answer of 0.012 because the zeros don’t count as significant digits. Quite often scientific journals will ask you to report numbers to two or three significant digits, so it’s useful to remember the distinction.</p>
</div>
<div id="modulus-and-integer-division" class="section level3">
<h3><span class="header-section-number">7.3.2</span> Modulus and integer division</h3>
<table>
<caption>(#tab:arithmetic2)Two more arithmetic operations that sometimes come in handy</caption>
<thead>
<tr class="header">
<th align="left">operation</th>
<th align="left">operator</th>
<th align="left">example.input</th>
<th align="left">answer</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">integer division</td>
<td align="left">%/%</td>
<td align="left">42 %/% 10</td>
<td align="left">4</td>
</tr>
<tr class="even">
<td align="left">modulus</td>
<td align="left">%%</td>
<td align="left">42 %% 10</td>
<td align="left">2</td>
</tr>
</tbody>
</table>
<p>Since we’re on the topic of simple calculations, there are two other arithmetic operations that I should mention, since they can come in handy when working with real data. These operations are calculating a modulus and doing integer division. They don’t come up anywhere else in this book, but they are worth knowing about. First, let’s consider <strong><em>integer division</em></strong>. Suppose I have $42 in my wallet, and want to buy some sandwiches, which are selling for $10 each. How many sandwiches can I afford<a href="#fn108" class="footnote-ref" id="fnref108"><sup>108</sup></a> to buy? The answer is of course 4. Note that it’s not 4.2, since no shop will sell me one-fifth of a sandwich. That’s integer division. In R we perform integer division by using the <code>%/%</code> operator:</p>
<div class="sourceCode" id="cb579"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb579-1" title="1"><span class="dv">42</span> <span class="op">%/%</span><span class="st"> </span><span class="dv">10</span></a></code></pre></div>
<pre><code>## [1] 4</code></pre>
<p>Okay, that’s easy enough. What about the <strong><em>modulus</em></strong>? Basically, a modulus is the remainder after integer division, and it’s calculated using the <code>%%</code> operator. For the sake of argument, let’s suppose I buy four overpriced $10 sandwiches. If I started out with $42, how much money do I have left? The answer, as both R and common sense tells us, is $2:</p>
<div class="sourceCode" id="cb581"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb581-1" title="1"><span class="dv">42</span> <span class="op">%%</span><span class="st"> </span><span class="dv">10</span></a></code></pre></div>
<pre><code>## [1] 2</code></pre>
<p>So that’s also pretty easy. There is, however, one subtlety that I need to mention, and this relates to how negative numbers are handled. Firstly, what would happen if I tried to do integer division with a negative number? Let’s have a look:</p>
<div class="sourceCode" id="cb583"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb583-1" title="1"><span class="dv">-42</span> <span class="op">%/%</span><span class="st"> </span><span class="dv">10</span></a></code></pre></div>
<pre><code>## [1] -5</code></pre>
<p>This might strike you as counterintuitive: why does <code>42 %/% 10</code> produce an answer of <code>4</code>, but <code>-42 %/% 10</code> gives us an answer of <code>-5</code>? Intuitively you might think that the answer to the second one should be <code>-4</code>. The way to think about it is like this. Suppose I <em>owe</em> the sandwich shop $42, but I don’t have any money. How many sandwiches would <em>I</em> have to give <em>them</em> in order to stop them from calling security? The answer<a href="#fn109" class="footnote-ref" id="fnref109"><sup>109</sup></a> here is 5, not 4. If I handed them 4 sandwiches, I’d still owe them $2, right? So I actually have to give them 5 sandwiches. And since it’s <em>me</em> giving them the sandwiches, the answer to <code>-42 %/% 10</code> is <code>-5</code>. As you might expect, the behaviour of the modulus operator has a similar pattern. If I’ve handed 5 sandwiches over to the shop in order to pay off my debt of $42, then <em>they</em> now owe me $8. So the modulus is now:</p>
<div class="sourceCode" id="cb585"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb585-1" title="1"><span class="dv">-42</span> <span class="op">%%</span><span class="st"> </span><span class="dv">10</span></a></code></pre></div>
<pre><code>## [1] 8</code></pre>
</div>
<div id="logarithms-and-exponentials" class="section level3">
<h3><span class="header-section-number">7.3.3</span> Logarithms and exponentials</h3>
<p>As I’ve mentioned earlier, R has an incredible range of mathematical functions built into it, and there really wouldn’t be much point in trying to describe or even list all of them. For the most part, I’ve focused only on those functions that are strictly necessary for this book. However I do want to make an exception for logarithms and exponentials. Although they aren’t needed anywhere else in this book, they are <em>everywhere</em> in statistics more broadly, and not only that, there are a <em>lot</em> of situations in which it is convenient to analyse the logarithm of a variable (i.e., to take a “log-transform” of the variable). I suspect that many (maybe most) readers of this book will have encountered logarithms and exponentials before, but from past experience I know that there’s a substantial proportion of students who take a social science statistics class who haven’t touched logarithms since high school, and would appreciate a bit of a refresher.</p>
<p>In order to understand logarithms and exponentials, the easiest thing to do is to actually calculate them and see how they relate to other simple calculations. There are three R functions in particular that I want to talk about, namely <code>log()</code>, <code>log10()</code> and <code>exp()</code>. To start with, let’s consider <code>log10()</code>, which is known as the “logarithm in base 10”. The trick to understanding a <strong><em>logarithm</em></strong> is to understand that it’s basically the “opposite” of taking a power. Specifically, the logarithm in base 10 is closely related to the powers of 10. So let’s start by noting that 10-cubed is 1000. Mathematically, we would write this:
<span class="math display">\[ 
10^3 = 1000
\]</span>
and in R we’d calculate it by using the command <code>10^3</code>. The trick to understanding a logarithm is to recognise that the statement that “10 to the power of 3 is equal to 1000” is equivalent to the statement that “the logarithm (in base 10) of 1000 is equal to 3”. Mathematically, we write this as follows,
<span class="math display">\[
\log_{10}( 1000 ) = 3
\]</span>
and if we wanted to do the calculation in R we would type this:</p>
<div class="sourceCode" id="cb587"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb587-1" title="1"><span class="kw">log10</span>( <span class="dv">1000</span> )</a></code></pre></div>
<pre><code>## [1] 3</code></pre>
<p>Obviously, since you already know that <span class="math inline">\(10^3 = 1000\)</span> there’s really no point in getting R to tell you that the base-10 logarithm of 1000 is 3. However, most of the time you probably don’t know what right answer is. For instance, I can honestly say that I didn’t know that <span class="math inline">\(10^{2.69897} = 500\)</span>, so it’s rather convenient for me that I can use R to calculate the base-10 logarithm of 500:</p>
<div class="sourceCode" id="cb589"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb589-1" title="1"><span class="kw">log10</span>( <span class="dv">500</span> )</a></code></pre></div>
<pre><code>## [1] 2.69897</code></pre>
<p>Or at least it would be convenient if I had a pressing need to know the base-10 logarithm of 500.</p>
<p>Okay, since the <code>log10()</code> function is related to the powers of 10, you might expect that there are other logarithms (in bases other than 10) that are related to other powers too. And of course that’s true: there’s not really anything mathematically special about the number 10. You and I happen to find it useful because decimal numbers are built around the number 10, but the big bad world of mathematics scoffs at our decimal numbers. Sadly, the universe doesn’t actually care how we write down numbers. Anyway, the consequence of this cosmic indifference is that there’s nothing particularly special about calculating logarithms in base 10. You could, for instance, calculate your logarithms in base 2, and in fact R does provide a function for doing that, which is (not surprisingly) called <code>log2()</code>. Since we know that <span class="math inline">\(2^3 = 2 \times 2 \times 2 = 8\)</span>, it’s not surprise to see that</p>
<div class="sourceCode" id="cb591"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb591-1" title="1"><span class="kw">log2</span>( <span class="dv">8</span> )</a></code></pre></div>
<pre><code>## [1] 3</code></pre>
<p>Alternatively, a third type of logarithm – and one we see a lot more of in statistics than either base 10 or base 2 – is called the <strong><em>natural logarithm</em></strong>, and corresponds to the logarithm in base <span class="math inline">\(e\)</span>. Since you might one day run into it, I’d better explain what <span class="math inline">\(e\)</span> is. The number <span class="math inline">\(e\)</span>, known as <strong><em>Euler’s number</em></strong>, is one of those annoying “irrational” numbers whose decimal expansion is infinitely long, and is considered one of the most important numbers in mathematics. The first few digits of <span class="math inline">\(e\)</span> are:
<span class="math display">\[
e = 2.718282 
\]</span>
There are quite a few situation in statistics that require us to calculate powers of <span class="math inline">\(e\)</span>, though none of them appear in this book. Raising <span class="math inline">\(e\)</span> to the power <span class="math inline">\(x\)</span> is called the <strong><em>exponential</em></strong> of <span class="math inline">\(x\)</span>, and so it’s very common to see <span class="math inline">\(e^x\)</span> written as <span class="math inline">\(\exp(x)\)</span>. And so it’s no surprise that R has a function that calculate exponentials, called <code>exp()</code>. For instance, suppose I wanted to calculate <span class="math inline">\(e^3\)</span>. I could try typing in the value of <span class="math inline">\(e\)</span> manually, like this:</p>
<div class="sourceCode" id="cb593"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb593-1" title="1"><span class="fl">2.718282</span> <span class="op">^</span><span class="st"> </span><span class="dv">3</span></a></code></pre></div>
<pre><code>## [1] 20.08554</code></pre>
<p>but it’s much easier to do the same thing using the <code>exp()</code> function:</p>
<div class="sourceCode" id="cb595"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb595-1" title="1"><span class="kw">exp</span>( <span class="dv">3</span> )</a></code></pre></div>
<pre><code>## [1] 20.08554</code></pre>
<p>Anyway, because the number <span class="math inline">\(e\)</span> crops up so often in statistics, the natural logarithm (i.e., logarithm in base <span class="math inline">\(e\)</span>) also tends to turn up. Mathematicians often write it as <span class="math inline">\(\log_e(x)\)</span> or <span class="math inline">\(\ln(x)\)</span>, or sometimes even just <span class="math inline">\(\log(x)\)</span>. In fact, R works the same way: the <code>log()</code> function corresponds to the natural logarithm<a href="#fn110" class="footnote-ref" id="fnref110"><sup>110</sup></a> Anyway, as a quick check, let’s calculate the natural logarithm of 20.08554 using R:</p>
<div class="sourceCode" id="cb597"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb597-1" title="1"><span class="kw">log</span>( <span class="fl">20.08554</span> )</a></code></pre></div>
<pre><code>## [1] 3</code></pre>
<p>And with that, I think we’ve had quite enough exponentials and logarithms for this book!</p>
</div>
</div>
<div id="subset" class="section level2">
<h2><span class="header-section-number">7.4</span> Extracting a subset of a vector</h2>
<p>One very important kind of data handling is being able to extract a particular subset of the data. For instance, you might be interested only in analysing the data from one experimental condition, or you may want to look closely at the data from people over 50 years in age. To do this, the first step is getting R to extract the subset of the data corresponding to the observations that you’re interested in. In this section I’ll talk about subsetting as it applies to vectors, extending the discussion from Chapters @ref(introR) and @ref(mechanics). In Section @ref(subsetdataframe) I’ll go on to talk about how this discussion extends to data frames.</p>
<div id="refresher" class="section level3">
<h3><span class="header-section-number">7.4.1</span> Refresher</h3>
<p>This section returns to the <code>nightgarden.Rdata</code> data set. If you’re reading this whole chapter in one sitting, then you should already have this data set loaded. If not, don’t forget to use the <code>load("nightgarden.Rdata")</code> command. For this section, let’s ignore the <code>itng</code> data frame that we created earlier, and focus instead on the two vectors <code>speaker</code> and <code>utterance</code> (see Section @ref(freqtables) if you’ve forgotten what those vectors look like). Suppose that what I want to do is pull out only those utterances that were made by Makka-Pakka. To that end, I could first use the equality operator to have R tell me which cases correspond to Makka-Pakka speaking:</p>
<div class="sourceCode" id="cb599"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb599-1" title="1">is.MP.speaking &lt;-<span class="st"> </span>speaker <span class="op">==</span><span class="st"> &quot;makka-pakka&quot;</span></a>
<a class="sourceLine" id="cb599-2" title="2">is.MP.speaking</a></code></pre></div>
<pre><code>##  [1] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE</code></pre>
<p>and then use logical indexing to get R to print out those elements of <code>utterance</code> for which <code>is.MP.speaking</code> is true, like so:</p>
<div class="sourceCode" id="cb601"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb601-1" title="1">utterance[ is.MP.speaking ]</a></code></pre></div>
<pre><code>## [1] &quot;pip&quot; &quot;pip&quot; &quot;onk&quot; &quot;onk&quot;</code></pre>
<p>Or, since I’m lazy, I could collapse it to a single command like so:</p>
<div class="sourceCode" id="cb603"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb603-1" title="1">utterance[ speaker <span class="op">==</span><span class="st"> &quot;makka-pakka&quot;</span> ]</a></code></pre></div>
<pre><code>## [1] &quot;pip&quot; &quot;pip&quot; &quot;onk&quot; &quot;onk&quot;</code></pre>
</div>
<div id="using-in-to-match-multiple-cases" class="section level3">
<h3><span class="header-section-number">7.4.2</span> Using <code>%in%</code> to match multiple cases</h3>
<p>A second useful trick to be aware of is the <code>%in%</code>
operator<a href="#fn111" class="footnote-ref" id="fnref111"><sup>111</sup></a>. It’s actually very similar to the <code>==</code> operator, except that you can supply a collection of acceptable values. For instance, suppose I wanted to keep only those cases when the utterance is either “pip” or “oo”. One simple way do to this is:</p>
<div class="sourceCode" id="cb605"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb605-1" title="1">utterance <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;pip&quot;</span>,<span class="st">&quot;oo&quot;</span>) </a></code></pre></div>
<pre><code>##  [1]  TRUE  TRUE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE FALSE</code></pre>
<p>What this does if return <code>TRUE</code> for those elements of <code>utterance</code> that are either <code>"pip"</code> or <code>"oo"</code> and returns <code>FALSE</code> for all the others. What that means is that if I want a list of all those instances of characters speaking either of these two words, I could do this:</p>
<div class="sourceCode" id="cb607"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb607-1" title="1">speaker[ utterance <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;pip&quot;</span>,<span class="st">&quot;oo&quot;</span>) ]</a></code></pre></div>
<pre><code>## [1] &quot;upsy-daisy&quot;  &quot;upsy-daisy&quot;  &quot;tombliboo&quot;   &quot;makka-pakka&quot; &quot;makka-pakka&quot;</code></pre>
</div>
<div id="using-negative-indices-to-drop-elements" class="section level3">
<h3><span class="header-section-number">7.4.3</span> Using negative indices to drop elements</h3>
<p>Before moving onto data frames, there’s a couple of other tricks worth mentioning. The first of these is to use negative values as indices. Recall from Section @ref(indexing) that we can use a vector of numbers to extract a set of elements that we would like to keep. For instance, suppose I want to keep only elements 2 and 3 from <code>utterance</code>. I could do so like this:</p>
<div class="sourceCode" id="cb609"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb609-1" title="1">utterance[<span class="dv">2</span><span class="op">:</span><span class="dv">3</span>]</a></code></pre></div>
<pre><code>## [1] &quot;pip&quot; &quot;onk&quot;</code></pre>
<p>But suppose, on the other hand, that I have discovered that observations 2 and 3 are untrustworthy, and I want to keep everything <em>except</em> those two elements. To that end, R lets you use negative numbers to remove specific values, like so:</p>
<div class="sourceCode" id="cb611"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb611-1" title="1">utterance [ <span class="op">-</span>(<span class="dv">2</span><span class="op">:</span><span class="dv">3</span>) ]</a></code></pre></div>
<pre><code>## [1] &quot;pip&quot; &quot;onk&quot; &quot;ee&quot;  &quot;oo&quot;  &quot;pip&quot; &quot;pip&quot; &quot;onk&quot; &quot;onk&quot;</code></pre>
<p>The output here corresponds to element 1 of the original vector, followed by elements 4, 5, and so on. When all you want to do is remove a few cases, this is a very handy convention.</p>
</div>
<div id="splitting-a-vector-by-group" class="section level3">
<h3><span class="header-section-number">7.4.4</span> Splitting a vector by group</h3>
<p>One particular example of subsetting that is especially common is the problem of splitting one one variable up into several different variables, one corresponding to each group. For instance, in our <em>In the Night Garden</em> example, I might want to create subsets of the <code>utterance</code> variable for every character. One way to do this would be to just repeat the exercise that I went through earlier separately for each character, but that quickly gets annoying. A faster way do it is to use the <code>split()</code> function. The arguments are:</p>
<ul>
<li><code>x</code>. The variable that needs to be split into groups.</li>
<li><code>f</code>. The grouping variable.</li>
</ul>
<p>What this function does is output a list (Section @ref(lists)), containing one variable for each group. For instance, I could split up the <code>utterance</code> variable by <code>speaker</code> using the following command:</p>
<div class="sourceCode" id="cb613"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb613-1" title="1">speech.by.char &lt;-<span class="st"> </span><span class="kw">split</span>( <span class="dt">x =</span> utterance, <span class="dt">f =</span> speaker )</a>
<a class="sourceLine" id="cb613-2" title="2">speech.by.char</a></code></pre></div>
<pre><code>## $`makka-pakka`
## [1] &quot;pip&quot; &quot;pip&quot; &quot;onk&quot; &quot;onk&quot;
## 
## $tombliboo
## [1] &quot;ee&quot; &quot;oo&quot;
## 
## $`upsy-daisy`
## [1] &quot;pip&quot; &quot;pip&quot; &quot;onk&quot; &quot;onk&quot;</code></pre>
<p>Once you’re starting to become comfortable working with lists and data frames, this output is all you need, since you can work with this list in much the same way that you would work with a data frame. For instance, if you want the first utterance made by Makka-Pakka, all you need to do is type this:</p>
<div class="sourceCode" id="cb615"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb615-1" title="1">speech.by.char<span class="op">$</span><span class="st">`</span><span class="dt">makka-pakka</span><span class="st">`</span>[<span class="dv">1</span>]</a></code></pre></div>
<pre><code>## [1] &quot;pip&quot;</code></pre>
<p>Just remember that R does need you to add the quoting characters (i.e. <code>'</code>). Otherwise, there’s nothing particularly new or difficult here.</p>
<p>However, sometimes – especially when you’re just starting out – it can be convenient to pull these variables out of the list, and into the workspace. This isn’t too difficult to do, though it can be a little daunting to novices. To that end, I’ve included a function called <code>importList()</code> in the <code>lsr</code> package that does this.<a href="#fn112" class="footnote-ref" id="fnref112"><sup>112</sup></a> First, here’s what you’d have if you had wiped the workspace before the start of this section:</p>
<div class="sourceCode" id="cb617"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb617-1" title="1"><span class="kw">who</span>()</a></code></pre></div>
<pre><code>##    -- Name --             -- Class --   -- Size --
##    afl.finalists          factor        400       
##    afl.margins            numeric       176       
##    afl2                   data.frame    4296 x 2  
##    age                    numeric       11        
##    age.breaks             numeric       4         
##    age.group              factor        11        
##    age.group2             factor        11        
##    age.group3             factor        11        
##    age.labels             character     3         
##    colour                 logical       1         
##    d.cor                  numeric       1         
##    describeImg            list          0         
##    df                     data.frame    10 x 4    
##    effort                 data.frame    10 x 2    
##    emphCol                character     1         
##    emphColLight           character     1         
##    emphGrey               character     1         
##    eps                    logical       1         
##    Fibonacci              numeric       7         
##    freq                   integer       17        
##    generateRLineTypes     function                
##    generateRPointShapes   function                
##    height                 numeric       1         
##    i                      character     1         
##    is.MP.speaking         logical       10        
##    itng                   data.frame    10 x 2    
##    itng.table             table         3 x 4     
##    likert.centred         numeric       10        
##    likert.raw             numeric       10        
##    old                    list          66        
##    oneCorPlot             function                
##    opinion.dir            numeric       10        
##    opinion.strength       numeric       10        
##    out.0                  data.frame    100 x 2   
##    out.1                  data.frame    100 x 2   
##    out.2                  data.frame    100 x 2   
##    parenthood             data.frame    100 x 4   
##    plotOne                function                
##    projecthome            character     1         
##    some.data              numeric       18        
##    speaker                character     10        
##    speech.by.char         list          3         
##    suspicious.cases       logical       176       
##    teams                  character     17        
##    tp                     character     6         
##    utterance              character     10        
##    width                  numeric       1         
##    X1                     numeric       11        
##    X2                     numeric       11        
##    X3                     numeric       11        
##    X4                     numeric       11        
##    Y1                     numeric       11        
##    Y2                     numeric       11        
##    Y3                     numeric       11        
##    Y4                     numeric       11</code></pre>
<p>Now we use the <code>importList()</code> function to copy all of the variables within the <code>speech.by.char</code> list:</p>
<div class="sourceCode" id="cb619"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb619-1" title="1"><span class="kw">importList</span>( speech.by.char, <span class="dt">ask =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<p>Because the <code>importList()</code> function is attempting to create new variables based on the names of the elements of the list, it pauses to check that you’re okay with the variable names. The reason it does this is that, if one of the to-be-created variables has the same name as a variable that you already have in your workspace, that variable will end up being overwritten, so it’s a good idea to check. Assuming that you type <code>y</code>, it will go on to create the variables. Nothing <em>appears</em> to have happened, but if we look at our workspace now:</p>
<div class="sourceCode" id="cb620"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb620-1" title="1"><span class="kw">who</span>()</a></code></pre></div>
<pre><code>##    -- Name --             -- Class --   -- Size --
##    afl.finalists          factor        400       
##    afl.margins            numeric       176       
##    afl2                   data.frame    4296 x 2  
##    age                    numeric       11        
##    age.breaks             numeric       4         
##    age.group              factor        11        
##    age.group2             factor        11        
##    age.group3             factor        11        
##    age.labels             character     3         
##    colour                 logical       1         
##    d.cor                  numeric       1         
##    describeImg            list          0         
##    df                     data.frame    10 x 4    
##    effort                 data.frame    10 x 2    
##    emphCol                character     1         
##    emphColLight           character     1         
##    emphGrey               character     1         
##    eps                    logical       1         
##    Fibonacci              numeric       7         
##    freq                   integer       17        
##    generateRLineTypes     function                
##    generateRPointShapes   function                
##    height                 numeric       1         
##    i                      character     1         
##    is.MP.speaking         logical       10        
##    itng                   data.frame    10 x 2    
##    itng.table             table         3 x 4     
##    likert.centred         numeric       10        
##    likert.raw             numeric       10        
##    makka.pakka            character     4         
##    old                    list          66        
##    oneCorPlot             function                
##    opinion.dir            numeric       10        
##    opinion.strength       numeric       10        
##    out.0                  data.frame    100 x 2   
##    out.1                  data.frame    100 x 2   
##    out.2                  data.frame    100 x 2   
##    parenthood             data.frame    100 x 4   
##    plotOne                function                
##    projecthome            character     1         
##    some.data              numeric       18        
##    speaker                character     10        
##    speech.by.char         list          3         
##    suspicious.cases       logical       176       
##    teams                  character     17        
##    tombliboo              character     2         
##    tp                     character     6         
##    upsy.daisy             character     4         
##    utterance              character     10        
##    width                  numeric       1         
##    X1                     numeric       11        
##    X2                     numeric       11        
##    X3                     numeric       11        
##    X4                     numeric       11        
##    Y1                     numeric       11        
##    Y2                     numeric       11        
##    Y3                     numeric       11        
##    Y4                     numeric       11</code></pre>
<p>we see that there are three new variables, called <code>makka.pakka</code>, <code>tombliboo</code> and <code>upsy.daisy</code>. Notice that the <code>importList()</code> function has converted the original character strings into valid R variable names, so the variable corresponding to <code>"makka-pakka"</code> is actually <code>makka.pakka</code>.<a href="#fn113" class="footnote-ref" id="fnref113"><sup>113</sup></a> Nevertheless, even though the names can change, note that each of these variables contains the exact same information as the original elements of the list did. For example:</p>
<pre><code>&gt; makka.pakka
[1] &quot;pip&quot; &quot;pip&quot; &quot;onk&quot; &quot;onk&quot;</code></pre>
</div>
</div>
<div id="subsetdataframe" class="section level2">
<h2><span class="header-section-number">7.5</span> Extracting a subset of a data frame</h2>
<p>In this section we turn to the question of how to subset a data frame rather than a vector. To that end, the first thing I should point out is that, if all you want to do is subset <em>one</em> of the variables inside the data frame, then as usual the <code>$</code> operator is your friend. For instance, suppose I’m working with the <code>itng</code> data frame, and what I want to do is create the <code>speech.by.char</code> list. I can use the exact same tricks that I used last time, since what I really want to do is <code>split()</code> the <code>itng$utterance</code> vector, using the <code>itng$speaker</code> vector as the grouping variable. However, most of the time what you actually want to do is select several different variables within the data frame (i.e., keep only some of the columns), or maybe a subset of cases (i.e., keep only some of the rows). In order to understand how this works, we need to talk more specifically about data frames and how to subset them.</p>
<div id="using-the-subset-function" class="section level3">
<h3><span class="header-section-number">7.5.1</span> Using the <code>subset()</code> function</h3>
<p>There are several different ways to subset a data frame in R, some easier than others. I’ll start by discussing the <code>subset()</code> function, which is probably the conceptually simplest way do it. For our purposes there are three different arguments that you’ll be most interested in:</p>
<ul>
<li><code>x</code>. The data frame that you want to subset.</li>
<li><code>subset</code>. A vector of logical values indicating which cases (rows) of the data frame you want to keep. By default, all cases will be retained.</li>
<li><code>select</code>. This argument indicates which variables (columns) in the data frame you want to keep. This can either be a list of variable names, or a logical vector indicating which ones to keep, or even just a numeric vector containing the relevant column numbers. By default, all variables will be retained.</li>
</ul>
<p>Let’s start with an example in which I use all three of these arguments. Suppose that I want to subset the <code>itng</code> data frame, keeping only the utterances made by Makka-Pakka. What that means is that I need to use the <code>select</code> argument to pick out the <code>utterance</code> variable, and I also need to use the <code>subset</code> variable, to pick out the cases when Makka-Pakka is speaking (i.e., <code>speaker == "makka-pakka"</code>). Therefore, the command I need to use is this:</p>
<div class="sourceCode" id="cb623"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb623-1" title="1">df &lt;-<span class="st"> </span><span class="kw">subset</span>( <span class="dt">x =</span> itng,                            <span class="co"># data frame is itng</span></a>
<a class="sourceLine" id="cb623-2" title="2">              <span class="dt">subset =</span> speaker <span class="op">==</span><span class="st"> &quot;makka-pakka&quot;</span>,   <span class="co"># keep only Makka-Pakkas speech</span></a>
<a class="sourceLine" id="cb623-3" title="3">              <span class="dt">select =</span> utterance )                 <span class="co"># keep only the utterance variable</span></a>
<a class="sourceLine" id="cb623-4" title="4"><span class="kw">print</span>( df )</a></code></pre></div>
<pre><code>##    utterance
## 7        pip
## 8        pip
## 9        onk
## 10       onk</code></pre>
<p>The variable <code>df</code> here is still a data frame, but it only contains one variable (called <code>utterance</code>) and four cases. Notice that the row numbers are actually the same ones from the original data frame. It’s worth taking a moment to briefly explain this. The reason that this happens is that these "row numbers’ are actually row <em>names</em>. When you create a new data frame from scratch R will assign each row a fairly boring row name, which is identical to the row number. However, when you subset the data frame, each row keeps its original row name. This can be quite useful, since – as in the current example – it provides you a visual reminder of what each row in the new data frame corresponds to in the original data frame. However, if it annoys you, you can change the row names using the <code>rownames()</code> function.<a href="#fn114" class="footnote-ref" id="fnref114"><sup>114</sup></a></p>
<p>In any case, let’s return to the <code>subset()</code> function, and look at what happens when we don’t use all three of the arguments. Firstly, suppose that I didn’t bother to specify the <code>select</code> argument. Let’s see what happens:</p>
<div class="sourceCode" id="cb625"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb625-1" title="1"><span class="kw">subset</span>( <span class="dt">x =</span> itng,</a>
<a class="sourceLine" id="cb625-2" title="2">        <span class="dt">subset =</span> speaker <span class="op">==</span><span class="st"> &quot;makka-pakka&quot;</span> )</a></code></pre></div>
<pre><code>##        speaker utterance
## 7  makka-pakka       pip
## 8  makka-pakka       pip
## 9  makka-pakka       onk
## 10 makka-pakka       onk</code></pre>
<p>Not surprisingly, R has kept the same cases from the original data set (i.e., rows 7 through 10), but this time it has kept all of the variables from the data frame. Equally unsurprisingly, if I don’t specify the <code>subset</code> argument, what we find is that R keeps all of the cases:</p>
<div class="sourceCode" id="cb627"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb627-1" title="1"><span class="kw">subset</span>( <span class="dt">x =</span> itng, </a>
<a class="sourceLine" id="cb627-2" title="2">         <span class="dt">select =</span> utterance )</a></code></pre></div>
<pre><code>##    utterance
## 1        pip
## 2        pip
## 3        onk
## 4        onk
## 5         ee
## 6         oo
## 7        pip
## 8        pip
## 9        onk
## 10       onk</code></pre>
<p>Again, it’s important to note that this output is still a data frame: it’s just a data frame with only a single variable.</p>
</div>
<div id="using-square-brackets-i.-rows-and-columns" class="section level3">
<h3><span class="header-section-number">7.5.2</span> Using square brackets: I. Rows and columns</h3>
<p>Throughout the book so far, whenever I’ve been subsetting a vector I’ve tended use the square brackets <code>[]</code> to do so. But in the previous section when I started talking about subsetting a data frame I used the <code>subset()</code> function. As a consequence, you might be wondering whether it is possible to use the square brackets to subset a data frame. The answer, of course, is yes. Not only <em>can</em> you use square brackets for this purpose, as you become more familiar with R you’ll find that this is actually much more convenient than using <code>subset()</code>. Unfortunately, the use of square brackets for this purpose is somewhat complicated, and can be very confusing to novices. So be warned: this section is more complicated than it feels like it “should” be. With that warning in place, I’ll try to walk you through it slowly. For this section, I’ll use a slightly different data set, namely the <code>garden</code> data frame that is stored in the <code>"nightgarden2.Rdata"</code> file.</p>
<div class="sourceCode" id="cb629"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb629-1" title="1"><span class="kw">load</span>(<span class="kw">file.path</span>(projecthome,<span class="st">&quot;data&quot;</span>,<span class="st">&quot;nightgarden2.Rdata&quot;</span>))</a>
<a class="sourceLine" id="cb629-2" title="2">garden</a></code></pre></div>
<pre><code>##            speaker utterance line
## case.1  upsy-daisy       pip    1
## case.2  upsy-daisy       pip    2
## case.3   tombliboo        ee    5
## case.4 makka-pakka       pip    7
## case.5 makka-pakka       onk    9</code></pre>
<p>As you can see, the <code>garden</code> data frame contains 3 variables and 5 cases, and this time around I’ve used the <code>rownames()</code> function to attach slightly verbose labels to each of the cases. Moreover, let’s assume that what we want to do is to pick out rows 4 and 5 (the two cases when Makka-Pakka is speaking), and columns 1 and 2 (variables <code>speaker</code> and <code>utterance</code>).</p>
<p>How shall we do this? As usual, there’s more than one way. The first way is based on the observation that, since a data frame is basically a table, every element in the data frame has a row number and a column number. So, if we want to pick out a single element, we have to specify the row number <em>and</em> a column number within the square brackets. By convention, the row number comes first. So, for the data frame above, which has 5 rows and 3 columns, the numerical indexing scheme looks like this:</p>
<div class="sourceCode" id="cb631"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb631-1" title="1">knitr<span class="op">::</span><span class="kw">kable</span>(<span class="kw">data.frame</span>(<span class="dt">stringsAsFactors=</span><span class="ot">FALSE</span>, <span class="dt">row =</span> <span class="kw">c</span>(<span class="st">&quot;1&quot;</span>,<span class="st">&quot;2&quot;</span>,<span class="st">&quot;3&quot;</span>, <span class="st">&quot;4&quot;</span>, <span class="st">&quot;5&quot;</span>), <span class="dt">col1 =</span> <span class="kw">c</span>(<span class="st">&quot;[1,1]&quot;</span>, <span class="st">&quot;[2,1]&quot;</span>, <span class="st">&quot;[3,1]&quot;</span>, <span class="st">&quot;[4,1]&quot;</span>, <span class="st">&quot;[5,1]&quot;</span>), <span class="dt">col2 =</span> <span class="kw">c</span>(<span class="st">&quot;[1,2]&quot;</span>, <span class="st">&quot;[2,2]&quot;</span>, <span class="st">&quot;[3,2]&quot;</span>, <span class="st">&quot;[4,2]&quot;</span>, <span class="st">&quot;[5,2]&quot;</span>), <span class="dt">col3 =</span> <span class="kw">c</span>(<span class="st">&quot;[1,3]&quot;</span>, <span class="st">&quot;[2,3]&quot;</span>, <span class="st">&quot;[3,3]&quot;</span>, <span class="st">&quot;[4,3]&quot;</span>, <span class="st">&quot;[5,3]&quot;</span>)))</a></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">row</th>
<th align="left">col1</th>
<th align="left">col2</th>
<th align="left">col3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1</td>
<td align="left">[1,1]</td>
<td align="left">[1,2]</td>
<td align="left">[1,3]</td>
</tr>
<tr class="even">
<td align="left">2</td>
<td align="left">[2,1]</td>
<td align="left">[2,2]</td>
<td align="left">[2,3]</td>
</tr>
<tr class="odd">
<td align="left">3</td>
<td align="left">[3,1]</td>
<td align="left">[3,2]</td>
<td align="left">[3,3]</td>
</tr>
<tr class="even">
<td align="left">4</td>
<td align="left">[4,1]</td>
<td align="left">[4,2]</td>
<td align="left">[4,3]</td>
</tr>
<tr class="odd">
<td align="left">5</td>
<td align="left">[5,1]</td>
<td align="left">[5,2]</td>
<td align="left">[5,3]</td>
</tr>
</tbody>
</table>
<p>If I want the 3rd case of the 2nd variable, what I would type is <code>garden[3,2]</code>, and R would print out some output showing that, this element corresponds to the utterance <code>"ee"</code>. However, let’s hold off from actually doing that for a moment, because there’s something slightly counterintuitive about the specifics of what R does under those circumstances (see Section @ref(dropping)). Instead, let’s aim to solve our original problem, which is to pull out two rows (4 and 5) and two columns (1 and 2). This is fairly simple to do, since R allows us to specify multiple rows and multiple columns. So let’s try that:</p>
<div class="sourceCode" id="cb632"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb632-1" title="1">garden[ <span class="dv">4</span><span class="op">:</span><span class="dv">5</span>, <span class="dv">1</span><span class="op">:</span><span class="dv">2</span> ]</a></code></pre></div>
<pre><code>##            speaker utterance
## case.4 makka-pakka       pip
## case.5 makka-pakka       onk</code></pre>
<p>Clearly, that’s exactly what we asked for: the output here is a data frame containing two variables and two cases. Note that I could have gotten the same answer if I’d used the <code>c()</code> function to produce my vectors rather than the <code>:</code> operator. That is, the following command is equivalent to the last one:</p>
<div class="sourceCode" id="cb634"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb634-1" title="1">garden[ <span class="kw">c</span>(<span class="dv">4</span>,<span class="dv">5</span>), <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>) ]</a></code></pre></div>
<pre><code>##            speaker utterance
## case.4 makka-pakka       pip
## case.5 makka-pakka       onk</code></pre>
<p>It’s just not as pretty. However, if the columns and rows that you want to keep don’t happen to be next to each other in the original data frame, then you might find that you have to resort to using commands like <code>garden[ c(2,4,5), c(1,3) ]</code> to extract them.</p>
<p>A second way to do the same thing is to use the names of the rows and columns. That is, instead of using the row numbers and column numbers, you use the character strings that are used as the labels for the rows and columns. To apply this idea to our <code>garden</code> data frame, we would use a command like this:</p>
<div class="sourceCode" id="cb636"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb636-1" title="1">garden[ <span class="kw">c</span>(<span class="st">&quot;case.4&quot;</span>, <span class="st">&quot;case.5&quot;</span>), <span class="kw">c</span>(<span class="st">&quot;speaker&quot;</span>, <span class="st">&quot;utterance&quot;</span>) ]</a></code></pre></div>
<pre><code>##            speaker utterance
## case.4 makka-pakka       pip
## case.5 makka-pakka       onk</code></pre>
<p>Once again, this produces exactly the same output, so I haven’t bothered to show it. Note that, although this version is more annoying to <em>type</em> than the previous version, it’s a bit easier to <em>read</em>, because it’s often more meaningful to refer to the elements by their names rather than their numbers. Also note that you don’t have to use the same convention for the rows and columns. For instance, I often find that the variable names are meaningful and so I sometimes refer to them by name, whereas the row names are pretty arbitrary so it’s easier to refer to them by number. In fact, that’s more or less exactly what’s happening with the <code>garden</code> data frame, so it probably makes more sense to use this as the command:</p>
<div class="sourceCode" id="cb638"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb638-1" title="1">garden[ <span class="dv">4</span><span class="op">:</span><span class="dv">5</span>, <span class="kw">c</span>(<span class="st">&quot;speaker&quot;</span>, <span class="st">&quot;utterance&quot;</span>) ]</a></code></pre></div>
<pre><code>##            speaker utterance
## case.4 makka-pakka       pip
## case.5 makka-pakka       onk</code></pre>
<p>Again, the output is identical.</p>
<p>Finally, both the rows and columns can be indexed using logicals vectors as well. For example, although I <em>claimed</em> earlier that my goal was to extract cases 4 and 5, it’s pretty obvious that what I really wanted to do was select the cases where Makka-Pakka is speaking. So what I could have done is create a logical vector that indicates which cases correspond to Makka-Pakka speaking:</p>
<div class="sourceCode" id="cb640"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb640-1" title="1">is.MP.speaking &lt;-<span class="st"> </span>garden<span class="op">$</span>speaker <span class="op">==</span><span class="st"> &quot;makka-pakka&quot;</span></a>
<a class="sourceLine" id="cb640-2" title="2">is.MP.speaking</a></code></pre></div>
<pre><code>## [1] FALSE FALSE FALSE  TRUE  TRUE</code></pre>
<p>As you can see, the 4th and 5th elements of this vector are <code>TRUE</code> while the others are <code>FALSE</code>. Now that I’ve constructed this “indicator” variable, what I can do is use this vector to select the rows that I want to keep:</p>
<div class="sourceCode" id="cb642"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb642-1" title="1">garden[ is.MP.speaking, <span class="kw">c</span>(<span class="st">&quot;speaker&quot;</span>, <span class="st">&quot;utterance&quot;</span>) ]</a></code></pre></div>
<pre><code>##            speaker utterance
## case.4 makka-pakka       pip
## case.5 makka-pakka       onk</code></pre>
<p>And of course the output is, yet again, the same.</p>
</div>
<div id="using-square-brackets-ii.-some-elaborations" class="section level3">
<h3><span class="header-section-number">7.5.3</span> Using square brackets: II. Some elaborations</h3>
There are two fairly useful elaborations on this “rows and columns” approach that I should point out. Firstly, what if you want to keep all of the rows, or all of the columns? To do this, all we have to do is leave the corresponding entry blank, but it is crucial to remember to 
<div id="refs" class="references">
<div id="ref-Adair1984">
<p>Adair, G. 1984. “The Hawthorne Effect: A Reconsideration of the Methodological Artifact.” <em>Journal of Applied Psychology</em> 69: 334–45.</p>
</div>
<div id="ref-Bickel1975">
<p>Bickel, P. J., E. A. Hammel, and J. W. O’Connell. 1975. “Sex Bias in Graduate Admissions: Data from Berkeley.” <em>Science</em> 187: 398–404.</p>
</div>
<div id="ref-Campbell1963">
<p>Campbell, D. T., and J. C. Stanley. 1963. <em>Experimental and Quasi-Experimental Designs for Research</em>. Boston, MA: Houghton Mifflin.</p>
</div>
<div id="ref-Ellman2002">
<p>Ellman, Michael. 2002. “Soviet Repression Statistics: Some Comments.” <em>Europe-Asia Studies</em> 54 (7): 1151–72.</p>
</div>
<div id="ref-Evans1983">
<p>Evans, J. St. B. T., J. L. Barston, and P. Pollard. 1983. “On the Conflict Between Logic and Belief in Syllogistic Reasoning.” <em>Memory and Cognition</em> 11: 295–306.</p>
</div>
<div id="ref-Fox2011">
<p>Fox, J., and S. Weisberg. 2011. <em>An R Companion to Applied Regression</em>. 2nd ed. Los Angeles: Sage.</p>
</div>
<div id="ref-Hothersall2004">
<p>Hothersall, D. 2004. <em>History of Psychology</em>. McGraw-Hill.</p>
</div>
<div id="ref-Ioannidis2005">
<p>Ioannidis, John P. A. 2005. “Why Most Published Research Findings Are False.” <em>PLoS Med</em> 2 (8): 697–701.</p>
</div>
<div id="ref-Kahneman1973">
<p>Kahneman, D., and A. Tversky. 1973. “On the Psychology of Prediction.” <em>Psychological Review</em> 80: 237–51.</p>
</div>
<div id="ref-Kuhberger2014">
<p>Kühberger, A, A Fritz, and T. Scherndl. 2014. “Publication Bias in Psychology: A Diagnosis Based on the Correlation Between Effect Size and Sample Size.” <em>Public Library of Science One</em> 9: 1–8.</p>
</div>
<div id="ref-Pfungst1911">
<p>Pfungst, O. 1911. <em>Clever Hans (the Horse of Mr. Von Osten): A Contribution to Experimental Animal and Human Psychology</em>. Translated by C. L. Rahn. New York: Henry Holt.</p>
</div>
<div id="ref-R2013">
<p>R Core Team. 2013. <em>R: A Language and Environment for Statistical Computing</em>. Vienna, Austria: R Foundation for Statistical Computing.</p>
</div>
<div id="ref-Rosenthal1966">
<p>Rosenthal, R. 1966. <em>Experimenter Effects in Behavioral Research</em>. New York: Appleton.</p>
</div>
<div id="ref-Stevens1946">
<p>Stevens, S. S. 1946. “On the Theory of Scales of Measurement.” <em>Science</em> 103: 677–80.</p>
</div>
<div id="ref-Wilkinson2006">
<p>Wilkinson, Leland, D Wills, D Rope, A Norton, and R Dubbs. 2006. <em>The Grammar of Graphics</em>. Springer.</p>
</div>
</div>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>The quote comes from Auden’s 1946 poem <em>Under Which Lyre: A Reactionary Tract for the Times</em>, delivered as part of a commencement address at Harvard University. The history of the poem is kind of interesting: <a href="http://harvardmagazine.com/2007/11/a-poets-warning.html" class="uri">http://harvardmagazine.com/2007/11/a-poets-warning.html</a><a href="#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p>Including the suggestion that common sense is in short supply among scientists.<a href="#fnref2" class="footnote-back">↩</a></p></li>
<li id="fn3"><p>In my more cynical moments I feel like this fact alone explains 95% of what I read on the internet.<a href="#fnref3" class="footnote-back">↩</a></p></li>
<li id="fn4"><p>Earlier versions of these notes incorrectly suggested that they actually were sued – apparently that’s not true. There’s a nice commentary on this here: <a href="https://www.refsmmat.com/posts/2016-05-08-simpsons-paradox-berkeley.html" class="uri">https://www.refsmmat.com/posts/2016-05-08-simpsons-paradox-berkeley.html</a>. A big thank you to Wilfried Van Hirtum for pointing this out to me!<a href="#fnref4" class="footnote-back">↩</a></p></li>
<li id="fn5"><p>Which might explain why physics is just a teensy bit further advanced as a science than we are.<a href="#fnref5" class="footnote-back">↩</a></p></li>
<li id="fn6"><p>Presidential Address to the First Indian Statistical Congress, 1938. Source: <a href="http://en.wikiquote.org/wiki/Ronald_Fisher" class="uri">http://en.wikiquote.org/wiki/Ronald_Fisher</a><a href="#fnref6" class="footnote-back">↩</a></p></li>
<li id="fn7"><p>Well… now this is awkward, isn’t it? This section is one of the oldest parts of the book, and it’s outdated in a rather embarrassing way. I wrote this in 2010, at which point all of those facts <em>were</em> true. Revisiting this in 2018… well I’m not 33 any more, but that’s not surprising I suppose. I can’t imagine my chromosomes have changed, so I’m going to guess my karyotype was then and is now XY. The self-identified gender, on the other hand… ah. I suppose the fact that the title page now refers to me as Danielle rather than Daniel might possibly be a giveaway, but I don’t typically identify as “male” on a gender questionnaire these days, and I prefer <em>“she/her”</em> pronouns as a default (it’s a long story)! I did think a little about how I was going to handle this in the book, actually. The book has a somewhat distinct authorial voice to it, and I feel like it would be a rather different work if I went back and wrote everything as Danielle and updated all the pronouns in the work. Besides, it would be a lot of work, so I’ve left my name as “Dan” throughout the book, and in ant case “Dan” is a perfectly good nickname for “Danielle”, don’t you think? In any case, it’s not a big deal. I only wanted to mention it to make life a little easier for readers who aren’t sure how to refer to me. I still don’t like anchovies though :-)<a href="#fnref7" class="footnote-back">↩</a></p></li>
<li id="fn8"><p>Actually, I’ve been informed by readers with greater physics knowledge than I that temperature isn’t strictly an interval scale, in the sense that the amount of energy required to heat something up by 3<span class="math inline">\(^\circ\)</span> depends on it’s current temperature. So in the sense that physicists care about, temperature isn’t actually interval scale. But it still makes a cute example, so I’m going to ignore this little inconvenient truth.<a href="#fnref8" class="footnote-back">↩</a></p></li>
<li id="fn9"><p>Annoyingly, though, there’s a lot of different names used out there. I won’t list all of them – there would be no point in doing that – other than to note that R often uses “response variable” where I’ve used “outcome”, and a traditionalist would use “dependent variable”. Sigh. This sort of terminological confusion is very common, I’m afraid.<a href="#fnref9" class="footnote-back">↩</a></p></li>
<li id="fn10"><p>The reason why I say that it’s unmeasured is that if you <em>have</em> measured it, then you can use some fancy statistical tricks to deal with the confound. Because of the existence of these statistical solutions to the problem of confounds, we often refer to a confound that we have measured and dealt with as a <em>covariate</em>. Dealing with covariates is a topic for a more advanced course, but I thought I’d mention it in passing, since it’s kind of comforting to at least know that this stuff exists.<a href="#fnref10" class="footnote-back">↩</a></p></li>
<li id="fn11"><p>Some people might argue that if you’re not honest then you’re not a real scientist. Which does have some truth to it I guess, but that’s disingenuous (google the “No true Scotsman” fallacy). The fact is that there are lots of people who are employed ostensibly as scientists, and whose work has all of the trappings of science, but who are outright fraudulent. Pretending that they don’t exist by saying that they’re not scientists is just childish.<a href="#fnref11" class="footnote-back">↩</a></p></li>
<li id="fn12"><p>Clearly, the real effect is that only insane people would even try to read <em>Finnegans Wake.</em><a href="#fnref12" class="footnote-back">↩</a></p></li>
<li id="fn13"><p>Source: <em>Dismal Light</em> (1968).<a href="#fnref13" class="footnote-back">↩</a></p></li>
<li id="fn14"><p>Although R is updated frequently, it doesn’t usually make much of a difference for the sort of work we’ll do in this book. In fact, during the writing of the book I upgraded several times, and didn’t have to change much except these sections describing the downloading.<a href="#fnref14" class="footnote-back">↩</a></p></li>
<li id="fn15"><p>If you’re running an older version of the Mac OS, then you need to follow the link to the “old” page (<a href="http://cran.r-project.org/bin/macosx/old/" class="uri">http://cran.r-project.org/bin/macosx/old/</a>). You should be able to find the installer file that you need at the bottom of the page.<a href="#fnref15" class="footnote-back">↩</a></p></li>
<li id="fn16"><p>Tip for advanced Mac users. You can run R from the terminal if you want to. The command is just “R”. It behaves like the normal desktop version, except that help documentation behaves like a “man” page instead of opening in a new window.<a href="#fnref16" class="footnote-back">↩</a></p></li>
<li id="fn17"><p>This is probably no coincidence: the people who design and distribute the core R language itself are focused on technical stuff. And sometimes they almost seem to forget that there’s an actual human user at the end. The people who design and distribute RStudio are focused on user interface. They want to make R as usable as possible. The two websites reflect that difference.<a href="#fnref17" class="footnote-back">↩</a></p></li>
<li id="fn18"><p>Seriously. If you’re in a position to do so, open up R and start typing. The simple act of typing it rather than “just reading” makes a big difference. It makes the concepts more concrete, and it ties the abstract ideas (programming and statistics) to the actual context in which you need to use them. Statistics is something you <em>do</em>, not just something you read about in a textbook.<a href="#fnref18" class="footnote-back">↩</a></p></li>
<li id="fn19"><p>If you’re running R from the terminal rather than from RStudio, escape doesn’t work: use CTRL-C instead.<a href="#fnref19" class="footnote-back">↩</a></p></li>
<li id="fn20"><p>For advanced users: yes, as you’ve probably guessed, R is printing out the source code for the function.<a href="#fnref20" class="footnote-back">↩</a></p></li>
<li id="fn21"><p>If you’re reading this with R open, a good learning trick is to try typing in a few different variations on what I’ve done here. If you experiment with your commands, you’ll quickly learn what works and what doesn’t<a href="#fnref21" class="footnote-back">↩</a></p></li>
<li id="fn22"><p>For advanced users: if you want a table showing the complete order of operator precedence in R, type <code>?Syntax</code>. I haven’t included it in this book since there are quite a few different operators, and we don’t need that much detail. Besides, in practice most people seem to figure it out from seeing examples: until writing this book I never looked at the formal statement of operator precedence for any language I ever coded in, and never ran into any difficulties.<a href="#fnref22" class="footnote-back">↩</a></p></li>
<li id="fn23"><p>If you are using RStudio, and the “environment” panel (formerly known as the “workspace” panel) is visible when you typed the command, then you probably saw something happening there. That’s to be expected, and is quite helpful. However, there’s two things to note here (1) I haven’t yet explained what that panel does, so for now just ignore it, and (2) this is one of the helpful things RStudio does, not a part of R itself.<a href="#fnref23" class="footnote-back">↩</a></p></li>
<li id="fn24"><p>As we’ll discuss later, by doing this we are implicitly using the <code>print()</code> function<a href="#fnref24" class="footnote-back">↩</a></p></li>
<li id="fn25"><p>Actually, in keeping with the R tradition of providing you with a billion different screwdrivers (even when you’re actually looking for a hammer) these aren’t the only options. There’s also the<code>assign()</code> function, and the <code>&lt;&lt;-</code> and <code>-&gt;&gt;</code> operators. However, we won’t be using these at all in this book.<a href="#fnref25" class="footnote-back">↩</a></p></li>
<li id="fn26"><p>A quick reminder: when using operators like <code>&lt;-</code> and <code>-&gt;</code> that span multiple characters, you can’t insert spaces in the middle. That is, if you type <code>- &gt;</code> or <code>&lt; -</code>, R will interpret your command the wrong way. And I will cry.<a href="#fnref26" class="footnote-back">↩</a></p></li>
<li id="fn27"><p>Actually, you can override any of these rules if you want to, and quite easily. All you have to do is add quote marks or backticks around your non-standard variable name. For instance <code>`my sales ` &lt;- 350</code> would work just fine, but it’s almost never a good idea to do this.<a href="#fnref27" class="footnote-back">↩</a></p></li>
<li id="fn28"><p>For very advanced users: there is one exception to this. If you’re naming a function, don’t use <code>.</code> in the name unless you are intending to make use of the S3 object oriented programming system in R. If you don’t know what S3 is, then you definitely don’t want to be using it! For function naming, there’s been a trend among R users to prefer <code>myFunctionName</code>.<a href="#fnref28" class="footnote-back">↩</a></p></li>
<li id="fn29"><p>A side note for students with a programming background. Technically speaking, operators <em>are</em> functions in R: the addition operator <code>+</code> is actually a convenient way of calling the addition function <code>+()</code>. Thus <code>10+20</code> is equivalent to the function call <code>+(20, 30)</code>. Not surprisingly, no-one ever uses this version. Because that would be stupid.<a href="#fnref29" class="footnote-back">↩</a></p></li>
<li id="fn30"><p>A note for the mathematically inclined: R does support complex numbers, but unless you explicitly specify that you want them it assumes all calculations must be real valued. By default, the square root of a negative number is treated as undefined: <code>sqrt(-9)</code> will produce <code>NaN</code> (not a number) as its output. To get complex numbers, you would type <code>sqrt(-9+0i)</code> and R would now return <code>0+3i</code>. However, since we won’t have any need for complex numbers in this book, I won’t refer to them again.<a href="#fnref30" class="footnote-back">↩</a></p></li>
<li id="fn31"><p>The two functions discussed previously, <code>sqrt()</code> and <code>abs()</code>, both only have a single argument, <code>x</code>. So I could have typed something like <code>sqrt(x = 225)</code> or <code>abs(x = -13)</code> earlier. The fact that all these functions use <code>x</code> as the name of the argument that corresponds the “main” variable that you’re working with is no coincidence. That’s a fairly widely used convention. Quite often, the writers of R functions will try to use conventional names like this to make your life easier. Or at least that’s the theory. In practice it doesn’t always work as well as you’d hope.<a href="#fnref31" class="footnote-back">↩</a></p></li>
<li id="fn32"><p>For advanced users: obviously, this isn’t just an RStudio thing. If you’re running R in a terminal window, tab autocomplete still works, and does so in exactly the way you’d expect. It’s not as visually pretty as the RStudio version, of course, and lacks some of the cooler features that RStudio provides. I don’t bother to document that here: my assumption is that if you are running R in the terminal then you’re already familiar with using tab autocomplete.<a href="#fnref32" class="footnote-back">↩</a></p></li>
<li id="fn33"><p>Incidentally, that always works: if you’ve started typing a command and you want to clear it and start again, hit escape.<a href="#fnref33" class="footnote-back">↩</a></p></li>
<li id="fn34"><p>Another method is to start typing some text and then hit the Control key and the up arrow together (on Windows or Linux) or the Command key and the up arrow together (on a Mac). This will bring up a window showing all your recent commands that started with the same text as what you’ve currently typed. That can come in quite handy sometimes.<a href="#fnref34" class="footnote-back">↩</a></p></li>
<li id="fn35"><p>Notice that I didn’t specify any argument names here. The <code>c()</code> function is one of those cases where we don’t use names. We just type all the numbers, and R just dumps them all in a single variable.<a href="#fnref35" class="footnote-back">↩</a></p></li>
<li id="fn36"><p>Though actually there’s no real need to do this, since R has an inbuilt variable called <code>month.name</code> that you can use for this purpose.<a href="#fnref36" class="footnote-back">↩</a></p></li>
<li id="fn37"><p>I offer up my teenage attempts to be “cool” as evidence that some things just can’t be done.<a href="#fnref37" class="footnote-back">↩</a></p></li>
<li id="fn38"><p>Note that this is a very different operator to the assignment operator <code>=</code> that I talked about in Section @ref(assign). A common typo that people make when trying to write logical commands in R (or other languages, since the “<code>=</code> versus <code>==</code>” distinction is important in most programming languages) is to accidentally type <code>=</code> when you really mean <code>==</code>. Be especially cautious with this – I’ve been programming in various languages since I was a teenager, and I <em>still</em> screw this up a lot. Hm. I think I see why I wasn’t cool as a teenager. And why I’m still not cool.<a href="#fnref38" class="footnote-back">↩</a></p></li>
<li id="fn39"><p>A note for those of you who have taken a computer science class: yes, R does have a function for exclusive-or, namely <code>xor()</code>. Also worth noting is the fact that R makes the distinction between element-wise operators <code>&amp;</code> and <code>|</code> and operators that look only at the first element of the vector, namely <code>&amp;&amp;</code> and <code>||</code>. To see the distinction, compare the behaviour of a command like <code>c(FALSE,TRUE) &amp; c(TRUE,TRUE)</code> to the behaviour of something like <code>c(FALSE,TRUE) &amp;&amp; c(TRUE,TRUE)</code>. If this doesn’t mean anything to you, ignore this footnote entirely. It’s not important for the content of this book.<a href="#fnref39" class="footnote-back">↩</a></p></li>
<li id="fn40"><p>Warning! <code>TRUE</code> and <code>FALSE</code> are reserved keywords in R, so you can trust that they always mean what they say they do. Unfortunately, the shortcut versions <code>T</code> and <code>F</code> do not have this property. It’s even possible to create variables that set up the reverse meanings, by typing commands like <code>T &lt;- FALSE</code> and <code>F &lt;- TRUE</code>. This is kind of insane, and something that is generally thought to be a design flaw in R. Anyway, the long and short of it is that it’s safer to use <code>TRUE</code> and <code>FALSE</code>.<a href="#fnref40" class="footnote-back">↩</a></p></li>
<li id="fn41"><p>Well, I say that… but in my personal experience it wasn’t until I started learning “regular expressions” that my loathing of computers reached its peak.<a href="#fnref41" class="footnote-back">↩</a></p></li>
<li id="fn42"><p>Notice that I used <code>print(keeper)</code> rather than just typing <code>keeper</code>. Later on in the text I’ll sometimes use the <code>print()</code> function to display things because I think it helps make clear what I’m doing, but in practice people rarely do this.<a href="#fnref42" class="footnote-back">↩</a></p></li>
<li id="fn43"><p>More precisely, there are 5000 or so packages on CRAN, the Comprehensive R Archive Network.<a href="#fnref43" class="footnote-back">↩</a></p></li>
<li id="fn44"><p>Basically, the reason is that there are 5000 packages, and probably about 4000 authors of packages, and no-one really knows what all of them do. Keeping the installation separate from the loading minimizes the chances that two packages will interact with each other in a nasty way.<a href="#fnref44" class="footnote-back">↩</a></p></li>
<li id="fn45"><p>If you’re using the command line, you can get the same information by typing <code>library()</code> at the command line.<a href="#fnref45" class="footnote-back">↩</a></p></li>
<li id="fn46"><p>The logit function a simple mathematical function that happens not to have been included in the basic R distribution.<a href="#fnref46" class="footnote-back">↩</a></p></li>
<li id="fn47"><p>Tip for advanced users. You can get R to use the one from the <code>car</code> package by using <code>car::logit()</code> as your command rather than <code>logit()</code>, since the <code>car::</code> part tells R explicitly which package to use. See also <code>:::</code> if you’re especially keen to force R to use functions it otherwise wouldn’t, but take care, since <code>:::</code> can be dangerous.<a href="#fnref47" class="footnote-back">↩</a></p></li>
<li id="fn48"><p>It is not very difficult.<a href="#fnref48" class="footnote-back">↩</a></p></li>
<li id="fn49"><p>This would be especially annoying if you’re reading an electronic copy of the book because the text displayed by the <code>who()</code> function is searchable, whereas text shown in a screen shot isn’t!<a href="#fnref49" class="footnote-back">↩</a></p></li>
<li id="fn50"><p>Mind you, all that means is that it’s been removed from the workspace. If you’ve got the data saved to file somewhere, then that <em>file</em> is perfectly safe.<a href="#fnref50" class="footnote-back">↩</a></p></li>
<li id="fn51"><p>Well, the partition, technically.<a href="#fnref51" class="footnote-back">↩</a></p></li>
<li id="fn52"><p>One additional thing worth calling your attention to is the <code>file.choose()</code> function. Suppose you want to load a file and you don’t quite remember where it is, but would like to browse for it. Typing <code>file.choose()</code> at the command line will open a window in which you can browse to find the file; when you click on the file you want, R will print out the full path to that file. This is kind of handy.<a href="#fnref52" class="footnote-back">↩</a></p></li>
<li id="fn53"><p>Notably those with .rda, .Rd, .Rhistory, .rdb and .rdx extensions<a href="#fnref53" class="footnote-back">↩</a></p></li>
<li id="fn54"><p>In a lot of books you’ll see the <code>read.table()</code> function used for this purpose instead of <code>read.csv()</code>. They’re more or less identical functions, with the same arguments and everything. They differ only in the default values.<a href="#fnref54" class="footnote-back">↩</a></p></li>
<li id="fn55"><p>Note that I didn’t to this in my earlier example when loading the .Rdata<a href="#fnref55" class="footnote-back">↩</a></p></li>
<li id="fn56"><p>A word of warning: what you <em>don’t</em> want to do is use the “File” menu. If you look in the “File” menu you will see “Save” and “Save As…” options, but they don’t save the workspace. Those options are used for dealing with <em>scripts</em>, and so they’ll produce <code>.R</code> files. We won’t get to those until Chapter @ref(scripting).<a href="#fnref56" class="footnote-back">↩</a></p></li>
<li id="fn57"><p>Or functions. But let’s ignore functions for the moment.<a href="#fnref57" class="footnote-back">↩</a></p></li>
<li id="fn58"><p>Actually, I don’t think I <em>ever</em> use this in practice. I don’t know why I bother to talk about it in the book anymore.<a href="#fnref58" class="footnote-back">↩</a></p></li>
<li id="fn59"><p>Taking all the usual caveats that attach to IQ measurement as a given, of course.<a href="#fnref59" class="footnote-back">↩</a></p></li>
<li id="fn60"><p>Or, more precisely, we don’t know how to measure it. Arguably, a rock has zero intelligence. But it doesn’t make sense to say that the IQ of a rock is 0 in the same way that we can say that the average human has an IQ of 100. And without knowing what the IQ value is that corresponds to a literal absence of any capacity to think, reason or learn, then we really can’t multiply or divide IQ scores and expect a meaningful answer.<a href="#fnref60" class="footnote-back">↩</a></p></li>
<li id="fn61"><p>Once again, this is an example of <em>coercing</em> a variable from one class to another. I’ll talk about coercion in more detail in Section @ref(coercion).<a href="#fnref61" class="footnote-back">↩</a></p></li>
<li id="fn62"><p>Note that, when I write out the formula, R doesn’t check to see if the <code>out</code> and <code>pred</code> variables actually exist: it’s only later on when you try to use the formula for something that this happens.<a href="#fnref62" class="footnote-back">↩</a></p></li>
<li id="fn63"><p>For readers with a programming background: what I’m describing is the very basics of how S3 methods work. However, you should be aware that R has two entirely distinct systems for doing object oriented programming, known as S3 and S4. Of the two, S3 is simpler and more informal, whereas S4 supports all the stuff that you might expect of a fully object oriented language. Most of the generics we’ll run into in this book use the S3 system, which is convenient for me because I’m still trying to figure out S4. <a href="#fnref63" class="footnote-back">↩</a></p></li>
<li id="fn64"><p>It’s extremely simple, by the way. We discussed it in Section 4.4, though I didn’t call it by that name. Tilde expansion is the thing where R recognises that, in the context of specifying a ﬁle location, the tilde symbol ~ corresponds to the user home directory (e.g., /Users/dan/).<a href="#fnref64" class="footnote-back">↩</a></p></li>
<li id="fn65"><p>Note for non-Australians: the AFL is an Australian rules football competition. You don’t need to know anything about Australian rules in order to follow this section.<a href="#fnref65" class="footnote-back">↩</a></p></li>
<li id="fn66"><p>The choice to use <span class="math inline">\(\Sigma\)</span> to denote summation isn’t arbitrary: it’s the Greek upper case letter sigma, which is the analogue of the letter S in that alphabet. Similarly, there’s an equivalent symbol used to denote the multiplication of lots of numbers: because multiplications are also called “products”, we use the <span class="math inline">\(\Pi\)</span> symbol for this; the Greek upper case pi, which is the analogue of the letter P.<a href="#fnref66" class="footnote-back">↩</a></p></li>
<li id="fn67"><p>Note that, just as we saw with the combine function <code>c()</code> and the remove function <code>rm()</code>, the <code>sum()</code> function has unnamed arguments. I’ll talk about unnamed arguments later in Section @ref(dotsargument), but for now let’s just ignore this detail.<a href="#fnref67" class="footnote-back">↩</a></p></li>
<li id="fn68"><p>www.abc.net.au/news/stories/2010/09/24/3021480.htm<a href="#fnref68" class="footnote-back">↩</a></p></li>
<li id="fn69"><p>Or at least, the basic statistical theory – these days there is a whole subfield of statistics called <em>robust statistics</em> that tries to grapple with the messiness of real data and develop theory that can cope with it.<a href="#fnref69" class="footnote-back">↩</a></p></li>
<li id="fn70"><p>As we saw earlier, it <em>does</em> have a function called <code>mode()</code>, but it does something completely different.<a href="#fnref70" class="footnote-back">↩</a></p></li>
<li id="fn71"><p>This is called a “0-1 loss function”, meaning that you either win (1) or you lose (0), with no middle ground.<a href="#fnref71" class="footnote-back">↩</a></p></li>
<li id="fn72"><p>Well, I will very briefly mention the one that I think is coolest, for a very particular definition of “cool”, that is. Variances are <em>additive</em>. Here’s what that means: suppose I have two variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, whose variances are $<a href="#fnref72" class="footnote-back">↩</a></p></li>
<li id="fn73"><p>With the possible exception of the third question.<a href="#fnref73" class="footnote-back">↩</a></p></li>
<li id="fn74"><p>Strictly, the assumption is that the data are <em>normally</em> distributed, which is an important concept that we’ll discuss more in Chapter @ref(probability), and will turn up over and over again later in the book.<a href="#fnref74" class="footnote-back">↩</a></p></li>
<li id="fn75"><p>The assumption again being that the data are normally-distributed!<a href="#fnref75" class="footnote-back">↩</a></p></li>
<li id="fn76"><p>The “<span class="math inline">\(-3\)</span>” part is something that statisticians tack on to ensure that the normal curve has kurtosis zero. It looks a bit stupid, just sticking a “-3” at the end of the formula, but there are good mathematical reasons for doing this.<a href="#fnref76" class="footnote-back">↩</a></p></li>
<li id="fn77"><p>I haven’t discussed how to compute <span class="math inline">\(z\)</span>-scores, explicitly, but you can probably guess. For a variable <code>X</code>, the simplest way is to use a command like <code>(X - mean(X)) / sd(X)</code>. There’s also a fancier function called <code>scale()</code> that you can use, but it relies on somewhat more complicated R concepts that I haven’t explained yet.<a href="#fnref77" class="footnote-back">↩</a></p></li>
<li id="fn78"><p>Technically, because I’m calculating means and standard deviations from a sample of data, but want to talk about my grumpiness relative to a population, what I’m actually doing is <em>estimating</em> a <span class="math inline">\(z\)</span> score. However, since we haven’t talked about estimation yet (see Chapter @ref(estimation)) I think it’s best to ignore this subtlety, especially as it makes very little difference to our calculations.<a href="#fnref78" class="footnote-back">↩</a></p></li>
<li id="fn79"><p>Though some caution is usually warranted. It’s not always the case that one standard deviation on variable A corresponds to the same “kind” of thing as one standard deviation on variable B. Use common sense when trying to determine whether or not the <span class="math inline">\(z\)</span> scores of two variables can be meaningfully compared.<a href="#fnref79" class="footnote-back">↩</a></p></li>
<li id="fn80"><p>Actually, even that table is more than I’d bother with. In practice most people pick <em>one</em> measure of central tendency, and <em>one</em> measure of variability only.<a href="#fnref80" class="footnote-back">↩</a></p></li>
<li id="fn81"><p>Just like we saw with the variance and the standard deviation, in practice we divide by <span class="math inline">\(N-1\)</span> rather than <span class="math inline">\(N\)</span>.<a href="#fnref81" class="footnote-back">↩</a></p></li>
<li id="fn82"><p>This is an oversimplification, but it’ll do for our purposes.<a href="#fnref82" class="footnote-back">↩</a></p></li>
<li id="fn83"><p>If you are reading this after having already completed Chapter @ref(hypothesistesting) you might be wondering about hypothesis tests for correlations. R has a function called <code>cor.test()</code> that runs a hypothesis test for a single correlation, and the <code>psych</code> package contains a version called <code>corr.test()</code> that can run tests for every correlation in a correlation matrix; hypothesis tests for correlations are discussed in more detail in Section @ref(corrhyp).<a href="#fnref83" class="footnote-back">↩</a></p></li>
<li id="fn84"><p>An alternative usage of <code>cor()</code> is to correlate one set of variables with another subset of variables. If <code>X</code> and <code>Y</code> are both data frames with the same number of rows, then <code>cor(x = X, y = Y)</code> will produce a correlation matrix that correlates all variables in <code>X</code> with all variables in <code>Y</code>.<a href="#fnref84" class="footnote-back">↩</a></p></li>
<li id="fn85"><p>It’s worth noting that, even though we have missing data for each of these variables, the output doesn’t contain any <code>NA</code> values. This is because, while <code>describe()</code> also has an <code>na.rm</code> argument, the default value for this function is <code>na.rm = TRUE</code>.<a href="#fnref85" class="footnote-back">↩</a></p></li>
<li id="fn86"><p>The technical term here is “missing completely at random” (often written MCAR for short). Makes sense, I suppose, but it does sound ungrammatical to me.<a href="#fnref86" class="footnote-back">↩</a></p></li>
<li id="fn87"><p>The origin of this quote is Tufte’s lovely book <em>The Visual Display of Quantitative Information</em>.<a href="#fnref87" class="footnote-back">↩</a></p></li>
<li id="fn88"><p>I should add that this isn’t unique to R. Like everything in R there’s a pretty steep learning curve to learning how to draw graphs, and like always there’s a massive payoff at the end in terms of the quality of what you can produce. But to be honest, I’ve seen the same problems show up regardless of what system people use. I suspect that the hardest thing to do is to force yourself to take the time to think deeply about what your graphs are doing. I say that in full knowledge that only about half of my graphs turn out as well as they ought to. Understanding what makes a good graph is easy: actually designing a good graph is <em>hard</em>.<a href="#fnref88" class="footnote-back">↩</a></p></li>
<li id="fn89"><p>Or, since you can always use the up and down keys to scroll through your recent command history, you can just pull up your most recent commands and edit them to fix your mistake. It becomes even easier once you start using scripts (Section @ref(scripts), since all you have to do is edit your script and then run it again.<a href="#fnref89" class="footnote-back">↩</a></p></li>
<li id="fn90"><p>Of course, even that is a slightly misleading description, since some R graphics tools make use of external graphical rendering systems like OpenGL (e.g., the <code>rgl</code> package). I absolutely will not be talking about OpenGL or the like in this book, but as it happens there is one graph in this book that relies on them: Figure @ref(fig:multipleregression).<a href="#fnref90" class="footnote-back">↩</a></p></li>
<li id="fn91"><p>The low-level function that does this is called <code>title()</code> in case you ever need to know, and you can type <code>?title</code> to find out a bit more detail about what these arguments do.<a href="#fnref91" class="footnote-back">↩</a></p></li>
<li id="fn92"><p>On the off chance that this isn’t enough freedom for you, you can select a colour directly as a “red, green, blue” specification using the <code>rgb()</code> function, or as a “hue, saturation, value” specification using the <code>hsv()</code> function.<a href="#fnref92" class="footnote-back">↩</a></p></li>
<li id="fn93"><p>Also, there’s a low level function called <code>axis()</code> that allows a lot more control over the appearance of the axes.<a href="#fnref93" class="footnote-back">↩</a></p></li>
<li id="fn94"><p>R being what it is, it’s no great surprise that there’s also a <code>fivenum()</code> function that does much the same thing.<a href="#fnref94" class="footnote-back">↩</a></p></li>
<li id="fn95"><p>I realise there’s a kind of logic to the way R names are constructed, but they still sound dumb. When I typed this sentence, all I could think was that it sounded like the name of a kids movie if it had been written by Lewis Carroll: “The frabjous gambolles of Staplewex and Whisklty” or something along those lines.<a href="#fnref95" class="footnote-back">↩</a></p></li>
<li id="fn96"><p>Sometimes it’s convenient to have the boxplot automatically label the outliers for you. The original <code>boxplot()</code> function doesn’t allow you to do this; however, the <code>Boxplot()</code> function in the <code>car</code> package does. The design of the <code>Boxplot()</code> function is very similar to <code>boxplot()</code>. It just adds a few new arguments that allow you to tweak the labelling scheme. I’ll leave it to the reader to check this out.<a href="#fnref96" class="footnote-back">↩</a></p></li>
<li id="fn97"><p>Sort of. The game was played in Launceston, which is a de facto home away from home for Hawthorn.<a href="#fnref97" class="footnote-back">↩</a></p></li>
<li id="fn98"><p>Contrast this situation with the next largest winning margin in the data set, which was Geelong’s 108 point demolition of Richmond in round 6 at their home ground, Kardinia Park. Geelong have been one of the most dominant teams over the last several years, a period during which they strung together an incredible 29-game winning streak at Kardinia Park. Richmond have been useless for several years. This is in no meaningful sense an outlier. Geelong have been winning by these margins (and Richmond losing by them) for quite some time. Frankly I’m surprised that the result wasn’t more lopsided: as happened to Melbourne in 2011 when Geelong won by a modest 186 points.<a href="#fnref98" class="footnote-back">↩</a></p></li>
<li id="fn99"><p>Actually, there’s other ways to do this. If the input argument <code>x</code> is a list object (see Section @ref(lists), the <code>boxplot()</code> function will draw a separate boxplot for each variable in that list. Relatedly, since the <code>plot()</code> function – which we’ll discuss shortly – is a generic (see Section @ref(generics), you might not be surprised to learn that one of its special cases is a boxplot: specifically, if you use <code>plot()</code> where the first argument <code>x</code> is a factor and the second argument <code>y</code> is numeric, then the result will be a boxplot, showing the values in <code>y</code>, with a separate boxplot for each level. For instance, something like <code>plot(x = afl2\$year, y = afl2\$margin)</code> would work. <a href="#fnref99" class="footnote-back">↩</a></p></li>
<li id="fn100"><p>The reason is that there’s an annoying design flaw in the way the <code>plot()</code> function handles this situation. The problem is that the <code>plot.formula()</code> function uses different names to for the arguments than the <code>plot()</code> function expects. As a consequence, you can’t specify the formula argument by name. If you just specify a formula as the first argument without using the name it works fine, because the <code>plot()</code> function thinks the formula corresponds to the <code>x</code> argument, and the <code>plot.formula()</code> function thinks it corresponds to the <code>formula</code> argument; and surprisingly, everything works nicely. But the moment that you, the user, tries to be unambiguous about the name, one of those two functions is going to cry.<a href="#fnref100" class="footnote-back">↩</a></p></li>
<li id="fn101"><p>You might be wondering why I haven’t specified the argument name for the formula. The reason is that there’s a bug in how the <code>scatterplot()</code> function is written: under the hood there’s one function that expects the argument to be named <code>x</code> and another one that expects it to be called <code>formula</code>. I don’t know why the function was written this way, but it’s not an isolated problem: this particular kind of bug repeats itself in a couple of other functions (you’ll see it again in Chapter @ref(ttest). The solution in such cases is to omit the argument name: that way, one function “thinks” that you’ve specified <code>x</code> and the other one “thinks” you’ve specified <code>formula</code> and everything works the way it’s supposed to. It’s not a great state of affairs, I’ll admit, but it sort of works.<a href="#fnref101" class="footnote-back">↩</a></p></li>
<li id="fn102"><p>Yet again, we could have produced this output using the <code>plot()</code> function: when the <code>x</code> argument is a data frame containing numeric variables only, then the output is a scatterplot matrix. So, once again, what I could have done is just type <code>plot( parenthood )</code>.<a href="#fnref102" class="footnote-back">↩</a></p></li>
<li id="fn103"><p>Once again, it’s worth noting the link to the generic <code>plot()</code> function. If the <code>x</code> argument to <code>plot()</code> is a factor (and no <code>y</code> argument is given), the result is a bar graph. So you could use <code>plot( afl.finalists )</code> and get the same output as <code>barplot( afl.finalists )</code>.<a href="#fnref103" class="footnote-back">↩</a></p></li>
<li id="fn104"><p>The quote comes from <em>Home is the Hangman</em>, published in 1975.<a href="#fnref104" class="footnote-back">↩</a></p></li>
<li id="fn105"><p>As usual, you can assign this output to a variable. If you type <code>speaker.freq &lt;- table(speaker)</code> at the command prompt R will store the table as a variable. If you then type <code>class(speaker.freq)</code> you’ll see that the output is actually of class <code>table</code>. The key thing to note about a table object is that it’s basically a matrix (see Section @ref(matrix).<a href="#fnref105" class="footnote-back">↩</a></p></li>
<li id="fn106"><p>It’s worth noting that there’s also a more powerful function called <code>recode()</code> function in the <code>car</code> package that I won’t discuss in this book but is worth looking into if you’re looking for a bit more flexibility.<a href="#fnref106" class="footnote-back">↩</a></p></li>
<li id="fn107"><p>If you’ve read further into the book, and are re-reading this section, then a good example of this would be someone choosing to do an ANOVA using <code>age.group3</code> as the grouping variable, instead of running a regression using <code>age</code> as a predictor. There are sometimes good reasons for do this: for instance, if the relationship between <code>age</code> and your outcome variable is highly non-linear, and you aren’t comfortable with trying to run non-linear regression! However, unless you really do have a good rationale for doing this, it’s best not to. It tends to introduce all sorts of other problems (e.g., the data will probably violate the normality assumption), and you can lose a lot of power.<a href="#fnref107" class="footnote-back">↩</a></p></li>
<li id="fn108"><p>The real answer is 0: $10 for a sandwich is a total ripoff so I should go next door and buy noodles.<a href="#fnref108" class="footnote-back">↩</a></p></li>
<li id="fn109"><p>Again, I doubt that’s the right “real world” answer. I suspect that most sandwich shops won’t allow you to pay off your debts to them in sandwiches. But you get the idea.<a href="#fnref109" class="footnote-back">↩</a></p></li>
<li id="fn110"><p>Actually, that’s a bit of a lie: the <code>log()</code> function is more flexible than that, and can be used to calculate logarithms in <em>any</em> base. The <code>log()</code> function has a <code>base</code> argument that you can specify, which has a default value of <span class="math inline">\(e\)</span>. Thus <code>log10(1000)</code> is actually equivalent to <code>log(x = 1000, base = 10)</code>.<a href="#fnref110" class="footnote-back">↩</a></p></li>
<li id="fn111"><p>It’s also worth checking out the <code>match()</code> function<a href="#fnref111" class="footnote-back">↩</a></p></li>
<li id="fn112"><p>It also works on data frames if you ever feel the need to import all of your variables from the data frame into the workspace. This can be useful at times, though it’s not a good idea if you have large data sets or if you’re working with multiple data sets at once. In particular, if you do this, never forget that you now have <em>two</em> copies of all your variables, one in the workspace and another in the data frame.<a href="#fnref112" class="footnote-back">↩</a></p></li>
<li id="fn113"><p>You can do this yourself using the <code>make.names()</code> function. In fact, this is itself a handy thing to know about. For example, if you want to convert the names of the variables in the <code>speech.by.char</code> list into valid R variable names, you could use a command like this: <code>names(speech.by.char) &lt;- make.names(names(speech.by.char))</code>. However, I won’t go into details here.<a href="#fnref113" class="footnote-back">↩</a></p></li>
<li id="fn114"><p>Conveniently, if you type <code>rownames(df) &lt;- NULL</code> R will renumber all the rows from scratch. For the <code>df</code> data frame, the labels that currently run from 7 to 10 will be changed to go from 1 to 4.<a href="#fnref114" class="footnote-back">↩</a></p></li>
</ol>
</div>
<!--bookdown:body:end-->
            </section>

          </div>
        </div>
      </div>
<!--bookdown:link_prev-->
<!--bookdown:link_next-->
    </div>
  </div>
<!--bookdown:config-->

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
